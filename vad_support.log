diff --git a/.gitignore b/.gitignore
index e6fe685..bc407ce 100644
--- a/.gitignore
+++ b/.gitignore
@@ -3,3 +3,6 @@ logs
 test_funasr
 test_funasr_0
 *.tar.gz
+build_x86_64
+k230_ai_assistant
+.vscode
\ No newline at end of file
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 6fa4d19..f1d0e86 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -1,6 +1,8 @@
 cmake_minimum_required(VERSION 3.16)
 
 project(FunASROnnx)
+set(CMAKE_CXX_STANDARD 17)            # 设置 C++ 标准（如 11/14/17/20）
+set(CMAKE_CXX_STANDARD_REQUIRED ON)   # 强制要求该标准
 
 option(EN_X86  "Whether to make x86" OFF)
 
@@ -33,13 +35,13 @@ FetchContent_MakeAvailable(json)
 endif()
 
 if(EN_X86)
-set(NNCASE_PATH ${CMAKE_SOURCE_DIR}/3rd_party/nncase/x86_64)
+set(NNCASE_PATH ${CMAKE_SOURCE_DIR}/third_party/nncase/x86_64)
 else()
-set(NNCASE_PATH ${CMAKE_SOURCE_DIR}/3rd_party/nncase/riscv64)
-link_directories(${CMAKE_SOURCE_DIR}/3rd_party/mmz/riscv64)
+set(NNCASE_PATH ${CMAKE_SOURCE_DIR}/third_party/nncase/riscv64)
+link_directories(${CMAKE_SOURCE_DIR}/third_party/mmz/riscv64)
 endif()
+
 include_directories(${NNCASE_PATH}/include
-                    ${NNCASE_PATH}/include/nncase/runtime
                     )
 link_directories(${NNCASE_PATH}/lib)
 
@@ -68,6 +70,7 @@ include_directories(${PROJECT_SOURCE_DIR}/third_party/jieba/include)
 include_directories(${PROJECT_SOURCE_DIR}/third_party/jieba/include/limonp/include)
 include_directories(${PROJECT_SOURCE_DIR}/third_party/kaldi)
 include_directories(${PROJECT_SOURCE_DIR}/third_party/json/include)
+include_directories(${PROJECT_SOURCE_DIR}/third_party/)
 
 if(GPU)
     add_definitions(-DUSE_GPU)
diff --git a/bin/funasr-onnx-offline-vad.cpp b/bin/funasr-onnx-offline-vad.cpp
index d0cb2ee..e62901c 100644
--- a/bin/funasr-onnx-offline-vad.cpp
+++ b/bin/funasr-onnx-offline-vad.cpp
@@ -64,8 +64,8 @@ int main(int argc, char *argv[])
     FLAGS_logtostderr = true;
 
     TCLAP::CmdLine cmd("funasr-onnx-offline-vad", ' ', "1.0");
-    TCLAP::ValueArg<std::string>    model_dir("", MODEL_DIR, "the vad model path, which contains model.onnx, vad.yaml, vad.mvn", true, "", "string");
-    TCLAP::ValueArg<std::string>    quantize("", QUANTIZE, "true (Default), load the model of model.onnx in model_dir. If set true, load the model of model_quant.onnx in model_dir", false, "true", "string");
+    TCLAP::ValueArg<std::string>    model_dir("", MODEL_DIR, "the vad model path, which contains test.kmodel(instead of model.onnx), vad.yaml, vad.mvn", true, "", "string");
+    TCLAP::ValueArg<std::string>    quantize("", QUANTIZE, "true (Default), load the model of test.kmodel(instead of model.onnx) in model_dir. If set true, load the model of model_quant.onnx in model_dir", false, "true", "string");
 
     TCLAP::ValueArg<std::string>    wav_path("", WAV_PATH, "the input could be: wav_path, e.g.: asr_example.wav; pcm_path, e.g.: asr_example.pcm; wav.scp, kaldi style wav list (wav_id \t wav_path)", true, "", "string");
     TCLAP::ValueArg<std::int32_t>   audio_fs("", AUDIO_FS, "the sample rate of audio", false, 16000, "int32_t");
diff --git a/include/com-define.h b/include/com-define.h
index 6b4c08f..06c88bc 100644
--- a/include/com-define.h
+++ b/include/com-define.h
@@ -48,7 +48,8 @@ namespace funasr {
 // #define PUNC_MODEL_PATH "punc-model"
 // #define PUNC_CONFIG_PATH "punc-config"
 
-#define MODEL_NAME "model.onnx"
+#define MODEL_NAME "test.kmodel"
+// #define MODEL_NAME "model.onnx"
 // hotword embedding compile model
 #define MODEL_EB_NAME "model_eb.onnx"
 #define TORCH_MODEL_EB_NAME "model_eb.torchscript"
diff --git a/include/nncasewrapper.h b/include/nncasewrapper.h
new file mode 100644
index 0000000..37609ef
--- /dev/null
+++ b/include/nncasewrapper.h
@@ -0,0 +1,103 @@
+//
+//  nncasewrapper.hpp
+//
+//  Created by zhaode on 2024/10/09.
+//  ZhaodeWang
+//
+
+#ifndef NRTWRAPPER_hpp
+#define NRTWRAPPER_hpp
+
+#include <memory>
+#include <nncase/runtime/interpreter.h>
+#include <nncase/runtime/runtime_tensor.h>
+#include <nncase/runtime/simple_types.h>
+#include <nncase/runtime/util.h>
+#include <type_traits>
+#include <iostream>
+#include <fstream>
+#include <filesystem>
+
+namespace fs = std::filesystem;
+
+namespace NRT {
+
+class RuntimeManager {
+public:
+  RuntimeManager() {}
+
+private:
+};
+
+class Module {
+public:
+  size_t count = 0;
+  Module(std::shared_ptr<RuntimeManager> runtime, const std::string &path) {
+    std::ifstream ifs(path, std::ios::binary);
+    interpreter_.load_model(ifs).unwrap_or_throw();
+    entry_function_ = interpreter_.entry_function().unwrap_or_throw();
+  }
+  void dump_input(std::ofstream &desc_file, nncase::value_t &input_data, std::string input_name, std::string dtype, size_t count)
+  {
+    auto tensor_ = input_data.as<nncase::tensor>().expect("not tensor");
+    auto data = nncase::runtime::get_output_data(tensor_).unwrap_or_throw();
+    auto shape = tensor_->shape();
+    auto datasize = 1;
+    desc_file<< dtype << ": ";
+    for(auto ii : shape)
+    {
+      desc_file<< ii << " ";
+      datasize*=ii;
+    }
+    desc_file<<std::endl;
+
+    std::ofstream oufile(input_name+std::to_string(count)+".bin", std::ios::binary);
+    if (oufile) 
+    {
+      oufile.write(reinterpret_cast<char*>(data), datasize * sizeof(float));
+      oufile.close();
+    }
+  }
+  nncase::tuple onForward(std::vector<nncase::value_t> &inputs) {
+    if (0)
+    {
+      fs::path dir_path = "calib";
+      try {
+          fs::create_directory(dir_path);
+          std::cout << "Directory created successfully: " << dir_path << std::endl;
+      } catch (const fs::filesystem_error& e) {
+          std::cerr << "Error: " << e.what() << std::endl;
+      }
+      std::ofstream outputFile("calib/input_desc"+std::to_string(count)+".txt");  
+      dump_input(outputFile, inputs[0], "calib/input_ids_float", "fp32", count);
+      dump_input(outputFile, inputs[1], "calib/attention_mask_float", "fp32", count);
+      dump_input(outputFile, inputs[2], "calib/postion_ids_int", "i32", count);
+      dump_input(outputFile, inputs[3], "calib/past_key_values_float", "fp32", count);
+      count+=1;
+    }
+  
+    return entry_function_->invoke(inputs)
+        .unwrap_or_throw()
+        .as<nncase::tuple>()
+        .unwrap_or_throw();
+  }
+
+private:
+  nncase::runtime::interpreter interpreter_;
+  nncase::runtime::runtime_function *entry_function_;
+};
+
+template <typename T>
+static nncase::tensor _Input(const std::vector<int> &shape,
+                             std::shared_ptr<RuntimeManager> rtmgr) {
+  nncase::dims_t shape_int64(shape.begin(), shape.end());
+  return nncase::runtime::hrt::create(
+             std::is_same_v<T, float> ? nncase::dt_float32 : nncase::dt_int32,
+             shape_int64, nncase::runtime::host_runtime_tensor::pool_shared)
+      .unwrap_or_throw()
+      .impl();
+}
+
+} // namespace NRT
+
+#endif /* NRTWRAPPER_hpp */
\ No newline at end of file
diff --git a/ltzrun.sh b/ltzrun.sh
index ba96dda..2672daf 100644
--- a/ltzrun.sh
+++ b/ltzrun.sh
@@ -5,10 +5,13 @@
 # make -j8
 
 cd build_x86_64
-rm -rf CMake* bin third_party/ Makefile *.cmake
-cmake  -DCMAKE_BUILD_TYPE=release .. -DEN_X86=ON -DONNXRUNTIME_DIR=/root/onnxruntime-linux-x64-1.14.0 \
-  -DFFMPEG_DIR=/root/ffmpeg-master-latest-linux64-gpl-shared
-make -j8
+# rm -rf CMake* bin third_party/ Makefile *.cmake
+cmake  -DCMAKE_BUILD_TYPE=debug .. -DEN_X86=ON -DONNXRUNTIME_DIR=/mnt/onnxruntime-linux-x64-1.14.0 \
+  -DFFMPEG_DIR=/mnt/ffmpeg-master-latest-linux64-gpl-shared
+# cmake  -DCMAKE_BUILD_TYPE=release .. -DEN_X86=ON -DONNXRUNTIME_DIR=/root/onnxruntime-linux-x64-1.14.0 \
+#   -DFFMPEG_DIR=/root/ffmpeg-master-latest-linux64-gpl-shared
+make -j
+cd ../
 
 
 # cd ..
@@ -37,4 +40,11 @@ qemu-riscv64 ./build/bin/funasr-onnx-offline \
 
 qemu-riscv64 ./build/bin/funasr-onnx-offline-vad \
 --model-dir ~/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/ \
---wav-path ~/.cache/modelscope/hub/models/iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/example/asr_example.wav
\ No newline at end of file
+--wav-path ~/.cache/modelscope/hub/models/iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/example/asr_example.wav
+
+./build_x86_64/bin/funasr-onnx-offline-vad \
+--model-dir ../test_ltz/fsmn_vad/ \
+--wav-path ../test_ltz/fsmn_vad/vad_example.wav
+# ref result: 
+# wav_default_id: [[70,2340],[2620,6200],[6480,23670],[23950,26250],[26780,28990],[29950,31430],[31750,37600],[38210,46900],[47310,49630],[49910,56460],[56740,59540],[59820,70450]]
+
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index b3f71b0..faa3c04 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -59,7 +59,18 @@ if(GPU)
     set(TORCH_DEPS torch torch_cuda torch_cpu c10 c10_cuda torch_blade ral_base_context)
 endif()
 
+# nncase
+include_directories(${NNCASE_PATH}/include
+                    ${NNCASE_PATH}/include/nncase/runtime
+                    )
+link_directories(${NNCASE_PATH}/lib)
+
 #message("CXX_FLAGS "${CMAKE_CXX_FLAGS})
 include_directories(${CMAKE_SOURCE_DIR}/include)
 include_directories(${CMAKE_SOURCE_DIR}/third_party)
-target_link_libraries(funasr PUBLIC onnxruntime ${EXTRA_LIBS} ${TORCH_DEPS})
+if (EN_X86)
+    target_link_libraries(funasr PUBLIC onnxruntime ${EXTRA_LIBS} ${TORCH_DEPS} Nncase.Runtime.Native)
+else()
+    target_link_libraries(funasr PUBLIC onnxruntime ${EXTRA_LIBS} ${TORCH_DEPS} nncase.rt_modules.k230 Nncase.Runtime.Native functional_k230 mmz)
+endif()
+# target_link_libraries(funasr PUBLIC onnxruntime ${EXTRA_LIBS} ${TORCH_DEPS})
diff --git a/src/fsmn-vad.cpp b/src/fsmn-vad.cpp
index bcef5d4..2cbe4aa 100644
--- a/src/fsmn-vad.cpp
+++ b/src/fsmn-vad.cpp
@@ -8,9 +8,11 @@
 
 namespace funasr {
 void FsmnVad::InitVad(const std::string &vad_model, const std::string &vad_cmvn, const std::string &vad_config, int thread_num) {
-    session_options_.SetIntraOpNumThreads(thread_num);
-    session_options_.SetGraphOptimizationLevel(ORT_ENABLE_ALL);
-    session_options_.DisableCpuMemArena();
+    // session_options_.SetIntraOpNumThreads(thread_num);
+    // session_options_.SetGraphOptimizationLevel(ORT_ENABLE_ALL);
+    // session_options_.DisableCpuMemArena();
+    runtime_manager_.reset(new NRT::RuntimeManager());
+
 
     ReadModel(vad_model.c_str());
     LoadCmvn(vad_cmvn.c_str());
@@ -53,15 +55,17 @@ void FsmnVad::LoadConfigFromYaml(const char* filename){
 
 void FsmnVad::ReadModel(const char* vad_model) {
     try {
-        vad_session_ = std::make_shared<Ort::Session>(
-                env_, ORTCHAR(vad_model), session_options_);
+        // vad_session_ = std::make_shared<Ort::Session>(
+        //         env_, ORTCHAR(vad_model), session_options_);
+        std::string model_path(vad_model);
+        module_.reset(new NRT::Module(runtime_manager_, model_path));
         LOG(INFO) << "Successfully load model from " << vad_model;
     } catch (std::exception const &e) {
         LOG(ERROR) << "Error when load vad onnx model: " << e.what();
         exit(-1);
     }
-    GetInputNames(vad_session_.get(), m_strInputNames, vad_in_names_);
-    GetOutputNames(vad_session_.get(), m_strOutputNames, vad_out_names_);
+    // GetInputNames(vad_session_.get(), m_strInputNames, vad_in_names_);
+    // GetOutputNames(vad_session_.get(), m_strOutputNames, vad_out_names_);
 }
 
 void FsmnVad::Forward(
@@ -69,62 +73,104 @@ void FsmnVad::Forward(
         std::vector<std::vector<float>> *out_prob,
         std::vector<std::vector<float>> *in_cache,
         bool is_final) {
-    Ort::MemoryInfo memory_info =
-            Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);
+    // Ort::MemoryInfo memory_info =
+    //         Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);
 
     int num_frames = chunk_feats.size();
     const int feature_dim = chunk_feats[0].size();
 
     //  2. Generate input nodes tensor
     // vad node { batch,frame number,feature dim }
-    const int64_t vad_feats_shape[3] = {1, num_frames, feature_dim};
+    // const int64_t vad_feats_shape[3] = {1, num_frames, feature_dim};
+    vector<int32_t> vad_feats_shape = {1, num_frames, feature_dim};
     std::vector<float> vad_feats;
     for (const auto &chunk_feat: chunk_feats) {
         vad_feats.insert(vad_feats.end(), chunk_feat.begin(), chunk_feat.end());
     }
-    Ort::Value vad_feats_ort = Ort::Value::CreateTensor<float>(
-            memory_info, vad_feats.data(), vad_feats.size(), vad_feats_shape, 3);
+    // Ort::Value vad_feats_ort = Ort::Value::CreateTensor<float>(
+    //         memory_info, vad_feats.data(), vad_feats.size(), vad_feats_shape, 3);
+    auto vad_feats_nncase = NRT::_Input<float>(vad_feats_shape, runtime_manager_);
+    auto vad_feats_nncase_buffer = vad_feats_nncase->buffer().as_host().unwrap_or_throw();
+    {
+        auto vad_feats_nncase_mapped = vad_feats_nncase_buffer.map(nncase::runtime::map_write).unwrap_or_throw();
+        auto vad_feats_nncase_ptr = vad_feats_nncase_mapped.buffer().as_span<float>().data();
+        memcpy(vad_feats_nncase_ptr, vad_feats.data(), sizeof(float) * vad_feats.size());
+    }
+    vad_feats_nncase_buffer.sync(nncase::runtime::sync_write_back, true).unwrap_or_throw();
     
     // 3. Put nodes into onnx input vector
-    std::vector<Ort::Value> vad_inputs;
-    vad_inputs.emplace_back(std::move(vad_feats_ort));
+    // std::vector<Ort::Value> vad_inputs;
+    std::vector<nncase::value_t> vad_inputs;
+    // vad_inputs.emplace_back(std::move(vad_feats_ort));
+    vad_inputs.emplace_back(std::move(vad_feats_nncase));
     // 4 caches
     // cache node {batch,128,19,1}
-    const int64_t cache_feats_shape[4] = {1, 128, 19, 1};
+    // const int64_t cache_feats_shape[4] = {1, 128, 19, 1};
+    vector<int32_t> cache_feats_shape = {1, 128, 19, 1};
     for (int i = 0; i < in_cache->size(); i++) {
-      vad_inputs.emplace_back(std::move(Ort::Value::CreateTensor<float>(
-              memory_info, (*in_cache)[i].data(), (*in_cache)[i].size(), cache_feats_shape, 4)));
+    //   vad_inputs.emplace_back(std::move(Ort::Value::CreateTensor<float>(
+    //           memory_info, (*in_cache)[i].data(), (*in_cache)[i].size(), cache_feats_shape, 4)));
+      auto cache_feats_nncase = NRT::_Input<float>(cache_feats_shape, runtime_manager_);
+      auto cache_feats_nncase_buffer = cache_feats_nncase->buffer().as_host().unwrap_or_throw();
+      {
+          auto cache_feats_nncase_mapped = cache_feats_nncase_buffer.map(nncase::runtime::map_write).unwrap_or_throw();
+          auto cache_feats_nncase_ptr = cache_feats_nncase_mapped.buffer().as_span<float>().data();
+          memcpy(cache_feats_nncase_ptr, (*in_cache)[i].data(), sizeof(float) * (*in_cache)[i].size());
+      }
+      cache_feats_nncase_buffer.sync(nncase::runtime::sync_write_back, true).unwrap_or_throw();
+      vad_inputs.emplace_back(std::move(cache_feats_nncase));
     }
   
     // 4. Onnx infer
-    std::vector<Ort::Value> vad_ort_outputs;
-    try {
-        vad_ort_outputs = vad_session_->Run(
-                Ort::RunOptions{nullptr}, vad_in_names_.data(), vad_inputs.data(),
-                vad_inputs.size(), vad_out_names_.data(), vad_out_names_.size());
-    } catch (std::exception const &e) {
-        LOG(ERROR) << "Error when run vad onnx forword: " << (e.what());
-        return;
-    }
+    // std::vector<Ort::Value> vad_ort_outputs;
+    // 4. nncase Infer
+    // std::vector<nncase::value_t> vad_nncase_outputs;
+    // try {
+    //     // vad_nncase_outputs = vad_session_->Run(
+    //     //         Ort::RunOptions{nullptr}, vad_in_names_.data(), vad_inputs.data(),
+    //     //         vad_inputs.size(), vad_out_names_.data(), vad_out_names_.size());
+    //     vad_nncase_outputs = module_->onForward(vad_inputs);
+    // } catch (std::exception const &e) {
+    //     LOG(ERROR) << "Error when run vad nncase forword: " << (e.what());
+    //     return;
+    // }
+    auto vad_nncase_outputs = module_->onForward(vad_inputs);
 
     // 5. Change infer result to output shapes
-    float *logp_data = vad_ort_outputs[0].GetTensorMutableData<float>();
-    auto type_info = vad_ort_outputs[0].GetTensorTypeAndShapeInfo();
-
-    int num_outputs = type_info.GetShape()[1];
-    int output_dim = type_info.GetShape()[2];
-    out_prob->resize(num_outputs);
-    for (int i = 0; i < num_outputs; i++) {
-        (*out_prob)[i].resize(output_dim);
-        memcpy((*out_prob)[i].data(), logp_data + i * output_dim,
-               sizeof(float) * output_dim);
+    auto logp_data_nncase = vad_nncase_outputs->fields()[0].as<nncase::tensor>().unwrap_or_throw();
+    auto logp_data_nncase_buffer = logp_data_nncase->buffer().as_host().unwrap_or_throw();
+    {
+    auto logp_data_nncase_mapped = logp_data_nncase_buffer.map(nncase::runtime::map_read).unwrap_or_throw();
+    auto logp_data = logp_data_nncase_mapped.buffer().as_span<float>().data();
+    memcpy((*out_prob).data(), logp_data, sizeof(float) * (*out_prob).size());
     }
+    logp_data_nncase_buffer.sync(nncase::runtime::sync_write_back, true).unwrap_or_throw();
+
+    // auto logp_data = vad_nncase_outputs[0].GetTensorMutableData<float>();
+    // auto type_info = vad_nncase_outputs->fields()[0].GetTensorTypeAndShapeInfo();
+
+    // int num_outputs = type_info.GetShape()[1];
+    // int output_dim = type_info.GetShape()[2];
+    // out_prob->resize(num_outputs);
+    // for (int i = 0; i < num_outputs; i++) {
+    //     (*out_prob)[i].resize(output_dim);
+    //     memcpy((*out_prob)[i].data(), logp_data + i * output_dim,
+    //            sizeof(float) * output_dim);
+    // }
   
     // get 4 caches outputs,each size is 128*19
     if(!is_final){
         for (int i = 1; i < 5; i++) {
-        float* data = vad_ort_outputs[i].GetTensorMutableData<float>();
-        memcpy((*in_cache)[i-1].data(), data, sizeof(float) * 128*19);
+        // float* data = vad_nncase_outputs[i].GetTensorMutableData<float>();
+        auto cache_data_nncase = vad_nncase_outputs->fields()[i].as<nncase::tensor>().unwrap_or_throw();
+        auto cache_data_nncase_buffer = cache_data_nncase->buffer().as_host().unwrap_or_throw();
+        {
+            auto cache_data_nncase_mapped = cache_data_nncase_buffer.map(nncase::runtime::map_read).unwrap_or_throw();
+            auto data = cache_data_nncase_mapped.buffer().as_span<float>().data();
+            memcpy((*in_cache)[i-1].data(), data, sizeof(float) * 128*19);
+        }
+        cache_data_nncase_buffer.sync(nncase::runtime::sync_write_back, true).unwrap_or_throw();
+        // memcpy((*in_cache)[i-1].data(), data, sizeof(float) * 128*19);       
         }
     }
 }
diff --git a/src/fsmn-vad.h b/src/fsmn-vad.h
index dc4726a..9352a24 100644
--- a/src/fsmn-vad.h
+++ b/src/fsmn-vad.h
@@ -34,6 +34,9 @@ public:
     std::shared_ptr<Ort::Session> vad_session_ = nullptr;
     Ort::Env env_;
     Ort::SessionOptions session_options_;
+    std::shared_ptr<NRT::RuntimeManager> runtime_manager_;
+    std::shared_ptr<NRT::Module> module_;
+
     vector<string> m_strInputNames, m_strOutputNames;
     std::vector<const char *> vad_in_names_;
     std::vector<const char *> vad_out_names_;
diff --git a/src/precomp.h b/src/precomp.h
index d525c65..0bc40e9 100644
--- a/src/precomp.h
+++ b/src/precomp.h
@@ -40,6 +40,7 @@ using namespace std;
 // mine
 #include <glog/logging.h>
 
+#include "nncasewrapper.h"
 
 #include "common-struct.h"
 #include "com-define.h"
diff --git a/third_party/gsl/gsl-lite.hpp b/third_party/gsl/gsl-lite.hpp
new file mode 100644
index 0000000..859f9cc
--- /dev/null
+++ b/third_party/gsl/gsl-lite.hpp
@@ -0,0 +1,4156 @@
+//
+// gsl-lite is based on GSL: Guidelines Support Library.
+// For more information see https://github.com/gsl-lite/gsl-lite
+//
+// Copyright (c) 2015-2018 Martin Moene
+// Copyright (c) 2015-2018 Microsoft Corporation. All rights reserved.
+//
+// This code is licensed under the MIT License (MIT).
+//
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+// THE SOFTWARE.
+
+#ifndef GSL_GSL_LITE_HPP_INCLUDED
+#define GSL_GSL_LITE_HPP_INCLUDED
+
+#include <algorithm> // for swap() [pre-C++11], equal(), lexicographical_compare()
+#include <exception> // for exception, terminate(), uncaught_exceptions()
+#include <iterator>  // for data(), size(), reverse_iterator<>, iterator_traits<>
+#include <limits>
+#include <memory>    // for addressof(), unique_ptr<>, shared_ptr<>
+#include <iosfwd>    // for basic_ostream<>
+#include <ios>       // for ios_base, streamsize
+#include <stdexcept> // for logic_error
+#include <string>
+#include <utility>   // for move(), forward<>(), swap()
+#include <cstddef>   // for size_t, ptrdiff_t, nullptr_t
+
+#define  gsl_lite_MAJOR  0
+#define  gsl_lite_MINOR  37
+#define  gsl_lite_PATCH  0
+
+#define  gsl_lite_VERSION  gsl_STRINGIFY(gsl_lite_MAJOR) "." gsl_STRINGIFY(gsl_lite_MINOR) "." gsl_STRINGIFY(gsl_lite_PATCH)
+
+// gsl-lite backward compatibility:
+
+#if !defined( gsl_CONFIG_DEFAULTS_VERSION )
+# define gsl_CONFIG_DEFAULTS_VERSION gsl_lite_MAJOR
+#endif
+
+#ifdef gsl_CONFIG_ALLOWS_SPAN_CONTAINER_CTOR
+# define gsl_CONFIG_ALLOWS_UNCONSTRAINED_SPAN_CONTAINER_CTOR  gsl_CONFIG_ALLOWS_SPAN_CONTAINER_CTOR
+# pragma message ("gsl_CONFIG_ALLOWS_SPAN_CONTAINER_CTOR is deprecated since gsl-lite 0.7; replace with gsl_CONFIG_ALLOWS_UNCONSTRAINED_SPAN_CONTAINER_CTOR, or consider span(with_container, cont).")
+#endif
+
+#if defined( gsl_CONFIG_CONTRACT_LEVEL_ON )
+# pragma message ("gsl_CONFIG_CONTRACT_LEVEL_ON is deprecated since gsl-lite 0.36; replace with gsl_CONFIG_CONTRACT_CHECKING_ON.")
+# define gsl_CONFIG_CONTRACT_CHECKING_ON
+#endif
+#if defined( gsl_CONFIG_CONTRACT_LEVEL_OFF )
+# pragma message ("gsl_CONFIG_CONTRACT_LEVEL_OFF is deprecated since gsl-lite 0.36; replace with gsl_CONFIG_CONTRACT_CHECKING_OFF.")
+# define gsl_CONFIG_CONTRACT_CHECKING_OFF
+#endif
+#if   defined( gsl_CONFIG_CONTRACT_LEVEL_EXPECTS_ONLY )
+# pragma message ("gsl_CONFIG_CONTRACT_LEVEL_EXPECTS_ONLY is deprecated since gsl-lite 0.36; replace with gsl_CONFIG_CONTRACT_CHECKING_ENSURES_OFF.")
+# define gsl_CONFIG_CONTRACT_CHECKING_ON
+# define gsl_CONFIG_CONTRACT_CHECKING_ENSURES_OFF
+#elif defined( gsl_CONFIG_CONTRACT_LEVEL_ENSURES_ONLY )
+# pragma message ("gsl_CONFIG_CONTRACT_LEVEL_ENSURES_ONLY is deprecated since gsl-lite 0.36; replace with gsl_CONFIG_CONTRACT_CHECKING_EXPECTS_OFF.")
+# define gsl_CONFIG_CONTRACT_CHECKING_ON
+# define gsl_CONFIG_CONTRACT_CHECKING_EXPECTS_OFF
+#endif
+
+// M-GSL compatibility:
+
+#if defined( GSL_THROW_ON_CONTRACT_VIOLATION )
+# define gsl_CONFIG_CONTRACT_VIOLATION_THROWS
+#endif
+
+#if defined( GSL_TERMINATE_ON_CONTRACT_VIOLATION )
+# define gsl_CONFIG_CONTRACT_VIOLATION_TERMINATES
+#endif
+
+#if defined( GSL_UNENFORCED_ON_CONTRACT_VIOLATION )
+# define gsl_CONFIG_CONTRACT_CHECKING_OFF
+#endif
+
+// Configuration: Features
+
+#ifndef  gsl_FEATURE_WITH_CONTAINER_TO_STD
+# define gsl_FEATURE_WITH_CONTAINER_TO_STD  99
+#endif
+
+#ifndef  gsl_FEATURE_MAKE_SPAN_TO_STD
+# define gsl_FEATURE_MAKE_SPAN_TO_STD  99
+#endif
+
+#ifndef  gsl_FEATURE_BYTE_SPAN_TO_STD
+# define gsl_FEATURE_BYTE_SPAN_TO_STD  99
+#endif
+
+#ifndef  gsl_FEATURE_IMPLICIT_MACRO
+# define gsl_FEATURE_IMPLICIT_MACRO  0
+#endif
+
+#ifndef  gsl_FEATURE_OWNER_MACRO
+# define gsl_FEATURE_OWNER_MACRO  (gsl_CONFIG_DEFAULTS_VERSION == 0)
+#endif
+
+#ifndef  gsl_FEATURE_EXPERIMENTAL_RETURN_GUARD
+# define gsl_FEATURE_EXPERIMENTAL_RETURN_GUARD  0
+#endif
+
+#ifndef  gsl_FEATURE_GSL_LITE_NAMESPACE
+# define gsl_FEATURE_GSL_LITE_NAMESPACE  (gsl_CONFIG_DEFAULTS_VERSION >= 1)
+#endif
+
+// Configuration: Other
+
+#if defined( gsl_CONFIG_TRANSPARENT_NOT_NULL ) && gsl_CONFIG_TRANSPARENT_NOT_NULL && defined( gsl_CONFIG_NOT_NULL_GET_BY_CONST_REF )
+# error configuration option gsl_CONFIG_NOT_NULL_GET_BY_CONST_REF is meaningless if gsl_CONFIG_TRANSPARENT_NOT_NULL=1
+#endif
+
+#ifndef  gsl_CONFIG_DEPRECATE_TO_LEVEL
+# if gsl_CONFIG_DEFAULTS_VERSION >= 1
+#  define gsl_CONFIG_DEPRECATE_TO_LEVEL  6
+# else
+#  define gsl_CONFIG_DEPRECATE_TO_LEVEL  0
+# endif
+#endif
+
+#ifndef  gsl_CONFIG_SPAN_INDEX_TYPE
+# define gsl_CONFIG_SPAN_INDEX_TYPE  std::size_t
+#endif
+
+#ifndef  gsl_CONFIG_INDEX_TYPE
+# if gsl_CONFIG_DEFAULTS_VERSION >= 1
+// p0122r3 uses std::ptrdiff_t
+#  define gsl_CONFIG_INDEX_TYPE  std::ptrdiff_t
+# else
+#  define gsl_CONFIG_INDEX_TYPE  gsl_CONFIG_SPAN_INDEX_TYPE
+# endif
+#endif
+
+#ifndef  gsl_CONFIG_NOT_NULL_EXPLICIT_CTOR
+# define gsl_CONFIG_NOT_NULL_EXPLICIT_CTOR  (gsl_CONFIG_DEFAULTS_VERSION >= 1)
+#endif
+
+#ifndef  gsl_CONFIG_NOT_NULL_GET_BY_CONST_REF
+# define gsl_CONFIG_NOT_NULL_GET_BY_CONST_REF  0
+#endif
+
+#ifndef  gsl_CONFIG_TRANSPARENT_NOT_NULL
+# define gsl_CONFIG_TRANSPARENT_NOT_NULL  (gsl_CONFIG_DEFAULTS_VERSION >= 1)
+#endif
+
+#ifndef  gsl_CONFIG_CONFIRMS_COMPILATION_ERRORS
+# define gsl_CONFIG_CONFIRMS_COMPILATION_ERRORS  0
+#endif
+
+#ifndef  gsl_CONFIG_ALLOWS_SPAN_COMPARISON
+# define gsl_CONFIG_ALLOWS_SPAN_COMPARISON  (gsl_CONFIG_DEFAULTS_VERSION == 0)
+#endif
+
+#ifndef  gsl_CONFIG_ALLOWS_NONSTRICT_SPAN_COMPARISON
+# define gsl_CONFIG_ALLOWS_NONSTRICT_SPAN_COMPARISON  1
+#endif
+
+#ifndef  gsl_CONFIG_ALLOWS_UNCONSTRAINED_SPAN_CONTAINER_CTOR
+# define gsl_CONFIG_ALLOWS_UNCONSTRAINED_SPAN_CONTAINER_CTOR  0
+#endif
+
+#ifndef  gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION
+# define gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION  (gsl_CONFIG_DEFAULTS_VERSION >= 1)
+#endif
+
+#if 1 < defined( gsl_CONFIG_CONTRACT_CHECKING_AUDIT ) + defined( gsl_CONFIG_CONTRACT_CHECKING_ON ) + defined( gsl_CONFIG_CONTRACT_CHECKING_OFF )
+# error only one of gsl_CONFIG_CONTRACT_CHECKING_AUDIT, gsl_CONFIG_CONTRACT_CHECKING_ON, and gsl_CONFIG_CONTRACT_CHECKING_OFF may be defined
+#endif
+#if 1 < defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS ) + defined( gsl_CONFIG_CONTRACT_VIOLATION_TERMINATES ) + defined( gsl_CONFIG_CONTRACT_VIOLATION_CALLS_HANDLER )
+# error only one of gsl_CONFIG_CONTRACT_VIOLATION_THROWS, gsl_CONFIG_CONTRACT_VIOLATION_TERMINATES, and gsl_CONFIG_CONTRACT_VIOLATION_CALLS_HANDLER may be defined
+#endif
+#if 1 < defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ASSUME ) + defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ELIDE )
+# error only one of gsl_CONFIG_UNENFORCED_CONTRACTS_ASSUME and gsl_CONFIG_UNENFORCED_CONTRACTS_ELIDE may be defined
+#endif
+
+// C++ language version detection (C++20 is speculative):
+// Note: VC14.0/1900 (VS2015) lacks too much from C++14.
+
+#ifndef   gsl_CPLUSPLUS
+# if defined(_MSVC_LANG ) && !defined(__clang__)
+#  define gsl_CPLUSPLUS  (_MSC_VER == 1900 ? 201103L : _MSVC_LANG )
+# else
+#  define gsl_CPLUSPLUS  __cplusplus
+# endif
+#endif
+
+#define gsl_CPP98_OR_GREATER  ( gsl_CPLUSPLUS >= 199711L )
+#define gsl_CPP11_OR_GREATER  ( gsl_CPLUSPLUS >= 201103L )
+#define gsl_CPP14_OR_GREATER  ( gsl_CPLUSPLUS >= 201402L )
+#define gsl_CPP17_OR_GREATER  ( gsl_CPLUSPLUS >= 201703L )
+#define gsl_CPP20_OR_GREATER  ( gsl_CPLUSPLUS >= 202000L )
+
+// C++ language version (represent 98 as 3):
+
+#define gsl_CPLUSPLUS_V  ( gsl_CPLUSPLUS / 100 - (gsl_CPLUSPLUS > 200000 ? 2000 : 1994) )
+
+// half-open range [lo..hi):
+#define gsl_BETWEEN( v, lo, hi ) ( (lo) <= (v) && (v) < (hi) )
+
+// Compiler versions:
+
+// MSVC++  6.0  _MSC_VER == 1200  gsl_COMPILER_MSVC_VERSION ==  60  (Visual Studio 6.0)
+// MSVC++  7.0  _MSC_VER == 1300  gsl_COMPILER_MSVC_VERSION ==  70  (Visual Studio .NET 2002)
+// MSVC++  7.1  _MSC_VER == 1310  gsl_COMPILER_MSVC_VERSION ==  71  (Visual Studio .NET 2003)
+// MSVC++  8.0  _MSC_VER == 1400  gsl_COMPILER_MSVC_VERSION ==  80  (Visual Studio 2005)
+// MSVC++  9.0  _MSC_VER == 1500  gsl_COMPILER_MSVC_VERSION ==  90  (Visual Studio 2008)
+// MSVC++ 10.0  _MSC_VER == 1600  gsl_COMPILER_MSVC_VERSION == 100  (Visual Studio 2010)
+// MSVC++ 11.0  _MSC_VER == 1700  gsl_COMPILER_MSVC_VERSION == 110  (Visual Studio 2012)
+// MSVC++ 12.0  _MSC_VER == 1800  gsl_COMPILER_MSVC_VERSION == 120  (Visual Studio 2013)
+// MSVC++ 14.0  _MSC_VER == 1900  gsl_COMPILER_MSVC_VERSION == 140  (Visual Studio 2015)
+// MSVC++ 14.1  _MSC_VER >= 1910  gsl_COMPILER_MSVC_VERSION == 141  (Visual Studio 2017)
+// MSVC++ 14.2  _MSC_VER >= 1920  gsl_COMPILER_MSVC_VERSION == 142  (Visual Studio 2019)
+
+#if defined(_MSC_VER ) && !defined(__clang__)
+# define gsl_COMPILER_MSVC_VER           (_MSC_VER )
+# define gsl_COMPILER_MSVC_VERSION       (_MSC_VER / 10 - 10 * ( 5 + (_MSC_VER < 1900 ) ) )
+# define gsl_COMPILER_MSVC_VERSION_FULL  (_MSC_VER - 100 * ( 5 + (_MSC_VER < 1900 ) ) )
+#else
+# define gsl_COMPILER_MSVC_VER           0
+# define gsl_COMPILER_MSVC_VERSION       0
+# define gsl_COMPILER_MSVC_VERSION_FULL  0
+#endif
+
+#define gsl_COMPILER_VERSION( major, minor, patch ) ( 10 * ( 10 * (major) + (minor) ) + (patch) )
+
+// AppleClang  7.0.0  __apple_build_version__ ==  7000172  gsl_COMPILER_APPLECLANG_VERSION ==  700  (Xcode 7.0, 7.0.1)          (LLVM 3.7.0)
+// AppleClang  7.0.0  __apple_build_version__ ==  7000176  gsl_COMPILER_APPLECLANG_VERSION ==  700  (Xcode 7.1)                 (LLVM 3.7.0)
+// AppleClang  7.0.2  __apple_build_version__ ==  7000181  gsl_COMPILER_APPLECLANG_VERSION ==  702  (Xcode 7.2, 7.2.1)          (LLVM 3.7.0)
+// AppleClang  7.3.0  __apple_build_version__ ==  7030029  gsl_COMPILER_APPLECLANG_VERSION ==  730  (Xcode 7.3)                 (LLVM 3.8.0)
+// AppleClang  7.3.0  __apple_build_version__ ==  7030031  gsl_COMPILER_APPLECLANG_VERSION ==  730  (Xcode 7.3.1)               (LLVM 3.8.0)
+// AppleClang  8.0.0  __apple_build_version__ ==  8000038  gsl_COMPILER_APPLECLANG_VERSION ==  800  (Xcode 8.0)                 (LLVM 3.9.0)
+// AppleClang  8.0.0  __apple_build_version__ ==  8000042  gsl_COMPILER_APPLECLANG_VERSION ==  800  (Xcode 8.1, 8.2, 8.2.1)     (LLVM 3.9.0)
+// AppleClang  8.1.0  __apple_build_version__ ==  8020038  gsl_COMPILER_APPLECLANG_VERSION ==  810  (Xcode 8.3)                 (LLVM 3.9.0)
+// AppleClang  8.1.0  __apple_build_version__ ==  8020041  gsl_COMPILER_APPLECLANG_VERSION ==  810  (Xcode 8.3.1)               (LLVM 3.9.0)
+// AppleClang  8.1.0  __apple_build_version__ ==  8020042  gsl_COMPILER_APPLECLANG_VERSION ==  810  (Xcode 8.3.2, 8.3.3)        (LLVM 3.9.0)
+// AppleClang  9.0.0  __apple_build_version__ ==  9000037  gsl_COMPILER_APPLECLANG_VERSION ==  900  (Xcode 9.0)                 (LLVM 4.0.0?)
+// AppleClang  9.0.0  __apple_build_version__ ==  9000038  gsl_COMPILER_APPLECLANG_VERSION ==  900  (Xcode 9.1)                 (LLVM 4.0.0?)
+// AppleClang  9.0.0  __apple_build_version__ ==  9000039  gsl_COMPILER_APPLECLANG_VERSION ==  900  (Xcode 9.2)                 (LLVM 4.0.0?)
+// AppleClang  9.1.0  __apple_build_version__ ==  9020039  gsl_COMPILER_APPLECLANG_VERSION ==  910  (Xcode 9.3, 9.3.1)          (LLVM 5.0.2?)
+// AppleClang  9.1.0  __apple_build_version__ ==  9020039  gsl_COMPILER_APPLECLANG_VERSION ==  910  (Xcode 9.4, 9.4.1)          (LLVM 5.0.2?)
+// AppleClang 10.0.0  __apple_build_version__ == 10001145  gsl_COMPILER_APPLECLANG_VERSION == 1000  (Xcode 10.0, 10.1)          (LLVM 6.0.1?)
+// AppleClang 10.0.1  __apple_build_version__ == 10010046  gsl_COMPILER_APPLECLANG_VERSION == 1001  (Xcode 10.2, 10.2.1, 10.3)  (LLVM 7.0.0?)
+// AppleClang 11.0.0  __apple_build_version__ == 11000033  gsl_COMPILER_APPLECLANG_VERSION == 1100  (Xcode 11.1, 11.2, 11.3)    (LLVM 8.0.0?)
+
+#if defined( __apple_build_version__ )
+# define gsl_COMPILER_APPLECLANG_VERSION gsl_COMPILER_VERSION( __clang_major__, __clang_minor__, __clang_patchlevel__ )
+# define gsl_COMPILER_CLANG_VERSION 0
+#elif defined( __clang__ )
+# define gsl_COMPILER_APPLECLANG_VERSION 0
+# define gsl_COMPILER_CLANG_VERSION gsl_COMPILER_VERSION( __clang_major__, __clang_minor__, __clang_patchlevel__ )
+#else
+# define gsl_COMPILER_APPLECLANG_VERSION 0
+# define gsl_COMPILER_CLANG_VERSION 0
+#endif
+
+#if defined(__GNUC__) && !defined(__clang__)
+# define gsl_COMPILER_GNUC_VERSION gsl_COMPILER_VERSION( __GNUC__, __GNUC_MINOR__, __GNUC_PATCHLEVEL__ )
+#else
+# define gsl_COMPILER_GNUC_VERSION 0
+#endif
+
+// Compiler non-strict aliasing:
+
+#if defined(__clang__) || defined(__GNUC__)
+# define gsl_may_alias  __attribute__((__may_alias__))
+#else
+# define gsl_may_alias
+#endif
+
+// Presence of gsl, language and library features:
+
+#define gsl_IN_STD( v )  ( ((v) == 98 ? 3 : (v)) >= gsl_CPLUSPLUS_V )
+
+#define gsl_DEPRECATE_TO_LEVEL( level )  ( level <= gsl_CONFIG_DEPRECATE_TO_LEVEL )
+#define gsl_FEATURE_TO_STD(   feature )  ( gsl_IN_STD( gsl_FEATURE( feature##_TO_STD ) ) )
+#define gsl_FEATURE(          feature )  ( gsl_FEATURE_##feature )
+#define gsl_CONFIG(           feature )  ( gsl_CONFIG_##feature )
+#define gsl_HAVE(             feature )  ( gsl_HAVE_##feature )
+
+// Presence of wide character support:
+
+#ifdef __DJGPP__
+# define gsl_HAVE_WCHAR 0
+#else
+# define gsl_HAVE_WCHAR 1
+#endif
+
+// Presence of language & library features:
+
+#if gsl_BETWEEN(gsl_COMPILER_GNUC_VERSION, 1, 500) || gsl_BETWEEN(gsl_COMPILER_CLANG_VERSION, 1, 360) || gsl_COMPILER_APPLECLANG_VERSION
+# ifdef __EXCEPTIONS
+#  define gsl_HAVE_EXCEPTIONS  1
+# else
+#  define gsl_HAVE_EXCEPTIONS  0
+# endif // __EXCEPTIONS
+#elif gsl_COMPILER_GNUC_VERSION >= 500 || gsl_COMPILER_CLANG_VERSION >= 500
+# ifdef __cpp_exceptions
+#  define gsl_HAVE_EXCEPTIONS  1
+# else
+#  define gsl_HAVE_EXCEPTIONS  0
+# endif // __cpp_exceptions
+#elif gsl_COMPILER_MSVC_VERSION
+# ifdef _CPPUNWIND
+#  define gsl_HAVE_EXCEPTIONS  1
+# else
+#  define gsl_HAVE_EXCEPTIONS  0
+# endif // _CPPUNWIND
+#else
+// For all other compilers, assume exceptions are always enabled.
+# define  gsl_HAVE_EXCEPTIONS  1
+#endif
+
+#if defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS ) && !gsl_HAVE( EXCEPTIONS )
+# error Cannot use gsl_CONFIG_CONTRACT_VIOLATION_THROWS if exceptions are disabled.
+#endif // defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS ) && !gsl_HAVE( EXCEPTIONS )
+
+#ifdef _HAS_CPP0X
+# define gsl_HAS_CPP0X  _HAS_CPP0X
+#else
+# define gsl_HAS_CPP0X  0
+#endif
+
+#define gsl_CPP11_100  (gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1600)
+#define gsl_CPP11_110  (gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1700)
+#define gsl_CPP11_120  (gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1800)
+#define gsl_CPP11_140  (gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1900)
+
+#define gsl_CPP14_000  (gsl_CPP14_OR_GREATER)
+#define gsl_CPP14_120  (gsl_CPP14_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1800)
+#define gsl_CPP14_140  (gsl_CPP14_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1900)
+
+#define gsl_CPP17_000  (gsl_CPP17_OR_GREATER)
+#define gsl_CPP17_140  (gsl_CPP17_OR_GREATER || gsl_COMPILER_MSVC_VER >= 1900)
+
+#define gsl_CPP11_140_CPP0X_90   (gsl_CPP11_140 || (gsl_COMPILER_MSVC_VER >= 1500 && gsl_HAS_CPP0X))
+#define gsl_CPP11_140_CPP0X_100  (gsl_CPP11_140 || (gsl_COMPILER_MSVC_VER >= 1600 && gsl_HAS_CPP0X))
+
+// Presence of C++11 language features:
+
+#define gsl_HAVE_AUTO                   gsl_CPP11_100
+#define gsl_HAVE_NULLPTR                gsl_CPP11_100
+#define gsl_HAVE_RVALUE_REFERENCE       gsl_CPP11_100
+#define gsl_HAVE_FUNCTION_REF_QUALIFIER ( gsl_CPP14_140 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 481 ) )
+
+#define gsl_HAVE_ENUM_CLASS             gsl_CPP11_110
+
+#define gsl_HAVE_ALIAS_TEMPLATE         gsl_CPP11_120
+#define gsl_HAVE_DEFAULT_FUNCTION_TEMPLATE_ARG  gsl_CPP11_120
+#define gsl_HAVE_EXPLICIT               gsl_CPP11_120
+#define gsl_HAVE_INITIALIZER_LIST       gsl_CPP11_120
+#define gsl_HAVE_VARIADIC_TEMPLATE      gsl_CPP11_120
+#define gsl_HAVE_IS_DELETE              gsl_CPP11_120
+
+#define gsl_HAVE_CONSTEXPR_11           gsl_CPP11_140
+#define gsl_HAVE_IS_DEFAULT             gsl_CPP11_140
+#define gsl_HAVE_NOEXCEPT               gsl_CPP11_140
+#define gsl_HAVE_NORETURN               ( gsl_CPP11_140 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 480 ) )
+
+#define gsl_HAVE_EXPRESSION_SFINAE      gsl_CPP11_140
+
+#if gsl_CPP11_OR_GREATER
+// see above
+#endif
+
+// Presence of C++14 language features:
+
+#define gsl_HAVE_CONSTEXPR_14           ( gsl_CPP14_000 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 600 ) )
+#define gsl_HAVE_DECLTYPE_AUTO          gsl_CPP14_140
+#define gsl_HAVE_DEPRECATED             ( gsl_CPP14_140 && ! gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION, 1, 142 ) )
+
+// Presence of C++17 language features:
+// MSVC: template parameter deduction guides since Visual Studio 2017 v15.7
+
+#define gsl_HAVE_ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE  gsl_CPP17_000
+#define gsl_HAVE_DEDUCTION_GUIDES       ( gsl_CPP17_000 && ! gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION_FULL, 1, 1414 ) )
+#define gsl_HAVE_NODISCARD              gsl_CPP17_000
+#define gsl_HAVE_CONSTEXPR_17           gsl_CPP17_OR_GREATER
+
+// Presence of C++20 language features:
+
+#define gsl_HAVE_CONSTEXPR_20           gsl_CPP20_OR_GREATER
+
+// Presence of C++ library features:
+
+#define gsl_HAVE_ADDRESSOF              gsl_CPP17_000
+#define gsl_HAVE_ARRAY                  gsl_CPP11_110
+#define gsl_HAVE_TYPE_TRAITS            gsl_CPP11_110
+#define gsl_HAVE_TR1_TYPE_TRAITS        gsl_CPP11_110
+
+#define gsl_HAVE_CONTAINER_DATA_METHOD  gsl_CPP11_140_CPP0X_90
+#define gsl_HAVE_STD_DATA               gsl_CPP17_000
+#ifdef __cpp_lib_ssize
+# define gsl_HAVE_STD_SSIZE             1
+#else
+# define gsl_HAVE_STD_SSIZE             ( gsl_COMPILER_GNUC_VERSION >= 1000 && __cplusplus > 201703L )
+#endif
+
+#define gsl_HAVE_SIZED_TYPES            gsl_CPP11_140
+
+#define gsl_HAVE_MAKE_SHARED            gsl_CPP11_140_CPP0X_100
+#define gsl_HAVE_SHARED_PTR             gsl_CPP11_140_CPP0X_100
+#define gsl_HAVE_UNIQUE_PTR             gsl_CPP11_140_CPP0X_100
+
+#define gsl_HAVE_MAKE_UNIQUE            gsl_CPP14_120
+
+#define gsl_HAVE_UNCAUGHT_EXCEPTIONS    gsl_CPP17_140
+
+#define gsl_HAVE_ADD_CONST              gsl_HAVE_TYPE_TRAITS
+#define gsl_HAVE_INTEGRAL_CONSTANT      gsl_HAVE_TYPE_TRAITS
+#define gsl_HAVE_REMOVE_CONST           gsl_HAVE_TYPE_TRAITS
+#define gsl_HAVE_REMOVE_REFERENCE       gsl_HAVE_TYPE_TRAITS
+#define gsl_HAVE_REMOVE_CVREF           gsl_CPP20_OR_GREATER
+
+#define gsl_HAVE_TR1_ADD_CONST          gsl_HAVE_TR1_TYPE_TRAITS
+#define gsl_HAVE_TR1_INTEGRAL_CONSTANT  gsl_HAVE_TR1_TYPE_TRAITS
+#define gsl_HAVE_TR1_REMOVE_CONST       gsl_HAVE_TR1_TYPE_TRAITS
+#define gsl_HAVE_TR1_REMOVE_REFERENCE   gsl_HAVE_TR1_TYPE_TRAITS
+
+// C++ feature usage:
+
+#if gsl_HAVE( ADDRESSOF )
+# define gsl_ADDRESSOF(x)  std::addressof(x)
+#else
+# define gsl_ADDRESSOF(x)  (&x)
+#endif
+
+#if gsl_HAVE( CONSTEXPR_11 )
+# define gsl_constexpr constexpr
+#else
+# define gsl_constexpr /*constexpr*/
+#endif
+
+#if gsl_HAVE( CONSTEXPR_14 )
+# define gsl_constexpr14 constexpr
+#else
+# define gsl_constexpr14 /*constexpr*/
+#endif
+
+#if gsl_HAVE( CONSTEXPR_17 )
+# define gsl_constexpr17 constexpr
+#else
+# define gsl_constexpr17 /*constexpr*/
+#endif
+
+#if gsl_HAVE( CONSTEXPR_20 )
+# define gsl_constexpr20 constexpr
+#else
+# define gsl_constexpr20 /*constexpr*/
+#endif
+
+#if gsl_HAVE( EXPLICIT )
+# define gsl_explicit explicit
+#else
+# define gsl_explicit /*explicit*/
+#endif
+
+#if gsl_FEATURE( IMPLICIT_MACRO )
+# define implicit /*implicit*/
+#endif
+
+#if gsl_HAVE( IS_DELETE )
+# define gsl_is_delete = delete
+#else
+# define gsl_is_delete
+#endif
+
+#if gsl_HAVE( IS_DELETE )
+# define gsl_is_delete_access public
+#else
+# define gsl_is_delete_access private
+#endif
+
+#if !gsl_HAVE( NOEXCEPT ) || defined( gsl_TESTING_ )
+# define gsl_noexcept /*noexcept*/
+#else
+# define gsl_noexcept noexcept
+#endif
+
+#if gsl_HAVE( NULLPTR )
+# define gsl_nullptr  nullptr
+#else
+# define gsl_nullptr  NULL
+#endif
+
+#if gsl_HAVE( NODISCARD )
+# define gsl_NODISCARD [[nodiscard]]
+#else
+# define gsl_NODISCARD
+#endif
+
+#if gsl_HAVE( NORETURN )
+# define gsl_NORETURN [[noreturn]]
+#elif defined(_MSC_VER)
+# define gsl_NORETURN __declspec(noreturn)
+#else
+# define gsl_NORETURN
+#endif
+
+#if gsl_HAVE( DEPRECATED ) && !defined( gsl_TESTING_ )
+# define gsl_DEPRECATED             [[deprecated]]
+# define gsl_DEPRECATED_MSG( msg )  [[deprecated( msg )]]
+#else
+# define gsl_DEPRECATED
+# define gsl_DEPRECATED_MSG( msg )
+#endif
+
+#if gsl_HAVE( TYPE_TRAITS )
+
+#define gsl_DEFINE_ENUM_BITMASK_OPERATORS_( ENUM )                    \
+    gsl_NODISCARD gsl_api inline gsl_constexpr ENUM                   \
+    operator~( ENUM val ) gsl_noexcept                                \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return ENUM( ~U( val ) );                                     \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr ENUM                   \
+    operator|( ENUM lhs, ENUM rhs ) gsl_noexcept                      \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return ENUM( U( lhs ) | U( rhs ) );                           \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr ENUM                   \
+    operator&( ENUM lhs, ENUM rhs ) gsl_noexcept                      \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return ENUM( U( lhs ) & U( rhs ) );                           \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr ENUM                   \
+    operator^( ENUM lhs, ENUM rhs ) gsl_noexcept                      \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return ENUM( U( lhs ) ^ U( rhs ) );                           \
+    }                                                                 \
+    gsl_api inline gsl_constexpr14 ENUM &                             \
+    operator|=( ENUM & lhs, ENUM rhs ) gsl_noexcept                   \
+    {                                                                 \
+        return lhs = lhs | rhs;                                       \
+    }                                                                 \
+    gsl_api inline gsl_constexpr14 ENUM &                             \
+    operator&=( ENUM & lhs, ENUM rhs ) gsl_noexcept                   \
+    {                                                                 \
+        return lhs = lhs & rhs;                                       \
+    }                                                                 \
+    gsl_api inline gsl_constexpr14 ENUM &                             \
+    operator^=( ENUM & lhs, ENUM rhs ) gsl_noexcept                   \
+    {                                                                 \
+        return lhs = lhs ^ rhs;                                       \
+    }
+
+#define gsl_DEFINE_ENUM_RELATIONAL_OPERATORS_( ENUM )                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr bool                   \
+    operator<( ENUM lhs, ENUM rhs ) gsl_noexcept                      \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return U( lhs ) < U( rhs );                                   \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr bool                   \
+    operator>( ENUM lhs, ENUM rhs ) gsl_noexcept                      \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return U( lhs ) > U( rhs );                                   \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr bool                   \
+    operator<=( ENUM lhs, ENUM rhs ) gsl_noexcept                     \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return U( lhs ) <= U( rhs );                                  \
+    }                                                                 \
+    gsl_NODISCARD gsl_api inline gsl_constexpr bool                   \
+    operator>=( ENUM lhs, ENUM rhs ) gsl_noexcept                     \
+    {                                                                 \
+        typedef typename ::gsl::std11::underlying_type<ENUM>::type U; \
+        return U( lhs ) >= U( rhs );                                  \
+    }
+
+    //
+    // Defines bitmask operators `|`, `&`, `^`, `~`, `|=`, `&=`, and `^=` for the given enum type.
+    //ᅟ
+    //ᅟ    enum class Vegetables {
+    //ᅟ        tomato   = 0b001,
+    //ᅟ        onion    = 0b010,
+    //ᅟ        eggplant = 0b100
+    //ᅟ    };
+    //ᅟ    gsl_DEFINE_ENUM_BITMASK_OPERATORS( Vegetables )
+    //
+#define gsl_DEFINE_ENUM_BITMASK_OPERATORS( ENUM ) gsl_DEFINE_ENUM_BITMASK_OPERATORS_( ENUM )
+
+    //
+    // Defines relational operators `<`, `>`, `<=`, `>=` for the given enum type.
+    //ᅟ
+    //ᅟ    enum class OperatorPrecedence {
+    //ᅟ        additive = 0,
+    //ᅟ        multiplicative = 1,
+    //ᅟ        power = 2
+    //ᅟ    };
+    //ᅟ    gsl_DEFINE_ENUM_RELATIONAL_OPERATORS( OperatorPrecedence )
+    //
+#define gsl_DEFINE_ENUM_RELATIONAL_OPERATORS( ENUM ) gsl_DEFINE_ENUM_RELATIONAL_OPERATORS_( ENUM )
+
+#endif // gsl_HAVE( TYPE_TRAITS )
+
+#define gsl_DIMENSION_OF( a ) ( sizeof(a) / sizeof(0[a]) )
+
+
+// Method enabling (C++98, VC120 (VS2013) cannot use __VA_ARGS__)
+
+#if gsl_HAVE( EXPRESSION_SFINAE )
+# define gsl_DECLTYPE_(T, EXPR) decltype( EXPR )
+#else
+# define gsl_DECLTYPE_(T, EXPR) T
+#endif
+
+// NOTE: When using SFINAE in gsl-lite, please note that overloads of function templates must always use SFINAE with non-type default arguments
+//       as explained in https://en.cppreference.com/w/cpp/types/enable_if#Notes. `gsl_ENABLE_IF_()` implements graceful fallback to default
+//       type arguments (for compilers that don't support non-type default arguments); please verify that this is appropriate in the given
+//       situation, and add additional checks if necessary.
+//
+//       Also, please note that `gsl_ENABLE_IF_()` doesn't enforce the constraint at all if no compiler/library support is available (i.e. pre-C++11).
+
+#if gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG )
+# if !gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION, 1, 140 ) // VS 2013 seems to have trouble with SFINAE for default non-type arguments
+#  define gsl_ENABLE_IF_(VA) , typename std::enable_if< ( VA ), int >::type = 0
+# else
+#  define gsl_ENABLE_IF_(VA) , typename = typename std::enable_if< ( VA ), ::gsl::detail::enabler >::type
+# endif
+#else
+# define  gsl_ENABLE_IF_(VA)
+#endif
+
+
+// Other features:
+
+#define gsl_HAVE_CONSTRAINED_SPAN_CONTAINER_CTOR  \
+    ( gsl_HAVE_DEFAULT_FUNCTION_TEMPLATE_ARG && gsl_HAVE_CONTAINER_DATA_METHOD )
+
+// Note: !defined(__NVCC__) doesn't work with nvcc here:
+#define gsl_HAVE_UNCONSTRAINED_SPAN_CONTAINER_CTOR  \
+    ( gsl_CONFIG_ALLOWS_UNCONSTRAINED_SPAN_CONTAINER_CTOR && (__NVCC__== 0) )
+
+// GSL API (e.g. for CUDA platform):
+
+// Guidelines for using `gsl_api`:
+//
+// NVCC imposes the restriction that a function annotated `__host__ __device__` cannot call host-only or device-only functions.
+// This makes `gsl_api` inappropriate for generic functions that call unknown code, e.g. the template constructors of `span<>`
+// or functions like `finally()` which accept an arbitrary  function object.
+// It is often preferable to annotate functions only with `gsl_constexpr` or `gsl_constexpr14`. The "extended constexpr" mode
+// of NVCC (currently an experimental feature) will implicitly consider constexpr functions `__host__ __device__` functions
+// but tolerates calls to host-only or device-only functions.
+
+#ifndef   gsl_api
+# ifdef   __CUDACC__
+#  define gsl_api __host__ __device__
+# else
+#  define gsl_api /*gsl_api*/
+# endif
+#endif
+
+// Additional includes:
+
+#if gsl_HAVE( ARRAY )
+# include <array>
+#endif
+
+#if !gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR ) || !gsl_HAVE( AUTO )
+# include <vector>
+#endif
+
+#if gsl_HAVE( INITIALIZER_LIST )
+# include <initializer_list>
+#endif
+
+#if gsl_HAVE( TYPE_TRAITS )
+# include <type_traits> // for enable_if<>,
+                        // add_const<>, add_pointer<>, common_type<>, make_signed<>, remove_cv<>, remove_const<>, remove_volatile<>, remove_reference<>, remove_cvref<>, remove_pointer<>, underlying_type<>,
+                        // is_assignable<>, is_constructible<>, is_const<>, is_convertible<>, is_integral<>, is_pointer<>, is_signed<>,
+                        // integral_constant<>, declval()
+#elif gsl_HAVE( TR1_TYPE_TRAITS )
+# include <tr1/type_traits> // for add_const<>, remove_cv<>, remove_const<>, remove_volatile<>, remove_reference<>, integral_constant<>
+#endif
+
+// MSVC warning suppression macros:
+
+#if gsl_COMPILER_MSVC_VERSION >= 140 && !defined(__NVCC__)
+# define gsl_SUPPRESS_MSGSL_WARNING(expr)        [[gsl::suppress(expr)]]
+# define gsl_SUPPRESS_MSVC_WARNING(code, descr)  __pragma(warning(suppress: code) )
+# define gsl_DISABLE_MSVC_WARNINGS(codes)        __pragma(warning(push))  __pragma(warning(disable: codes))
+# define gsl_RESTORE_MSVC_WARNINGS()             __pragma(warning(pop ))
+#else
+// TODO: define for Clang
+# define gsl_SUPPRESS_MSGSL_WARNING(expr)
+# define gsl_SUPPRESS_MSVC_WARNING(code, descr)
+# define gsl_DISABLE_MSVC_WARNINGS(codes)
+# define gsl_RESTORE_MSVC_WARNINGS()
+#endif
+
+// Suppress the following MSVC GSL warnings:
+// - C26432: gsl::c.21 : if you define or delete any default operation in the type '...', define or delete them all
+// - C26410: gsl::r.32 : the parameter 'ptr' is a reference to const unique pointer, use const T* or const T& instead
+// - C26415: gsl::r.30 : smart pointer parameter 'ptr' is used only to access contained pointer. Use T* or T& instead
+// - C26418: gsl::r.36 : shared pointer parameter 'ptr' is not copied or moved. Use T* or T& instead
+// - C26472: gsl::t.1  : don't use a static_cast for arithmetic conversions;
+//                       use brace initialization, gsl::narrow_cast or gsl::narrow
+// - C26439: gsl::f.6  : special function 'function' can be declared 'noexcept'
+// - C26440: gsl::f.6  : function 'function' can be declared 'noexcept'
+// - C26455: gsl::f.6  : default constructor may not throw. Declare it 'noexcept'
+// - C26473: gsl::t.1  : don't cast between pointer types where the source type and the target type are the same
+// - C26481: gsl::b.1  : don't use pointer arithmetic. Use span instead
+// - C26482: gsl::b.2  : only index into arrays using constant expressions
+// - C26446: gdl::b.4  : prefer to use gsl::at() instead of unchecked subscript operator
+// - C26490: gsl::t.1  : don't use reinterpret_cast
+// - C26487: gsl::l.4  : don't return a pointer '(<some number>'s result)' that may be invalid
+
+gsl_DISABLE_MSVC_WARNINGS( 26432 26410 26415 26418 26472 26439 26440 26455 26473 26481 26482 26446 26490 26487 )
+
+namespace gsl {
+
+// forward declare span<>:
+
+template< class T >
+class span;
+
+// C++11 emulation:
+
+namespace std11 {
+
+#if gsl_HAVE( ADD_CONST )
+
+using std::add_const;
+
+#elif gsl_HAVE( TR1_ADD_CONST )
+
+using std::tr1::add_const;
+
+#else
+
+template< class T > struct add_const { typedef const T type; };
+
+#endif // gsl_HAVE( ADD_CONST )
+
+#if gsl_HAVE( REMOVE_CONST )
+
+using std::remove_cv;
+using std::remove_const;
+using std::remove_volatile;
+
+#elif gsl_HAVE( TR1_REMOVE_CONST )
+
+using std::tr1::remove_cv;
+using std::tr1::remove_const;
+using std::tr1::remove_volatile;
+
+#else
+
+template< class T > struct remove_const          { typedef T type; };
+template< class T > struct remove_const<T const> { typedef T type; };
+
+template< class T > struct remove_volatile             { typedef T type; };
+template< class T > struct remove_volatile<T volatile> { typedef T type; };
+
+template< class T >
+struct remove_cv
+{
+    typedef typename remove_volatile<typename remove_const<T>::type>::type type;
+};
+
+#endif // gsl_HAVE( REMOVE_CONST )
+
+#if gsl_HAVE( REMOVE_REFERENCE )
+
+using std::remove_reference;
+
+#elif gsl_HAVE( TR1_REMOVE_REFERENCE )
+
+using std::tr1::remove_reference;
+
+#else
+
+template< class T > struct remove_reference { typedef T type; };
+template< class T > struct remove_reference<T&> { typedef T type; };
+# if gsl_HAVE( RVALUE_REFERENCE )
+template< class T > struct remove_reference<T&&> { typedef T type; };
+# endif
+
+#endif // gsl_HAVE( REMOVE_REFERENCE )
+
+
+#if gsl_HAVE( INTEGRAL_CONSTANT )
+
+using std::integral_constant;
+using std::true_type;
+using std::false_type;
+
+#elif gsl_HAVE( TR1_INTEGRAL_CONSTANT )
+
+using std::tr1::integral_constant;
+using std::tr1::true_type;
+using std::tr1::false_type;
+
+#else
+
+template< class T, T v > struct integral_constant { enum { value = v }; };
+typedef integral_constant< bool, true  > true_type;
+typedef integral_constant< bool, false > false_type;
+
+#endif
+
+#if gsl_HAVE( TYPE_TRAITS )
+
+using std::underlying_type;
+
+#elif gsl_HAVE( TR1_TYPE_TRAITS )
+
+using std::tr1::underlying_type;
+
+#else
+
+// We could try to define `underlying_type<>` for pre-C++11 here, but let's not until someone actually needs it.
+
+#endif
+
+} // namespace std11
+
+// C++14 emulation:
+
+namespace std14 {
+
+#if gsl_HAVE( UNIQUE_PTR )
+# if gsl_HAVE( MAKE_UNIQUE )
+
+using std::make_unique;
+
+# elif gsl_HAVE( VARIADIC_TEMPLATE )
+
+template< class T, class... Args >
+std::unique_ptr<T> make_unique( Args &&... args )
+{
+    return std::unique_ptr<T>( new T( std::forward<Args>( args )... ) );
+}
+
+# endif // gsl_HAVE( MAKE_UNIQUE ), gsl_HAVE( VARIADIC_TEMPLATE )
+#endif // gsl_HAVE( UNIQUE_PTR )
+
+} // namespace std14
+
+namespace detail {
+
+#if gsl_HAVE( VARIADIC_TEMPLATE )
+
+template < bool V0, class T0, class... Ts > struct conjunction_ { using type = T0; };
+template < class T0, class T1, class... Ts > struct conjunction_<true, T0, T1, Ts...> : conjunction_<T1::value, T1, Ts...> { };
+template < bool V0, class T0, class... Ts > struct disjunction_ { using type = T0; };
+template < class T0, class T1, class... Ts > struct disjunction_<false, T0, T1, Ts...> : disjunction_<T1::value, T1, Ts...> { };
+
+#endif
+
+} // namespace detail
+
+// C++17 emulation:
+
+namespace std17 {
+
+template< bool v > struct bool_constant : std11::integral_constant<bool, v>{};
+
+#if gsl_CPP11_120
+
+template < class... Ts > struct conjunction;
+template < > struct conjunction< > : std11::true_type { };
+template < class T0, class... Ts > struct conjunction<T0, Ts...> : detail::conjunction_<T0::value, T0, Ts...>::type { };
+template < class... Ts > struct disjunction;
+template < > struct disjunction< > : std11::false_type { };
+template < class T0, class... Ts > struct disjunction<T0, Ts...> : detail::disjunction_<T0::value, T0, Ts...>::type { };
+template < class T > struct negation : std11::integral_constant<bool, !T::value> { };
+
+# if gsl_CPP14_OR_GREATER
+
+template < class... Ts > constexpr bool conjunction_v = conjunction<Ts...>::value;
+template < class... Ts > constexpr bool disjunction_v = disjunction<Ts...>::value;
+template < class T > constexpr bool negation_v = negation<T>::value;
+
+# endif // gsl_CPP14_OR_GREATER
+
+template< class... Ts >
+struct make_void { typedef void type; };
+
+template< class... Ts >
+using void_t = typename make_void< Ts... >::type;
+
+#endif // gsl_CPP11_120
+
+#if gsl_HAVE( STD_DATA )
+
+using std::data;
+using std::size;
+
+#elif gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR )
+
+template< class T, size_t N >
+gsl_api inline gsl_constexpr auto size( T const(&)[N] ) gsl_noexcept -> size_t
+{
+    return N;
+}
+
+template< class C >
+inline gsl_constexpr auto size( C const & cont ) -> decltype( cont.size() )
+{
+    return cont.size();
+}
+
+template< class T, size_t N >
+gsl_api inline gsl_constexpr auto data( T(&arr)[N] ) gsl_noexcept -> T*
+{
+    return &arr[0];
+}
+
+template< class C >
+inline gsl_constexpr auto data( C & cont ) -> decltype( cont.data() )
+{
+    return cont.data();
+}
+
+template< class C >
+inline gsl_constexpr auto data( C const & cont ) -> decltype( cont.data() )
+{
+    return cont.data();
+}
+
+template< class E >
+inline gsl_constexpr auto data( std::initializer_list<E> il ) gsl_noexcept -> E const *
+{
+    return il.begin();
+}
+
+#endif // span_HAVE( DATA )
+
+} // namespace std17
+
+// C++20 emulation:
+
+namespace std20 {
+
+#if gsl_CPP11_100
+
+struct identity
+{
+    template < class T >
+    gsl_constexpr T && operator ()( T && arg ) const gsl_noexcept
+    {
+        return std::forward<T>( arg );
+    }
+};
+
+#endif // gsl_CPP11_100
+
+template< class T >
+struct type_identity
+{
+    typedef T type;
+};
+#if gsl_HAVE( ALIAS_TEMPLATE )
+template< class T >
+using type_identity_t = typename type_identity<T>::type;
+#endif // gsl_HAVE( ALIAS_TEMPLATE )
+
+#if gsl_HAVE( STD_SSIZE )
+
+using std::ssize;
+
+#elif gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR )
+
+template < class C >
+gsl_constexpr auto ssize( C const & c )
+    -> typename std::common_type<std::ptrdiff_t, typename std::make_signed<decltype(c.size())>::type>::type
+{
+    using R = typename std::common_type<std::ptrdiff_t, typename std::make_signed<decltype(c.size())>::type>::type;
+    return static_cast<R>( c.size() );
+}
+
+template <class T, std::size_t N>
+gsl_constexpr auto ssize( T const(&)[N] ) gsl_noexcept -> std::ptrdiff_t
+{
+    return std::ptrdiff_t( N );
+}
+
+#endif // gsl_HAVE( STD_SSIZE )
+
+#if gsl_HAVE( REMOVE_CVREF )
+
+using std::remove_cvref;
+
+#else
+
+template< class T > struct remove_cvref { typedef typename std11::remove_cv< typename std11::remove_reference< T >::type >::type type; };
+
+#endif // gsl_HAVE( REMOVE_CVREF )
+
+} // namespace std20
+
+namespace detail {
+
+/// for nsel_REQUIRES_T
+
+/*enum*/ class enabler{};
+
+#if gsl_HAVE( TYPE_TRAITS )
+
+template< class Q >
+struct is_span_oracle : std::false_type{};
+
+template< class T>
+struct is_span_oracle< span<T> > : std::true_type{};
+
+template< class Q >
+struct is_span : is_span_oracle< typename std::remove_cv<Q>::type >{};
+
+template< class Q >
+struct is_std_array_oracle : std::false_type{};
+
+#if gsl_HAVE( ARRAY )
+
+template< class T, std::size_t Extent >
+struct is_std_array_oracle< std::array<T, Extent> > : std::true_type{};
+
+#endif
+
+template< class Q >
+struct is_std_array : is_std_array_oracle< typename std::remove_cv<Q>::type >{};
+
+template< class Q >
+struct is_array : std::false_type{};
+
+template< class T >
+struct is_array<T[]> : std::true_type{};
+
+template< class T, std::size_t N >
+struct is_array<T[N]> : std::true_type{};
+
+# if gsl_CPP11_140 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 500 )
+
+template< class, class = void >
+struct has_size_and_data : std::false_type{};
+
+template< class C >
+struct has_size_and_data
+<
+    C, std17::void_t<
+        decltype( std17::size(std::declval<C>()) ),
+        decltype( std17::data(std::declval<C>()) ) >
+> : std::true_type{};
+
+template< class, class, class = void >
+struct is_compatible_element : std::false_type {};
+
+template< class C, class E >
+struct is_compatible_element
+<
+    C, E, std17::void_t<
+        decltype( std17::data(std::declval<C>()) ),
+        typename std::remove_pointer<decltype( std17::data( std::declval<C&>() ) )>::type(*)[] >
+> : std::is_convertible< typename std::remove_pointer<decltype( std17::data( std::declval<C&>() ) )>::type(*)[], E(*)[] >{};
+
+template< class C >
+struct is_container : std17::bool_constant
+<
+    ! is_span< C >::value
+    && ! is_array< C >::value
+    && ! is_std_array< C >::value
+    &&   has_size_and_data< C >::value
+>{};
+
+template< class C, class E >
+struct is_compatible_container : std17::bool_constant
+<
+    is_container<C>::value
+    && is_compatible_element<C,E>::value
+>{};
+
+# else // ^^^ gsl_CPP11_140 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 500 ) ^^^ / vvv ! gsl_CPP11_140 || gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 500 ) vvv
+
+template<
+    class C, class E
+        , typename = typename std::enable_if<
+            ! is_span< C >::value
+            && ! is_array< C >::value
+            && ! is_std_array< C >::value
+            && ( std::is_convertible< typename std::remove_pointer<decltype( std17::data( std::declval<C&>() ) )>::type(*)[], E(*)[] >::value)
+        //  &&   has_size_and_data< C >::value
+        , enabler>::type
+        , class = decltype( std17::size(std::declval<C>()) )
+        , class = decltype( std17::data(std::declval<C>()) )
+>
+#  if gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION, 1, 140 )
+// VS2013 has insufficient support for expression SFINAE; we cannot make `is_compatible_container<>` a proper type trait here
+struct is_compatible_container : std::true_type { };
+#  else
+struct is_compatible_container_r { is_compatible_container_r(int); };
+template< class C, class E >
+std::true_type  is_compatible_container_f( is_compatible_container_r<C, E> );
+template< class C, class E >
+std::false_type is_compatible_container_f( ... );
+
+template< class C, class E >
+struct is_compatible_container : decltype( is_compatible_container_f< C, E >( 0 ) ) { };
+#  endif // gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION, 1, 140 )
+
+# endif // gsl_CPP11_140 && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 1, 500 )
+
+#endif // gsl_HAVE( TYPE_TRAITS )
+
+} // namespace detail
+
+//
+// GSL.util: utilities
+//
+
+// Integer type for indices (e.g. in a loop).
+typedef gsl_CONFIG_INDEX_TYPE index;
+
+//
+// GSL.owner: ownership pointers
+//
+#if gsl_HAVE( SHARED_PTR )
+  using std::unique_ptr;
+  using std::shared_ptr;
+  using std::make_shared;
+# if gsl_HAVE( MAKE_UNIQUE ) || gsl_HAVE( VARIADIC_TEMPLATE )
+  using std14::make_unique;
+# endif
+#endif
+
+#if  gsl_HAVE( ALIAS_TEMPLATE )
+  template< class T
+#if gsl_HAVE( TYPE_TRAITS )
+          , typename = typename std::enable_if< std::is_pointer<T>::value >::type
+#endif
+  >
+  using owner = T;
+#elif gsl_CONFIG_DEFAULTS_VERSION == 0
+  // TODO vNext: remove
+  template< class T > struct owner { typedef T type; };
+#endif
+
+#define gsl_HAVE_OWNER_TEMPLATE  gsl_HAVE_ALIAS_TEMPLATE
+
+// TODO vNext: remove
+#if gsl_FEATURE( OWNER_MACRO )
+# if gsl_HAVE( OWNER_TEMPLATE )
+#  define Owner(t)  ::gsl::owner<t>
+# else
+#  define Owner(t)  ::gsl::owner<t>::type
+# endif
+#endif
+
+//
+// GSL.assert: assertions
+//
+
+#if gsl_HAVE( TYPE_TRAITS )
+# define gsl_ELIDE_CONTRACT_( x )  static_assert(::std::is_constructible<bool, decltype( x )>::value, "argument of contract check must be convertible to bool")
+#else
+# define gsl_ELIDE_CONTRACT_( x )
+#endif
+
+#if defined( __CUDACC__ ) && defined( __CUDA_ARCH__ )
+# define  gsl_ASSUME( x )  gsl_ELIDE_CONTRACT_( x ) /* there is no assume intrinsic in CUDA device code */
+#elif gsl_COMPILER_MSVC_VERSION
+# define  gsl_ASSUME( x )  __assume( x )
+#elif gsl_COMPILER_GNUC_VERSION
+#  define gsl_ASSUME( x )  (( x ) ? static_cast<void>(0) : __builtin_unreachable())
+#elif defined(__has_builtin)
+# if __has_builtin(__builtin_unreachable)
+#  define gsl_ASSUME( x )  (( x ) ? static_cast<void>(0) : __builtin_unreachable())
+# endif
+#else
+# define  gsl_ASSUME( x )  gsl_ELIDE_CONTRACT_( x ) /* unknown compiler; cannot rely on assume intrinsic */
+#endif
+
+#if defined( gsl_CONFIG_CONTRACT_VIOLATION_CALLS_HANDLER )
+#  define  gsl_CONTRACT_CHECK_( str, x )  ( ( x ) ? static_cast<void>(0) : ::gsl::fail_fast_assert_handler( #x, "GSL: " str, __FILE__, __LINE__ ) )
+#elif defined( __CUDACC__ ) && defined( __CUDA_ARCH__ )
+#  define  gsl_CONTRACT_CHECK_( str, x )  assert( ( x ) && str )
+#elif   defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+#  define  gsl_CONTRACT_CHECK_( str, x )  ( ( x ) ? static_cast<void>(0) : ::gsl::detail::fail_fast_throw( "GSL: " str " at " __FILE__ ":" gsl_STRINGIFY(__LINE__) ) )
+#else // defined( gsl_CONFIG_CONTRACT_VIOLATION_TERMINATES ) [default]
+#  define  gsl_CONTRACT_CHECK_( str, x )  ( ( x ) ? static_cast<void>(0) : ::gsl::detail::fail_fast_terminate() )
+#endif
+
+#if defined( gsl_CONFIG_CONTRACT_CHECKING_OFF ) || defined( gsl_CONFIG_CONTRACT_CHECKING_EXPECTS_OFF )
+# if defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ASSUME )
+#  define gsl_Expects( x )       gsl_ASSUME( x )
+# else // defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ELIDE ) [default]
+#  define gsl_Expects( x )       gsl_ELIDE_CONTRACT_( x )
+# endif
+#else
+# define  gsl_Expects( x )       gsl_CONTRACT_CHECK_( "Precondition failure", x )
+#endif
+#define   Expects( x )           gsl_Expects( x )
+
+#if !defined( gsl_CONFIG_CONTRACT_CHECKING_AUDIT ) || defined( gsl_CONFIG_CONTRACT_CHECKING_EXPECTS_OFF )
+# define  gsl_ExpectsAudit( x )  gsl_ELIDE_CONTRACT_( x )
+#else
+# define  gsl_ExpectsAudit( x )  gsl_CONTRACT_CHECK_( "Precondition failure (audit)", x )
+#endif
+
+#if defined( gsl_CONFIG_CONTRACT_CHECKING_OFF ) || defined( gsl_CONFIG_CONTRACT_CHECKING_ENSURES_OFF )
+# if defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ASSUME )
+#  define gsl_Ensures( x )       gsl_ASSUME( x )
+# else // defined( gsl_CONFIG_UNENFORCED_CONTRACTS_ELIDE ) [default]
+#  define gsl_Ensures( x )       gsl_ELIDE_CONTRACT_( x )
+# endif
+#else
+# define  gsl_Ensures( x )       gsl_CONTRACT_CHECK_( "Postcondition failure", x )
+#endif
+#define   Ensures( x )           gsl_Ensures( x )
+
+#if !defined( gsl_CONFIG_CONTRACT_CHECKING_AUDIT ) || defined( gsl_CONFIG_CONTRACT_CHECKING_ENSURES_OFF )
+# define  gsl_EnsuresAudit( x )  gsl_ELIDE_CONTRACT_( x )
+#else
+# define  gsl_EnsuresAudit( x )  gsl_CONTRACT_CHECK_( "Postcondition failure (audit)", x )
+#endif
+
+#define gsl_STRINGIFY(  x )  gsl_STRINGIFY_( x )
+#define gsl_STRINGIFY_( x )  #x
+
+struct fail_fast : public std::logic_error
+{
+    explicit fail_fast( char const * message )
+    : std::logic_error( message ) {}
+};
+
+namespace detail {
+
+
+#if gsl_HAVE( EXCEPTIONS )
+gsl_NORETURN inline void fail_fast_throw( char const * message )
+{
+    throw fail_fast( message );
+}
+#endif // gsl_HAVE( EXCEPTIONS )
+gsl_NORETURN inline void fail_fast_terminate() gsl_noexcept
+{
+    std::terminate();
+}
+
+} // namespace detail
+
+// Should be defined by user
+gsl_api void fail_fast_assert_handler( char const * const expression, char const * const message, char const * const file, int line );
+
+#if   defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+
+# if gsl_HAVE( EXCEPTIONS )
+gsl_DEPRECATED_MSG("don't call gsl::fail_fast_assert() directly; use contract checking macros instead")
+gsl_constexpr14 inline
+void fail_fast_assert( bool cond, char const * const message )
+{
+    if ( !cond )
+        throw fail_fast( message );
+}
+# endif // gsl_HAVE( EXCEPTIONS )
+
+#elif defined( gsl_CONFIG_CONTRACT_VIOLATION_CALLS_HANDLER )
+
+gsl_DEPRECATED_MSG("don't call gsl::fail_fast_assert() directly; use contract checking macros instead")
+gsl_api gsl_constexpr14 inline
+void fail_fast_assert( bool cond, char const * const expression, char const * const message, char const * const file, int line )
+{
+    if ( !cond )
+        ::gsl::fail_fast_assert_handler( expression, message, file, line );
+}
+
+#else // defined( gsl_CONFIG_CONTRACT_VIOLATION_TERMINATES ) [default]
+
+gsl_DEPRECATED_MSG("don't call gsl::fail_fast_assert() directly; use contract checking macros instead")
+gsl_constexpr14 inline
+void fail_fast_assert( bool cond ) gsl_noexcept
+{
+    if ( !cond )
+        std::terminate();
+}
+
+#endif
+
+
+//
+// GSL.util: utilities
+//
+
+#if gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+// Add uncaught_exceptions for pre-2017 MSVC, GCC and Clang
+// Return unsigned char to save stack space, uncaught_exceptions can only increase by 1 in a scope
+
+namespace detail {
+
+gsl_api inline unsigned char to_uchar( unsigned x ) gsl_noexcept
+{
+    return static_cast<unsigned char>( x );
+}
+
+} // namespace detail
+
+namespace std11 {
+
+#if gsl_HAVE( UNCAUGHT_EXCEPTIONS )
+
+inline unsigned char uncaught_exceptions() gsl_noexcept
+{
+    return detail::to_uchar( std::uncaught_exceptions() );
+}
+
+#elif gsl_COMPILER_MSVC_VERSION
+
+extern "C" char * __cdecl _getptd();
+inline unsigned char uncaught_exceptions() gsl_noexcept
+{
+    return detail::to_uchar( *reinterpret_cast<unsigned*>(_getptd() + (sizeof(void*) == 8 ? 0x100 : 0x90) ) );
+}
+
+#elif gsl_COMPILER_CLANG_VERSION || gsl_COMPILER_GNUC_VERSION || gsl_COMPILER_APPLECLANG_VERSION
+
+extern "C" char * __cxa_get_globals();
+inline unsigned char uncaught_exceptions() gsl_noexcept
+{
+    return detail::to_uchar( *reinterpret_cast<unsigned*>(__cxa_get_globals() + sizeof(void*) ) );
+}
+#endif
+} // namespace std11
+#endif
+
+#if gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 110
+
+template< class F >
+class final_action
+{
+public:
+    explicit final_action( F action ) gsl_noexcept
+        : action_( std::move( action ) )
+        , invoke_( true )
+    {}
+
+    final_action( final_action && other ) gsl_noexcept
+        : action_( std::move( other.action_ ) )
+        , invoke_( other.invoke_ )
+    {
+        other.invoke_ = false;
+    }
+
+    gsl_SUPPRESS_MSGSL_WARNING(f.6)
+    virtual ~final_action() gsl_noexcept
+    {
+        if ( invoke_ )
+            action_();
+    }
+
+gsl_is_delete_access:
+    final_action( final_action const  & ) gsl_is_delete;
+    final_action & operator=( final_action const & ) gsl_is_delete;
+    final_action & operator=( final_action && ) gsl_is_delete;
+
+protected:
+    void dismiss() gsl_noexcept
+    {
+        invoke_ = false;
+    }
+
+private:
+    F action_;
+    bool invoke_;
+};
+
+template< class F >
+inline final_action<F> finally( F const & action ) gsl_noexcept
+{
+    return final_action<F>( action );
+}
+
+template< class F >
+inline final_action<F> finally( F && action ) gsl_noexcept
+{
+    return final_action<F>( std::forward<F>( action ) );
+}
+
+#if gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+template< class F >
+class final_action_return : public final_action<F>
+{
+public:
+    explicit final_action_return( F && action ) gsl_noexcept
+        : final_action<F>( std::move( action ) )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    final_action_return( final_action_return && other ) gsl_noexcept
+        : final_action<F>( std::move( other ) )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    ~final_action_return() override
+    {
+        if ( std11::uncaught_exceptions() != exception_count )
+            this->dismiss();
+    }
+
+gsl_is_delete_access:
+    final_action_return( final_action_return const & ) gsl_is_delete;
+    final_action_return & operator=( final_action_return const & ) gsl_is_delete;
+
+private:
+    unsigned char exception_count;
+};
+
+template< class F >
+inline final_action_return<F> on_return( F const & action ) gsl_noexcept
+{
+    return final_action_return<F>( action );
+}
+
+template< class F >
+inline final_action_return<F> on_return( F && action ) gsl_noexcept
+{
+    return final_action_return<F>( std::forward<F>( action ) );
+}
+
+template< class F >
+class final_action_error : public final_action<F>
+{
+public:
+    explicit final_action_error( F && action ) gsl_noexcept
+        : final_action<F>( std::move( action ) )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    final_action_error( final_action_error && other ) gsl_noexcept
+        : final_action<F>( std::move( other ) )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    ~final_action_error() override
+    {
+        if ( std11::uncaught_exceptions() == exception_count )
+            this->dismiss();
+    }
+
+gsl_is_delete_access:
+    final_action_error( final_action_error const & ) gsl_is_delete;
+    final_action_error & operator=( final_action_error const & ) gsl_is_delete;
+
+private:
+    unsigned char exception_count;
+};
+
+template< class F >
+inline final_action_error<F> on_error( F const & action ) gsl_noexcept
+{
+    return final_action_error<F>( action );
+}
+
+template< class F >
+inline final_action_error<F> on_error( F && action ) gsl_noexcept
+{
+    return final_action_error<F>( std::forward<F>( action ) );
+}
+
+#endif // gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+#else // gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 110
+
+class final_action
+{
+public:
+    typedef void (*Action)();
+
+    final_action( Action action )
+    : action_( action )
+    , invoke_( true )
+    {}
+
+    final_action( final_action const & other )
+        : action_( other.action_ )
+        , invoke_( other.invoke_ )
+    {
+        other.invoke_ = false;
+    }
+
+    virtual ~final_action()
+    {
+        if ( invoke_ )
+            action_();
+    }
+
+protected:
+    void dismiss()
+    {
+        invoke_ = false;
+    }
+
+private:
+    final_action & operator=( final_action const & );
+
+private:
+    Action action_;
+    mutable bool invoke_;
+};
+
+template< class F >
+inline final_action finally( F const & f )
+{
+    return final_action(( f ));
+}
+
+#if gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+class final_action_return : public final_action
+{
+public:
+    explicit final_action_return( Action action )
+        : final_action( action )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    ~final_action_return()
+    {
+        if ( std11::uncaught_exceptions() != exception_count )
+            this->dismiss();
+    }
+
+private:
+    final_action_return & operator=( final_action_return const & );
+
+private:
+    unsigned char exception_count;
+};
+
+template< class F >
+inline final_action_return on_return( F const & action )
+{
+    return final_action_return( action );
+}
+
+class final_action_error : public final_action
+{
+public:
+    explicit final_action_error( Action action )
+        : final_action( action )
+        , exception_count( std11::uncaught_exceptions() )
+    {}
+
+    ~final_action_error()
+    {
+        if ( std11::uncaught_exceptions() == exception_count )
+            this->dismiss();
+    }
+
+private:
+    final_action_error & operator=( final_action_error const & );
+
+private:
+    unsigned char exception_count;
+};
+
+template< class F >
+inline final_action_error on_error( F const & action )
+{
+    return final_action_error( action );
+}
+
+#endif // gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+#endif // gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION == 110
+
+#if gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 120
+
+template< class T, class U >
+gsl_api inline gsl_constexpr T narrow_cast( U && u ) gsl_noexcept
+{
+    return static_cast<T>( std::forward<U>( u ) );
+}
+
+#else
+
+template< class T, class U >
+gsl_api inline T narrow_cast( U u ) gsl_noexcept
+{
+    return static_cast<T>( u );
+}
+
+#endif // gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 120
+
+struct narrowing_error : public std::exception {};
+
+#if gsl_HAVE( TYPE_TRAITS )
+
+namespace detail {
+
+    template< class T, class U >
+    struct is_same_signedness : public std::integral_constant<bool, std::is_signed<T>::value == std::is_signed<U>::value>
+    {};
+
+# if defined( __NVCC__ )
+    // We do this to circumvent NVCC warnings about pointless unsigned comparisons with 0.
+    template< class T >
+    gsl_constexpr gsl_api bool is_negative( T value, std::true_type /*isSigned*/ ) gsl_noexcept
+    {
+        return value < T();
+    }
+    template< class T >
+    gsl_constexpr gsl_api bool is_negative( T /*value*/, std::false_type /*isUnsigned*/ ) gsl_noexcept
+    {
+        return false;
+    }
+    template< class T, class U >
+    gsl_constexpr gsl_api bool have_same_sign( T t, U u, std::true_type /*isSameSignedness*/ ) gsl_noexcept
+    {
+        return true;
+    }
+    template< class T, class U >
+    gsl_constexpr gsl_api bool have_same_sign( T t, U u, std::false_type /*isSameSignedness*/ ) gsl_noexcept
+    {
+        return detail::is_negative( t, std::is_signed<T>() ) == detail::is_negative( u, std::is_signed<U>() );
+    }
+# endif // defined( __NVCC__ )
+
+} // namespace detail
+
+#endif
+
+#if gsl_HAVE( EXCEPTIONS ) || !gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION
+template< class T, class U >
+# if !gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION && !defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+gsl_api
+# endif // !gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION && !defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+inline T narrow( U u )
+{
+    T t = static_cast<T>( u );
+
+    if ( static_cast<U>( t ) != u )
+    {
+# if gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION || defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+        throw narrowing_error();
+# else
+        std::terminate();
+# endif
+    }
+
+# if gsl_HAVE( TYPE_TRAITS )
+#  if defined( __NVCC__ )
+    if ( ! detail::have_same_sign( t, u, detail::is_same_signedness<T, U>() ) )
+#  else
+    gsl_SUPPRESS_MSVC_WARNING( 4127, "conditional expression is constant" )
+    if ( ! detail::is_same_signedness<T, U>::value && ( t < T() ) != ( u < U() ) )
+#  endif
+# else
+    // Don't assume T() works:
+    gsl_SUPPRESS_MSVC_WARNING( 4127, "conditional expression is constant" )
+    if ( ( t < 0 ) != ( u < 0 ) )
+# endif
+    {
+# if gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION || defined( gsl_CONFIG_CONTRACT_VIOLATION_THROWS )
+        throw narrowing_error();
+# else
+        std::terminate();
+# endif
+    }
+
+    return t;
+}
+#endif // gsl_HAVE( EXCEPTIONS ) || !gsl_CONFIG_NARROW_THROWS_ON_TRUNCATION
+
+template< class T, class U >
+gsl_api inline T narrow_failfast( U u )
+{
+    T t = static_cast<T>( u );
+
+    gsl_Expects( static_cast<U>( t ) == u );
+
+#if gsl_HAVE( TYPE_TRAITS )
+# if defined( __NVCC__ )
+    gsl_Expects( ::gsl::detail::have_same_sign( t, u, ::gsl::detail::is_same_signedness<T, U>() ) );
+# else
+    gsl_SUPPRESS_MSVC_WARNING( 4127, "conditional expression is constant" )
+    gsl_Expects( ( ::gsl::detail::is_same_signedness<T, U>::value || ( t < T() ) == ( u < U() ) ) );
+# endif
+#else
+    // Don't assume T() works:
+    gsl_SUPPRESS_MSVC_WARNING( 4127, "conditional expression is constant" )
+    gsl_Expects( ( t < 0 ) == ( u < 0 ) );
+#endif
+
+    return t;
+}
+
+
+//
+// at() - Bounds-checked way of accessing static arrays, std::array, std::vector.
+//
+
+template< class T, size_t N >
+gsl_api inline gsl_constexpr14 T & at( T(&arr)[N], size_t pos )
+{
+    gsl_Expects( pos < N );
+    return arr[pos];
+}
+
+template< class Container >
+inline gsl_constexpr14 typename Container::value_type & at( Container & cont, size_t pos )
+{
+    gsl_Expects( pos < cont.size() );
+    return cont[pos];
+}
+
+template< class Container >
+inline gsl_constexpr14 typename Container::value_type const & at( Container const & cont, size_t pos )
+{
+    gsl_Expects( pos < cont.size() );
+    return cont[pos];
+}
+
+#if gsl_HAVE( INITIALIZER_LIST )
+
+template< class T >
+inline const gsl_constexpr14 T at( std::initializer_list<T> cont, size_t pos )
+{
+    gsl_Expects( pos < cont.size() );
+    return *( cont.begin() + pos );
+}
+#endif
+
+template< class T >
+gsl_api inline gsl_constexpr14 T & at( span<T> s, size_t pos )
+{
+    return s[ pos ];
+}
+
+//
+// GSL.views: views
+//
+
+//
+// not_null<> - Wrap any indirection and enforce non-null.
+//
+
+template< class T >
+class not_null;
+
+namespace detail {
+
+// helper class to figure out the pointed-to type of a pointer
+#if gsl_CPP11_OR_GREATER
+template< class T, class E = void >
+struct element_type_helper
+{
+    // For types without a member element_type (this will handle raw pointers)
+    typedef typename std::remove_reference< decltype( *std::declval<T>() ) >::type type;
+};
+
+template< class T >
+struct element_type_helper< T, std17::void_t< typename T::element_type > >
+{
+    // For types with a member element_type
+    typedef typename T::element_type type;
+};
+#else
+// Pre-C++11, we cannot have decltype, so we cannot handle types without a member element_type
+template< class T, class E = void >
+struct element_type_helper
+{
+    typedef typename T::element_type type;
+};
+
+template< class T >
+struct element_type_helper< T* >
+{
+    typedef T type;
+};
+#endif
+
+template< class T >
+struct is_not_null_oracle : std11::false_type { };
+template< class T >
+struct is_not_null_oracle< not_null<T> > : std11::true_type { };
+
+template< class T, bool IsCopyable = true >
+struct not_null_data;
+#if gsl_HAVE( RVALUE_REFERENCE ) && gsl_HAVE( TYPE_TRAITS )
+template< class T >
+struct not_null_data< T, false >
+{
+    T ptr_;
+
+    gsl_constexpr14 not_null_data( T && _ptr ) gsl_noexcept
+    : ptr_( std::move( _ptr ) )
+    {
+    }
+    
+    gsl_constexpr14 not_null_data( not_null_data && other ) gsl_noexcept
+    : ptr_( std::move( other.ptr_ ) )
+    {
+    }
+    gsl_constexpr14 not_null_data & operator=( not_null_data && other ) gsl_noexcept
+    {
+        ptr_ = std::move( other.ptr_ );
+        return *this;
+    }
+
+gsl_is_delete_access:
+    not_null_data( not_null_data const & other ) gsl_is_delete;
+    not_null_data & operator=( not_null_data const & other ) gsl_is_delete;
+};
+#endif // gsl_HAVE( RVALUE_REFERENCE ) && gsl_HAVE( TYPE_TRAITS )
+template< class T >
+struct not_null_data< T, true >
+{
+    T ptr_;
+
+    gsl_constexpr14 not_null_data( T const & _ptr ) gsl_noexcept
+    : ptr_( _ptr )
+    {
+    }
+
+#if gsl_HAVE( RVALUE_REFERENCE )
+    gsl_constexpr14 not_null_data( T && _ptr ) gsl_noexcept
+    : ptr_( std::move( _ptr ) )
+    {
+    }
+    
+    gsl_constexpr14 not_null_data( not_null_data && other ) gsl_noexcept
+    : ptr_( std::move( other.ptr_ ) )
+    {
+    }
+    gsl_constexpr14 not_null_data & operator=( not_null_data && other ) gsl_noexcept
+    {
+        ptr_ = std::move( other.ptr_ );
+        return *this;
+    }
+#endif // gsl_HAVE( RVALUE_REFERENCE )
+
+    gsl_constexpr14 not_null_data( not_null_data const & other )
+    : ptr_( other.ptr_ )
+    {
+        gsl_Expects( ptr_ != gsl_nullptr );
+    }
+    gsl_constexpr14 not_null_data & operator=( not_null_data const & other )
+    {
+        gsl_Expects( other.ptr_ != gsl_nullptr );
+        ptr_ = other.ptr_;
+        return *this;
+    }
+};
+
+template< class T >
+struct is_copyable
+#if gsl_HAVE( TYPE_TRAITS )
+: std11::integral_constant< bool, std::is_copy_constructible<T>::value && std::is_copy_assignable<T>::value >
+#else
+: std11::true_type
+#endif
+{
+};
+#if gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( UNIQUE_PTR ) && gsl_BETWEEN( gsl_COMPILER_MSVC_VERSION, 1, 140 )
+// Type traits are buggy in VC++ 2013, so we explicitly declare `unique_ptr<>` non-copyable.
+template< class T, class Deleter >
+struct is_copyable< std::unique_ptr< T, Deleter > > : std11::false_type
+{
+};
+#endif
+
+} // namespace detail
+
+template< class T >
+class not_null
+{
+private:
+    detail::not_null_data< T, detail::is_copyable< T >::value > data_;
+
+    // need to access `not_null<U>::data_`
+    template< class U >
+    friend class not_null;
+
+public:
+    typedef typename detail::element_type_helper<T>::type element_type;
+
+#if gsl_HAVE( TYPE_TRAITS )
+    static_assert( std::is_assignable<T&, std::nullptr_t>::value, "T cannot be assigned nullptr." );
+#endif
+
+#if gsl_CONFIG( NOT_NULL_EXPLICIT_CTOR )
+# if gsl_HAVE( RVALUE_REFERENCE )
+    template< class U
+    // In Clang 3.x, `is_constructible<not_null<unique_ptr<X>>, unique_ptr<X>>` tries to instantiate the copy constructor of `unique_ptr<>`, triggering an error.
+    // Note that Apple Clang's `__clang_major__` etc. are different from regular Clang.
+#  if gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<T, U>::value ), int >::type = 0
+#  endif
+    >
+    gsl_constexpr14 explicit not_null( U other )
+    : data_( T( std::move( other ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+# else // a.k.a. !gsl_HAVE( RVALUE_REFERENCE )
+    template< class U >
+    gsl_constexpr14 explicit not_null( U const& other )
+    : data_( T( other ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+# endif // gsl_HAVE( RVALUE_REFERENCE )
+#else // a.k.a. !gsl_CONFIG( NOT_NULL_EXPLICIT_CTOR )
+# if gsl_HAVE( RVALUE_REFERENCE )
+    // In Clang 3.x, `is_constructible<not_null<unique_ptr<X>>, unique_ptr<X>>` tries to instantiate the copy constructor of `unique_ptr<>`, triggering an error.
+    // Note that Apple Clang's `__clang_major__` etc. are different from regular Clang.
+#  if gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<T, U>::value && !std::is_convertible<U, T>::value ), int >::type = 0
+    >
+    gsl_constexpr14 explicit not_null( U other )
+    : data_( T( std::move( other ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_convertible<U, T>::value ), int >::type = 0
+    >
+    gsl_constexpr14 not_null( U other )
+    : data_( T( std::move( other ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+#  else // a.k.a. !( gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+    // If type_traits are not available, then we can't distinguish `is_convertible<>` and `is_constructible<>`, so we unconditionally permit implicit construction.
+    template< class U >
+    gsl_constexpr14 not_null( U other )
+    : data_( T( std::move( other ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+#  endif // gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+# else // a.k.a. !gsl_HAVE( RVALUE_REFERENCE )
+    template< class U >
+    gsl_constexpr14 not_null( U const& other )
+    : data_( T( other ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+# endif // gsl_HAVE( RVALUE_REFERENCE )
+#endif // gsl_CONFIG( NOT_NULL_EXPLICIT_CTOR )
+
+# if gsl_HAVE( RVALUE_REFERENCE )
+    // In Clang 3.x, `is_constructible<not_null<unique_ptr<X>>, unique_ptr<X>>` tries to instantiate the copy constructor of `unique_ptr<>`, triggering an error.
+    // Note that Apple Clang's `__clang_major__` etc. are different from regular Clang.
+#  if gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<T, U>::value && !std::is_convertible<U, T>::value ), int >::type = 0
+    >
+    gsl_constexpr14 explicit not_null( not_null<U> other )
+    : data_( T( std::move( other.data_.ptr_ ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_convertible<U, T>::value ), int >::type = 0
+    >
+    gsl_constexpr14 not_null( not_null<U> other )
+    : data_( T( std::move( other.data_.ptr_ ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+#  else // a.k.a. !( gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+    // If type_traits are not available, then we can't distinguish `is_convertible<>` and `is_constructible<>`, so we unconditionally permit implicit construction.
+    template< class U >
+    gsl_constexpr14 not_null( not_null<U> other )
+    : data_( T( std::move( other.data_.ptr_ ) ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+    template< class U >
+    gsl_constexpr14 not_null<T>& operator=( not_null<U> other )
+    {
+        gsl_Expects( other.data_.ptr_ != gsl_nullptr );
+        data_.ptr_ = std::move( other.data_.ptr_ );
+        return *this;
+    }
+#  endif // gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && !gsl_BETWEEN( gsl_COMPILER_CLANG_VERSION, 1, 400 ) && !gsl_BETWEEN( gsl_COMPILER_APPLECLANG_VERSION, 1, 1001 )
+# else // a.k.a. !gsl_HAVE( RVALUE_REFERENCE )
+    template< class U >
+    gsl_constexpr14 not_null( not_null<U> const& other )
+    : data_( T( other.data_.ptr_ ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+    template< class U >
+    gsl_constexpr14 not_null<T>& operator=( not_null<U> const & other )
+    {
+        gsl_Expects( other.data_.ptr_ != gsl_nullptr );
+        data_.ptr_ = other.data_.ptr_;
+        return *this;
+    }
+# endif // gsl_HAVE( RVALUE_REFERENCE )
+
+#if gsl_CONFIG( TRANSPARENT_NOT_NULL )
+    gsl_constexpr14 element_type *
+    get() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_.get();
+    }
+#else
+# if gsl_CONFIG( NOT_NULL_GET_BY_CONST_REF )
+    gsl_constexpr14 T const & get() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_;
+    }
+# else
+    gsl_constexpr14 T get() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_;
+    }
+# endif
+#endif
+
+    // We want an implicit conversion operator that can be used to convert from both lvalues (by
+    // const reference or by copy) and rvalues (by move). So it seems like we could define
+    //
+    //     template< class U >
+    //     operator U const &() const & { ... }
+    //     template< class U >
+    //     operator U &&() && { ... }
+    //
+    // However, having two conversion operators with different return types renders the assignment
+    // operator of the result type ambiguous:
+    //
+    //     not_null<std::unique_ptr<T>> p( ... );
+    //     std::unique_ptr<U> q;
+    //     q = std::move( p ); // ambiguous
+    //
+    // To avoid this ambiguity, we have both overloads of the conversion operator return `U`
+    // rather than `U const &` or `U &&`. This implies that converting an lvalue always induces
+    // a copy, which can cause unnecessary copies or even fail to compile in some situations:
+    //
+    //     not_null<std::shared_ptr<T>> sp( ... );
+    //     std::shared_ptr<U> const & rs = sp; // unnecessary copy
+    //     std::unique_ptr<U> const & ru = p; // error: cannot copy `unique_ptr<T>`
+    //
+    // However, these situations are rather unusual, and the following, more frequent situations
+    // remain unimpaired:
+    //
+    //     std::shared_ptr<U> vs = sp; // no extra copy
+    //     std::unique_ptr<U> vu = std::move( p );
+
+#if gsl_HAVE( RVALUE_REFERENCE ) && gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && gsl_HAVE( EXPLICIT )
+    // explicit conversion operator
+
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<U, T const &>::value && !std::is_convertible<T, U>::value && !detail::is_not_null_oracle<U>::value ), int >::type = 0
+    >
+    gsl_constexpr14 explicit
+    operator U() const
+# if gsl_HAVE( FUNCTION_REF_QUALIFIER )
+    &
+# endif
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return U( data_.ptr_ );
+    }
+# if gsl_HAVE( FUNCTION_REF_QUALIFIER )
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<U, T>::value && !std::is_convertible<T, U>::value && !detail::is_not_null_oracle<U>::value ), int >::type = 0
+    >
+    gsl_constexpr14 explicit
+    operator U() &&
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return U( std::move( data_.ptr_ ) );
+    }
+# endif
+
+    // implicit conversion operator
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_constructible<U, T const &>::value && std::is_convertible<T, U>::value && !detail::is_not_null_oracle<U>::value ), int >::type = 0
+    >
+    gsl_constexpr14
+    operator U() const
+# if gsl_HAVE( FUNCTION_REF_QUALIFIER )
+    &
+# endif
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_;
+    }
+# if gsl_HAVE( FUNCTION_REF_QUALIFIER )
+    template< class U
+        // We *have* to use SFINAE with an NTTP arg here, otherwise the overload is ambiguous.
+        , typename std::enable_if< ( std::is_convertible<T, U>::value && !detail::is_not_null_oracle<U>::value ), int >::type = 0
+    >
+    gsl_constexpr14
+    operator U() &&
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return std::move( data_.ptr_ );
+    }
+# endif
+#else // a.k.a. #if !( gsl_HAVE( RVALUE_REFERENCE ) && gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && gsl_HAVE( EXPLICIT ) )
+    template< class U >
+    gsl_constexpr14
+    operator U() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_;
+    }
+#endif // gsl_HAVE( RVALUE_REFERENCE ) && gsl_HAVE( TYPE_TRAITS ) && gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) && gsl_HAVE( EXPLICIT )
+
+    gsl_constexpr14 T const &
+    operator->() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return data_.ptr_;
+    }
+
+    gsl_constexpr14 element_type &
+    operator*() const
+    {
+        gsl_Ensures( data_.ptr_ != gsl_nullptr );
+        return *data_.ptr_;
+    }
+
+#if gsl_HAVE( RVALUE_REFERENCE )
+    // Visual C++ 2013 doesn't generate default move constructors, so we declare them explicitly.
+    gsl_constexpr14 not_null( not_null && other ) gsl_noexcept
+    : data_( std::move( other.data_ ) )
+    {
+        gsl_Expects( data_.ptr_ != gsl_nullptr );
+    }
+    gsl_constexpr14 not_null & operator=( not_null && other ) gsl_noexcept
+    {
+        gsl_Expects( other.data_.ptr_ != gsl_nullptr );
+        data_ = std::move( other.data_ );
+        return *this;
+    }
+#endif // gsl_HAVE( RVALUE_REFERENCE )
+
+#if gsl_HAVE( IS_DEFAULT )
+    gsl_constexpr14 not_null( not_null const & other ) = default;
+    gsl_constexpr14 not_null & operator=( not_null const & other ) = default;
+#endif
+
+gsl_is_delete_access:
+    not_null() gsl_is_delete;
+    // prevent compilation when initialized with a nullptr or literal 0:
+#if gsl_HAVE( NULLPTR )
+    not_null(             std::nullptr_t ) gsl_is_delete;
+    not_null & operator=( std::nullptr_t ) gsl_is_delete;
+#else
+    not_null(             int ) gsl_is_delete;
+    not_null & operator=( int ) gsl_is_delete;
+#endif
+
+    // unwanted operators...pointers only point to single objects!
+    not_null & operator++() gsl_is_delete;
+    not_null & operator--() gsl_is_delete;
+    not_null   operator++( int ) gsl_is_delete;
+    not_null   operator--( int ) gsl_is_delete;
+    not_null & operator+ ( size_t ) gsl_is_delete;
+    not_null & operator+=( size_t ) gsl_is_delete;
+    not_null & operator- ( size_t ) gsl_is_delete;
+    not_null & operator-=( size_t ) gsl_is_delete;
+    not_null & operator+=( std::ptrdiff_t ) gsl_is_delete;
+    not_null & operator-=( std::ptrdiff_t ) gsl_is_delete;
+    void       operator[]( std::ptrdiff_t ) const gsl_is_delete;
+};
+#if gsl_HAVE( DEDUCTION_GUIDES )
+template< class U >
+not_null( U ) -> not_null<U>;
+template< class U >
+not_null( not_null<U> ) -> not_null<U>;
+#endif
+
+#if gsl_HAVE( NULLPTR )
+void make_not_null( std::nullptr_t ) gsl_is_delete;
+#endif // gsl_HAVE( NULLPTR )
+#if gsl_HAVE( RVALUE_REFERENCE )
+template< class U >
+not_null<U> make_not_null( U u )
+{
+    return not_null<U>( std::move( u ) );
+}
+template< class U >
+not_null<U> make_not_null( not_null<U> u )
+{
+    return std::move( u );
+}
+#else // a.k.a. !gsl_HAVE( RVALUE_REFERENCE )
+template< class U >
+not_null<U> make_not_null( U const & u )
+{
+    return not_null<U>( u );
+}
+template< class U >
+not_null<U> make_not_null( not_null<U> const & u )
+{
+    return u;
+}
+#endif // gsl_HAVE( RVALUE_REFERENCE )
+
+
+// not_null with implicit constructor, allowing copy-initialization:
+
+template< class T >
+class not_null_ic : public not_null<T>
+{
+public:
+    template< class U
+        gsl_ENABLE_IF_(( std::is_constructible<T, U>::value ))
+    >
+    gsl_constexpr14
+#if gsl_HAVE( RVALUE_REFERENCE )
+    not_null_ic( U && u )
+    : not_null<T>( std::forward<U>( u ) )
+#else
+    not_null_ic( U const & u )
+    : not_null<T>( u )
+#endif
+    {}
+};
+
+// more not_null unwanted operators
+
+template< class T, class U >
+std::ptrdiff_t operator-( not_null<T> const &, not_null<U> const & ) gsl_is_delete;
+
+template< class T >
+not_null<T> operator-( not_null<T> const &, std::ptrdiff_t ) gsl_is_delete;
+
+template< class T >
+not_null<T> operator+( not_null<T> const &, std::ptrdiff_t ) gsl_is_delete;
+
+template< class T >
+not_null<T> operator+( std::ptrdiff_t, not_null<T> const & ) gsl_is_delete;
+
+// not_null comparisons
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() == std::declval<U const>() )
+operator==( not_null<T> const & l, not_null<U> const & r )
+{
+    return l.operator->() == r.operator->();
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() == std::declval<U const>() )
+operator==( not_null<T> const & l, U const & r )
+{
+    return l.operator->() == r;
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() == std::declval<U const>() )
+operator==( T const & l, not_null<U> const & r )
+{
+    return l == r.operator->();
+}
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() < std::declval<U const>() )
+operator<( not_null<T> const & l, not_null<U> const & r )
+{
+    return l.operator->() < r.operator->();
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() < std::declval<U const>() )
+operator<( not_null<T> const & l, U const & r )
+{
+    return l.operator->() < r;
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<T const>() < std::declval<U const>() )
+operator<( T const & l, not_null<U> const & r )
+{
+    return l < r.operator->();
+}
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() == std::declval<U const>() ) )
+operator!=( not_null<T> const & l, not_null<U> const & r )
+{
+    return !( l == r );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() == std::declval<U const>() ) )
+operator!=( not_null<T> const & l, U const & r )
+{
+    return !( l == r );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() == std::declval<U const>() ) )
+operator!=( T const & l, not_null<U> const & r )
+{
+    return !( l == r );
+}
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<U const>() < std::declval<T const>() ) )
+operator<=( not_null<T> const & l, not_null<U> const & r )
+{
+    return !( r < l );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<U const>() < std::declval<T const>() ) )
+operator<=( not_null<T> const & l, U const & r )
+{
+    return !( r < l );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<U const>() < std::declval<T const>() ) )
+operator<=( T const & l, not_null<U> const & r )
+{
+    return !( r < l );
+}
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<U const>() < std::declval<T const>() )
+operator>( not_null<T> const & l, not_null<U> const & r )
+{
+    return r < l;
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<U const>() < std::declval<T const>() )
+operator>( not_null<T> const & l, U const & r )
+{
+    return r < l;
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, std::declval<U const>() < std::declval<T const>() )
+operator>( T const & l, not_null<U> const & r )
+{
+    return r < l;
+}
+
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() < std::declval<U const>() ) )
+operator>=( not_null<T> const & l, not_null<U> const & r )
+{
+    return !( l < r );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() < std::declval<U const>() ) )
+operator>=( not_null<T> const & l, U const & r )
+{
+    return !( l < r );
+}
+template< class T, class U >
+inline gsl_constexpr gsl_DECLTYPE_( bool, !( std::declval<T const>() < std::declval<U const>() ) )
+operator>=( T const & l, not_null<U> const & r )
+{
+    return !( l < r );
+}
+
+// print not_null
+
+template< class CharType, class Traits, class T >
+std::basic_ostream< CharType, Traits > & operator<<( std::basic_ostream< CharType, Traits > & os, not_null<T> const & p )
+{
+    return os << p.operator->();
+}
+
+
+//
+// Byte-specific type.
+//
+#if gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+  enum class gsl_may_alias byte : unsigned char {};
+#else
+  struct gsl_may_alias byte { typedef unsigned char type; type v; };
+#endif
+
+template< class T >
+gsl_api inline gsl_constexpr byte to_byte( T v ) gsl_noexcept
+{
+#if    gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+    return static_cast<byte>( v );
+#elif  gsl_HAVE( CONSTEXPR_11 )
+    return { static_cast<typename byte::type>( v ) };
+#else
+    byte b = { static_cast<typename byte::type>( v ) }; return b;
+#endif
+}
+
+template< class IntegerType  gsl_ENABLE_IF_(( std::is_integral<IntegerType>::value )) >
+gsl_api inline gsl_constexpr IntegerType to_integer( byte b ) gsl_noexcept
+{
+#if gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+    return static_cast<typename std::underlying_type<byte>::type>( b );
+#else
+    return b.v;
+#endif
+}
+
+gsl_api inline gsl_constexpr unsigned char to_uchar( byte b ) gsl_noexcept
+{
+    return to_integer<unsigned char>( b );
+}
+
+gsl_api inline gsl_constexpr unsigned char to_uchar( int i ) gsl_noexcept
+{
+    return static_cast<unsigned char>( i );
+}
+
+template< class IntegerType  gsl_ENABLE_IF_(( std::is_integral<IntegerType>::value )) >
+gsl_api inline gsl_constexpr14 byte & operator<<=( byte & b, IntegerType shift ) gsl_noexcept
+{
+#if gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+    return b = ::gsl::to_byte( ::gsl::to_uchar( b ) << shift );
+#else
+    b.v = ::gsl::to_uchar( b.v << shift ); return b;
+#endif
+}
+
+template< class IntegerType  gsl_ENABLE_IF_(( std::is_integral<IntegerType>::value )) >
+gsl_api inline gsl_constexpr byte operator<<( byte b, IntegerType shift ) gsl_noexcept
+{
+    return ::gsl::to_byte( ::gsl::to_uchar( b ) << shift );
+}
+
+template< class IntegerType  gsl_ENABLE_IF_(( std::is_integral<IntegerType>::value )) >
+gsl_api inline gsl_constexpr14 byte & operator>>=( byte & b, IntegerType shift ) gsl_noexcept
+{
+#if gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+    return b = ::gsl::to_byte( ::gsl::to_uchar( b ) >> shift );
+#else
+    b.v = ::gsl::to_uchar( b.v >> shift ); return b;
+#endif
+}
+
+template< class IntegerType  gsl_ENABLE_IF_(( std::is_integral<IntegerType>::value )) >
+gsl_api inline gsl_constexpr byte operator>>( byte b, IntegerType shift ) gsl_noexcept
+{
+    return ::gsl::to_byte( ::gsl::to_uchar( b ) >> shift );
+}
+
+#if gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+gsl_DEFINE_ENUM_BITMASK_OPERATORS( byte )
+gsl_DEFINE_ENUM_RELATIONAL_OPERATORS( byte )
+#else // a.k.a. !gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+gsl_api inline gsl_constexpr bool operator==( byte l, byte r ) gsl_noexcept
+{
+    return l.v == r.v;
+}
+
+gsl_api inline gsl_constexpr bool operator!=( byte l, byte r ) gsl_noexcept
+{
+    return !( l == r );
+}
+
+gsl_api inline gsl_constexpr bool operator< ( byte l, byte r ) gsl_noexcept
+{
+    return l.v < r.v;
+}
+
+gsl_api inline gsl_constexpr bool operator<=( byte l, byte r ) gsl_noexcept
+{
+    return !( r < l );
+}
+
+gsl_api inline gsl_constexpr bool operator> ( byte l, byte r ) gsl_noexcept
+{
+    return ( r < l );
+}
+
+gsl_api inline gsl_constexpr bool operator>=( byte l, byte r ) gsl_noexcept
+{
+    return !( l < r );
+}
+
+gsl_api inline gsl_constexpr14 byte & operator|=( byte & l, byte r ) gsl_noexcept
+{
+    l.v |= r.v; return l;
+}
+
+gsl_api inline gsl_constexpr byte operator|( byte l, byte r ) gsl_noexcept
+{
+    return ::gsl::to_byte( l.v | r.v );
+}
+
+gsl_api inline gsl_constexpr14 byte & operator&=( byte & l, byte r ) gsl_noexcept
+{
+    l.v &= r.v; return l;
+}
+
+gsl_api inline gsl_constexpr byte operator&( byte l, byte r ) gsl_noexcept
+{
+    return ::gsl::to_byte( l.v & r.v );
+}
+
+gsl_api inline gsl_constexpr14 byte & operator^=( byte & l, byte r ) gsl_noexcept
+{
+    l.v ^= r.v; return l;
+}
+
+gsl_api inline gsl_constexpr byte operator^( byte l, byte r ) gsl_noexcept
+{
+    return ::gsl::to_byte( l.v ^ r.v );
+}
+
+gsl_api inline gsl_constexpr byte operator~( byte b ) gsl_noexcept
+{
+    return ::gsl::to_byte( ~b.v );
+}
+#endif // gsl_HAVE( ENUM_CLASS_CONSTRUCTION_FROM_UNDERLYING_TYPE )
+
+#if gsl_FEATURE_TO_STD( WITH_CONTAINER )
+
+// Tag to select span constructor taking a container:
+
+struct with_container_t { gsl_constexpr with_container_t() gsl_noexcept {} };
+const  gsl_constexpr   with_container_t with_container; // TODO: this can lead to ODR violations because the symbol will be defined in multiple translation units
+
+#endif
+
+//
+// span<> - A 1D view of contiguous T's, replace (*,len).
+//
+template< class T >
+class span
+{
+    template< class U > friend class span;
+
+public:
+    typedef gsl_CONFIG_SPAN_INDEX_TYPE index_type;
+
+    typedef T element_type;
+    typedef typename std11::remove_cv< T >::type value_type;
+
+    typedef T & reference;
+    typedef T * pointer;
+    typedef T const * const_pointer;
+    typedef T const & const_reference;
+
+    typedef pointer       iterator;
+    typedef const_pointer const_iterator;
+
+    typedef std::reverse_iterator< iterator >       reverse_iterator;
+    typedef std::reverse_iterator< const_iterator > const_reverse_iterator;
+
+    typedef typename std::iterator_traits< iterator >::difference_type difference_type;
+
+    // 26.7.3.2 Constructors, copy, and assignment [span.cons]
+
+    gsl_api gsl_constexpr14 span() gsl_noexcept
+        : first_( gsl_nullptr )
+        , last_ ( gsl_nullptr )
+    {
+    }
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 5 )
+
+#if gsl_HAVE( NULLPTR )
+    gsl_api gsl_constexpr14 span( std::nullptr_t, index_type size_in )
+        : first_( nullptr )
+        , last_ ( nullptr )
+    {
+        gsl_Expects( size_in == 0 );
+    }
+#endif
+
+#if gsl_HAVE( IS_DELETE )
+    gsl_DEPRECATED
+    gsl_api gsl_constexpr span( reference data_in )
+        : span( &data_in, 1 )
+    {}
+
+    gsl_api gsl_constexpr span( element_type && ) = delete;
+#endif
+
+#endif // deprecate
+
+    gsl_api gsl_constexpr14 span( pointer data_in, index_type size_in )
+        : first_( data_in )
+        , last_ ( data_in + size_in )
+    {
+        gsl_Expects( size_in == 0 || ( size_in > 0 && data_in != gsl_nullptr ) );
+    }
+
+    gsl_api gsl_constexpr14 span( pointer first_in, pointer last_in )
+        : first_( first_in )
+        , last_ ( last_in )
+    {
+        gsl_Expects( first_in <= last_in );
+    }
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 5 )
+
+    template< class U >
+    gsl_api gsl_constexpr14 span( U * data_in, index_type size_in )
+        : first_( data_in )
+        , last_ ( data_in + size_in )
+    {
+        gsl_Expects( size_in == 0 || ( size_in > 0 && data_in != gsl_nullptr ) );
+    }
+
+#endif // deprecate
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 5 )
+    template< class U, size_t N >
+    gsl_api gsl_constexpr span( U (&arr)[N] ) gsl_noexcept
+        : first_( gsl_ADDRESSOF( arr[0] ) )
+        , last_ ( gsl_ADDRESSOF( arr[0] ) + N )
+    {}
+#else
+    template< size_t N
+        gsl_ENABLE_IF_(( std::is_convertible<value_type(*)[], element_type(*)[] >::value ))
+    >
+    gsl_api gsl_constexpr span( element_type (&arr)[N] ) gsl_noexcept
+        : first_( gsl_ADDRESSOF( arr[0] ) )
+        , last_ ( gsl_ADDRESSOF( arr[0] ) + N )
+    {}
+#endif // deprecate
+
+#if gsl_HAVE( ARRAY )
+#if ! gsl_DEPRECATE_TO_LEVEL( 5 )
+
+    template< class U, size_t N >
+    gsl_constexpr span( std::array< U, N > & arr )
+        : first_( arr.data() )
+        , last_ ( arr.data() + N )
+    {}
+
+    template< class U, size_t N >
+    gsl_constexpr span( std::array< U, N > const & arr )
+        : first_( arr.data() )
+        , last_ ( arr.data() + N )
+    {}
+
+#else
+
+    template< size_t N
+        gsl_ENABLE_IF_(( std::is_convertible<value_type(*)[], element_type(*)[] >::value ))
+    >
+    gsl_constexpr span( std::array< value_type, N > & arr )
+        : first_( arr.data() )
+        , last_ ( arr.data() + N )
+    {}
+
+    template< size_t N
+        gsl_ENABLE_IF_(( std::is_convertible<value_type(*)[], element_type(*)[] >::value ))
+    >
+    gsl_constexpr span( std::array< value_type, N > const & arr )
+        : first_( arr.data() )
+        , last_ ( arr.data() + N )
+    {}
+
+#endif // deprecate
+#endif // gsl_HAVE( ARRAY )
+
+#if gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR )
+    template< class Container
+        gsl_ENABLE_IF_(( detail::is_compatible_container< Container, element_type >::value ))
+    >
+    gsl_constexpr span( Container & cont ) gsl_noexcept
+        : first_( std17::data( cont ) )
+        , last_ ( std17::data( cont ) + std17::size( cont ) )
+    {}
+
+    template< class Container
+        gsl_ENABLE_IF_((
+            std::is_const< element_type >::value
+            && detail::is_compatible_container< Container, element_type >::value
+        ))
+    >
+    gsl_constexpr span( Container const & cont ) gsl_noexcept
+        : first_( std17::data( cont ) )
+        , last_ ( std17::data( cont ) + std17::size( cont ) )
+    {}
+
+#elif gsl_HAVE( UNCONSTRAINED_SPAN_CONTAINER_CTOR )
+
+    template< class Container >
+    gsl_constexpr span( Container & cont )
+        : first_( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) )
+        , last_ ( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) + cont.size() )
+    {}
+
+    template< class Container >
+    gsl_constexpr span( Container const & cont )
+        : first_( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) )
+        , last_ ( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) + cont.size() )
+    {}
+
+#endif
+
+#if gsl_FEATURE_TO_STD( WITH_CONTAINER )
+
+    template< class Container >
+    gsl_constexpr span( with_container_t, Container & cont ) gsl_noexcept
+        : first_( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) )
+        , last_ ( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) + cont.size() )
+    {}
+
+    template< class Container >
+    gsl_constexpr span( with_container_t, Container const & cont ) gsl_noexcept
+        : first_( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) )
+        , last_ ( cont.size() == 0 ? gsl_nullptr : gsl_ADDRESSOF( cont[0] ) + cont.size() )
+    {}
+
+#endif
+
+#if !gsl_DEPRECATE_TO_LEVEL( 4 )
+    // constructor taking shared_ptr deprecated since 0.29.0
+
+# if gsl_HAVE( SHARED_PTR )
+    gsl_DEPRECATED
+    gsl_constexpr span( shared_ptr<element_type> const & ptr )
+        : first_( ptr.get() )
+        , last_ ( ptr.get() ? ptr.get() + 1 : gsl_nullptr )
+    {}
+# endif
+
+    // constructors taking unique_ptr deprecated since 0.29.0
+
+# if gsl_HAVE( UNIQUE_PTR )
+#  if gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG )
+    template< class ArrayElementType = typename std::add_pointer<element_type>::type >
+#  else
+    template< class ArrayElementType >
+#  endif
+    gsl_DEPRECATED
+    gsl_constexpr span( unique_ptr<ArrayElementType> const & ptr, index_type count )
+        : first_( ptr.get() )
+        , last_ ( ptr.get() + count )
+    {}
+
+    gsl_DEPRECATED
+    gsl_constexpr span( unique_ptr<element_type> const & ptr )
+        : first_( ptr.get() )
+        , last_ ( ptr.get() ? ptr.get() + 1 : gsl_nullptr )
+    {}
+# endif
+
+#endif // deprecate shared_ptr, unique_ptr
+
+#if gsl_HAVE( IS_DEFAULT ) && ! gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 430, 600)
+    gsl_constexpr span( span && ) gsl_noexcept = default;
+    gsl_constexpr span( span const & ) = default;
+#else
+    gsl_api gsl_constexpr span( span const & other )
+        : first_( other.begin() )
+        , last_ ( other.end() )
+    {}
+#endif
+
+#if gsl_HAVE( IS_DEFAULT )
+    gsl_constexpr14 span & operator=( span && ) gsl_noexcept = default;
+    gsl_constexpr14 span & operator=( span const & ) gsl_noexcept = default;
+#else
+    gsl_constexpr14 span & operator=( span other ) gsl_noexcept
+    {
+        first_ = other.first_;
+        last_ = other.last_;
+        return *this;
+    }
+#endif
+
+    template< class U
+        gsl_ENABLE_IF_(( std::is_convertible<U(*)[], element_type(*)[]>::value ))
+    >
+    gsl_api gsl_constexpr span( span<U> const & other )
+        : first_( other.begin() )
+        , last_ ( other.end() )
+    {}
+
+#if 0
+    // Converting from other span ?
+    template< class U > operator=();
+#endif
+
+    // 26.7.3.3 Subviews [span.sub]
+
+    gsl_api gsl_constexpr14 span first( index_type count ) const
+    {
+        gsl_Expects( std::size_t( count ) <= std::size_t( this->size() ) );
+        return span( this->data(), count );
+    }
+
+    gsl_api gsl_constexpr14 span last( index_type count ) const
+    {
+        gsl_Expects( std::size_t( count ) <= std::size_t( this->size() ) );
+        return span( this->data() + this->size() - count, count );
+    }
+
+    gsl_api gsl_constexpr14 span subspan( index_type offset ) const
+    {
+        gsl_Expects( std::size_t( offset ) <= std::size_t( this->size() ) );
+        return span( this->data() + offset, this->size() - offset );
+    }
+
+    gsl_api gsl_constexpr14 span subspan( index_type offset, index_type count ) const
+    {
+        gsl_Expects(
+            std::size_t( offset ) <= std::size_t( this->size() ) &&
+            std::size_t( count ) <= std::size_t( this->size() - offset ) );
+        return span( this->data() + offset, count );
+    }
+
+    // 26.7.3.4 Observers [span.obs]
+
+    gsl_api gsl_constexpr index_type size() const gsl_noexcept
+    {
+        return narrow_cast<index_type>( last_ - first_ );
+    }
+
+    gsl_api gsl_constexpr std::ptrdiff_t ssize() const gsl_noexcept
+    {
+        return narrow_cast<std::ptrdiff_t>( last_ - first_ );
+    }
+
+    gsl_api gsl_constexpr index_type size_bytes() const gsl_noexcept
+    {
+        return size() * narrow_cast<index_type>( sizeof( element_type ) );
+    }
+
+    gsl_api gsl_constexpr bool empty() const gsl_noexcept
+    {
+        return size() == 0;
+    }
+
+    // 26.7.3.5 Element access [span.elem]
+
+    gsl_api gsl_constexpr14 reference operator[]( index_type pos ) const
+    {
+        gsl_Expects( pos < size() );
+        return first_[ pos ];
+    }
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 6 )
+    gsl_DEPRECATED_MSG("use subscript indexing instead")
+    gsl_api gsl_constexpr14 reference operator()( index_type pos ) const
+    {
+        return (*this)[ pos ];
+    }
+
+    gsl_DEPRECATED_MSG("use subscript indexing instead")
+    gsl_api gsl_constexpr14 reference at( index_type pos ) const
+    {
+        return (*this)[ pos ];
+    }
+#endif // deprecate
+
+    gsl_api gsl_constexpr14 reference front() const
+    {
+        gsl_Expects( first_ != last_ );
+        return *first_;
+    }
+
+    gsl_api gsl_constexpr14 reference back() const
+    {
+        gsl_Expects( first_ != last_ );
+        return *(last_ - 1);
+    }
+
+    gsl_api gsl_constexpr pointer data() const gsl_noexcept
+    {
+        return first_;
+    }
+
+    // 26.7.3.6 Iterator support [span.iterators]
+
+    gsl_api gsl_constexpr iterator begin() const gsl_noexcept
+    {
+        return iterator( first_ );
+    }
+
+    gsl_api gsl_constexpr iterator end() const gsl_noexcept
+    {
+        return iterator( last_ );
+    }
+
+    gsl_api gsl_constexpr const_iterator cbegin() const gsl_noexcept
+    {
+#if gsl_CPP11_OR_GREATER
+        return { begin() };
+#else
+        return const_iterator( begin() );
+#endif
+    }
+
+    gsl_api gsl_constexpr const_iterator cend() const gsl_noexcept
+    {
+#if gsl_CPP11_OR_GREATER
+        return { end() };
+#else
+        return const_iterator( end() );
+#endif
+    }
+
+    gsl_constexpr17 reverse_iterator rbegin() const gsl_noexcept
+    {
+        return reverse_iterator( end() );
+    }
+
+    gsl_constexpr17 reverse_iterator rend() const gsl_noexcept
+    {
+        return reverse_iterator( begin() );
+    }
+
+    gsl_constexpr17 const_reverse_iterator crbegin() const gsl_noexcept
+    {
+        return const_reverse_iterator( cend() );
+    }
+
+    gsl_constexpr17 const_reverse_iterator crend() const gsl_noexcept
+    {
+        return const_reverse_iterator( cbegin() );
+    }
+
+    gsl_constexpr14 void swap( span & other ) gsl_noexcept
+    {
+        std::swap( first_, other.first_ );
+        std::swap( last_ , other.last_  );
+    }
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 3 )
+    // member length() deprecated since 0.29.0
+
+    gsl_DEPRECATED_MSG("use size() instead")
+    gsl_api gsl_constexpr index_type length() const gsl_noexcept
+    {
+        return size();
+    }
+
+    // member length_bytes() deprecated since 0.29.0
+
+    gsl_DEPRECATED_MSG("use size_bytes() instead")
+    gsl_api gsl_constexpr index_type length_bytes() const gsl_noexcept
+    {
+        return size_bytes();
+    }
+#endif
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 2 )
+    // member as_bytes(), as_writeable_bytes deprecated since 0.17.0
+
+    gsl_DEPRECATED_MSG("use free function gsl::as_bytes() instead")
+    gsl_api span< const byte > as_bytes() const gsl_noexcept
+    {
+        return span< const byte >( reinterpret_cast<const byte *>( data() ), size_bytes() ); // NOLINT
+    }
+
+    gsl_DEPRECATED_MSG("use free function gsl::as_writable_bytes() instead")
+    gsl_api span< byte > as_writeable_bytes() const gsl_noexcept
+    {
+        return span< byte >( reinterpret_cast<byte *>( data() ), size_bytes() ); // NOLINT
+    }
+
+#endif
+
+    template< class U >
+    gsl_api span< U > as_span() const
+    {
+        gsl_Expects( ( this->size_bytes() % sizeof(U) ) == 0 );
+        return span< U >( reinterpret_cast<U *>( this->data() ), this->size_bytes() / sizeof( U ) ); // NOLINT
+    }
+
+private:
+    pointer first_;
+    pointer last_;
+};
+
+// class template argument deduction guides:
+
+#if gsl_HAVE( DEDUCTION_GUIDES )   // gsl_CPP17_OR_GREATER
+
+template< class T, size_t N >
+span( T (&)[N] ) -> span<T /*, N*/>;
+
+template< class T, size_t N >
+span( std::array<T, N> & ) -> span<T /*, N*/>;
+
+template< class T, size_t N >
+span( std::array<T, N> const & ) -> span<const T /*, N*/>;
+
+template< class Container >
+span( Container& ) -> span<typename Container::value_type>;
+
+template< class Container >
+span( Container const & ) -> span<const typename Container::value_type>;
+
+#endif // gsl_HAVE( DEDUCTION_GUIDES )
+
+// 26.7.3.7 Comparison operators [span.comparison]
+
+#if gsl_CONFIG( ALLOWS_SPAN_COMPARISON )
+# if gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T, class U >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr bool operator==( span<T> const & l, span<U> const & r )
+{
+    return  l.size()  == r.size()
+        && (l.begin() == r.begin() || std::equal( l.begin(), l.end(), r.begin() ) );
+}
+
+template< class T, class U >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr bool operator< ( span<T> const & l, span<U> const & r )
+{
+    return std::lexicographical_compare( l.begin(), l.end(), r.begin(), r.end() );
+}
+
+# else // a.k.a. !gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr bool operator==( span<T> const & l, span<T> const & r )
+{
+    return  l.size()  == r.size()
+        && (l.begin() == r.begin() || std::equal( l.begin(), l.end(), r.begin() ) );
+}
+
+template< class T >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr bool operator< ( span<T> const & l, span<T> const & r )
+{
+    return std::lexicographical_compare( l.begin(), l.end(), r.begin(), r.end() );
+}
+# endif // gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T, class U >
+inline gsl_constexpr bool operator!=( span<T> const & l, span<U> const & r )
+{
+    return !( l == r );
+}
+
+template< class T, class U >
+inline gsl_constexpr bool operator<=( span<T> const & l, span<U> const & r )
+{
+    return !( r < l );
+}
+
+template< class T, class U >
+inline gsl_constexpr bool operator> ( span<T> const & l, span<U> const & r )
+{
+    return ( r < l );
+}
+
+template< class T, class U >
+inline gsl_constexpr bool operator>=( span<T> const & l, span<U> const & r )
+{
+    return !( l < r );
+}
+#endif // gsl_CONFIG( ALLOWS_SPAN_COMPARISON )
+
+// span algorithms
+
+template< class T >
+gsl_api inline gsl_constexpr std::size_t size( span<T> const & spn )
+{
+    return static_cast<std::size_t>( spn.size() );
+}
+
+template< class T >
+gsl_api inline gsl_constexpr std::ptrdiff_t ssize( span<T> const & spn )
+{
+    return spn.ssize();
+}
+
+namespace detail {
+
+template< class II, class N, class OI >
+gsl_api gsl_constexpr14 inline OI copy_n( II first, N count, OI result )
+{
+    if ( count > 0 )
+    {
+        *result++ = *first;
+        for ( N i = 1; i < count; ++i )
+        {
+            *result++ = *++first;
+        }
+    }
+    return result;
+}
+}
+
+template< class T, class U >
+gsl_api gsl_constexpr14 inline void copy( span<T> src, span<U> dest )
+{
+#if gsl_CPP14_OR_GREATER // gsl_HAVE( TYPE_TRAITS ) (circumvent Travis clang 3.4)
+    static_assert( std::is_assignable<U &, T const &>::value, "Cannot assign elements of source span to elements of destination span" );
+#endif
+    gsl_Expects( dest.size() >= src.size() );
+    detail::copy_n( src.data(), src.size(), dest.data() );
+}
+
+// span creator functions (see ctors)
+
+template< class T >
+gsl_api inline span< const byte > as_bytes( span<T> spn ) gsl_noexcept
+{
+    return span< const byte >( reinterpret_cast<const byte *>( spn.data() ), spn.size_bytes() ); // NOLINT
+}
+
+template< class T>
+gsl_api inline span< byte > as_writable_bytes( span<T> spn ) gsl_noexcept
+{
+    return span< byte >( reinterpret_cast<byte *>( spn.data() ), spn.size_bytes() ); // NOLINT
+}
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 6 )
+template< class T>
+gsl_DEPRECATED_MSG("use as_writable_bytes() (different spelling) instead")
+gsl_api inline span< byte > as_writeable_bytes( span<T> spn ) gsl_noexcept
+{
+    return span< byte >( reinterpret_cast<byte *>( spn.data() ), spn.size_bytes() ); // NOLINT
+}
+#endif // deprecate
+
+#if gsl_FEATURE_TO_STD( MAKE_SPAN )
+
+template< class T >
+gsl_api inline gsl_constexpr span<T>
+make_span( T * ptr, typename span<T>::index_type count )
+{
+    return span<T>( ptr, count );
+}
+
+template< class T >
+gsl_api inline gsl_constexpr span<T>
+make_span( T * first, T * last )
+{
+    return span<T>( first, last );
+}
+
+template< class T, size_t N >
+gsl_api inline gsl_constexpr span<T>
+make_span( T (&arr)[N] )
+{
+    return span<T>( gsl_ADDRESSOF( arr[0] ), N );
+}
+
+#if gsl_HAVE( ARRAY )
+
+template< class T, size_t N >
+inline gsl_constexpr span<T>
+make_span( std::array<T,N> & arr )
+{
+    return span<T>( arr );
+}
+
+template< class T, size_t N >
+inline gsl_constexpr span<const T>
+make_span( std::array<T,N> const & arr )
+{
+    return span<const T>( arr );
+}
+#endif
+
+#if gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR ) && gsl_HAVE( AUTO )
+
+template< class Container, class EP = decltype( std17::data(std::declval<Container&>())) >
+inline gsl_constexpr auto
+make_span( Container & cont ) -> span< typename std::remove_pointer<EP>::type >
+{
+    return span< typename std::remove_pointer<EP>::type >( cont );
+}
+
+template< class Container, class EP = decltype( std17::data(std::declval<Container&>())) >
+inline gsl_constexpr auto
+make_span( Container const & cont ) -> span< const typename std::remove_pointer<EP>::type >
+{
+    return span< const typename std::remove_pointer<EP>::type >( cont );
+}
+
+#else
+
+template< class T >
+inline span<T>
+make_span( std::vector<T> & cont )
+{
+    return span<T>( with_container, cont );
+}
+
+template< class T >
+inline span<const T>
+make_span( std::vector<T> const & cont )
+{
+    return span<const T>( with_container, cont );
+}
+#endif
+
+#if gsl_FEATURE_TO_STD( WITH_CONTAINER )
+
+template< class Container >
+inline gsl_constexpr span<typename Container::value_type>
+make_span( with_container_t, Container & cont ) gsl_noexcept
+{
+    return span< typename Container::value_type >( with_container, cont );
+}
+
+template< class Container >
+inline gsl_constexpr span<const typename Container::value_type>
+make_span( with_container_t, Container const & cont ) gsl_noexcept
+{
+    return span< const typename Container::value_type >( with_container, cont );
+}
+
+#endif // gsl_FEATURE_TO_STD( WITH_CONTAINER )
+
+#if !gsl_DEPRECATE_TO_LEVEL( 4 )
+template< class Ptr >
+gsl_DEPRECATED
+inline span<typename Ptr::element_type>
+make_span( Ptr & ptr )
+{
+    return span<typename Ptr::element_type>( ptr );
+}
+#endif // !gsl_DEPRECATE_TO_LEVEL( 4 )
+
+template< class Ptr >
+gsl_DEPRECATED
+inline span<typename Ptr::element_type>
+make_span( Ptr & ptr, typename span<typename Ptr::element_type>::index_type count )
+{
+    return span<typename Ptr::element_type>( ptr, count );
+}
+
+#endif // gsl_FEATURE_TO_STD( MAKE_SPAN )
+
+#if gsl_FEATURE_TO_STD( BYTE_SPAN )
+
+template< class T >
+gsl_api inline gsl_constexpr span<byte>
+byte_span( T & t ) gsl_noexcept
+{
+    return span<byte>( reinterpret_cast<byte *>( &t ), sizeof(T) );
+}
+
+template< class T >
+gsl_api inline gsl_constexpr span<const byte>
+byte_span( T const & t ) gsl_noexcept
+{
+    return span<const byte>( reinterpret_cast<byte const *>( &t ), sizeof(T) );
+}
+
+#endif // gsl_FEATURE_TO_STD( BYTE_SPAN )
+
+//
+// basic_string_span:
+//
+
+template< class T >
+class basic_string_span;
+
+namespace detail {
+
+template< class T >
+struct is_basic_string_span_oracle : std11::false_type {};
+
+template< class T >
+struct is_basic_string_span_oracle< basic_string_span<T> > : std11::true_type {};
+
+template< class T >
+struct is_basic_string_span : is_basic_string_span_oracle< typename std11::remove_cv<T>::type > {};
+
+template< class T >
+gsl_api inline gsl_constexpr14 std::size_t string_length( T * ptr, std::size_t max )
+{
+    if ( ptr == gsl_nullptr || max <= 0 )
+        return 0;
+
+    std::size_t len = 0;
+    while ( len < max && ptr[len] ) // NOLINT
+        ++len;
+
+    return len;
+}
+
+} // namespace detail
+
+//
+// basic_string_span<> - A view of contiguous characters, replace (*,len).
+//
+template< class T >
+class basic_string_span
+{
+public:
+    typedef T element_type;
+    typedef span<T> span_type;
+
+    typedef typename span_type::index_type index_type;
+    typedef typename span_type::difference_type difference_type;
+
+    typedef typename span_type::pointer pointer ;
+    typedef typename span_type::reference reference ;
+
+    typedef typename span_type::iterator iterator ;
+    typedef typename span_type::const_iterator const_iterator ;
+    typedef typename span_type::reverse_iterator reverse_iterator;
+    typedef typename span_type::const_reverse_iterator const_reverse_iterator;
+
+    // construction:
+
+#if gsl_HAVE( IS_DEFAULT )
+    gsl_constexpr basic_string_span() gsl_noexcept = default;
+#else
+    gsl_api gsl_constexpr basic_string_span() gsl_noexcept {}
+#endif
+
+#if gsl_HAVE( NULLPTR )
+    gsl_api gsl_constexpr basic_string_span( std::nullptr_t ) gsl_noexcept
+    : span_( nullptr, static_cast<index_type>( 0 ) )
+    {}
+#endif
+
+#ifdef __CUDACC_RELAXED_CONSTEXPR__
+    gsl_api
+#endif // __CUDACC_RELAXED_CONSTEXPR__
+    gsl_constexpr basic_string_span( pointer ptr )
+    : span_( remove_z( ptr, (std::numeric_limits<index_type>::max)() ) )
+    {}
+
+    gsl_api gsl_constexpr basic_string_span( pointer ptr, index_type count )
+    : span_( ptr, count )
+    {}
+
+    gsl_api gsl_constexpr basic_string_span( pointer firstElem, pointer lastElem )
+    : span_( firstElem, lastElem )
+    {}
+
+    template< std::size_t N >
+    gsl_api gsl_constexpr basic_string_span( element_type (&arr)[N] )
+    : span_( remove_z( gsl_ADDRESSOF( arr[0] ), N ) )
+    {}
+
+#if gsl_HAVE( ARRAY )
+
+    template< std::size_t N >
+    gsl_constexpr basic_string_span( std::array< typename std11::remove_const<element_type>::type, N> & arr )
+    : span_( remove_z( arr ) )
+    {}
+
+    template< std::size_t N >
+    gsl_constexpr basic_string_span( std::array< typename std11::remove_const<element_type>::type, N> const & arr )
+    : span_( remove_z( arr ) )
+    {}
+
+#endif
+
+#if gsl_HAVE( CONSTRAINED_SPAN_CONTAINER_CTOR )
+
+    // Exclude: array, [basic_string,] basic_string_span
+
+    template< class Container
+        gsl_ENABLE_IF_((
+            ! detail::is_std_array< Container >::value
+            && ! detail::is_basic_string_span< Container >::value
+            && std::is_convertible< typename Container::pointer, pointer >::value
+            && std::is_convertible< typename Container::pointer, decltype(std::declval<Container>().data()) >::value
+        ))
+    >
+    gsl_constexpr basic_string_span( Container & cont )
+    : span_( ( cont ) )
+    {}
+
+    // Exclude: array, [basic_string,] basic_string_span
+
+    template< class Container
+        gsl_ENABLE_IF_((
+            ! detail::is_std_array< Container >::value
+            && ! detail::is_basic_string_span< Container >::value
+            && std::is_convertible< typename Container::pointer, pointer >::value
+            && std::is_convertible< typename Container::pointer, decltype(std::declval<Container const &>().data()) >::value
+        ))
+    >
+    gsl_constexpr basic_string_span( Container const & cont )
+    : span_( ( cont ) )
+    {}
+
+#elif gsl_HAVE( UNCONSTRAINED_SPAN_CONTAINER_CTOR )
+
+    template< class Container >
+    gsl_constexpr basic_string_span( Container & cont )
+    : span_( cont )
+    {}
+
+    template< class Container >
+    gsl_constexpr basic_string_span( Container const & cont )
+    : span_( cont )
+    {}
+
+#else
+
+    template< class U >
+    gsl_api gsl_constexpr basic_string_span( span<U> const & rhs )
+    : span_( rhs )
+    {}
+
+#endif
+
+#if gsl_FEATURE_TO_STD( WITH_CONTAINER )
+
+    template< class Container >
+    gsl_constexpr basic_string_span( with_container_t, Container & cont )
+    : span_( with_container, cont )
+    {}
+#endif
+
+#if gsl_HAVE( IS_DEFAULT )
+# if gsl_BETWEEN( gsl_COMPILER_GNUC_VERSION, 440, 600 )
+    gsl_constexpr basic_string_span( basic_string_span const & rhs ) = default;
+
+    gsl_constexpr basic_string_span( basic_string_span && rhs ) = default;
+# else
+    gsl_constexpr basic_string_span( basic_string_span const & rhs ) gsl_noexcept = default;
+
+    gsl_constexpr basic_string_span( basic_string_span && rhs ) gsl_noexcept = default;
+# endif
+#endif
+
+    template< class U
+        gsl_ENABLE_IF_(( std::is_convertible<typename basic_string_span<U>::pointer, pointer>::value ))
+    >
+    gsl_api gsl_constexpr basic_string_span( basic_string_span<U> const & rhs )
+    : span_( reinterpret_cast<pointer>( rhs.data() ), rhs.length() ) // NOLINT
+    {}
+
+#if gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 120
+    template< class U
+        gsl_ENABLE_IF_(( std::is_convertible<typename basic_string_span<U>::pointer, pointer>::value ))
+    >
+    gsl_api gsl_constexpr basic_string_span( basic_string_span<U> && rhs )
+    : span_( reinterpret_cast<pointer>( rhs.data() ), rhs.length() ) // NOLINT
+    {}
+#endif
+
+    template< class CharTraits, class Allocator >
+    gsl_constexpr basic_string_span(
+        std::basic_string< typename std11::remove_const<element_type>::type, CharTraits, Allocator > & str )
+    : span_( gsl_ADDRESSOF( str[0] ), str.length() )
+    {}
+
+    template< class CharTraits, class Allocator >
+    gsl_constexpr basic_string_span(
+        std::basic_string< typename std11::remove_const<element_type>::type, CharTraits, Allocator > const & str )
+    : span_( gsl_ADDRESSOF( str[0] ), str.length() )
+    {}
+
+    // assignment:
+
+#if gsl_HAVE( IS_DEFAULT )
+    gsl_constexpr14 basic_string_span & operator=( basic_string_span const & rhs ) gsl_noexcept = default;
+
+    gsl_constexpr14 basic_string_span & operator=( basic_string_span && rhs ) gsl_noexcept = default;
+#endif
+
+    // sub span:
+
+    /*gsl_api*/ // currently disabled due to an apparent NVCC bug
+    gsl_constexpr14 basic_string_span first( index_type count ) const
+    {
+        return span_.first( count );
+    }
+
+    /*gsl_api*/ // currently disabled due to an apparent NVCC bug
+    gsl_constexpr14 basic_string_span last( index_type count ) const
+    {
+        return span_.last( count );
+    }
+
+    /*gsl_api*/ // currently disabled due to an apparent NVCC bug
+    gsl_constexpr14 basic_string_span subspan( index_type offset ) const
+    {
+        return span_.subspan( offset );
+    }
+
+    /*gsl_api*/ // currently disabled due to an apparent NVCC bug
+    gsl_constexpr14 basic_string_span subspan( index_type offset, index_type count ) const
+    {
+        return span_.subspan( offset, count );
+    }
+
+    // observers:
+
+    gsl_api gsl_constexpr index_type length() const gsl_noexcept
+    {
+        return span_.size();
+    }
+
+    gsl_api gsl_constexpr index_type size() const gsl_noexcept
+    {
+        return span_.size();
+    }
+
+    gsl_api gsl_constexpr index_type length_bytes() const gsl_noexcept
+    {
+        return span_.size_bytes();
+    }
+
+    gsl_api gsl_constexpr index_type size_bytes() const gsl_noexcept
+    {
+        return span_.size_bytes();
+    }
+
+    gsl_api gsl_constexpr bool empty() const gsl_noexcept
+    {
+        return size() == 0;
+    }
+
+    gsl_api gsl_constexpr14 reference operator[]( index_type idx ) const
+    {
+        return span_[idx];
+    }
+
+#if ! gsl_DEPRECATE_TO_LEVEL( 6 )
+    gsl_DEPRECATED_MSG("use subscript indexing instead")
+    gsl_api gsl_constexpr14 reference operator()( index_type idx ) const
+    {
+        return span_[idx];
+    }
+#endif // deprecate
+
+    gsl_api gsl_constexpr14 reference front() const
+    {
+        return span_.front();
+    }
+
+    gsl_api gsl_constexpr14 reference back() const
+    {
+        return span_.back();
+    }
+
+    gsl_api gsl_constexpr pointer data() const gsl_noexcept
+    {
+        return span_.data();
+    }
+
+    gsl_api gsl_constexpr iterator begin() const gsl_noexcept
+    {
+        return span_.begin();
+    }
+
+    gsl_api gsl_constexpr iterator end() const gsl_noexcept
+    {
+        return span_.end();
+    }
+
+    gsl_constexpr17 reverse_iterator rbegin() const gsl_noexcept
+    {
+        return span_.rbegin();
+    }
+
+    gsl_constexpr17 reverse_iterator rend() const gsl_noexcept
+    {
+        return span_.rend();
+    }
+
+    // const version not in p0123r2:
+
+    gsl_api gsl_constexpr const_iterator cbegin() const gsl_noexcept
+    {
+        return span_.cbegin();
+    }
+
+    gsl_api gsl_constexpr const_iterator cend() const gsl_noexcept
+    {
+        return span_.cend();
+    }
+
+    gsl_constexpr17 const_reverse_iterator crbegin() const gsl_noexcept
+    {
+        return span_.crbegin();
+    }
+
+    gsl_constexpr17 const_reverse_iterator crend() const gsl_noexcept
+    {
+        return span_.crend();
+    }
+
+private:
+    gsl_api static gsl_constexpr14 span_type remove_z( pointer const & sz, std::size_t max )
+    {
+        return span_type( sz, detail::string_length( sz, max ) );
+    }
+
+#if gsl_HAVE( ARRAY )
+    template< size_t N >
+    static gsl_constexpr14 span_type remove_z( std::array<typename std11::remove_const<element_type>::type, N> & arr )
+    {
+        return remove_z( gsl_ADDRESSOF( arr[0] ), narrow_cast< std::size_t >( N ) );
+    }
+
+    template< size_t N >
+    static gsl_constexpr14 span_type remove_z( std::array<typename std11::remove_const<element_type>::type, N> const & arr )
+    {
+        return remove_z( gsl_ADDRESSOF( arr[0] ), narrow_cast< std::size_t >( N ) );
+    }
+#endif
+
+private:
+    span_type span_;
+};
+
+// basic_string_span comparison functions:
+
+#if gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T, class U >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator==( basic_string_span<T> const & l, U const & u ) gsl_noexcept
+{
+    const basic_string_span< typename std11::add_const<T>::type > r( u );
+
+    return l.size() == r.size()
+        && std::equal( l.begin(), l.end(), r.begin() );
+}
+
+template< class T, class U >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator<( basic_string_span<T> const & l, U const & u ) gsl_noexcept
+{
+    const basic_string_span< typename std11::add_const<T>::type > r( u );
+
+    return std::lexicographical_compare( l.begin(), l.end(), r.begin(), r.end() );
+}
+
+#if gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG )
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator==( U const & u, basic_string_span<T> const & r ) gsl_noexcept
+{
+    const basic_string_span< typename std11::add_const<T>::type > l( u );
+
+    return l.size() == r.size()
+        && std::equal( l.begin(), l.end(), r.begin() );
+}
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator<( U const & u, basic_string_span<T> const & r ) gsl_noexcept
+{
+    const basic_string_span< typename std11::add_const<T>::type > l( u );
+
+    return std::lexicographical_compare( l.begin(), l.end(), r.begin(), r.end() );
+}
+#endif
+
+#else //gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator==( basic_string_span<T> const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return l.size() == r.size()
+        && std::equal( l.begin(), l.end(), r.begin() );
+}
+
+template< class T >
+gsl_SUPPRESS_MSGSL_WARNING(stl.1)
+inline gsl_constexpr14 bool operator<( basic_string_span<T> const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return std::lexicographical_compare( l.begin(), l.end(), r.begin(), r.end() );
+}
+
+#endif // gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+
+template< class T, class U >
+inline gsl_constexpr14 bool operator!=( basic_string_span<T> const & l, U const & r ) gsl_noexcept
+{
+    return !( l == r );
+}
+
+template< class T, class U >
+inline gsl_constexpr14 bool operator<=( basic_string_span<T> const & l, U const & r ) gsl_noexcept
+{
+#if gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) || ! gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+    return !( r < l );
+#else
+    basic_string_span< typename std11::add_const<T>::type > rr( r );
+    return !( rr < l );
+#endif
+}
+
+template< class T, class U >
+inline gsl_constexpr14 bool operator>( basic_string_span<T> const & l, U const & r ) gsl_noexcept
+{
+#if gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG ) || ! gsl_CONFIG( ALLOWS_NONSTRICT_SPAN_COMPARISON )
+    return ( r < l );
+#else
+    basic_string_span< typename std11::add_const<T>::type > rr( r );
+    return ( rr < l );
+#endif
+}
+
+template< class T, class U >
+inline gsl_constexpr14 bool operator>=( basic_string_span<T> const & l, U const & r ) gsl_noexcept
+{
+    return !( l < r );
+}
+
+#if gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG )
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+inline gsl_constexpr14 bool operator!=( U const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return !( l == r );
+}
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+inline gsl_constexpr14 bool operator<=( U const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return !( r < l );
+}
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+inline gsl_constexpr14 bool operator>( U const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return ( r < l );
+}
+
+template< class T, class U
+    gsl_ENABLE_IF_(( !detail::is_basic_string_span<U>::value ))
+>
+inline gsl_constexpr14 bool operator>=( U const & l, basic_string_span<T> const & r ) gsl_noexcept
+{
+    return !( l < r );
+}
+
+#endif // gsl_HAVE( DEFAULT_FUNCTION_TEMPLATE_ARG )
+
+// convert basic_string_span to byte span:
+
+template< class T >
+gsl_api inline span< const byte > as_bytes( basic_string_span<T> spn ) gsl_noexcept
+{
+    return span< const byte >( reinterpret_cast<const byte *>( spn.data() ), spn.size_bytes() ); // NOLINT
+}
+
+//
+// String types:
+//
+
+typedef char * zstring;
+typedef const char * czstring;
+
+#if gsl_HAVE( WCHAR )
+typedef wchar_t * wzstring;
+typedef const wchar_t * cwzstring;
+#endif
+
+typedef basic_string_span< char > string_span;
+typedef basic_string_span< char const > cstring_span;
+
+#if gsl_HAVE( WCHAR )
+typedef basic_string_span< wchar_t > wstring_span;
+typedef basic_string_span< wchar_t const > cwstring_span;
+#endif
+
+// to_string() allow (explicit) conversions from string_span to string
+
+#if 0
+
+template< class T >
+inline std::basic_string< typename std::remove_const<T>::type > to_string( basic_string_span<T> spn )
+{
+     std::string( spn.data(), spn.length() );
+}
+
+#else
+
+inline std::string to_string( string_span const & spn )
+{
+    return std::string( spn.data(), spn.length() );
+}
+
+inline std::string to_string( cstring_span const & spn )
+{
+    return std::string( spn.data(), spn.length() );
+}
+
+#if gsl_HAVE( WCHAR )
+
+inline std::wstring to_string( wstring_span const & spn )
+{
+    return std::wstring( spn.data(), spn.length() );
+}
+
+inline std::wstring to_string( cwstring_span const & spn )
+{
+    return std::wstring( spn.data(), spn.length() );
+}
+
+#endif // gsl_HAVE( WCHAR )
+#endif // to_string()
+
+//
+// Stream output for string_span types
+//
+
+namespace detail {
+
+template< class Stream >
+void write_padding( Stream & os, std::streamsize n )
+{
+    for ( std::streamsize i = 0; i < n; ++i )
+        os.rdbuf()->sputc( os.fill() );
+}
+
+template< class Stream, class Span >
+Stream & write_to_stream( Stream & os, Span const & spn )
+{
+    typename Stream::sentry sentry( os );
+
+    if ( !os )
+        return os;
+
+    const std::streamsize length = narrow<std::streamsize>( spn.length() );
+
+    // Whether, and how, to pad
+    const bool pad = ( length < os.width() );
+    const bool left_pad = pad && ( os.flags() & std::ios_base::adjustfield ) == std::ios_base::right;
+
+    if ( left_pad )
+        write_padding( os, os.width() - length );
+
+    // Write span characters
+    os.rdbuf()->sputn( spn.begin(), length );
+
+    if ( pad && !left_pad )
+        write_padding( os, os.width() - length );
+
+    // Reset output stream width
+    os.width(0);
+
+    return os;
+}
+
+} // namespace detail
+
+template< typename Traits >
+std::basic_ostream< char, Traits > & operator<<( std::basic_ostream< char, Traits > & os, string_span const & spn )
+{
+    return detail::write_to_stream( os, spn );
+}
+
+template< typename Traits >
+std::basic_ostream< char, Traits > & operator<<( std::basic_ostream< char, Traits > & os, cstring_span const & spn )
+{
+    return detail::write_to_stream( os, spn );
+}
+
+#if gsl_HAVE( WCHAR )
+
+template< typename Traits >
+std::basic_ostream< wchar_t, Traits > & operator<<( std::basic_ostream< wchar_t, Traits > & os, wstring_span const & spn )
+{
+    return detail::write_to_stream( os, spn );
+}
+
+template< typename Traits >
+std::basic_ostream< wchar_t, Traits > & operator<<( std::basic_ostream< wchar_t, Traits > & os, cwstring_span const & spn )
+{
+    return detail::write_to_stream( os, spn );
+}
+
+#endif // gsl_HAVE( WCHAR )
+
+//
+// ensure_sentinel()
+//
+// Provides a way to obtain a span from a contiguous sequence
+// that ends with a (non-inclusive) sentinel value.
+//
+// Will fail-fast if sentinel cannot be found before max elements are examined.
+//
+namespace detail {
+
+template< class T, class SizeType, const T Sentinel >
+gsl_api static span<T> ensure_sentinel( T * seq, SizeType max = (std::numeric_limits<SizeType>::max)() )
+{
+    typedef T * pointer;
+
+    gsl_SUPPRESS_MSVC_WARNING( 26429, "f.23: symbol 'cur' is never tested for nullness, it can be marked as not_null" )
+    pointer cur = seq;
+
+    while ( static_cast<SizeType>( cur - seq ) < max && *cur != Sentinel )
+        ++cur;
+
+    gsl_Expects( *cur == Sentinel );
+
+    return span<T>( seq, narrow_cast< typename span<T>::index_type >( cur - seq ) );
+}
+} // namespace detail
+
+//
+// ensure_z - creates a string_span for a czstring or cwzstring.
+// Will fail fast if a null-terminator cannot be found before
+// the limit of size_type.
+//
+
+template< class T >
+gsl_api inline span<T> ensure_z( T * const & sz, size_t max = (std::numeric_limits<size_t>::max)() )
+{
+    return detail::ensure_sentinel<T, size_t, 0>( sz, max );
+}
+
+template< class T, size_t N >
+gsl_api inline span<T> ensure_z( T (&sz)[N] )
+{
+    return ::gsl::ensure_z( gsl_ADDRESSOF( sz[0] ), N );
+}
+
+# if gsl_HAVE( TYPE_TRAITS )
+
+template< class Container >
+inline span< typename std::remove_pointer<typename Container::pointer>::type >
+ensure_z( Container & cont )
+{
+    return ::gsl::ensure_z( cont.data(), cont.length() );
+}
+# endif
+
+//
+// basic_zstring_span<> - A view of contiguous null-terminated characters, replace (*,len).
+//
+
+template <typename T>
+class basic_zstring_span
+{
+public:
+    typedef T element_type;
+    typedef span<T> span_type;
+
+    typedef typename span_type::index_type index_type;
+    typedef typename span_type::difference_type difference_type;
+
+    typedef element_type * czstring_type;
+    typedef basic_string_span<element_type> string_span_type;
+
+    gsl_api gsl_constexpr14 basic_zstring_span( span_type s )
+        : span_( s )
+    {
+        // expects a zero-terminated span
+        gsl_Expects( s[s.size() - 1] == '\0');
+    }
+
+#if gsl_HAVE( IS_DEFAULT )
+    gsl_constexpr basic_zstring_span( basic_zstring_span const & other ) = default;
+    gsl_constexpr basic_zstring_span( basic_zstring_span &&      other ) = default;
+    gsl_constexpr14 basic_zstring_span & operator=( basic_zstring_span const & other ) = default;
+    gsl_constexpr14 basic_zstring_span & operator=( basic_zstring_span &&      other ) = default;
+#else
+    gsl_api gsl_constexpr basic_zstring_span( basic_zstring_span const & other) : span_ ( other.span_ ) {}
+    gsl_api gsl_constexpr basic_zstring_span & operator=( basic_zstring_span const & other ) { span_ = other.span_; return *this; }
+#endif
+
+    gsl_api gsl_constexpr bool empty() const gsl_noexcept
+    {
+        return span_.size() == 0;
+    }
+
+    gsl_api gsl_constexpr string_span_type as_string_span() const gsl_noexcept
+    {
+        return string_span_type( span_.data(), span_.size() > 1 ? span_.size() - 1 : 0 );
+    }
+
+    /*gsl_api*/ // currently disabled due to an apparent NVCC bug
+    gsl_constexpr string_span_type ensure_z() const
+    {
+        return ::gsl::ensure_z(span_.data(), span_.size());
+    }
+
+    gsl_api gsl_constexpr czstring_type assume_z() const gsl_noexcept
+    {
+        return span_.data();
+    }
+
+private:
+    span_type span_;
+};
+
+//
+// zString types:
+//
+
+typedef basic_zstring_span< char > zstring_span;
+typedef basic_zstring_span< char const > czstring_span;
+
+#if gsl_HAVE( WCHAR )
+typedef basic_zstring_span< wchar_t > wzstring_span;
+typedef basic_zstring_span< wchar_t const > cwzstring_span;
+#endif
+
+} // namespace gsl
+
+#if gsl_CPP11_OR_GREATER || gsl_COMPILER_MSVC_VERSION >= 120
+
+namespace std {
+
+template<>
+struct hash< ::gsl::byte >
+{
+public:
+    gsl_constexpr std::size_t operator()( ::gsl::byte v ) const gsl_noexcept
+    {
+        return ::gsl::to_integer<std::size_t>( v );
+    }
+};
+
+} // namespace std
+
+#endif
+
+#if gsl_FEATURE_GSL_LITE_NAMESPACE
+
+// gsl_lite namespace:
+
+// gsl-lite currently keeps all symbols in the namespace `gsl`. The `gsl_lite` namespace contains all the symbols in the
+// `gsl` namespace, plus some extensions that are not specified in the Core Guidelines.
+//
+// Going forward, we want to support coexistence of gsl-lite with M-GSL, so we want to encourage using the `gsl_lite`
+// namespace when consuming gsl-lite. Typical use in library code would be:
+//
+//     #include <gsl-lite/gsl-lite.hpp> // instead of <gsl/gsl-lite.hpp>
+//
+//     namespace foo {
+//         namespace gsl = ::gsl_lite; // convenience alias
+//         double mean(gsl::span<double const> elements) {
+//             gsl_Expects(!elements.empty()); // instead of Expects()
+//             ...
+//         }
+//     } // namespace foo
+//
+// In a future version, the new <gsl-lite/gsl-lite.hpp> header will only define the `gsl_lite` namespace and no
+// unprefixed `Expects()` and `Ensures()` macros to avoid collision with M-GSL. To ensure backward compatibility, the
+// old header <gsl/gsl-lite.hpp> will keep defining the `gsl` namespace and the `Expects()` and `Ensures()` macros.
+
+namespace gsl_lite
+{
+
+namespace std11 = ::gsl::std11;
+namespace std14 = ::gsl::std14;
+namespace std17 = ::gsl::std17;
+namespace std20 = ::gsl::std20;
+
+using namespace std11;
+using namespace std14;
+using namespace std17;
+using namespace std20;
+
+#if gsl_HAVE( SHARED_PTR )
+using std::unique_ptr;
+using std::shared_ptr;
+using std::make_shared;
+#endif
+
+using ::gsl::index;
+
+// Integer type for dimensions.
+typedef gsl_CONFIG_INDEX_TYPE dim;
+
+// Integer type for array strides.
+typedef gsl_CONFIG_INDEX_TYPE stride;
+
+// Integer type for pointer, iterator, or index differences.
+typedef gsl_CONFIG_INDEX_TYPE diff;
+
+#if  gsl_HAVE( ALIAS_TEMPLATE )
+using ::gsl::owner;
+#endif
+
+using ::gsl::fail_fast;
+
+using ::gsl::finally;
+#if gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+using ::gsl::on_return;
+using ::gsl::on_error;
+#endif // gsl_FEATURE( EXPERIMENTAL_RETURN_GUARD )
+
+using ::gsl::narrow_cast;
+using ::gsl::narrowing_error;
+using ::gsl::narrow;
+using ::gsl::narrow_failfast;
+
+
+using ::gsl::at;
+
+using ::gsl::not_null;
+using ::gsl::make_not_null;
+
+using ::gsl::byte;
+
+using ::gsl::with_container_t;
+using ::gsl::with_container;
+
+using ::gsl::span;
+using ::gsl::make_span;
+using ::gsl::byte_span;
+using ::gsl::copy;
+using ::gsl::as_bytes;
+using ::gsl::as_writable_bytes;
+#if ! gsl_DEPRECATE_TO_LEVEL( 6 )
+using ::gsl::as_writeable_bytes;
+#endif
+
+using ::gsl::basic_string_span;
+using ::gsl::string_span;
+using ::gsl::cstring_span;
+
+using ::gsl::basic_zstring_span;
+using ::gsl::zstring_span;
+using ::gsl::czstring_span;
+
+using ::gsl::zstring;
+using ::gsl::czstring;
+
+#if gsl_HAVE( WCHAR )
+using ::gsl::wzstring;
+using ::gsl::cwzstring;
+
+using ::gsl::wzstring_span;
+using ::gsl::cwzstring_span;
+#endif // gsl_HAVE( WCHAR )
+
+} // namespace gsl_lite
+
+#endif // gsl_FEATURE_GSL_LITE_NAMESPACE
+
+gsl_RESTORE_MSVC_WARNINGS()
+
+#endif // GSL_GSL_LITE_HPP_INCLUDED
+
+// end of file
diff --git a/third_party/mmz/mmz.h b/third_party/mmz/mmz.h
new file mode 100644
index 0000000..8542e5a
--- /dev/null
+++ b/third_party/mmz/mmz.h
@@ -0,0 +1,19 @@
+#ifndef __MMZ__
+#define __MMZ__
+
+#ifdef __cplusplus
+extern "C" {
+#endif /* End of #ifdef __cplusplus */
+
+int kd_mpi_mmz_init(void);
+int kd_mpi_mmz_deinit(void);
+int kd_mpi_sys_mmz_alloc(unsigned long *phy_addr, void **virt_addr, const char *mmb, const char *zone, unsigned int len);
+int kd_mpi_sys_mmz_alloc_cached(unsigned long *phy_addr, void **virt_addr, const char *mmb, const char *zone, unsigned int len);
+int kd_mpi_sys_mmz_flush_cache(unsigned long phy_addr, void *virt_addr, unsigned int size);
+int kd_mpi_sys_mmz_free(unsigned long phy_addr, void *virt_addr);
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif
diff --git a/third_party/mmz/riscv64/libmmz.a b/third_party/mmz/riscv64/libmmz.a
new file mode 100644
index 0000000..267ee7b
Binary files /dev/null and b/third_party/mmz/riscv64/libmmz.a differ
diff --git a/third_party/nncase/riscv64/bin/accuracy_test.elf b/third_party/nncase/riscv64/bin/accuracy_test.elf
new file mode 100644
index 0000000..2eefba6
Binary files /dev/null and b/third_party/nncase/riscv64/bin/accuracy_test.elf differ
diff --git a/third_party/nncase/riscv64/bin/accuracy_test_nmt_en2fr.elf b/third_party/nncase/riscv64/bin/accuracy_test_nmt_en2fr.elf
new file mode 100644
index 0000000..3f187d7
Binary files /dev/null and b/third_party/nncase/riscv64/bin/accuracy_test_nmt_en2fr.elf differ
diff --git a/third_party/nncase/riscv64/bin/ai2d_cpu_test.elf b/third_party/nncase/riscv64/bin/ai2d_cpu_test.elf
new file mode 100644
index 0000000..0623ae0
Binary files /dev/null and b/third_party/nncase/riscv64/bin/ai2d_cpu_test.elf differ
diff --git a/third_party/nncase/riscv64/bin/list_file.elf b/third_party/nncase/riscv64/bin/list_file.elf
new file mode 100644
index 0000000..5d7f446
Binary files /dev/null and b/third_party/nncase/riscv64/bin/list_file.elf differ
diff --git a/third_party/nncase/riscv64/bin/nncase_test.elf b/third_party/nncase/riscv64/bin/nncase_test.elf
new file mode 100644
index 0000000..0db1a11
Binary files /dev/null and b/third_party/nncase/riscv64/bin/nncase_test.elf differ
diff --git a/third_party/nncase/riscv64/bin/nncase_test_ci.elf b/third_party/nncase/riscv64/bin/nncase_test_ci.elf
new file mode 100644
index 0000000..b6a8ef4
Binary files /dev/null and b/third_party/nncase/riscv64/bin/nncase_test_ci.elf differ
diff --git a/third_party/nncase/riscv64/bin/nncase_test_dynamic.elf b/third_party/nncase/riscv64/bin/nncase_test_dynamic.elf
new file mode 100644
index 0000000..467394b
Binary files /dev/null and b/third_party/nncase/riscv64/bin/nncase_test_dynamic.elf differ
diff --git a/third_party/nncase/riscv64/bin/nncase_test_ppl.elf b/third_party/nncase/riscv64/bin/nncase_test_ppl.elf
new file mode 100644
index 0000000..0888a77
Binary files /dev/null and b/third_party/nncase/riscv64/bin/nncase_test_ppl.elf differ
diff --git a/third_party/nncase/riscv64/bin/nncase_test_v2.elf b/third_party/nncase/riscv64/bin/nncase_test_v2.elf
new file mode 100644
index 0000000..db22190
Binary files /dev/null and b/third_party/nncase/riscv64/bin/nncase_test_v2.elf differ
diff --git a/third_party/nncase/riscv64/get.sh b/third_party/nncase/riscv64/get.sh
new file mode 100644
index 0000000..5ca3f9e
--- /dev/null
+++ b/third_party/nncase/riscv64/get.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+
+rm -rf bin lib include
+
+cp -r /home/zhangyang/workspace/k230_conan2_test/nncase_linux_runtime/* .
diff --git a/third_party/nncase/riscv64/include/nncase/api.h b/third_party/nncase/riscv64/include/nncase/api.h
new file mode 100644
index 0000000..1f457d1
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/api.h
@@ -0,0 +1,111 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/simple_types.h>
+
+namespace nncase {
+class object_node;
+class tensor_node;
+class tuple_node;
+class value_node;
+class type_node;
+class datatype_node;
+
+namespace runtime {
+class buffer_allocator;
+class buffer_node;
+class host_buffer_node;
+class interpreter;
+class runtime_function;
+} // namespace runtime
+} // namespace nncase
+
+extern "C" {
+struct nncase_buffer_slice {
+    nncase::runtime::buffer_node *buffer;
+    uint32_t start;
+    uint32_t size_bytes;
+};
+
+NNCASE_API int nncase_object_add_ref(nncase::object_node *node);
+NNCASE_API int nncase_object_release(nncase::object_node *node);
+
+NNCASE_API int nncase_interp_create(nncase::runtime::interpreter **interp);
+NNCASE_API int nncase_interp_free(nncase::runtime::interpreter *interp);
+NNCASE_API int nncase_interp_load_model(nncase::runtime::interpreter *interp,
+                                        void *model_buffer, uint32_t model_size,
+                                        bool copy_buffer);
+NNCASE_API int nncase_interp_set_dump_root(nncase::runtime::interpreter *interp,
+                                           const char *path);
+NNCASE_API int
+nncase_interp_get_entry_func(nncase::runtime::interpreter *interp,
+                             nncase::runtime::runtime_function **func);
+
+NNCASE_API int
+nncase_func_get_params_size(nncase::runtime::runtime_function *func,
+                            uint32_t *size);
+NNCASE_API int nncase_func_invoke(nncase::runtime::runtime_function *func,
+                                  nncase::value_node **params,
+                                  uint32_t params_size,
+                                  nncase::value_node **result);
+
+NNCASE_API int
+nncase_buffer_allocator_get_host(nncase::runtime::buffer_allocator **alloc);
+NNCASE_API int
+nncase_buffer_allocator_alloc(nncase::runtime::buffer_allocator *alloc,
+                              uint32_t bytes, void *options,
+                              nncase::runtime::buffer_node **buffer);
+NNCASE_API int
+nncase_buffer_as_host(nncase::runtime::buffer_node *buffer,
+                      nncase::runtime::host_buffer_node **host_buffer);
+
+NNCASE_API int
+nncase_host_buffer_map(nncase::runtime::host_buffer_node *host_buffer,
+                       nncase::runtime::map_access_t access, void **data,
+                       uint32_t *bytes);
+NNCASE_API int
+nncase_host_buffer_unmap(nncase::runtime::host_buffer_node *host_buffer);
+
+NNCASE_API int nncase_dtype_create_prime(nncase::typecode_t typecode,
+                                         nncase::datatype_node **dtype);
+
+NNCASE_API int nncase_dtype_get_typecode(nncase::datatype_node *dtype);
+
+NNCASE_API int nncase_value_is_tensor(nncase::value_node *value,
+                                      bool *is_tensor);
+
+NNCASE_API int nncase_tensor_create(nncase::datatype_node *dtype,
+                                    const uint32_t *dims, uint32_t dims_length,
+                                    const uint32_t *strides,
+                                    uint32_t strides_length,
+                                    nncase_buffer_slice *buffer,
+                                    nncase::tensor_node **tensor);
+NNCASE_API int nncase_tensor_get_dtype(nncase::tensor_node *tensor,
+                                       nncase::datatype_node **dtype);
+NNCASE_API int nncase_tensor_get_buffer(nncase::tensor_node *tensor,
+                                        nncase_buffer_slice *buffer);
+NNCASE_API int nncase_tensor_get_dims(nncase::tensor_node *tensor,
+                                      uint32_t *dims, uint32_t *dims_length);
+NNCASE_API int nncase_tensor_get_strides(nncase::tensor_node *tensor,
+                                         uint32_t *dims, uint32_t *dims_length);
+
+NNCASE_API int nncase_tuple_create(nncase::value_node **fields,
+                                   uint32_t fields_length,
+                                   nncase::tuple_node **tuple);
+NNCASE_API int nncase_tuple_get_fields(nncase::tuple_node *tuple,
+                                       nncase::value_node **fields,
+                                       uint32_t *fields_length);
+}
diff --git a/third_party/nncase/riscv64/include/nncase/compiler.h b/third_party/nncase/riscv64/include/nncase/compiler.h
new file mode 100644
index 0000000..1ef12f9
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/compiler.h
@@ -0,0 +1,697 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <iostream>
+#include <map>
+#include <nlohmann/json.hpp>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/simple_types.h>
+#include <nncase/value.h>
+#include <string>
+#include <unordered_map>
+using nlohmann::json;
+
+extern "C" {
+typedef void *clr_object_handle_t;
+typedef void *nncase_stream_handle_t;
+
+typedef enum {
+    nncase_array_rtvalue = 0,
+    nncase_array_var = 1
+} nncase_array_element_kind_t;
+
+typedef enum {
+    nncase_mqm_no_quant = 0,
+    nncase_mqm_use_ptq = 1,
+    nncase_mqm_use_qat = 2
+} nncase_model_quant_mode_t;
+
+typedef enum {
+    nncase_qm_unsigned = 0,
+    nncase_qm_signed_symmetric = 1,
+    nncase_qm_signed_asymmetric = 2
+} nncase_quant_mode_t;
+
+typedef enum {
+    nncase_qt_uint8 = 0,
+    nncase_qt_int8 = 1,
+    nncase_qt_int16 = 2
+} nncase_quant_type_t;
+
+typedef enum {
+    nncase_calib_noclip = 0,
+    nncase_calib_kld = 1
+} nncase_calib_method_t;
+
+typedef enum {
+    nncase_no_finetune_weights = 0,
+    nncase_finetune_weights_squant = 1,
+    nncase_finetune_weights_adaround = 2
+} nncase_finetune_weights_method_t;
+
+typedef enum {
+    nncase_dump_flags_none = 0,
+    nncase_dump_flags_import_ops = 1 << 1,
+    nncase_dump_flags_pass_ir = 1 << 2,
+    nncase_dump_flags_egraph_cost = 1 << 3,
+    nncase_dump_flags_rewrite = 1 << 4,
+    nncase_dump_flags_calibration = 1 << 5,
+    nncase_dump_flags_evaluator = 1 << 6,
+    nncase_dump_flags_compile = 1 << 7,
+    nncase_dump_flags_tiling = 1 << 8,
+    nncase_dump_flags_schedule = 1 << 9,
+    nncase_dump_flags_codegen = 1 << 10
+} nncase_dump_flags_t;
+
+typedef enum {
+    nncase_it_uint8 = 0,
+    nncase_it_int8 = 1,
+    nncase_it_float32 = 2
+} nncase_input_type_t;
+
+typedef struct {
+    void (*add_ref)(nncase_stream_handle_t handle);
+    void (*release)(nncase_stream_handle_t handle);
+    bool (*can_read)(nncase_stream_handle_t handle);
+    bool (*can_seek)(nncase_stream_handle_t handle);
+    bool (*can_write)(nncase_stream_handle_t handle);
+    void (*flush)(nncase_stream_handle_t handle);
+    int64_t (*get_length)(nncase_stream_handle_t handle);
+    int64_t (*set_length)(nncase_stream_handle_t handle, uint64_t value);
+    int64_t (*get_position)(nncase_stream_handle_t handle);
+    size_t (*read)(nncase_stream_handle_t handle, uint8_t *buffer,
+                   size_t length);
+    int64_t (*seek)(nncase_stream_handle_t handle, int origin, int64_t offset);
+    void (*write)(nncase_stream_handle_t handle, const uint8_t *buffer,
+                  size_t length);
+} nncase_stream_mt_t;
+
+typedef struct {
+    clr_object_handle_t (*array_create)(nncase_array_element_kind_t kind,
+                                        const clr_object_handle_t *elements,
+                                        size_t count);
+    clr_object_handle_t (*array_get_item)(clr_object_handle_t array,
+                                          size_t index);
+    size_t (*array_get_length)(clr_object_handle_t array);
+    clr_object_handle_t (*calibration_dataset_provider_create)(
+        clr_object_handle_t dataset, size_t samplesCount,
+        clr_object_handle_t fn_params);
+    void (*handle_dispose)(clr_object_handle_t handle);
+    void (*handle_free)(clr_object_handle_t handle);
+    clr_object_handle_t (*compile_options_create)();
+    void (*compile_options_set_input_file)(clr_object_handle_t compile_options,
+                                           const char *input_file,
+                                           size_t input_file_length);
+    void (*compile_options_set_input_format)(
+        clr_object_handle_t compile_options, const char *input_format,
+        size_t input_format_length);
+    void (*compile_options_set_dump_dir)(clr_object_handle_t compile_options,
+                                         const char *dump_dir,
+                                         size_t dump_dir_length);
+    nncase_dump_flags_t (*compile_options_get_dump_flags)(
+        clr_object_handle_t compile_options);
+    void (*compile_options_set_dump_flags)(clr_object_handle_t compile_options,
+                                           nncase_dump_flags_t dump_flags);
+    void (*compile_options_set_quantize_options)(
+        clr_object_handle_t compile_options,
+        clr_object_handle_t quantize_options);
+    void (*compile_options_set_preprocess)(clr_object_handle_t compile_options,
+                                           bool preprocess);
+    void (*compile_options_set_input_layout)(
+        clr_object_handle_t compile_options, const char *input_layout,
+        size_t input_layout_length);
+    void (*compile_options_set_output_layout)(
+        clr_object_handle_t compile_options, const char *output_layout,
+        size_t output_layout_length);
+    void (*compile_options_set_input_type)(clr_object_handle_t compile_options,
+                                           nncase_input_type_t input_type);
+    void (*compile_options_set_input_shape)(clr_object_handle_t compile_options,
+                                            const char *input_shape,
+                                            size_t input_shape_length);
+    void (*compile_options_set_input_range)(clr_object_handle_t compile_options,
+                                            const char *input_range,
+                                            size_t input_range_length);
+    void (*compile_options_set_swapRB)(clr_object_handle_t compile_options,
+                                       bool swapRB);
+    void (*compile_options_set_letterbox_value)(
+        clr_object_handle_t compile_options, float letterbox_value);
+    void (*compile_options_set_mean)(clr_object_handle_t compile_options,
+                                     const char *mean, size_t mean_length);
+    void (*compile_options_set_std)(clr_object_handle_t compile_options,
+                                    const char *std, size_t std_length);
+    void (*compile_options_set_shape_bucket_options)(
+        clr_object_handle_t compile_options,
+        clr_object_handle_t shape_bucket_options);
+    clr_object_handle_t (*compile_session_create)(
+        clr_object_handle_t target, clr_object_handle_t compile_options);
+    clr_object_handle_t (*compile_session_get_compiler)(
+        clr_object_handle_t compile_session);
+    void (*compiler_initialize)();
+    clr_object_handle_t (*compiler_import_tflite_module)(
+        clr_object_handle_t compiler, clr_object_handle_t stream);
+    clr_object_handle_t (*compiler_import_onnx_module)(
+        clr_object_handle_t compiler, clr_object_handle_t stream);
+    clr_object_handle_t (*compiler_import_ncnn_module)(
+        clr_object_handle_t compiler, clr_object_handle_t param_stream,
+        clr_object_handle_t bin_stream);
+    void (*compiler_compile)(clr_object_handle_t compiler);
+    void (*compiler_gencode)(clr_object_handle_t compiler,
+                             clr_object_handle_t stream);
+    clr_object_handle_t (*datatype_from_typecode)(nncase::typecode_t typecode);
+    clr_object_handle_t (*expr_evaluate)(clr_object_handle_t expr,
+                                         clr_object_handle_t parameters,
+                                         clr_object_handle_t inputs);
+    clr_object_handle_t (*function_get_body)(clr_object_handle_t function);
+    clr_object_handle_t (*function_get_parameters)(
+        clr_object_handle_t function);
+    clr_object_handle_t (*ir_module_get_entry)(clr_object_handle_t module);
+    void (*luanch_debugger)();
+    clr_object_handle_t (*quantize_options_create)();
+    clr_object_handle_t (*shape_bucket_options_create)();
+    void (*quantize_options_set_calibration_dataset)(
+        clr_object_handle_t quantize_options, clr_object_handle_t dataset);
+    void (*quantize_options_set_calibration_method)(
+        clr_object_handle_t quantize_options, nncase_calib_method_t method);
+    void (*quantize_options_set_model_quant_mode)(
+        clr_object_handle_t quantize_options,
+        nncase_model_quant_mode_t model_quant_mode);
+    void (*quantize_options_set_quant_type)(
+        clr_object_handle_t quantize_options, nncase_quant_type_t quant_type);
+    void (*quantize_options_set_w_quant_type)(
+        clr_object_handle_t quantize_options, nncase_quant_type_t w_quant_type);
+    void (*quantize_options_set_finetune_weights_method)(
+        clr_object_handle_t quantize_options,
+        nncase_finetune_weights_method_t method);
+    void (*quantize_options_set_use_mix_quant)(
+        clr_object_handle_t quantize_options, bool use_mix_quant);
+    void (*quantize_options_set_quant_scheme)(
+        clr_object_handle_t quantize_options, const char *quant_scheme,
+        size_t quant_scheme_length);
+    void (*quantize_options_set_quant_scheme_strict_mode)(
+        clr_object_handle_t quantize_options, bool quant_scheme_strict_mode);
+    void (*quantize_options_set_export_quant_scheme)(
+        clr_object_handle_t quantize_options, bool export_quant_scheme);
+    void (*quantize_options_set_export_weight_range_by_channel)(
+        clr_object_handle_t quantize_options,
+        bool export_weight_range_by_channel);
+    void (*quantize_options_set_dump_quant_error)(
+        clr_object_handle_t quantize_options, bool dump_quant_error);
+    void (*quantize_options_set_dump_quant_error_symmetric_for_signed)(
+        clr_object_handle_t quantize_options,
+        bool dump_quant_error_symmetric_for_signed);
+    void (*shape_bucket_options_set_enable)(
+        clr_object_handle_t shape_bucket_options, bool enable);
+    void (*shape_bucket_options_set_range_info)(
+        clr_object_handle_t shape_bucket_options, const char *range_info,
+        size_t range_info_size);
+    void (*shape_bucket_options_set_segments_count)(
+        clr_object_handle_t shape_bucket_options, int segments_count);
+    void (*shape_bucket_options_set_fix_var_map)(
+        clr_object_handle_t shape_bucket_options, const char *fix_var_map,
+        size_t fix_var_map_size);
+
+    clr_object_handle_t (*rtvalue_from_handle)(nncase::value_node *value);
+    nncase::value_node *(*rtvalue_get_handle)(clr_object_handle_t rtvalue);
+    clr_object_handle_t (*stream_create)(const nncase_stream_mt_t *mt,
+                                         void *handle);
+    clr_object_handle_t (*target_create)(const char *target_name,
+                                         size_t target_name_length);
+    bool (*target_exists)(const char *target_name, size_t target_name_length);
+} nncase_api_mt_t;
+
+NNCASE_API nncase_api_mt_t *nncase_clr_api();
+NNCASE_API int nncase_clr_initialize(const char *root_assembly_path);
+NNCASE_API int nncase_clr_uninitialize();
+}
+
+DEFINE_ENUM_BITMASK_OPERATORS(nncase_dump_flags_t)
+
+namespace nncase::clr {
+class clr_object_ptr {
+  public:
+    constexpr clr_object_ptr(std::nullptr_t = nullptr) noexcept
+        : handle_(nullptr) {}
+    constexpr clr_object_ptr(clr_object_handle_t handle) noexcept
+        : handle_(handle) {}
+    constexpr clr_object_ptr(clr_object_ptr &&other) noexcept
+        : handle_(other.handle_) {
+        other.handle_ = nullptr;
+    }
+
+    ~clr_object_ptr() { release(); }
+
+    clr_object_ptr(const clr_object_ptr &) = delete;
+    clr_object_ptr &operator=(const clr_object_ptr &) = delete;
+
+    clr_object_ptr &operator=(clr_object_ptr &&other) noexcept {
+        release();
+        handle_ = other.handle_;
+        other.handle_ = nullptr;
+        return *this;
+    }
+
+    clr_object_handle_t get() const noexcept { return handle_; }
+
+    clr_object_handle_t detach() noexcept {
+        auto handle = handle_;
+        handle_ = nullptr;
+        return handle;
+    }
+
+    clr_object_handle_t *release_and_addressof() noexcept {
+        release();
+        return &handle_;
+    }
+
+  private:
+    void release() {
+        if (auto handle = handle_) {
+            handle_ = nullptr;
+            nncase_clr_api()->handle_free(handle);
+        }
+    }
+
+  private:
+    clr_object_handle_t handle_;
+};
+
+#define CHECK_CLR(x) x
+
+class clr_object_base {
+  public:
+    constexpr clr_object_base(std::nullptr_t = nullptr) noexcept
+        : obj_(nullptr) {}
+
+    clr_object_base(std::in_place_t, clr_object_ptr ptr) noexcept
+        : obj_(std::move(ptr)) {}
+
+    clr_object_base(clr_object_base &&) = default;
+    clr_object_base &operator=(clr_object_base &&) = default;
+
+    clr_object_handle_t get() const noexcept { return obj_.get(); }
+    clr_object_handle_t *release_and_addressof() noexcept {
+        return obj_.release_and_addressof();
+    }
+
+    template <class T, std::enable_if_t<std::is_base_of_v<clr_object_base, T>>>
+    T &cast() noexcept {
+        return static_cast<T &>(*this);
+    }
+
+  protected:
+    clr_object_ptr obj_;
+};
+
+class array : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    array(nncase_array_element_kind_t kind, const clr_object_handle_t *elements,
+          size_t length) {
+        obj_ = nncase_clr_api()->array_create(kind, elements, length);
+    }
+
+    template <class T = clr_object_base> T at(size_t index) {
+        return {std::in_place,
+                nncase_clr_api()->array_get_item(obj_.get(), index)};
+    }
+
+    size_t length() { return nncase_clr_api()->array_get_length(obj_.get()); }
+
+    template <class T = clr_object_base> std::vector<T> to_vector() {
+        std::vector<T> vector(length());
+        for (size_t i = 0; i < vector.size(); i++) {
+            vector[i] = at<T>(i);
+        }
+        return vector;
+    }
+};
+
+class calibration_dataset_provider : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    calibration_dataset_provider(array dataset, size_t samples_count,
+                                 array fn_params) {
+        obj_ = nncase_clr_api()->calibration_dataset_provider_create(
+            dataset.get(), samples_count, fn_params.get());
+    }
+};
+
+class quantize_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    quantize_options() { obj_ = nncase_clr_api()->quantize_options_create(); }
+
+    calibration_dataset_provider calibration_dataset() { return nullptr; }
+    void calibration_dataset(const calibration_dataset_provider &value) {
+        nncase_clr_api()->quantize_options_set_calibration_dataset(obj_.get(),
+                                                                   value.get());
+    }
+
+    nncase_model_quant_mode_t model_quant_mode() { return nncase_mqm_no_quant; }
+    void model_quant_mode(nncase_model_quant_mode_t value) {
+        nncase_clr_api()->quantize_options_set_model_quant_mode(obj_.get(),
+                                                                value);
+    }
+
+    nncase_calib_method_t calibrate_method() { return nncase_calib_noclip; }
+    void calibrate_method(nncase_calib_method_t value) {
+        nncase_clr_api()->quantize_options_set_calibration_method(obj_.get(),
+                                                                  value);
+    }
+
+    nncase_quant_type_t quant_type() { return nncase_qt_uint8; }
+    void quant_type(nncase_quant_type_t value) {
+        nncase_clr_api()->quantize_options_set_quant_type(obj_.get(), value);
+    }
+
+    nncase_quant_type_t w_quant_type() { return nncase_qt_uint8; }
+    void w_quant_type(nncase_quant_type_t value) {
+        nncase_clr_api()->quantize_options_set_w_quant_type(obj_.get(), value);
+    }
+
+    nncase_finetune_weights_method_t finetune_weights_method() {
+        return nncase_no_finetune_weights;
+    }
+    void finetune_weights_method(nncase_finetune_weights_method_t value) {
+        nncase_clr_api()->quantize_options_set_finetune_weights_method(
+            obj_.get(), value);
+    }
+
+    bool use_mix_quant() { return false; }
+    void use_mix_quant(bool value) {
+        nncase_clr_api()->quantize_options_set_use_mix_quant(obj_.get(), value);
+    }
+
+    std::string quant_scheme() { return ""; }
+    void quant_scheme(std::string_view value) {
+        nncase_clr_api()->quantize_options_set_quant_scheme(
+            obj_.get(), value.data(), value.length());
+    }
+
+    bool quant_scheme_strict_mode() { return false; }
+    void quant_scheme_strict_mode(bool value) {
+        nncase_clr_api()->quantize_options_set_quant_scheme_strict_mode(
+            obj_.get(), value);
+    }
+
+    bool export_quant_scheme() { return false; }
+    void export_quant_scheme(bool value) {
+        nncase_clr_api()->quantize_options_set_export_quant_scheme(obj_.get(),
+                                                                   value);
+    }
+
+    bool export_weight_range_by_channel() { return false; }
+    void export_weight_range_by_channel(bool value) {
+        nncase_clr_api()->quantize_options_set_export_weight_range_by_channel(
+            obj_.get(), value);
+    }
+
+    bool dump_quant_error() { return false; }
+    void dump_quant_error(bool value) {
+        nncase_clr_api()->quantize_options_set_dump_quant_error(obj_.get(),
+                                                                value);
+    }
+
+    bool dump_quant_error_symmetric_for_signed() { return false; }
+    void dump_quant_error_symmetric_for_signed(bool value) {
+        nncase_clr_api()
+            ->quantize_options_set_dump_quant_error_symmetric_for_signed(
+                obj_.get(), value);
+    }
+};
+
+class shape_bucket_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    shape_bucket_options() {
+        obj_ = nncase_clr_api()->shape_bucket_options_create();
+    }
+
+    bool enable() { return false; }
+    void enable(bool value) {
+        nncase_clr_api()->shape_bucket_options_set_enable(obj_.get(), value);
+    }
+
+    std::map<std::string, std::tuple<int, int>> range_info() { return {}; }
+    void range_info(std::map<std::string, std::tuple<int, int>> value) {
+        json j = value;
+        std::string s = j.dump();
+        nncase_clr_api()->shape_bucket_options_set_range_info(
+            obj_.get(), s.c_str(), s.length());
+    }
+
+    int segments_count() { return 2; }
+    void segments_count(int value) {
+        nncase_clr_api()->shape_bucket_options_set_segments_count(obj_.get(),
+                                                                  value);
+    }
+
+    std::map<std::string, int> fix_var_map() { return {}; }
+    void fix_var_map(std::map<std::string, int> value) {
+        json j = value;
+        std::string s = j.dump();
+        nncase_clr_api()->shape_bucket_options_set_fix_var_map(
+            obj_.get(), s.c_str(), s.length());
+    }
+};
+
+class cstream : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    cstream(const nncase_stream_mt_t *mt, void *handle) {
+        obj_ = nncase_clr_api()->stream_create(mt, handle);
+    }
+
+    ~cstream() { nncase_clr_api()->handle_dispose(obj_.get()); }
+};
+
+class compile_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    compile_options() { obj_ = nncase_clr_api()->compile_options_create(); }
+
+    std::string input_format() { return "cpu"; }
+    void input_format(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_format(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string dump_dir() { return "cpu"; }
+    void dump_dir(std::string_view value) {
+        nncase_clr_api()->compile_options_set_dump_dir(obj_.get(), value.data(),
+                                                       value.length());
+    }
+
+    nncase_dump_flags_t dump_flags() {
+        return nncase_clr_api()->compile_options_get_dump_flags(obj_.get());
+    }
+    void dump_flags(nncase_dump_flags_t value) {
+        nncase_clr_api()->compile_options_set_dump_flags(obj_.get(), value);
+    }
+
+    clr::quantize_options quantize_options() { return nullptr; }
+    void quantize_options(const clr::quantize_options &value) {
+        nncase_clr_api()->compile_options_set_quantize_options(obj_.get(),
+                                                               value.get());
+    }
+
+    bool preprocess() { return true; }
+    void preprocess(bool value) {
+        nncase_clr_api()->compile_options_set_preprocess(obj_.get(), value);
+    }
+
+    std::string input_layout() { return ""; }
+    void input_layout(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_layout(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string output_layout() { return ""; }
+    void output_layout(std::string_view value) {
+        nncase_clr_api()->compile_options_set_output_layout(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string input_file() { return ""; }
+    void input_file(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_file(
+            obj_.get(), value.data(), value.length());
+    }
+
+    nncase_input_type_t input_type() { return nncase_it_float32; }
+    void input_type(nncase_input_type_t value) {
+        nncase_clr_api()->compile_options_set_input_type(obj_.get(), value);
+    }
+
+    std::string input_shape() { return ""; }
+    void input_shape(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_shape(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string input_range() { return ""; }
+    void input_range(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_range(
+            obj_.get(), value.data(), value.length());
+    }
+
+    bool swapRB() { return false; }
+    void swapRB(bool value) {
+        nncase_clr_api()->compile_options_set_swapRB(obj_.get(), value);
+    }
+
+    float letterbox_value() { return 0.f; }
+    void letterbox_value(float value) {
+        nncase_clr_api()->compile_options_set_letterbox_value(obj_.get(),
+                                                              value);
+    }
+
+    std::string mean() { return ""; }
+    void mean(std::string_view value) {
+        nncase_clr_api()->compile_options_set_mean(obj_.get(), value.data(),
+                                                   value.length());
+    }
+
+    std::string std() { return ""; }
+    void std(std::string_view value) {
+        nncase_clr_api()->compile_options_set_std(obj_.get(), value.data(),
+                                                  value.length());
+    }
+
+    clr::shape_bucket_options shape_bucket_options() { return nullptr; }
+    void shape_bucket_options(const clr::shape_bucket_options &value) {
+        nncase_clr_api()->compile_options_set_shape_bucket_options(obj_.get(),
+                                                                   value.get());
+    }
+};
+
+class target : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    static bool exists(std::string_view name) {
+        return nncase_clr_api()->target_exists(name.data(), name.length());
+    }
+
+    target(std::string_view name) {
+        obj_ = nncase_clr_api()->target_create(name.data(), name.length());
+    }
+};
+
+class rtvalue : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    rtvalue(nncase::value_t value) {
+        obj_ = nncase_clr_api()->rtvalue_from_handle(value.get());
+    }
+
+    value_t to_value() const {
+        auto ptr = nncase_clr_api()->rtvalue_get_handle(obj_.get());
+        return ptr;
+    }
+};
+
+class expr : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    rtvalue evaluate(const array &params, const array &inputs) {
+        return {std::in_place, nncase_clr_api()->expr_evaluate(
+                                   get(), params.get(), inputs.get())};
+    }
+};
+
+class var : public expr {
+  public:
+    using expr::expr;
+};
+
+class base_function : public expr {
+  public:
+    using expr::expr;
+};
+
+class function : public base_function {
+  public:
+    using base_function::base_function;
+
+    expr body() {
+        return {std::in_place, nncase_clr_api()->function_get_body(get())};
+    }
+
+    array parameters() {
+        return {std::in_place,
+                nncase_clr_api()->function_get_parameters(get())};
+    }
+};
+
+class ir_module : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    function entry() {
+        return {std::in_place, nncase_clr_api()->ir_module_get_entry(get())};
+    }
+};
+
+class compiler : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    ir_module import_tflite_module(cstream &stream) {
+        return {std::in_place, nncase_clr_api()->compiler_import_tflite_module(
+                                   get(), stream.get())};
+    }
+
+    ir_module import_onnx_module(cstream &stream) {
+        return {std::in_place, nncase_clr_api()->compiler_import_onnx_module(
+                                   get(), stream.get())};
+    }
+
+    ir_module import_ncnn_module(cstream &param_stream, cstream &bin_stream) {
+        return {std::in_place,
+                nncase_clr_api()->compiler_import_ncnn_module(
+                    get(), param_stream.get(), bin_stream.get())};
+    }
+
+    void compile() { nncase_clr_api()->compiler_compile(obj_.get()); }
+    void gencode(cstream &stream) {
+        nncase_clr_api()->compiler_gencode(obj_.get(), stream.get());
+    }
+};
+
+class compile_session : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    compile_session(const target &target, const compile_options &options) {
+        obj_ = nncase_clr_api()->compile_session_create(target.get(),
+                                                        options.get());
+    }
+
+    clr::compiler compiler() {
+        return {std::in_place,
+                nncase_clr_api()->compile_session_get_compiler(obj_.get())};
+    }
+};
+} // namespace nncase::clr
diff --git a/third_party/nncase/riscv64/include/nncase/compiler_defs.h b/third_party/nncase/riscv64/include/nncase/compiler_defs.h
new file mode 100644
index 0000000..ea44203
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/compiler_defs.h
@@ -0,0 +1,107 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <gsl/gsl-lite.hpp>
+#include <type_traits>
+
+#if defined(_MSC_VER)
+#ifdef NNCASE_DLL
+#define NNCASE_API __declspec(dllexport)
+#elif defined(NNCASE_SHARED_LIBS)
+#define NNCASE_API __declspec(dllimport)
+#else
+#define NNCASE_API
+#endif
+#else
+#define NNCASE_API __attribute__((visibility("default")))
+#endif
+
+#if defined(_MSC_VER)
+#define NNCASE_UNREACHABLE() __assume(0)
+#else
+#define NNCASE_UNREACHABLE() __builtin_unreachable()
+#endif
+
+#if gsl_CPP17_OR_GREATER
+#define NNCASE_INLINE_VAR inline
+#define NNCASE_UNUSED [[maybe_unused]]
+namespace nncase {
+template <class Callable, class... Args>
+using invoke_result_t = std::invoke_result_t<Callable, Args...>;
+}
+#else
+#define NNCASE_INLINE_VAR
+#if defined(_MSC_VER)
+#define NNCASE_UNUSED
+#else
+#define NNCASE_UNUSED __attribute__((unused))
+#endif
+namespace nncase {
+template <class Callable, class... Args>
+using invoke_result_t = std::result_of_t<Callable(Args...)>;
+}
+#endif
+
+#define NNCASE_LITTLE_ENDIAN 1
+
+#define NNCASE_HAVE_STD_BYTE gsl_CPP17_OR_GREATER
+#define NNCASE_NODISCARD gsl_NODISCARD
+#define NNCASE_NORETURN gsl_NORETURN
+
+#define BEGIN_NS_NNCASE_RUNTIME                                                \
+    namespace nncase {                                                         \
+    namespace runtime {
+#define END_NS_NNCASE_RUNTIME                                                  \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_RT_MODULE(MODULE)                                      \
+    namespace nncase {                                                         \
+    namespace runtime {                                                        \
+    namespace MODULE {
+
+#define END_NS_NNCASE_RT_MODULE                                                \
+    }                                                                          \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_KERNELS                                                \
+    namespace nncase {                                                         \
+    namespace kernels {
+
+#define END_NS_NNCASE_KERNELS                                                  \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_KERNELS_MODULE(MODULE)                                 \
+    namespace nncase {                                                         \
+    namespace kernels {                                                        \
+    namespace MODULE {
+
+#define END_NS_NNCASE_KERNELS_MODULE                                           \
+    }                                                                          \
+    }                                                                          \
+    }
+
+#ifndef DEFINE_ENUM_BITMASK_OPERATORS
+#define DEFINE_ENUM_BITMASK_OPERATORS(ENUMTYPE)                                \
+    gsl_DEFINE_ENUM_BITMASK_OPERATORS(ENUMTYPE)
+#endif
+
+namespace nncase {
+struct default_init_t {};
+
+NNCASE_INLINE_VAR constexpr default_init_t default_init{};
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/functional/ai2d/ai2d_builder.h b/third_party/nncase/riscv64/include/nncase/functional/ai2d/ai2d_builder.h
new file mode 100644
index 0000000..00c5461
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/ai2d/ai2d_builder.h
@@ -0,0 +1,102 @@
+#ifndef BUILDING_RUNTIME
+#include <filesystem>
+#endif
+#include <nncase/runtime/k230/gnne_tile_utils.h>
+
+namespace nncase
+{
+namespace F
+{
+    namespace k230
+    {
+        using namespace nncase::runtime;
+        using namespace nncase::runtime::k230;
+        // using namespace nncase::ir::transforms;
+
+#define AI2D_BASE_ADDR_PAGE_ALIGNED 0x80400000
+#define AI2D_BASE_OFFSET 0x0c00
+#define AI2D_MMAP_SIZE 0x1000
+
+        typedef enum AI2D_INTR
+        {
+            AI2D_INTR_OK,
+            AI2D_INTR_TIME_OUT,
+            AI2D_INTR_EXCEPTION,
+        } ai2d_intr_t;
+
+#if defined(BUILDING_RUNTIME)
+        struct addr
+        {
+            volatile void *addr;
+            volatile void *paddr;
+#if defined(__linux__)
+            volatile void *vaddr;
+            size_t mmap_size;
+#endif
+        };
+#endif
+
+        class ai2d_builder
+        {
+        private:
+            ai2d_datatype_t ai2d_dtype_;
+            ai2d_crop_param_t crop_param_;
+            ai2d_shift_param_t shift_param_;
+            ai2d_pad_param_t pad_param_;
+            ai2d_resize_param_t resize_param_;
+            ai2d_affine_param_t affine_param_;
+            std::vector<std::vector<uint32_t>> regs_;
+            std::vector<uint32_t> split_pos_;
+            ai2d_config config_;
+
+            result<void> check_config();
+
+            int32_t input_c_;
+            int32_t output_c_;
+            int32_t input_h_;
+            int32_t input_w_;
+            int32_t output_h_;
+            int32_t output_w_;
+
+#if defined(BUILDING_RUNTIME)
+            struct addr ai2d_addr_;
+#if !defined(__linux__)
+            volatile bool ai2d_done_;
+#else
+            int ai2d_fd_;
+            int mem_fd_;
+#endif
+            void ai2d_set_base(volatile void *addr);
+            volatile uint8_t *ai2d_get_base();
+            uint16_t ai2d_get_intr_num();
+            void ai2d_set_time_out(uint32_t val);
+#endif
+
+        public:
+            ai2d_builder(dims_t &input_shape, dims_t &output_shape, ai2d_datatype_t ai2d_dtype,
+                ai2d_crop_param_t crop_param, ai2d_shift_param_t shift_param, ai2d_pad_param_t pad_param,
+                ai2d_resize_param_t resize_param, ai2d_affine_param_t affine_param);
+            static std::unique_ptr<ai2d_builder> create(dims_t &input_shape, dims_t &output_shape, ai2d_datatype_t &ai2d_dtype,
+                ai2d_crop_param_t &crop_param, ai2d_shift_param_t &shift_param, ai2d_pad_param_t &pad_param,
+                ai2d_resize_param_t &resize_param, ai2d_affine_param_t &affine_param);
+            ~ai2d_builder();
+
+#if defined(BUILDING_RUNTIME)
+            void ai2d_clear_cpu_intr();
+#endif
+            dims_t input_shape_, output_shape_;
+            // runtime::k230::span_writer input_writer_, reg_writer_;
+
+            bool dump_asm_;
+#ifndef BUILDING_RUNTIME
+            std::filesystem::path dump_dir_;
+#endif
+
+            result<void> build_schedule();
+            void dump_asm(bool write_all);
+            result<void> dump_gmodel();
+            result<void> invoke(runtime_tensor &input, runtime_tensor &output);
+        };
+    }
+}
+}
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/functional/ai2d/ops_utils.h b/third_party/nncase/riscv64/include/nncase/functional/ai2d/ops_utils.h
new file mode 100644
index 0000000..d98baab
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/ai2d/ops_utils.h
@@ -0,0 +1,390 @@
+#pragma once
+#include <array>
+#include <functional>
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/k230/error.h>
+// #include <nncase/runtime/k230/fp24.h>
+// #include <nncase/runtime/k230/gnne_instructions.h>
+// #include <nncase/runtime/k230/runtime_types.h>
+#include <nncase/runtime/runtime_op_utility.h>
+#include <nncase/runtime/runtime_tensor.h>
+#include <string>
+#include <utility>
+
+namespace nncase
+{
+namespace F
+{
+    namespace k230
+    {
+        enum class slot_t : uint8_t
+        {
+            in_shape = 0x1,
+            in_stride = 0x2,
+            in_bytes = 0x3,
+            out_shape = 0x4,
+            out_stride = 0x5,
+            out_bytes = 0x6
+        };
+
+        struct range_t
+        {
+            size_t begin;
+            size_t end;
+
+            template <typename T>
+            range_t(T a)
+                : begin(0), end(a)
+            {
+            }
+
+            template <typename T>
+            range_t(T a, T b)
+                : begin(a), end(b)
+            {
+            }
+
+            friend std::ostream &operator<<(std::ostream &os, const range_t &range)
+            {
+                os << std::to_string(range.begin) << std::string(" ") << std::to_string(range.end);
+                return os;
+            }
+        };
+
+        template <typename T, bool ByteAligned = true>
+        struct slot_decs
+        {
+            using datatype = T;
+            const static bool byte_aligned = ByteAligned;
+            size_t bits_offset;
+            size_t total_bits;
+            range_t range;
+        };
+
+        // template <typename From, typename To>
+        // struct is_explicit_convertiable : std::bool_constant<std::is_constructible_v<To, From> && !std::is_convertible_v<From, To>>
+        // {
+        // };
+
+        // template <typename From, typename To>
+        // constexpr bool is_explicit_convertiable_v = is_explicit_convertiable<From, To>::value;
+
+        template <typename WriteDtype, typename T>
+        inline void overwrite(const uint8_t *dest, size_t offset, T &value)
+        {
+            WriteDtype *ptr = reinterpret_cast<WriteDtype *>(const_cast<uint8_t *>(dest + offset));
+            *ptr = (WriteDtype)value;
+        }
+
+        template <typename WriteDtype>
+        inline void overwrite(const uint8_t *dest, size_t offset, const dims_t &value)
+        {
+            for (size_t i = 0; i < value.size(); i++)
+            {
+                overwrite<WriteDtype>(dest, offset + i * sizeof(WriteDtype), value[i]);
+            }
+        }
+
+        template <typename T>
+        inline void overwrite(datatype_t dt, const uint8_t *dest, size_t offset, const T &value)
+        {
+            if (dt->typecode() == dt_uint32)
+            {
+                overwrite<uint32_t>(dest, offset, value);
+            }
+        }
+
+        /**
+ * @brief write bits
+ *
+ * @param total_bits the value field total bits
+ * @param writed_bits current writed bits , for recursive
+ * @param bits_offest current bits offset in the one byte
+ */
+        inline void bits_writer(uint8_t *dest, size_t total_bits, size_t writed_bits, size_t bits_offest, const uint64_t value)
+        {
+            // inner var
+            int write_bits_ = std::min(total_bits - writed_bits, (size_t)8);
+            int over_flow_ = std::max(write_bits_ + (int)bits_offest - 8, 0);
+            // used var
+            int cur_bits = write_bits_ - over_flow_;
+            uint8_t byte = ((value >> writed_bits) & (0xff >> (8 - cur_bits))) << bits_offest;
+            uint8_t mask = (0xff >> (8 - bits_offest)) | (0xff << (cur_bits + bits_offest));
+            int carry = (bits_offest + cur_bits) / 8;
+            int mod = (bits_offest + cur_bits) % 8;
+            // assgin value
+
+            *dest = byte | (*dest & mask);
+            if (total_bits > writed_bits + cur_bits)
+            {
+                bits_writer(dest + carry, total_bits, writed_bits + cur_bits, mod, value);
+            }
+        }
+
+        // template <typename Datatype, typename T, class = std::enable_if_t<std::is_integral_v<T>>>
+        // inline void write_value(const slot_decs<Datatype, true> &slot, uint8_t *dest, const T value)
+        // {
+        //     Datatype *ptr = reinterpret_cast<Datatype *>(dest + slot.bits_offset / 8);
+        //     *ptr = static_cast<Datatype>(value);
+        // }
+
+        // template <typename Datatype, typename T, class = std::enable_if_t<std::is_integral_v<T>>>
+        // inline void write_value(const slot_decs<Datatype, false> &slot, uint8_t *dest, const T &value)
+        // {
+        //     // bits write int value
+        //     size_t byte_offset = slot.bits_offset / 8;
+        //     size_t mod = slot.bits_offset - (byte_offset * 8);
+        //     bits_writer(dest + byte_offset, slot.total_bits, 0, mod, (uint64_t)value);
+        // }
+
+        // template <typename Datatype, bool Aligned>
+        // inline void write_value(const slot_decs<Datatype, Aligned> &slot, uint8_t *dest, const fp24 &value)
+        // {
+        //     write_value<Datatype>(slot, dest, value.value);
+        // }
+
+        // template <typename Datatype, bool Aligned, typename T, class = std::enable_if_t<!std::is_integral_v<T>>>
+        // inline void write_value(const slot_decs<Datatype, Aligned> &slot, uint8_t *dest, const T &value)
+        // {
+        //     // bits write int value
+        //     if constexpr (std::is_convertible_v<T, uint64_t> || is_explicit_convertiable_v<T, uint64_t>)
+        //     {
+        //         write_value<Datatype>(slot, dest, (uint64_t)value);
+        //     }
+        //     else
+        //     {
+        //         static_assert(sizeof(T) == 0, "current datatype is not integral and can't cast to uint64_t, please check !");
+        //     }
+        // }
+
+        /**
+ * @brief when write vectorlike, dispatch aligned inner loop
+ */
+        template <typename Datatype, bool Aligned,
+            template <typename, size_t> class Container, typename T, size_t N>
+        inline void write_value(const slot_decs<Datatype, Aligned> &slot, uint8_t *dest, const Container<T, N> &value)
+        {
+            for (size_t i = slot.range.begin; i < slot.range.end; i++)
+            {
+                // NOTE the inst write offset must start from 0.
+                write_value<Datatype>(slot, dest + (i - slot.range.begin) * (slot.total_bits / 8), value[i]);
+            }
+        }
+
+        // template <typename... TArgs, typename Callable, size_t... Is>
+        // inline void foreach_slots(const std::tuple<TArgs...> &slots, Callable &&fn, std::index_sequence<Is...>)
+        // {
+        //     (fn(std::get<Is>(slots)), ...);
+        // }
+
+        template <typename... TArgs, typename Callable>
+        inline void foreach_slots(const std::tuple<TArgs...> &slots, Callable &&fn)
+        {
+            foreach_slots(slots, fn, std::make_index_sequence<sizeof...(TArgs)> {});
+        }
+
+        template <typename T>
+        inline auto get_callback(uint8_t *dest, const T &value)
+        {
+            return [dest, &value](auto slot) {
+                write_value(slot, dest, value);
+            };
+        }
+
+        /**
+ * @brief compute fold shape, for fast load and store
+ *
+ * @param shape
+ * @param split
+ * @return dims_t
+ */
+        inline dims_t compute_shape_fold(dims_t shape, int split)
+        {
+            dims_t fold_shape = shape;
+            if (split == -1)
+                return fold_shape;
+            for (int i = split + 1; i < int(shape.size()) - 1; i++)
+            {
+                fold_shape[i + 1] *= fold_shape[i];
+                fold_shape[i] = 1;
+            }
+            return fold_shape;
+        }
+
+        inline dims_t get_default_strides(const dims_t &shape)
+        {
+            dims_t strides = runtime::get_default_strides(shape);
+            // remove the zero strides.
+            for (int i = shape.size() - 1; i >= 0; i--)
+            {
+                if (strides[i] == 0)
+                    strides[i] = (i == int(shape.size()) - 1) ? 1 : (strides[i + 1] * shape[i + 1]);
+            }
+            return strides;
+        }
+
+        inline dims_t compute_ddr_stride(const dims_t &shape, datatype_t ddr_dtype)
+        {
+            // NOTE if the inst use ddr data,the STRIDE_GLB actual is tensor.shape
+            size_t bytes = runtime::get_bytes(ddr_dtype);
+            dims_t strides = runtime::get_default_strides(shape);
+            // remove the zero strides.
+            for (int i = shape.size() - 1; i >= 0; i--)
+            {
+                if (strides[i] == 0)
+                    strides[i] = (i == int(shape.size()) - 1) ? 1 : (strides[i + 1] * shape[i + 1]);
+            }
+            std::for_each(strides.begin(), strides.end(), [&bytes](size_t &x) { x *= bytes; });
+            return strides;
+        }
+
+        template <typename ShapeT>
+        inline ShapeT align_broadcast_shape(const ShapeT &src, const ShapeT &dest)
+        {
+            assert(src.size() == dest.size());
+            auto it = std::find_if(src.begin(), src.end(), [](size_t dim) { return dim != 1; });
+            if (it == src.end())
+            {
+                return ShapeT(dest.size(), 1);
+            }
+            else
+            {
+                auto begin = std::distance(src.begin(), it);
+                auto sub_len = src.size() - begin;
+                for (int32_t i = dest.size() - sub_len; i >= 0; i--)
+                {
+                    bool found = true;
+                    for (size_t j = 0; j < sub_len; j++)
+                    {
+                        auto dim = src.at(begin + j);
+                        if (dim != 1 && dim != dest.at(i + j))
+                        {
+                            found = false;
+                            break;
+                        }
+                    }
+
+                    if (found)
+                    {
+                        ShapeT ret(i, 1);
+                        for (size_t j = 0; j < sub_len; j++)
+                            ret.push_back(src.at(begin + j));
+                        auto surfix = dest.size() - ret.size();
+                        for (size_t j = 0; j < surfix; j++)
+                            ret.push_back(1);
+                        return ret;
+                    }
+                }
+            }
+
+            throw std::runtime_error("Unexpected broadcast");
+        }
+
+        template <typename T = size_t>
+        inline T compute_size(const dims_t &shape)
+        {
+            size_t size = std::accumulate(shape.begin(), shape.end(), 1, std::multiplies<size_t>());
+            return static_cast<T>(size);
+        }
+
+        /**
+ * @brief 把一个shape按split axis 分为两部分, 外面是主重复次数, 里面是block的size
+ *
+ * @param shape
+ * @param split_axis
+ * @return std::tuple<size_t, size_t>
+ */
+        inline std::tuple<size_t, size_t> compute_size(const dims_t &shape, int split_axis)
+        {
+            size_t inner = std::accumulate(shape.begin() + split_axis, shape.end(), 1, std::multiplies<size_t> {});
+            size_t outter = std::accumulate(shape.begin(), shape.begin() + split_axis, 1, std::multiplies<size_t> {});
+            return std::make_tuple(outter, inner);
+        }
+
+        template <typename T = size_t>
+        inline T compute_bytes(size_t size, datatype_t dtype)
+        {
+            size_t bytes = size * runtime::get_bytes(dtype);
+            return static_cast<T>(bytes);
+        }
+
+        inline size_t compute_once_size(const dims_t &shape, size_t split_axis)
+        {
+            return std::accumulate(shape.begin() + split_axis, shape.end(), 1, std::multiplies<size_t> {});
+        }
+
+        // template <datatype_t Dtype = dt_bfloat16>
+        // gsl::span<to_cpp_type_t<Dtype>> runtime_tensor_view(nncase::runtime::runtime_tensor &t)
+        // {
+        //     auto map = std::move(nncase::runtime::hrt::map(t, nncase::runtime::hrt::map_read).unwrap_or_throw());
+        //     return map.buffer().as_span<to_cpp_type_t<Dtype>>();
+        // }
+
+        // template <typename Dtype>
+        // gsl::span<Dtype> runtime_tensor_view(nncase::runtime::runtime_tensor &t)
+        // {
+        //     auto map = std::move(nncase::runtime::hrt::map(t, nncase::runtime::hrt::map_read).unwrap_or_throw());
+        //     return map.buffer().as_span<Dtype>();
+        // }
+
+        inline value_range<float> fixup_range(value_range<float> range, bool symmetric = false)
+        {
+            if (symmetric)
+            {
+                auto r = std::max({ std::abs(range.min), std::abs(range.max), 0.01f });
+                return { -r, r };
+            }
+            else
+            {
+                if (range.min < -1e3)
+                    range.min = -1e3;
+                if (range.max > 1e3)
+                    range.max = 1e3;
+                auto r = range.max - range.min;
+                if (r == 0)
+                    r = 0.1f;
+                else if (r < 0.01f)
+                    r = 0.01f;
+                range.max = range.min + r;
+
+                if (range.max < 0)
+                    range.max = 0;
+                if (range.min > 0)
+                    range.min = 0;
+            }
+
+            return range;
+        }
+
+        inline quant_param_t get_quant_param(value_range<float> range, int32_t bits = 8)
+        {
+            range = fixup_range(range);
+            auto Q_max = (float)pow(2, bits) - 1;
+            auto Q_min = bits % 2 == 0 ? 0 : -(float)pow(2, bits);
+            auto scale = (range.max - range.min) / (Q_max - Q_min);
+            auto bias = roundf((range.max * Q_min - range.min * Q_max) / (range.max - range.min));
+            return quant_param_t { static_cast<int32_t>(bias), (float)scale };
+        }
+
+        inline size_t offset(const dims_t &strides, size_t b)
+        {
+            return b * strides[0];
+        }
+
+        inline size_t offset(const dims_t &strides, size_t b, size_t c)
+        {
+            return offset(strides, b) + c * strides[1];
+        }
+
+        inline size_t offset(const dims_t &strides, size_t b, size_t c, size_t h)
+        {
+            return offset(strides, b, c) + h * strides[2];
+        }
+
+        inline size_t offset(const dims_t &strides, size_t b, size_t c, size_t h, size_t w)
+        {
+            return offset(strides, b, c, h) + w * strides[3];
+        }
+    }
+}
+}
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_function.h b/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_function.h
new file mode 100644
index 0000000..c8f4f7f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_function.h
@@ -0,0 +1,25 @@
+/* Copyright 2022 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+
+#include <nncase/kernels/kernel_context.h>
+#include <nncase/runtime/k230/compiler_defs.h>
+#include <nncase/tensor.h>
+
+BEGIN_NS_NNCASE_FUNCTIONAL_K230
+
+NNCASE_MODULES_K230_API result<void> dynamic_function_invoke_core(gsl::span<const gsl::byte> text, gsl::span<const value_t> inputs, value_t output, const kernels::kernel_context &context) noexcept;
+
+END_NS_NNCASE_FUNCTIONAL_K230
diff --git a/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_gnne_matmul.h b/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_gnne_matmul.h
new file mode 100644
index 0000000..47654d4
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/k230/dynamic_gnne_matmul.h
@@ -0,0 +1,26 @@
+/* Copyright 2022 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+
+#include <nncase/kernels/kernel_context.h>
+#include <nncase/runtime/k230/compiler_defs.h>
+#include <nncase/tensor.h>
+
+BEGIN_NS_NNCASE_FUNCTIONAL_K230
+
+NNCASE_MODULES_K230_API result<value_t> dynamic_gnne_matmul(gsl::span<const gsl::byte> field_span,
+    const std::vector<value_t> &inputs, const kernels::kernel_context &context = kernels::default_kernel_context());
+
+END_NS_NNCASE_FUNCTIONAL_K230
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/functional/ops.h b/third_party/nncase/riscv64/include/nncase/functional/ops.h
new file mode 100644
index 0000000..f9e3454
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/ops.h
@@ -0,0 +1,307 @@
+/**
+ * @file ops.h
+ * @date 2021-09-27
+ *
+ * @copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+#pragma once
+#include <nncase/runtime/runtime_tensor.h>
+
+#ifndef NNCASE_FUNCTIONAL_IMPL_PLATFORM_HEADER
+#include <nncase/functional/ops.platform.h>
+#else
+#include NNCASE_FUNCTIONAL_IMPL_PLATFORM_HEADER
+#endif
+
+namespace nncase::F {
+
+/**
+ * @brief unary_square
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+square(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_square);
+}
+/**
+ * @brief unary_sqrt
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sqrt(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_sqrt);
+}
+/**
+ * @brief unary_log
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+log(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_log);
+}
+/**
+ * @brief unary_exp
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+exp(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_exp);
+}
+/**
+ * @brief unary_sin
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sin(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_sin);
+}
+/**
+ * @brief unary_cos
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+cos(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_cos);
+}
+/**
+ * @brief unary_round
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+round(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_round);
+}
+/**
+ * @brief unary_floor
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+floor(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_floor);
+}
+/**
+ * @brief unary_ceil
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+ceil(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_ceil);
+}
+/**
+ * @brief unary_abs
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+abs(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_abs);
+}
+/**
+ * @brief unary_neg
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+neg(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_neg);
+}
+
+/**
+ * @brief binary add
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+add(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_add);
+}
+/**
+ * @brief binary sub
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sub(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_sub);
+}
+/**
+ * @brief binary mul
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+mul(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_mul);
+}
+/**
+ * @brief binary div
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+div(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_div);
+}
+/**
+ * @brief binary min
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+min(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_min);
+}
+/**
+ * @brief binary max
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+max(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_max);
+}
+
+/**
+ * @brief quantize float or bfloat tensor to uint8 or int8
+ *
+ * @param input runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+quantize(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::quantize(input, dtype);
+}
+/**
+ * @brief dequantize uint8 or int8 tensor to float or bfloat
+ *
+ * @param input runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+dequantize(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::dequantize(input, dtype);
+}
+
+/**
+ * @brief give bboxs, crop new tensor from current tensor.
+ *
+ * @param input
+ * @param bbox runtime tensor, shape should be [1,1,roi_amounts,4], layout
+ * should be [y0, x0, y1, x1]
+ * @param out_h output tensor height
+ * @param out_w output tensor width
+ * @param resize_mode resize mode
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+crop(runtime::runtime_tensor &input, runtime::runtime_tensor &bbox,
+     size_t out_h, size_t out_w, image_resize_mode_t resize_mode,
+     bool align_corners, bool half_pixel_centers) noexcept {
+    return impl::crop(input, bbox, out_h, out_w, resize_mode, align_corners,
+                      half_pixel_centers);
+}
+
+/**
+ * @brief resize tensor to new height or width
+ *
+ * @param input
+ * @param out_h
+ * @param out_w
+ * @param resize_mode
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+resize(runtime::runtime_tensor &input, size_t out_h, size_t out_w,
+       image_resize_mode_t resize_mode, bool align_corners,
+       bool half_pixel_centers) noexcept {
+    return impl::resize(input, out_h, out_w, resize_mode, align_corners,
+                        half_pixel_centers);
+}
+
+/**
+ * @brief padding value on the input tensor
+ *        temporary not support
+ * @param input
+ * @param padding vector for padding param, from last to frist. eg. vector [
+ * {2,3}, {1,3} ] mean pad {2,3} in last dim, pad {1,3} in last second dim
+ * @param pad_mode
+ * @param fill_v const fill value
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+pad(runtime::runtime_tensor &input, runtime_paddings_t &paddings,
+    pad_mode_t pad_mode, float fill_v) noexcept {
+    return impl::pad(input, paddings, pad_mode, fill_v);
+}
+
+} // namespace nncase::F
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/functional/ops.platform.h b/third_party/nncase/riscv64/include/nncase/functional/ops.platform.h
new file mode 100644
index 0000000..5990248
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/functional/ops.platform.h
@@ -0,0 +1,52 @@
+/**
+ * @file ops.platform.h
+ * @copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+#pragma once
+#include <nncase/runtime/runtime_tensor.h>
+
+namespace nncase::F::impl {
+
+result<runtime::runtime_tensor> unary(runtime::runtime_tensor &input,
+                                      datatype_t dtype,
+                                      unary_op_t op_type) noexcept;
+
+result<runtime::runtime_tensor> binary(runtime::runtime_tensor &input_a,
+                                       runtime::runtime_tensor &input_b,
+                                       datatype_t dtype,
+                                       binary_op_t op_type) noexcept;
+
+result<runtime::runtime_tensor> quantize(runtime::runtime_tensor &input,
+                                         datatype_t dtype) noexcept;
+
+result<runtime::runtime_tensor> dequantize(runtime::runtime_tensor &input,
+                                           datatype_t dtype) noexcept;
+
+result<runtime::runtime_tensor>
+crop(runtime::runtime_tensor &input, runtime::runtime_tensor &bbox,
+     size_t out_h, size_t out_w, image_resize_mode_t resize_mode,
+     bool align_corners, bool half_pixel_centers) noexcept;
+
+result<runtime::runtime_tensor> resize(runtime::runtime_tensor &input,
+                                       size_t out_h, size_t out_w,
+                                       image_resize_mode_t resize_mode,
+                                       bool align_corners,
+                                       bool half_pixel_centers) noexcept;
+
+result<runtime::runtime_tensor> pad(runtime::runtime_tensor &input,
+                                    runtime_paddings_t &paddings,
+                                    pad_mode_t pad_mode, float fill_v) noexcept;
+} // namespace nncase::F::impl
diff --git a/third_party/nncase/riscv64/include/nncase/io_utils.h b/third_party/nncase/riscv64/include/nncase/io_utils.h
new file mode 100644
index 0000000..bfd474f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/io_utils.h
@@ -0,0 +1,36 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <filesystem>
+#include <fstream>
+#include <vector>
+
+namespace nncase {
+inline std::vector<uint8_t> read_stream(std::istream &stream) {
+    stream.seekg(0, std::ios::end);
+    size_t length = stream.tellg();
+    stream.seekg(0, std::ios::beg);
+    std::vector<uint8_t> data(length);
+    stream.read(reinterpret_cast<char *>(data.data()), length);
+    return data;
+}
+
+inline std::vector<uint8_t> read_file(const std::filesystem::path &filename) {
+    std::ifstream infile(filename.string(), std::ios::binary | std::ios::in);
+    if (!infile.good())
+        throw std::runtime_error("Cannot open file: " + filename.string());
+    return read_stream(infile);
+}
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/apply.h b/third_party/nncase/riscv64/include/nncase/kernels/apply.h
new file mode 100644
index 0000000..1df7158
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/apply.h
@@ -0,0 +1,153 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#ifdef _WIN32
+#include <malloc.h> // alloca
+#else
+#include <alloca.h> // alloca
+#endif
+
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/result.h>
+
+#define BEGIN_NS_NNCASE_KERNELS_STACKVM                                        \
+    namespace nncase {                                                         \
+    namespace kernels {                                                        \
+    namespace stackvm {
+namespace reference {
+
+#define END_NS_NNCASE_KERNELS_STACKVM                                          \
+    }                                                                          \
+    }                                                                          \
+    }
+} // namespace reference
+
+BEGIN_NS_NNCASE_KERNELS_STACKVM
+
+namespace detail {
+#define APPLY_IMPL_FOR(i) for (index[i] = 0; index[i] < shape[i]; index[i]++)
+
+template <class Callable>
+result<void> apply_1(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[1];
+    APPLY_IMPL_FOR(0)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_2(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[2];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_3(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[3];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_4(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[4];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    APPLY_IMPL_FOR(3)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_5(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[5];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    APPLY_IMPL_FOR(3)
+    APPLY_IMPL_FOR(4)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_generic(gsl::span<const size_t> shape,
+                           Callable &&callable) noexcept {
+    auto index_buffer = (size_t *)
+#ifdef _WIN32
+        _alloca
+#else
+        __builtin_alloca
+#endif
+        (sizeof(size_t) * shape.size());
+
+    gsl::span<size_t> index(index_buffer, shape.size());
+    std::fill(index.begin(), index.end(), 0);
+    auto last_dim_idx = (int32_t)shape.size() - 1;
+    while (true) {
+        int dim = last_dim_idx;
+        while (index[dim] == shape[dim]) {
+            if (dim == 0) {
+                return ok();
+            }
+
+            index[dim] = 0;
+            index[--dim]++;
+        }
+
+        try_(callable(index));
+        index[last_dim_idx]++;
+    }
+    return ok();
+}
+} // namespace detail
+
+template <class Callable>
+result<void> apply(gsl::span<const size_t> shape,
+                   Callable &&callable) noexcept {
+    switch (shape.size()) {
+    case 0:
+        return callable(shape);
+    case 1:
+        return detail::apply_1(shape, std::forward<Callable>(callable));
+    case 2:
+        return detail::apply_2(shape, std::forward<Callable>(callable));
+    case 3:
+        return detail::apply_3(shape, std::forward<Callable>(callable));
+    case 4:
+        return detail::apply_4(shape, std::forward<Callable>(callable));
+    case 5:
+        return detail::apply_5(shape, std::forward<Callable>(callable));
+    default:
+        break;
+    }
+
+    return detail::apply_generic(shape, std::forward<Callable>(callable));
+}
+
+END_NS_NNCASE_KERNELS_STACKVM
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/k230/k230_kernels.h b/third_party/nncase/riscv64/include/nncase/kernels/k230/k230_kernels.h
new file mode 100644
index 0000000..f5e7c9f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/k230/k230_kernels.h
@@ -0,0 +1,198 @@
+/* Copyright 2020 Canaan Inc.
+*
+* Licensed under the Apache License, Version 2.0 (the "License");
+* you may not use this file except in compliance with the License.
+* You may obtain a copy of the License at
+*
+*     http://www.apache.org/licenses/LICENSE-2.0
+*
+* Unless required by applicable law or agreed to in writing, software
+* distributed under the License is distributed on an "AS IS" BASIS,
+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+* See the License for the specific language governing permissions and
+* limitations under the License.
+*/
+#pragma once
+#include "../kernel_utils.h"
+#include <cmath>
+#include <nncase/runtime/nnil.h>
+#include <nncase/runtime/runtime_op_utility.h>
+#include <stdexcept>
+#include <type_traits>
+#include <xtl/xspan.hpp>
+#ifdef __riscv
+#include "../riscv/k230_kernels.h"
+#endif
+using namespace knn::runtime::k230;
+using namespace nncase::ir::k230;
+namespace knn::kernels::k230
+{
+void gnne_transpose(const bfloat16 *CXX_RESTRICT input, bfloat16 *CXX_RESTRICT output, const runtime_shape_t &in_shape, const mfu_trans_permute &gnne_perm)
+{
+    auto perm = to_axis(gnne_perm);
+    runtime_shape_t out_shape;
+    for (size_t i = 0; i < 4; i++)
+        out_shape[i] = in_shape[perm[i]];
+    runtime_shape_t i, o;
+    for (o[3] = 0; o[3] < out_shape[3]; o[3]++)
+    {
+        i[perm[3]] = o[3];
+        for (o[2] = 0; o[2] < out_shape[2]; o[2]++)
+        {
+            i[perm[2]] = o[2];
+            for (o[1] = 0; o[1] < out_shape[1]; o[1]++)
+            {
+                i[perm[1]] = o[1];
+                for (o[0] = 0; o[0] < out_shape[0]; o[0]++)
+                {
+                    i[perm[0]] = o[0];
+                    output[offset(out_shape, o)] = input[offset(in_shape, i)];
+                }
+            }
+        }
+    }
+}
+
+void gnne_conv2d(const bfloat16 *input, bfloat16 *output, const bfloat16 *weights, const bfloat16 *psum, const bfloat16 *act, const runtime_shape_t &in_shape,
+    int32_t groups, int32_t out_channels, int32_t filter_h, int32_t filter_w, int32_t stride_h, int32_t stride_w, int32_t dilation_h, int32_t dilation_w,
+    const padding &padding_h, const padding &padding_w, value_range<bfloat16> fused_clamp)
+{
+    const auto out_h = details::get_windowed_output_size(in_shape[2], filter_h, stride_h, dilation_h, padding_h);
+    const auto out_w = details::get_windowed_output_size(in_shape[3], filter_w, stride_w, dilation_w, padding_w);
+    const auto g_ic = in_shape[1] / groups;
+    const auto g_oc = out_channels / groups;
+    for (int32_t batch = 0; batch < in_shape[0]; batch++)
+    {
+        const bfloat16 *in_batch_p = input + (size_t)batch * in_shape[1] * in_shape[2] * in_shape[3];
+        for (int32_t og = 0; og < groups; og++)
+        {
+            const bfloat16 *in_group_p = in_batch_p + (size_t)og * g_ic * in_shape[2] * in_shape[3];
+            const bfloat16 *w_group_p = weights + (size_t)og * g_oc * g_ic * filter_h * filter_w;
+            for (int32_t oc = 0; oc < g_oc; oc++)
+            {
+                const bfloat16 *w_oc_p = w_group_p + (size_t)oc * g_ic * filter_h * filter_w;
+                for (int32_t oy = 0; oy < out_h; oy++)
+                {
+                    for (int32_t ox = 0; ox < out_w; ox++)
+                    {
+                        const int32_t in_y_origin = (oy * stride_h) - padding_h.before;
+                        const int32_t in_x_origin = (ox * stride_w) - padding_w.before;
+                        const int32_t filter_y_start = std::max(0, (-in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_y_end = std::min(filter_h, (in_shape[2] - in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_x_start = std::max(0, (-in_x_origin + dilation_w - 1) / dilation_w);
+                        const int32_t filter_x_end = std::min(filter_w, (in_shape[3] - in_x_origin + dilation_w - 1) / dilation_w);
+                        bfloat16 value = (bfloat16)0;
+                        for (int32_t ic = 0; ic < g_ic; ic++)
+                        {
+                            const bfloat16 *in_c_p = in_group_p + (size_t)ic * in_shape[2] * in_shape[3];
+                            const bfloat16 *w_ic_p = w_oc_p + (size_t)ic * filter_h * filter_w;
+                            for (int32_t ky = filter_y_start; ky < filter_y_end; ky++)
+                            {
+                                for (int32_t kx = filter_x_start; kx < filter_x_end; kx++)
+                                {
+                                    const int32_t in_y = in_y_origin + dilation_h * ky;
+                                    const int32_t in_x = in_x_origin + dilation_w * kx;
+                                    const bfloat16 in_v = in_c_p[in_y * in_shape[3] + in_x];
+                                    const bfloat16 w = w_ic_p[ky * filter_w + kx];
+                                    value = value + in_v * w;
+                                }
+                            }
+                        }
+                        value = details::apply_activation(value, act[oc * 5], act[oc * 5 + 1], act[oc * 5 + 2], act[oc * 5 + 3], act[oc * 5 + 4]);
+                        *output++ = psum[og * g_oc + oc] + details::apply_activation(value, fused_clamp);
+                    }
+                }
+            }
+        }
+    }
+}
+
+void gnne_matmul(const bfloat16 *input_a, const bfloat16 *input_b, bfloat16 *output, const bfloat16 *act, int32_t a_rows, int32_t a_cols, int32_t b_cols, const value_range<bfloat16> &fused_activation)
+{
+    for (int32_t oy = 0; oy < a_rows; oy++)
+    {
+        for (int32_t ox = 0; ox < b_cols; ox++)
+        {
+            bfloat16 value = bfloat16(0);
+
+            for (int32_t i = 0; i < a_cols; i++)
+            {
+                const auto a = input_a[oy * a_cols + i];
+                const auto b = input_b[i * b_cols + ox];
+                value = value + a * b;
+            }
+
+            if (value < act[0])
+                value = value * act[1] + act[2];
+            else
+                value = value * act[3] + act[4];
+
+            output[oy * b_cols + ox] = details::apply_activation(value, fused_activation);
+        }
+    }
+}
+
+template <typename TI, typename TO>
+void gnne_load(const TI *input, const TO *output, const runtime_shape_t &in_shape, const int32_t &channel_axis, const bfloat16 *deq_params)
+{
+    if (std::is_same_v<TI, TO>)
+    {
+        std::memcpy(output, input, sizeof(TI) * details::compute_size(in_shape));
+    }
+    else if ((std::is_same_v<TI, float> && std::is_same_v<TO, bfloat16>)
+        || (std::is_same_v<TI, bfloat16> && std::is_same_v<TO, float>))
+    {
+        for (size_t i = 0; i < details::compute_size(in_shape); i++)
+            output[i] = static_cast<TO>(input[i]);
+    }
+    else if ((std::is_same_v<TI, int8_t> || std::is_same_v<TO, uint8_t>)&&(std::is_same_v<TI, bfloat16> || std::is_same_v<TO, float>))
+    {
+        size_t size_per_channel = 1;
+        for (int32_t i = channel_axis + 1; i < 4; i++)
+        {
+            size_per_channel *= in_shape[i];
+        }
+        for (size_t i = 0; i < details::compute_size(in_shape); i++)
+        {
+            auto value = (input[i] - deq_params[(i % size_per_channel) * 2 + 1]) * deq_params[(i % size_per_channel) * 2];
+            output[i] = static_cast<TO>(value);
+        }
+    }
+    else
+    {
+        std::runtime_error("unsupported convert type in gnne_load!");
+    }
+}
+
+template <typename TI, typename TO>
+void gnne_store(const TI *input, const TO *output, const runtime_shape_t &in_shape, const int32_t &channel_axis, const bfloat16 *q_params)
+{
+    if (std::is_same_v<TI, TO>)
+    {
+        std::memcpy(output, input, sizeof(TI) * details::compute_size(in_shape));
+    }
+    else if ((std::is_same_v<TI, float> && std::is_same_v<TO, bfloat16>)
+        || (std::is_same_v<TI, bfloat16> && std::is_same_v<TO, float>))
+    {
+        for (size_t i = 0; i < details::compute_size(in_shape); i++)
+            output[i] = static_cast<TO>(input[i]);
+    }
+    else if ((std::is_same_v<TI, int8_t> || std::is_same_v<TO, uint8_t>)&&std::is_same_v<TI, bfloat16>)
+    {
+        size_t size_per_channel = 1;
+        for (int32_t i = channel_axis + 1; i < 4; i++)
+        {
+            size_per_channel *= in_shape[i];
+        }
+        for (size_t i = 0; i < details::compute_size(in_shape); i++)
+        {
+            auto value = (input[i] - q_params[(i % size_per_channel) * 2 + 1]) / q_params[(i % size_per_channel) * 2];
+            output[i] = static_cast<TO>(value);
+        }
+    }
+    else
+    {
+        std::runtime_error("unsupported convert type in gnne_store!");
+    }
+}
+}
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/kernel_context.h b/third_party/nncase/riscv64/include/nncase/kernels/kernel_context.h
new file mode 100644
index 0000000..695473a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/kernel_context.h
@@ -0,0 +1,28 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/runtime/dump_manager.h>
+#include <nncase/runtime/result.h>
+
+BEGIN_NS_NNCASE_KERNELS
+
+struct NNCASE_API kernel_context {
+    uint32_t num_threads;
+    std::shared_ptr<runtime::dump_manager> dump_manager;
+};
+
+NNCASE_API kernel_context &default_kernel_context();
+
+END_NS_NNCASE_KERNELS
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/kernel_utils.h b/third_party/nncase/riscv64/include/nncase/kernels/kernel_utils.h
new file mode 100644
index 0000000..e2158f7
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/kernel_utils.h
@@ -0,0 +1,113 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <algorithm>
+#include <cassert>
+#include <cstddef>
+#include <datatypes.h>
+
+#ifdef __GNUC__
+#define CXX_RESTRICT __restrict__
+#elif _MSC_VER
+#define CXX_RESTRICT __restrict
+#else
+#define CXX_RESTRICT fvck
+#endif
+
+namespace knn::kernels
+{
+inline size_t offset(const runtime_shape_t &shape, const runtime_shape_t &index)
+{
+    return (((size_t)index[0] * shape[1] + index[1]) * shape[2] + index[2]) * shape[3] + index[3];
+}
+
+namespace details
+{
+    inline int32_t get_windowed_output_size(int32_t size, int32_t filter, int32_t stride, int32_t dilation, const padding &padding)
+    {
+        auto effective_filter_size = (filter - 1) * dilation + 1;
+        return (size + padding.before + padding.after - effective_filter_size + stride) / stride;
+    }
+
+    inline size_t compute_size(const runtime_shape_t &shape)
+    {
+        return size_t(shape[0]) * shape[1] * shape[2] * shape[3];
+    }
+
+    template <class T>
+    inline T apply_activation(T value, value_range<T> activation)
+    {
+        return std::clamp(value, activation.min, activation.max);
+    }
+    template <class T>
+    inline T apply_activation(T value, T x0, T kl, T bl, T kr, T br)
+    {
+        if (value < x0)
+        {
+            return value * kl + bl;
+        }
+        else
+        {
+            return value * kr + br;
+        }
+    }
+
+    inline runtime_shape_t get_reduced_offset(const runtime_shape_t &in_offset, const runtime_shape_t &reduced_shape)
+    {
+        runtime_shape_t off;
+        for (size_t i = 0; i < in_offset.size(); i++)
+        {
+            if (in_offset[i] >= reduced_shape[i])
+                off[i] = 0;
+            else
+                off[i] = in_offset[i];
+        }
+
+        return off;
+    }
+
+    template <class T, class TRange>
+    struct default_ptr_getter
+    {
+        T *operator()(const TRange &range) const noexcept { return range; }
+    };
+
+    template <int32_t Bits>
+    int32_t to_signed(uint32_t value)
+    {
+        auto mask = uint32_t(1) << (Bits - 1);
+        if (Bits != 32 && (value & mask) != 0)
+        {
+            auto sign = 0xFFFFFFFF << Bits;
+            return (int)(value | sign);
+        }
+
+        return (int32_t)value;
+    }
+
+    template <int32_t Bits>
+    int64_t to_signed(uint64_t value)
+    {
+        auto mask = uint64_t(1) << (Bits - 1);
+        if ((value & mask) != 0)
+        {
+            auto sign = 0xFFFFFFFFFFFFFFFF << Bits;
+            return (int64_t)(value | sign);
+        }
+
+        return (int64_t)value;
+    }
+}
+}
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/neutral/neutral_kernels.h b/third_party/nncase/riscv64/include/nncase/kernels/neutral/neutral_kernels.h
new file mode 100644
index 0000000..fba3139
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/neutral/neutral_kernels.h
@@ -0,0 +1,806 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../kernel_utils.h"
+#include <cmath>
+#include <nncase/runtime/nnil.h>
+#include <nncase/runtime/runtime_op_utility.h>
+#include <xtl/xspan.hpp>
+#ifdef __riscv
+#include "../riscv/neutral_kernels.h"
+#endif
+
+namespace knn::kernels::neutral
+{
+template <class TOp>
+void binary(const float *input_a, const float *input_b, float *output, const runtime_shape_t &in_a_shape,
+    const runtime_shape_t &in_b_shape, const runtime_shape_t &out_shape, const value_range<float> &fused_activation, TOp &&op)
+{
+    // opt. no broadcast
+    if (in_a_shape == in_b_shape)
+    {
+        auto size = kernels::details::compute_size(in_a_shape);
+        for (size_t i = 0; i < size; i++)
+        {
+            const auto a = input_a[i];
+            const auto b = input_b[i];
+            output[i] = kernels::details::apply_activation(op(a, b), fused_activation);
+        }
+    }
+    // fallback
+    else
+    {
+        for (int32_t d0 = 0; d0 < out_shape[0]; d0++)
+        {
+            for (int32_t d1 = 0; d1 < out_shape[1]; d1++)
+            {
+                for (int32_t d2 = 0; d2 < out_shape[2]; d2++)
+                {
+                    for (int32_t d3 = 0; d3 < out_shape[3]; d3++)
+                    {
+                        runtime_shape_t in_off = { d0, d1, d2, d3 };
+                        const auto in_a_off = kernels::details::get_reduced_offset(in_off, in_a_shape);
+                        const auto in_b_off = kernels::details::get_reduced_offset(in_off, in_b_shape);
+                        const auto a = input_a[offset(in_a_shape, in_a_off)];
+                        const auto b = input_b[offset(in_b_shape, in_b_off)];
+                        output[offset(out_shape, in_off)] = kernels::details::apply_activation(op(a, b), fused_activation);
+                    }
+                }
+            }
+        }
+    }
+}
+
+template <class TOp>
+void quantized_binary(const uint8_t *input_a, const uint8_t *input_b, uint8_t *output, const runtime_shape_t &in_a_shape,
+    const runtime_shape_t &in_b_shape, const runtime_shape_t &out_shape, int32_t input_a_offset, int32_t input_a_mul, int32_t input_a_shift,
+    int32_t input_b_offset, int32_t input_b_mul, int32_t input_b_shift, int32_t output_mul, int32_t output_shift, int32_t output_offset, TOp &&op)
+{
+    // opt. no broadcast
+    if (in_a_shape == in_b_shape)
+    {
+        auto size = kernels::details::compute_size(in_a_shape);
+        for (size_t i = 0; i < size; i++)
+        {
+            auto a = (int32_t)input_a[i];
+            auto b = (int32_t)input_b[i];
+            a = runtime::mul_and_carry_shift(a + input_a_offset, input_a_mul, input_a_shift);
+            b = runtime::mul_and_carry_shift(b + input_b_offset, input_b_mul, input_b_shift);
+
+            auto output_val = runtime::mul_and_carry_shift(op(a, b), output_mul, output_shift);
+            output[i] = (uint8_t)std::clamp(output_val + output_offset, 0, 255);
+        }
+    }
+    // fallback
+    else
+    {
+        for (int32_t d0 = 0; d0 < out_shape[0]; d0++)
+        {
+            for (int32_t d1 = 0; d1 < out_shape[1]; d1++)
+            {
+                for (int32_t d2 = 0; d2 < out_shape[2]; d2++)
+                {
+                    for (int32_t d3 = 0; d3 < out_shape[3]; d3++)
+                    {
+                        runtime_shape_t in_off = { d0, d1, d2, d3 };
+                        const auto in_a_off = kernels::details::get_reduced_offset(in_off, in_a_shape);
+                        const auto in_b_off = kernels::details::get_reduced_offset(in_off, in_b_shape);
+                        auto a = (int32_t)input_a[offset(in_a_shape, in_a_off)];
+                        auto b = (int32_t)input_b[offset(in_b_shape, in_b_off)];
+                        a = runtime::mul_and_carry_shift(a + input_a_offset, input_a_mul, input_a_shift);
+                        b = runtime::mul_and_carry_shift(b + input_b_offset, input_b_mul, input_b_shift);
+
+                        auto output_val = runtime::mul_and_carry_shift(op(a, b), output_mul, output_shift);
+                        output[offset(out_shape, in_off)] = (uint8_t)std::clamp(output_val + output_offset, 0, 255);
+                    }
+                }
+            }
+        }
+    }
+}
+
+template <class TRange, class TPtrGetter = details::default_ptr_getter<uint8_t, TRange>>
+inline void concat(xtl::span<TRange> inputs, uint8_t *output, xtl::span<const int32_t> concat_dims, size_t inner_size, size_t outer_size, TPtrGetter getter = {})
+{
+    for (size_t oc = 0; oc < outer_size; oc++)
+    {
+        for (size_t i = 0; i < inputs.size(); i++)
+        {
+            auto size = inner_size * concat_dims[i];
+            auto src = getter(inputs[i]) + oc * size;
+            std::copy(src, src + size, output);
+            output += size;
+        }
+    }
+}
+
+inline void conv2d(const float *input, float *output, const float *weights, const float *bias, const runtime_shape_t &in_shape,
+    int32_t groups, int32_t out_channels, int32_t filter_h, int32_t filter_w, int32_t stride_h, int32_t stride_w, int32_t dilation_h, int32_t dilation_w,
+    const padding &padding_h, const padding &padding_w, const value_range<float> &fused_activation)
+{
+    const auto out_h = details::get_windowed_output_size(in_shape[2], filter_h, stride_h, dilation_h, padding_h);
+    const auto out_w = details::get_windowed_output_size(in_shape[3], filter_w, stride_w, dilation_w, padding_w);
+    const auto g_ic = in_shape[1] / groups;
+    const auto g_oc = out_channels / groups;
+
+    for (int32_t batch = 0; batch < in_shape[0]; batch++)
+    {
+        const float *in_batch_p = input + (size_t)batch * in_shape[1] * in_shape[2] * in_shape[3];
+
+        for (int32_t og = 0; og < groups; og++)
+        {
+            const float *in_group_p = in_batch_p + (size_t)og * g_ic * in_shape[2] * in_shape[3];
+            const float *w_group_p = weights + (size_t)og * g_oc * g_ic * filter_h * filter_w;
+
+            for (int32_t oc = 0; oc < g_oc; oc++)
+            {
+                const float *w_oc_p = w_group_p + (size_t)oc * g_ic * filter_h * filter_w;
+
+                for (int32_t oy = 0; oy < out_h; oy++)
+                {
+                    for (int32_t ox = 0; ox < out_w; ox++)
+                    {
+                        const int32_t in_y_origin = (oy * stride_h) - padding_h.before;
+                        const int32_t in_x_origin = (ox * stride_w) - padding_w.before;
+                        const int32_t filter_y_start = std::max(0, (-in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_y_end = std::min(filter_h, (in_shape[2] - in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_x_start = std::max(0, (-in_x_origin + dilation_w - 1) / dilation_w);
+                        const int32_t filter_x_end = std::min(filter_w, (in_shape[3] - in_x_origin + dilation_w - 1) / dilation_w);
+                        float value = bias[og * g_oc + oc];
+
+                        for (int32_t ic = 0; ic < g_ic; ic++)
+                        {
+                            const float *in_c_p = in_group_p + (size_t)ic * in_shape[2] * in_shape[3];
+                            const float *w_ic_p = w_oc_p + (size_t)ic * filter_h * filter_w;
+
+                            for (int32_t ky = filter_y_start; ky < filter_y_end; ky++)
+                            {
+                                for (int32_t kx = filter_x_start; kx < filter_x_end; kx++)
+                                {
+                                    const int32_t in_y = in_y_origin + dilation_h * ky;
+                                    const int32_t in_x = in_x_origin + dilation_w * kx;
+
+                                    const float in_v = in_c_p[in_y * in_shape[3] + in_x];
+                                    const float w = w_ic_p[ky * filter_w + kx];
+
+                                    value += in_v * w;
+                                }
+                            }
+                        }
+
+                        *output++ = details::apply_activation(value, fused_activation);
+                    }
+                }
+            }
+        }
+    }
+}
+
+inline void quantized_conv2d(const uint8_t *input, uint8_t *output, const uint8_t *weights, const int32_t *bias, int32_t input_offset, int32_t filter_offset,
+    int32_t output_mul, int32_t output_shift, int32_t output_offset, const runtime_shape_t &in_shape, int32_t groups, int32_t out_channels,
+    int32_t filter_h, int32_t filter_w, int32_t stride_h, int32_t stride_w, int32_t dilation_h, int32_t dilation_w,
+    const padding &padding_h, const padding &padding_w)
+{
+    const auto out_h = details::get_windowed_output_size(in_shape[2], filter_h, stride_h, dilation_h, padding_h);
+    const auto out_w = details::get_windowed_output_size(in_shape[3], filter_w, stride_w, dilation_w, padding_w);
+    const auto g_ic = in_shape[1] / groups;
+    const auto g_oc = out_channels / groups;
+
+    for (int32_t batch = 0; batch < in_shape[0]; batch++)
+    {
+        const uint8_t *in_batch_p = input + (size_t)batch * in_shape[1] * in_shape[2] * in_shape[3];
+
+        for (int32_t og = 0; og < groups; og++)
+        {
+            const uint8_t *in_group_p = in_batch_p + (size_t)og * g_ic * in_shape[2] * in_shape[3];
+            const uint8_t *w_group_p = weights + (size_t)og * g_oc * g_ic * filter_h * filter_w;
+
+            for (int32_t oc = 0; oc < g_oc; oc++)
+            {
+                const uint8_t *w_oc_p = w_group_p + (size_t)oc * g_ic * filter_h * filter_w;
+
+                for (int32_t oy = 0; oy < out_h; oy++)
+                {
+                    for (int32_t ox = 0; ox < out_w; ox++)
+                    {
+                        const int32_t in_y_origin = (oy * stride_h) - padding_h.before;
+                        const int32_t in_x_origin = (ox * stride_w) - padding_w.before;
+                        const int32_t filter_y_start = std::max(0, (-in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_y_end = std::min(filter_h, (in_shape[2] - in_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_x_start = std::max(0, (-in_x_origin + dilation_w - 1) / dilation_w);
+                        const int32_t filter_x_end = std::min(filter_w, (in_shape[3] - in_x_origin + dilation_w - 1) / dilation_w);
+                        int32_t value = bias[og * g_oc + oc];
+
+                        for (int32_t ic = 0; ic < g_ic; ic++)
+                        {
+                            const uint8_t *in_c_p = in_group_p + (size_t)ic * in_shape[2] * in_shape[3];
+                            const uint8_t *w_ic_p = w_oc_p + (size_t)ic * filter_h * filter_w;
+
+                            for (int32_t ky = filter_y_start; ky < filter_y_end; ky++)
+                            {
+                                for (int32_t kx = filter_x_start; kx < filter_x_end; kx++)
+                                {
+                                    const int32_t in_y = in_y_origin + dilation_h * ky;
+                                    const int32_t in_x = in_x_origin + dilation_w * kx;
+
+                                    const int32_t in_v = (int32_t)in_c_p[in_y * in_shape[3] + in_x] + input_offset;
+                                    const int32_t w = (int32_t)w_ic_p[ky * filter_w + kx] + filter_offset;
+
+                                    value += in_v * w;
+                                }
+                            }
+                        }
+
+                        auto output_val = static_cast<int32_t>(runtime::mul_and_carry_shift(value, output_mul, output_shift));
+                        output_val += output_offset;
+                        *output++ = (uint8_t)std::clamp(output_val, 0, 255);
+                    }
+                }
+            }
+        }
+    }
+}
+
+inline void conv2d_transpose(const float *input, float *output, const float *weights, [[maybe_unused]] const float *bias, const runtime_shape_t &in_shape,
+    int32_t groups, const runtime_shape_t &out_shape, int32_t filter_h, int32_t filter_w, int32_t stride_h, int32_t stride_w, int32_t dilation_h, int32_t dilation_w,
+    const padding &padding_h, const padding &padding_w, const value_range<float> &fused_activation)
+{
+    std::fill(output, output + kernels::details::compute_size(out_shape), 0.f);
+    const auto g_ic = in_shape[1] / groups;
+    const auto g_oc = out_shape[1] / groups;
+
+    for (int32_t batch = 0; batch < in_shape[0]; batch++)
+    {
+        float *out_batch_p = output + (size_t)batch * out_shape[1] * out_shape[2] * out_shape[3];
+
+        for (int32_t g = 0; g < groups; g++)
+        {
+            float *out_group_p = out_batch_p + (size_t)g * g_oc * out_shape[2] * out_shape[3];
+            const float *w_group_p = weights + (size_t)g * g_oc * g_ic * filter_h * filter_w;
+
+            for (int32_t ic = 0; ic < g_ic; ic++)
+            {
+                for (int32_t iy = 0; iy < in_shape[2]; iy++)
+                {
+                    for (int32_t ix = 0; ix < in_shape[3]; ix++)
+                    {
+                        const int32_t out_y_origin = (iy * stride_h) - padding_h.before;
+                        const int32_t out_x_origin = (ix * stride_w) - padding_w.before;
+                        const int32_t filter_y_start = std::max(0, (-out_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_y_end = std::min(filter_h, (out_shape[2] - out_y_origin + dilation_h - 1) / dilation_h);
+                        const int32_t filter_x_start = std::max(0, (-out_x_origin + dilation_w - 1) / dilation_w);
+                        const int32_t filter_x_end = std::min(filter_w, (out_shape[3] - out_x_origin + dilation_w - 1) / dilation_w);
+                        const float in_v = *input++;
+
+                        for (int32_t oc = 0; oc < g_oc; oc++)
+                        {
+                            assert(bias[g * g_oc + oc] == 0.f);
+                            float *out_c_p = out_group_p + (size_t)oc * out_shape[2] * out_shape[3];
+                            const float *w_oc_p = w_group_p + (size_t)oc * g_ic * filter_h * filter_w;
+                            const float *w_ic_p = w_oc_p + (size_t)ic * filter_h * filter_w;
+
+                            for (int32_t ky = filter_y_start; ky < filter_y_end; ky++)
+                            {
+                                for (int32_t kx = filter_x_start; kx < filter_x_end; kx++)
+                                {
+                                    const int32_t out_y = out_y_origin + dilation_h * ky;
+                                    const int32_t out_x = out_x_origin + dilation_w * kx;
+
+                                    const float w = w_ic_p[ky * filter_w + kx];
+
+                                    out_c_p[out_y * out_shape[3] + out_x] += in_v * w;
+                                }
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    if (fused_activation != value_range<float>::full())
+    {
+        for (size_t i = 0; i < kernels::details::compute_size(out_shape); i++)
+            output[i] = details::apply_activation(output[i], fused_activation);
+    }
+}
+
+template <class TQ>
+void dequantize(const TQ *CXX_RESTRICT input, float *CXX_RESTRICT output, size_t count, const quant_param_t &param)
+{
+#if __riscv
+    riscv_dequantize(input, output, count, param);
+#else
+    size_t channel = param.zero_point.size();
+    size_t per_channel_count = count / channel;
+    for (size_t i = 0; i < channel; i++)
+    {
+        for (size_t j = 0; j < per_channel_count; j++)
+        {
+            output[i * per_channel_count + j] = (input[i * per_channel_count + j] - param.zero_point[i]) * param.scale[i];
+        }
+    }
+#endif
+}
+
+inline void matmul(const float *input_a, const float *input_b, float *output, const float *bias, int32_t a_rows, int32_t a_cols, int32_t b_cols, const value_range<float> &fused_activation)
+{
+    for (int32_t oy = 0; oy < a_rows; oy++)
+    {
+        for (int32_t ox = 0; ox < b_cols; ox++)
+        {
+            float value = bias[ox];
+
+            for (int32_t i = 0; i < a_cols; i++)
+            {
+                const auto a = input_a[oy * a_cols + i];
+                const auto b = input_b[i * b_cols + ox];
+                value += a * b;
+            }
+
+            output[oy * b_cols + ox] = details::apply_activation(value, fused_activation);
+        }
+    }
+}
+
+inline void quantized_matmul(const uint8_t *input_a, const uint8_t *input_b, uint8_t *output, const int32_t *bias, int32_t a_rows, int32_t a_cols, int32_t b_cols, int32_t input_a_offset, int32_t input_b_offset,
+    int32_t output_mul, int32_t output_shift, int32_t output_offset)
+{
+    for (int32_t oy = 0; oy < a_rows; oy++)
+    {
+        for (int32_t ox = 0; ox < b_cols; ox++)
+        {
+            int32_t value = bias[ox];
+            for (int32_t i = 0; i < a_cols; i++)
+            {
+                const auto a = (int32_t)input_a[oy * a_cols + i] + input_a_offset;
+                const auto b = (int32_t)input_b[i * b_cols + ox] + input_b_offset;
+                value += a * b;
+            }
+
+            auto output_val = static_cast<int32_t>(runtime::mul_and_carry_shift(value, output_mul, output_shift));
+            output_val += output_offset;
+            output[oy * b_cols + ox] = (uint8_t)std::clamp(output_val, 0, 255);
+        }
+    }
+}
+
+template <class T>
+void pad(const T *input, T *output, const runtime_shape_t &in_shape, const runtime_paddings_t &paddings, T pad_value)
+{
+    runtime_shape_t out_shape = { in_shape[0] + paddings[0].sum(),
+        in_shape[1] + paddings[1].sum(),
+        in_shape[2] + paddings[2].sum(),
+        in_shape[3] + paddings[3].sum() };
+
+    for (int d0 = 0; d0 < out_shape[0]; d0++)
+    {
+        auto d0_origin = -paddings[0].before;
+        auto in0 = input + ((size_t)d0_origin + d0) * in_shape[1] * in_shape[2] * in_shape[3];
+
+        for (int d1 = 0; d1 < out_shape[1]; d1++)
+        {
+            auto d1_origin = -paddings[1].before;
+            auto in1 = in0 + ((size_t)d1_origin + d1) * in_shape[2] * in_shape[3];
+
+            for (int d2 = 0; d2 < out_shape[2]; d2++)
+            {
+                auto d2_origin = -paddings[2].before;
+                auto in2 = in1 + ((size_t)d2_origin + d2) * in_shape[3];
+
+                for (int d3 = 0; d3 < out_shape[3]; d3++)
+                {
+                    auto d3_origin = -paddings[3].before;
+
+                    if (d0 < paddings[0].before || d0 >= out_shape[0] - paddings[0].after
+                        || d1 < paddings[1].before || d1 >= out_shape[1] - paddings[1].after
+                        || d2 < paddings[2].before || d2 >= out_shape[2] - paddings[2].after
+                        || d3 < paddings[3].before || d3 >= out_shape[3] - paddings[3].after)
+                        *output++ = pad_value;
+                    else
+                        *output++ = in2[d3_origin + d3];
+                }
+            }
+        }
+    }
+}
+
+template <class TQ>
+void quantize(const float *CXX_RESTRICT input, TQ *CXX_RESTRICT output, size_t count, const quant_param_t &param)
+{
+#if __riscv
+    riscv_quantize(input, output, count, param);
+#else
+    size_t channel = param.zero_point.size();
+    size_t per_channel_count = count / channel;
+    for (size_t i = 0; i < channel; i++)
+    {
+        for (size_t j = 0; j < per_channel_count; j++)
+        {
+            /**********************************************************************************************
+             * 这里的计算公式不会起作用，只有输出需要进行量化，但是数据部分的输出不会使用这个，所以这里的改动不会产生影响
+             * 按照tflite在图上的量化参数来计算的话 公式应该是： X' = (x-zero_point)*scale; 目前不需要任何改动
+             **********************************************************************************************/
+            int32_t tmp = (int32_t)roundf(input[i * per_channel_count + j] / param.scale[i] + param.zero_point[i]);
+            output[i * per_channel_count + j] = std::clamp(tmp, (int32_t)std::numeric_limits<TQ>::lowest(), (int32_t)std::numeric_limits<TQ>::max());
+        }
+    }
+
+#endif
+}
+
+template <class TReducer>
+void reduce(const float *input, float *output, float init_value, const runtime_shape_t &in_shape, const runtime_shape_t &reduced_shape, TReducer &&reducer)
+{
+    std::fill(output, output + kernels::details::compute_size(reduced_shape), init_value);
+
+    for (int32_t d0 = 0; d0 < in_shape[0]; d0++)
+    {
+        for (int32_t d1 = 0; d1 < in_shape[1]; d1++)
+        {
+            for (int32_t d2 = 0; d2 < in_shape[2]; d2++)
+            {
+                for (int32_t d3 = 0; d3 < in_shape[3]; d3++)
+                {
+                    runtime_shape_t in_off = { d0, d1, d2, d3 };
+                    auto out_off = kernels::details::get_reduced_offset(in_off, reduced_shape);
+                    const auto a = input[offset(in_shape, in_off)];
+                    auto &b = output[offset(reduced_shape, out_off)];
+                    b = reducer(b, a);
+                }
+            }
+        }
+    }
+}
+
+template <class TOp>
+void unary(const float *CXX_RESTRICT input, float *CXX_RESTRICT output, size_t count, TOp &&op)
+{
+    for (size_t i = 0; i < count; i++)
+        output[i] = op(input[i]);
+}
+
+template <class TBinaryOp, class TOutputOp>
+void reduce_window2d(const float *input, float *output, float init_value, const runtime_shape_t &in_shape, int32_t filter_h, int32_t filter_w,
+    int32_t stride_h, int32_t stride_w, int32_t dilation_h, int32_t dilation_w, const padding &padding_h, const padding &padding_w,
+    const value_range<float> &fused_activation, TBinaryOp &&binary_op, TOutputOp &&window_op)
+{
+    const auto out_h = kernels::details::get_windowed_output_size(in_shape[2], filter_h, stride_h, dilation_h, padding_h);
+    const auto out_w = kernels::details::get_windowed_output_size(in_shape[3], filter_w, stride_w, dilation_w, padding_w);
+    runtime_shape_t out_shape { in_shape[0], in_shape[1], out_h, out_w };
+
+    for (int32_t batch = 0; batch < in_shape[0]; batch++)
+    {
+        for (int32_t oc = 0; oc < in_shape[1]; oc++)
+        {
+            for (int32_t oy = 0; oy < out_h; oy++)
+            {
+                for (int32_t ox = 0; ox < out_w; ox++)
+                {
+                    const int32_t in_y_origin = (oy * stride_h) - padding_h.before;
+                    const int32_t in_x_origin = (ox * stride_w) - padding_w.before;
+                    const int32_t filter_y_start = std::max(0, (-in_y_origin + dilation_h - 1) / dilation_h);
+                    const int32_t filter_y_end = std::min(filter_h, (in_shape[2] - in_y_origin + dilation_h - 1) / dilation_h);
+                    const int32_t filter_x_start = std::max(0, (-in_x_origin + dilation_w - 1) / dilation_w);
+                    const int32_t filter_x_end = std::min(filter_w, (in_shape[3] - in_x_origin + dilation_w - 1) / dilation_w);
+                    float value = init_value;
+                    int32_t kernel_count = 0;
+
+                    for (int32_t ky = filter_y_start; ky < filter_y_end; ky++)
+                    {
+                        for (int32_t kx = filter_x_start; kx < filter_x_end; kx++)
+                        {
+                            const int32_t in_y = in_y_origin + dilation_h * ky;
+                            const int32_t in_x = in_x_origin + dilation_w * kx;
+
+                            const float in_v = input[offset(in_shape, { batch, oc, in_y, in_x })];
+
+                            value = binary_op(value, in_v);
+                            kernel_count++;
+                        }
+                    }
+
+                    output[offset(out_shape, { batch, oc, oy, ox })] = kernels::details::apply_activation(window_op(value, kernel_count), fused_activation);
+                }
+            }
+        }
+    }
+}
+
+template <class T>
+void resize_nearest_neighbor(const T *input, T *output, const runtime_shape_t &in_shape, int32_t out_h, int32_t out_w)
+{
+    auto height_scale = (float)in_shape[2] / out_h;
+    auto width_scale = (float)in_shape[3] / out_w;
+
+    for (int batch = 0; batch < in_shape[0]; batch++)
+    {
+        auto in_batch = input + batch * in_shape[1] * in_shape[2] * in_shape[3];
+
+        for (int oc = 0; oc < in_shape[1]; oc++)
+        {
+            auto in_c = in_batch + oc * in_shape[2] * in_shape[3];
+
+            for (int oy = 0; oy < out_h; oy++)
+            {
+                auto in_y = std::min((int32_t)floorf(oy * height_scale), in_shape[2] - 1);
+                auto in_row = in_c + in_y * in_shape[3];
+
+                for (int ox = 0; ox < out_w; ox++)
+                {
+                    auto in_x = std::min((int32_t)floorf(ox * width_scale), in_shape[3] - 1);
+                    *output++ = in_row[in_x];
+                }
+            }
+        }
+    }
+}
+
+template <class T>
+inline void resize_bilinear(const T *input, T *output, const runtime_shape_t &in_shape, int32_t out_h, int32_t out_w, bool align_corners)
+{
+    auto height_scale = (float)in_shape[2] / out_h;
+    auto width_scale = (float)in_shape[3] / out_w;
+    if (align_corners && out_h > 1)
+        height_scale = (float)(in_shape[2] - 1) / (out_h - 1);
+    if (align_corners && out_w > 1)
+        width_scale = (float)(in_shape[3] - 1) / (out_w - 1);
+
+    auto destIdx = 0;
+    for (int batch = 0; batch < in_shape[0]; batch++)
+    {
+        auto in_batch = input + (size_t)batch * in_shape[1] * in_shape[2] * in_shape[3];
+
+        for (int oc = 0; oc < in_shape[1]; oc++)
+        {
+            auto in_c = in_batch + (size_t)oc * in_shape[2] * in_shape[3];
+
+            for (int oy = 0; oy < out_h; oy++)
+            {
+                auto in_y = oy * height_scale;
+                auto in_y0 = (int)floorf(in_y);
+                auto in_y1 = std::min(in_y0 + 1, in_shape[2] - 1);
+
+                for (int ox = 0; ox < out_w; ox++)
+                {
+                    auto in_x = ox * width_scale;
+                    auto in_x0 = (int)floorf(in_x);
+                    auto in_x1 = std::min(in_x0 + 1, in_shape[3] - 1);
+
+                    auto v0 = in_c[in_y0 * in_shape[3] + in_x0];
+                    auto v1 = in_c[in_y1 * in_shape[3] + in_x0];
+                    auto v2 = in_c[in_y0 * in_shape[3] + in_x1];
+                    auto v3 = in_c[in_y1 * in_shape[3] + in_x1];
+
+                    auto a0 = (1 - (in_y - in_y0)) * (1 - (in_x - in_x0));
+                    auto a1 = (in_y - in_y0) * (1 - (in_x - in_x0));
+                    auto a2 = (1 - (in_y - in_y0)) * (in_x - in_x0);
+                    auto a3 = (in_y - in_y0) * (in_x - in_x0);
+
+                    output[destIdx++] = T(v0 * a0 + v1 * a1 + v2 * a2 + v3 * a3);
+                }
+            }
+        }
+    }
+}
+
+inline void softmax(const float *input, float *output, float beta, int32_t outer_size, size_t inner_size)
+{
+    for (int32_t batch = 0; batch < outer_size; batch++)
+    {
+        auto src = input + batch * inner_size;
+        auto dest = output + batch * inner_size;
+
+        auto max = *std::max_element(src, src + inner_size);
+        float sum = 0;
+
+        for (size_t i = 0; i < inner_size; i++)
+        {
+            auto value = expf((src[i] - max) * beta);
+            sum += value;
+            dest[i] = value;
+        }
+
+        for (size_t i = 0; i < inner_size; i++)
+            dest[i] /= sum;
+    }
+}
+
+template <class T>
+void transpose(const T *CXX_RESTRICT input, T *CXX_RESTRICT output, const runtime_shape_t &in_shape, const runtime_shape_t &perm)
+{
+    runtime_shape_t out_shape;
+    for (size_t i = 0; i < 4; i++)
+        out_shape[i] = in_shape[perm[i]];
+
+    runtime_shape_t i, o;
+    for (o[3] = 0; o[3] < out_shape[3]; o[3]++)
+    {
+        i[perm[3]] = o[3];
+        for (o[2] = 0; o[2] < out_shape[2]; o[2]++)
+        {
+            i[perm[2]] = o[2];
+            for (o[1] = 0; o[1] < out_shape[1]; o[1]++)
+            {
+                i[perm[1]] = o[1];
+                for (o[0] = 0; o[0] < out_shape[0]; o[0]++)
+                {
+                    i[perm[0]] = o[0];
+                    output[offset(out_shape, o)] = input[offset(in_shape, i)];
+                }
+            }
+        }
+    }
+}
+
+template <class T>
+void strided_slice(const T *CXX_RESTRICT input, T *CXX_RESTRICT output, const runtime_shape_t &in_shape, const runtime_shape_t &begin, const runtime_shape_t &end, const runtime_shape_t &strides)
+{
+    auto loop_cond = [](int32_t i, int32_t stop, int32_t stride) {
+        return stride > 0 ? i < stop : i > stop;
+    };
+
+    for (int32_t d0 = begin[0]; loop_cond(d0, end[0], strides[0]); d0 += strides[0])
+    {
+        auto d0_origin = input + (size_t)d0 * in_shape[1] * in_shape[2] * in_shape[3];
+        for (int d1 = begin[1]; loop_cond(d1, end[1], strides[1]); d1 += strides[1])
+        {
+            auto d1_origin = d0_origin + (size_t)d1 * in_shape[2] * in_shape[3];
+            for (int32_t d2 = begin[2]; loop_cond(d2, end[2], strides[2]); d2 += strides[2])
+            {
+                auto d2_origin = d1_origin + (size_t)d2 * in_shape[3];
+                for (int32_t d3 = begin[3]; loop_cond(d3, end[3], strides[3]); d3 += strides[3])
+                    *output++ = d2_origin[d3];
+            }
+        }
+    }
+}
+
+inline void nnil_unary_method(const float *input, float *output, size_t count, xtl::span<const uint8_t> body)
+{
+    using namespace knn::runtime;
+
+    for (size_t i = 0; i < count; i++)
+    {
+        nnil_evalstack stack;
+        span_reader sr(body);
+        nnil_reader reader(sr);
+        bool ret = false;
+
+        while (reader.avail() && !ret)
+        {
+            auto op = reader.next();
+            switch (op.opcode)
+            {
+            case nnil_nop:
+                break;
+            case nnil_dup:
+                stack.dup();
+                break;
+            case nnil_pop:
+                stack.pop();
+                break;
+            case nnil_lda_0:
+                stack.push(input[i]);
+                break;
+            case nnil_ldc_r4_0:
+                stack.push(0.f);
+                break;
+            case nnil_ldc_r4_1:
+                stack.push(1.f);
+                break;
+            case nnil_ldc_r4:
+                stack.push(op.ldc_r4.r4);
+                break;
+            case nnil_abs:
+                stack.push(fabsf(stack.pop()));
+                break;
+            case nnil_ceil:
+                stack.push(ceilf(stack.pop()));
+                break;
+            case nnil_cos:
+                stack.push(cosf(stack.pop()));
+                break;
+            case nnil_exp:
+                stack.push(expf(stack.pop()));
+                break;
+            case nnil_floor:
+                stack.push(floorf(stack.pop()));
+                break;
+            case nnil_log:
+                stack.push(logf(stack.pop()));
+                break;
+            case nnil_neg:
+                stack.push(-stack.pop());
+                break;
+            case nnil_rsqrt:
+                stack.push(1.f / sqrtf(stack.pop()));
+                break;
+            case nnil_sin:
+                stack.push(sinf(stack.pop()));
+                break;
+            case nnil_square:
+            {
+                auto v = stack.pop();
+                stack.push(v * v);
+                break;
+            }
+            case nnil_add:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(a + b);
+                break;
+            }
+            case nnil_sub:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(a - b);
+                break;
+            }
+            case nnil_mul:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(a * b);
+                break;
+            }
+            case nnil_div:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(a / b);
+                break;
+            }
+            case nnil_min:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(std::min(a, b));
+                break;
+            }
+            case nnil_max:
+            {
+                auto b = stack.pop();
+                auto a = stack.pop();
+                stack.push(std::max(a, b));
+                break;
+            }
+            case nnil_clamp:
+            {
+                auto high = stack.pop();
+                auto low = stack.pop();
+                auto v = stack.pop();
+                stack.push(std::clamp(v, low, high));
+                break;
+            }
+            case nnil_ret:
+                output[i] = stack.pop();
+                ret = true;
+                break;
+            default:
+                throw std::runtime_error("Invalid nnil op");
+            }
+        }
+    }
+}
+
+inline void table_lookup1d(const uint8_t *CXX_RESTRICT input, uint8_t *CXX_RESTRICT output, size_t size, const uint8_t *CXX_RESTRICT table)
+{
+    for (size_t i = 0; i < size; i++)
+        output[i] = table[input[i]];
+}
+}
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/riscv/neutral_kernels.h b/third_party/nncase/riscv64/include/nncase/kernels/riscv/neutral_kernels.h
new file mode 100644
index 0000000..dddaa57
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/riscv/neutral_kernels.h
@@ -0,0 +1,79 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../kernel_utils.h"
+#include <cmath>
+#include <runtime/runtime_op_utility.h>
+#include <xtl/xspan.hpp>
+
+namespace nncase {
+namespace kernels {
+namespace neutral {
+template <class TQ>
+void riscv_dequantize(const TQ *CXX_RESTRICT input, float *CXX_RESTRICT output,
+                      size_t count, const quant_param_t &param) {
+    float scale = 1.f / param.scale;
+    float zero = -param.zero_point * scale;
+
+    for (size_t i = 0; i < count / 2; i++) {
+        // handwritten pipeline for in order CPU
+        auto in1_q = input[i * 2];
+        auto in2_q = input[i * 2 + 1];
+        auto in1 = (float)in1_q;
+        auto in2 = (float)in2_q;
+        auto out1 = in1 * scale + zero;
+        auto out2 = in2 * scale + zero;
+
+        output[i * 2] = out1;
+        output[i * 2 + 1] = out2;
+    }
+
+    if (count % 2)
+        output[count - 1] = input[count - 1] * scale + zero;
+}
+
+template <class TQ>
+void riscv_quantize(const float *CXX_RESTRICT input, TQ *CXX_RESTRICT output,
+                    size_t count, const quant_param_t &param) {
+    float scale = param.scale;
+    float zero = param.zero_point;
+
+    for (size_t i = 0; i < count / 2; i++) {
+        auto in1 = input[i * 2];
+        auto in2 = input[i * 2 + 1];
+        in1 = in1 * scale + zero;
+        in2 = in2 * scale + zero;
+        int32_t out1, out2;
+        asm volatile("fcvt.w.s %0, %1, rne" : "=r"(out1) : "f"(in1));
+        asm volatile("fcvt.w.s %0, %1, rne" : "=r"(out2) : "f"(in2));
+
+        output[i * 2] =
+            std::clamp(out1, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+        output[i * 2 + 1] =
+            std::clamp(out2, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+    }
+
+    if (count % 2) {
+        auto in = (int32_t)roundf(input[count - 1] * scale + zero);
+        output[count - 1] =
+            std::clamp(in, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+    }
+}
+} // namespace neutral
+} // namespace kernels
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/stackvm/resize_image.h b/third_party/nncase/riscv64/include/nncase/kernels/stackvm/resize_image.h
new file mode 100644
index 0000000..820a05f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/stackvm/resize_image.h
@@ -0,0 +1,94 @@
+/* Copyright 2019-2023 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+#include <nncase/runtime/stackvm/opcode.h>
+
+using namespace nncase::runtime::stackvm;
+
+using get_coordinate_func_t = float (*)(float, float, float, float, float,
+                                        float);
+using get_nearest_pixel_func_t = int64_t (*)(float);
+
+get_coordinate_func_t get_coordinate_from_resized(
+    image_resize_transformation_mode_t coordinate_transform_mode);
+
+get_nearest_pixel_func_t
+get_nearest_pixel_from_origin(image_resize_nearest_mode_t nearest_mode);
+
+inline get_coordinate_func_t get_coordinate_from_resized(
+    image_resize_transformation_mode_t coordinate_transform_mode) {
+    switch (coordinate_transform_mode) {
+    case image_resize_transformation_mode_t::asymmetric:
+        return [](float x_resized, float x_scale, float, float, float, float) {
+            return x_resized * x_scale;
+        };
+    case image_resize_transformation_mode_t::pytorch_half_pixel:
+        return [](float x_resized, float x_scale, float length_resized, float,
+                  float, float) {
+            return length_resized > 1 ? (x_resized + 0.5f) * x_scale - 0.5f
+                                      : 0.0f;
+        };
+    case image_resize_transformation_mode_t::align_corners:
+        return [](float x_resized, float, float length_resized,
+                  float length_original, float, float) {
+            return length_resized == 1 ? 0
+                                       : x_resized * (length_original - 1) /
+                                             (length_resized - 1);
+        };
+    case image_resize_transformation_mode_t::tfcrop_and_resize:
+        return [](float x_resized, float, float length_resized,
+                  float length_original, float roi_start, float roi_end) {
+            auto orig =
+                length_resized > 1
+                    ? roi_start * (length_original - 1) +
+                          (x_resized * (roi_end - roi_start) *
+                           (length_original - 1)) /
+                              (length_resized - 1)
+                    : 0.5 * (roi_start + roi_end) * (length_original - 1);
+            return static_cast<float>(orig);
+        };
+    default: // "image_resize_transformation_mode_t::half_pixel"
+        return [](float x_resized, float x_scale, float, float, float, float) {
+            return ((x_resized + 0.5f) * x_scale) - 0.5f;
+        };
+    }
+}
+
+inline get_nearest_pixel_func_t
+get_nearest_pixel_from_origin(image_resize_nearest_mode_t nearest_mode) {
+    switch (nearest_mode) {
+    case image_resize_nearest_mode_t::round_prefer_ceil:
+        return [](float x_original) {
+            return static_cast<int64_t>(roundf(x_original));
+        };
+    case image_resize_nearest_mode_t::floor:
+        return [](float x_original) {
+            return static_cast<int64_t>(std::floor(x_original));
+        };
+    case image_resize_nearest_mode_t::ceil:
+        return [](float x_original) {
+            return static_cast<int64_t>(std::ceil(x_original));
+        };
+    default: // default is round_prefer_floor
+        return [](float x_original) {
+            // for half way cases prefer floor
+            if (x_original == static_cast<int64_t>(x_original) + 0.5f) {
+                return static_cast<int64_t>(std::floor(x_original));
+            }
+            return static_cast<int64_t>(roundf(x_original));
+        };
+    }
+}
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/kernels/stackvm/tensor_ops.h b/third_party/nncase/riscv64/include/nncase/kernels/stackvm/tensor_ops.h
new file mode 100644
index 0000000..84cae4e
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/kernels/stackvm/tensor_ops.h
@@ -0,0 +1,474 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/kernels/kernel_context.h>
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/stackvm/opcode.h>
+#include <nncase/tensor.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_KERNELS_MODULE(stackvm)
+
+NNCASE_API result<value_t>
+batch_normalization(value_t input, value_t scale, value_t bias,
+                    value_t input_mean, value_t input_var, value_t epsilon,
+                    value_t momentum, value_t output = nullptr,
+                    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+batch_to_space(value_t input, value_t block_shape, value_t crops,
+               value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+binary(runtime::stackvm::binary_op_t binary_op, value_t lhs, value_t rhs,
+       value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+bitcast(prim_type_t type, prim_type_t new_type, value_t input,
+        value_t new_shape, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+broadcast(value_t input, value_t shape, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+broadcast_shape(value_t inputs, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+bucket_pad(value_t input, value_t shape, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+cast(typecode_t new_type, runtime::stackvm::cast_mode_t cast_mode,
+     value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+celu(value_t input, value_t alpha, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+clamp(value_t input, value_t min, value_t max, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+compare(runtime::stackvm::compare_op_t compare_op, value_t lhs, value_t rhs,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+concat(int32_t axis, value_t input, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+condition(bool can_fold_const_call, value_t predicate, value_t value,
+          value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+constant_of_shape(value_t shape, value_t value, value_t output = nullptr,
+                  kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d(runtime::stackvm::pad_mode_t pad_mode, value_t input, value_t weights,
+       value_t bias, value_t stride, value_t padding, value_t dilation,
+       value_t groups, value_t fused_clamp, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_shape(value_t input, value_t weights, value_t padding, value_t stride,
+             value_t dilation, value_t groups, value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_transpose(runtime::stackvm::pad_mode_t pad_mode, value_t input,
+                 value_t weights, value_t bias, value_t output_shape,
+                 value_t stride, value_t padding, value_t output_padding,
+                 value_t dilation, value_t groups, value_t fused_clamp,
+                 value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_transpose_shape(value_t input, value_t weights, value_t stride,
+                       value_t dilation, value_t padding,
+                       value_t output_padding, value_t groups,
+                       value_t output = nullptr,
+                       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+cum_sum(value_t input, value_t axis, value_t exclusive, value_t reverse,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+dequantize(typecode_t target_type, value_t input, value_t dequant_param,
+           value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+elu(value_t input, value_t alpha, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+erf(value_t input, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+expand(value_t input, value_t shape, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fake_dequantize(typecode_t target_type, value_t input, value_t dequant_param,
+                value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fake_quantize(typecode_t target_type, value_t input, value_t quant_param,
+              value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fix_shape(value_t input, value_t shape, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+flatten(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather(int32_t axis, value_t input, value_t index, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather_elements(value_t input, value_t axis, value_t indices,
+                value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather_nd(value_t input, value_t batch_dims, value_t index,
+          value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gelu(value_t input, value_t alpha, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+get_item(value_t input, value_t index, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+get_paddings(value_t input_shape, value_t weights_shape, value_t strides,
+             value_t dilations, value_t same, value_t lower,
+             value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hard_sigmoid(value_t input, value_t alpha, value_t beta,
+             value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hard_swish(value_t input, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hardmax(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+index_of(value_t input, value_t value, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+instance_normalization(value_t input, value_t scale, value_t bias,
+                       value_t epsilon, value_t output = nullptr,
+                       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+l2_normalization(value_t input, value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+layer_norm(int32_t axis, float epsilon, bool use_mean, value_t input,
+           value_t scale, value_t bias, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+leaky_relu(value_t input, value_t alpha, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+log_softmax(value_t input, value_t axis, value_t output = nullptr,
+            kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lp_normalization(value_t input, value_t axis, value_t p,
+                 value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lrn(value_t input, value_t alpha, value_t beta, value_t bias, value_t size,
+    value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lstm(runtime::stackvm::lstmdirection_t direction,
+     runtime::stackvm::lstmlayout_t layout,
+     std::vector<std::string> activations, value_t x, value_t w, value_t r,
+     value_t b, value_t sequence_lens, value_t initial_h, value_t initial_c,
+     value_t p, value_t activation_alpha, value_t activation_beta, value_t clip,
+     value_t hidden_size, value_t input_forget, value_t output_size,
+     value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+mat_mul(value_t lhs, value_t rhs, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+mat_mul_shape(value_t lhs, value_t rhs, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+normal(typecode_t type, value_t mean, value_t scale, value_t seed,
+       value_t shape, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+normal_like(typecode_t type, value_t input, value_t mean, value_t scale,
+            value_t seed, value_t output = nullptr,
+            kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+one_hot(runtime::stackvm::one_hot_mode_t one_hot_mode, value_t indices,
+        value_t depth, value_t values, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+pad(runtime::stackvm::pad_mode_t pad_mode, value_t input, value_t pads,
+    value_t value, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+prelu(value_t input, value_t slope, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+prod(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+quant_param_of(runtime::stackvm::quant_mode_t quant_mode, value_t range,
+               value_t bits, value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+quantize(typecode_t target_type, value_t input, value_t quant_param,
+         value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+range(value_t begin, value_t end, value_t step, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+range_of(bool is_range_of_weight, value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+rank(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce(runtime::stackvm::reduce_op_t reduce_op, value_t input, value_t axis,
+       value_t init_value, value_t keep_dims, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce_arg(runtime::stackvm::reduce_arg_op_t reduce_arg_op,
+           typecode_t dest_type, value_t input, value_t axis, value_t keep_dims,
+           value_t select_last_index, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce_window2d(runtime::stackvm::reduce_op_t reduce_op, value_t input,
+                value_t init_value, value_t filter, value_t stride,
+                value_t padding, value_t dilation, value_t ceil_mode,
+                value_t count_include_pad, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+relu(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+relu6(value_t input, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+require(std::string message, bool can_fold_const_call, value_t predicate,
+        value_t value, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reshape(value_t input, value_t shape, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reshape_shape(value_t input_shape, value_t shape, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t> resize_image(
+    runtime::stackvm::image_resize_mode_t resize_mode,
+    runtime::stackvm::image_resize_transformation_mode_t transformation_mode,
+    runtime::stackvm::image_resize_nearest_mode_t nearest_mode,
+    bool is_tfresize, value_t input, value_t roi, value_t new_size,
+    value_t cubic_coeff_a, value_t exclude_outside, value_t extrapolation_value,
+    value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reverse_sequence(value_t input, value_t seq_lens, value_t batch_axis,
+                 value_t time_axis, value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+scatter_nd(value_t input, value_t indices, value_t updates,
+           value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+select(value_t predicate, value_t true_value, value_t false_value,
+       value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+selu(value_t input, value_t alpha, value_t gamma, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+shape_of(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+sigmoid(value_t input, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+size_of(value_t input, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+slice(value_t input, value_t begins, value_t ends, value_t axes,
+      value_t strides, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softmax(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softplus(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softsign(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+space_to_batch(value_t input, value_t block_shape, value_t paddings,
+               value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+split(value_t input, value_t axis, value_t sections, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+squeeze(value_t input, value_t dim, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+squeeze_shape(value_t input_shape, value_t dim, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+stack(value_t inputs, value_t axis, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+swish(value_t input, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+tile(value_t input, value_t repeats, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+top_k(value_t x, value_t k, value_t axis, value_t largest, value_t sorted,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+transpose(value_t input, value_t perm, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+transpose_shape(value_t input_shape, value_t perm, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+trilu(value_t input, value_t k, value_t upper, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unary(runtime::stackvm::unary_op_t unary_op, value_t input,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+uniform(typecode_t type, value_t high, value_t low, value_t seed, value_t shape,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+uniform_like(typecode_t type, value_t input, value_t high, value_t low,
+             value_t seed, value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unsqueeze(value_t input, value_t dim, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unsqueeze_shape(value_t input_shape, value_t dim, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+where(bool is_tf_where, value_t cond, value_t x, value_t y,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+END_NS_NNCASE_KERNELS_MODULE
diff --git a/third_party/nncase/riscv64/include/nncase/object.h b/third_party/nncase/riscv64/include/nncase/object.h
new file mode 100644
index 0000000..87a7ea4
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/object.h
@@ -0,0 +1,206 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object_kind.h"
+#include <atomic>
+#include <memory>
+#include <nncase/api.h>
+#include <nncase/runtime/result.h>
+#include <optional>
+#include <type_traits>
+#include <utility>
+
+namespace nncase {
+#define DEFINE_OBJECT_KIND(base_t, kind_)                                      \
+  public:                                                                      \
+    static constexpr object_kind kind() noexcept { return kind_; }             \
+    const object_kind &runtime_kind() const noexcept override {                \
+        return kind_;                                                          \
+    }                                                                          \
+                                                                               \
+  protected:                                                                   \
+    bool is_a(const object_kind &kind) const noexcept override {               \
+        return kind == kind_ || base_t::is_a(kind);                            \
+    }
+
+class NNCASE_API object_node {
+  public:
+    object_node() noexcept;
+    object_node(const object_node &) = delete;
+    object_node &operator=(const object_node &) = delete;
+    virtual ~object_node() = default;
+
+    /** @brief Get the kind of the object */
+    virtual const object_kind &runtime_kind() const noexcept = 0;
+
+  protected:
+    template <class T> friend class object_t;
+
+    /** @brief Is the object an instance of specific kind */
+    virtual bool is_a(const object_kind &kind) const noexcept;
+
+    /** @brief Is the object equal to another instance */
+    virtual bool equals(const object_node &other) const noexcept;
+
+  private:
+    uint32_t add_ref() const noexcept {
+        return ref_count_.fetch_add(1, std::memory_order_relaxed);
+    }
+
+    uint32_t release() const noexcept {
+        assert(ref_count_);
+        auto count = ref_count_.fetch_sub(1, std::memory_order_acq_rel);
+        if (count == 1) {
+            delete this;
+        }
+        return count;
+    }
+
+    template <class T> friend class object_t;
+    friend int ::nncase_object_add_ref(nncase::object_node *node);
+    friend int ::nncase_object_release(nncase::object_node *node);
+
+  private:
+    mutable std::atomic<uint32_t> ref_count_;
+};
+
+template <class T> class object_t {
+  public:
+    using node_type = T;
+
+    /** @brief Construct an empty object */
+    constexpr object_t(std::nullptr_t = nullptr) noexcept : object_(nullptr) {}
+    ~object_t() { release(); }
+
+    object_t(T *node) noexcept : object_(node) { add_ref(); }
+    object_t(std::in_place_t, T *node) noexcept : object_(node) {}
+
+    object_t(object_t &&other) noexcept : object_(other.object_) {
+        other.object_ = nullptr;
+    }
+
+    object_t(const object_t &other) noexcept : object_(other.object_) {
+        add_ref();
+    }
+
+    template <class U,
+              class = std::enable_if_t<std::is_convertible_v<U *, T *>>>
+    object_t(object_t<U> &&other) noexcept : object_(other.object_) {
+        other.object_ = nullptr;
+    }
+
+    template <class U,
+              class = std::enable_if_t<std::is_convertible_v<U *, T *>>>
+    object_t(const object_t<U> &other) noexcept : object_(other.object_) {
+        add_ref();
+    }
+
+    template <class... TArgs>
+    object_t(std::in_place_t, TArgs &&...args)
+        : object_(new T(std::forward<TArgs>(args)...)) {}
+
+    /** @brief Get the managed pointer to the object */
+    T *get() const noexcept { return object_; }
+    T *operator->() const noexcept { return get(); }
+
+    bool empty() const noexcept { return !object_; }
+
+    object_t value_or(object_t &&other) const noexcept {
+        if (!empty())
+            return *this;
+        return std::move(other);
+    }
+
+    /** @brief Is the object an instance of specific type */
+    bool is_a(const object_kind &kind) const noexcept {
+        return object_ && static_cast<object_node *>(object_)->is_a(kind);
+    }
+
+    /** @brief Is the object an instance of specific type */
+    template <class U> bool is_a() const noexcept {
+        return is_a(U::node_type::kind());
+    }
+
+    template <class U> result<U> as() const noexcept {
+        if (is_a<U>()) {
+            return ok(U(static_cast<typename U::node_type *>(object_)));
+        } else {
+            return err(std::errc::invalid_argument);
+        }
+    }
+
+    /** @brief Is the object equal to another instance */
+    template <class U> bool equals(const U &other) const noexcept {
+        if (get() == other.get())
+            return true;
+        else if (!empty() && !other.empty())
+            return object_->equals(*other.get());
+        return false;
+    }
+
+    object_t &operator=(object_t &&other) noexcept {
+        if (this != &other) {
+            release();
+            object_ = other.object_;
+            other.object_ = nullptr;
+        }
+        return *this;
+    }
+
+    object_t &operator=(const object_t &other) noexcept {
+        if (this != &other) {
+            release();
+            object_ = other.object_;
+            add_ref();
+        }
+        return *this;
+    }
+
+    T *detach() noexcept {
+        auto obj = object_;
+        object_ = nullptr;
+        return obj;
+    }
+
+    T **release_and_addressof() noexcept {
+        release();
+        return &object_;
+    }
+
+    void dangerous_add_ref() noexcept { return add_ref(); }
+
+  private:
+    void add_ref() noexcept {
+        if (object_) {
+            object_->add_ref();
+        }
+    }
+
+    void release() noexcept {
+        auto obj = object_;
+        if (obj) {
+            obj->release();
+            object_ = nullptr;
+        }
+    }
+
+  private:
+    template <class U> friend class object_t;
+
+    T *object_;
+};
+
+using object = object_t<object_node>;
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/object_kind.def b/third_party/nncase/riscv64/include/nncase/object_kind.def
new file mode 100644
index 0000000..7979ea3
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/object_kind.def
@@ -0,0 +1,17 @@
+DEFINE_OBJECT_KIND(datatype,         DataType,       1)
+DEFINE_OBJECT_KIND(prim_type,        PrimType,       2)
+DEFINE_OBJECT_KIND(pointer_type,     PointerType,    3)
+DEFINE_OBJECT_KIND(value_type,       ValueType,      4)
+DEFINE_OBJECT_KIND(type,             Type,           5)
+DEFINE_OBJECT_KIND(any_type,         AnyType,        6)
+DEFINE_OBJECT_KIND(invalid_type,     InvalidType,    7)
+DEFINE_OBJECT_KIND(tensor_type,      TensorType,     8)
+DEFINE_OBJECT_KIND(tuple_type,       TupleType,      9)
+DEFINE_OBJECT_KIND(callable_type,    CallableType,   10)
+DEFINE_OBJECT_KIND(buffer,           Buffer,         11)
+DEFINE_OBJECT_KIND(host_buffer,      HostBuffer,     12)
+DEFINE_OBJECT_KIND(device_buffer,    DeviceBuffer,   13)
+DEFINE_OBJECT_KIND(remote_buffer,    RemoteBuffer,   14)
+DEFINE_OBJECT_KIND(value,            Value,          15)
+DEFINE_OBJECT_KIND(tensor,			 Tensor,         16)
+DEFINE_OBJECT_KIND(tuple,            Tuple,          17)
diff --git a/third_party/nncase/riscv64/include/nncase/object_kind.h b/third_party/nncase/riscv64/include/nncase/object_kind.h
new file mode 100644
index 0000000..9b28b30
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/object_kind.h
@@ -0,0 +1,47 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <stdexcept>
+#include <string_view>
+#include <type_traits>
+
+namespace nncase {
+struct object_kind {
+    uint32_t id;
+    std::string_view name;
+};
+
+constexpr inline bool operator==(const object_kind &lhs,
+                                 const object_kind &rhs) noexcept {
+    return lhs.id == rhs.id;
+}
+
+#define DEFINE_OBJECT_KIND(id, name, value)                                    \
+    inline constexpr object_kind object_##id{value, #name};
+
+#include "object_kind.def"
+
+#undef DEFINE_OBJECT_KIND
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::object_kind> {
+    [[nodiscard]] size_t
+    operator()(const nncase::object_kind &opcode) const noexcept {
+        return std::hash<uint32_t>()(opcode.id);
+    }
+};
+} // namespace std
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/allocator.h b/third_party/nncase/riscv64/include/nncase/runtime/allocator.h
new file mode 100644
index 0000000..b81353a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/allocator.h
@@ -0,0 +1,49 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "buffer.h"
+#include <memory>
+#include <nncase/compiler_defs.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+struct buffer_allocate_options {
+    size_t flags;
+};
+
+inline constexpr size_t HOST_BUFFER_ALLOCATE_CPU_ONLY = 1;
+inline constexpr size_t HOST_BUFFER_ALLOCATE_SHARED = 2;
+
+struct buffer_attach_options {
+    size_t flags;
+    uintptr_t physical_address;
+    std::function<void(gsl::byte *)> deleter;
+};
+
+inline constexpr size_t HOST_BUFFER_ATTACH_SHARED = 1;
+
+class NNCASE_API buffer_allocator {
+  public:
+    virtual result<buffer_t>
+    allocate(size_t bytes, const buffer_allocate_options &options) = 0;
+
+    virtual result<buffer_t> attach(gsl::span<gsl::byte> data,
+                                    const buffer_attach_options &options) = 0;
+
+    static buffer_allocator &host();
+    virtual void shrink_memory_pool() = 0;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/bfloat16.h b/third_party/nncase/riscv64/include/nncase/runtime/bfloat16.h
new file mode 100644
index 0000000..b97a4e7
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/bfloat16.h
@@ -0,0 +1,317 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <cmath>
+#include <cstdint>
+#include <float.h>
+#include <functional>
+#include <limits>
+
+namespace nncase {
+struct from_raw_t {
+    explicit from_raw_t() = default;
+};
+
+NNCASE_INLINE_VAR constexpr from_raw_t from_raw{};
+
+struct bfloat16 {
+  private:
+    union fp32 {
+        uint32_t u32;
+        float f32;
+
+        uint16_t u16() const noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<const uint16_t *>(&u32)[index];
+        }
+
+        uint16_t &u16() noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<uint16_t *>(&u32)[index];
+        }
+    };
+
+    // A value that represents "zero".
+    static constexpr uint16_t ZERO_VALUE = 0;
+
+    // A value that represents "not a number".
+    static constexpr uint16_t NAN_VALUE = 0x7FC0;
+
+  public:
+    bfloat16() noexcept = default;
+
+    explicit bfloat16(float v) noexcept : value_(round_to_bfloat16(v).value_) {}
+
+    template <class T,
+              class = std::enable_if_t<std::is_integral<T>::value ||
+                                       std::is_floating_point<T>::value>>
+    explicit bfloat16(const T &val) noexcept
+        : bfloat16(static_cast<float>(val)) {}
+
+    bfloat16(int &&val) noexcept : bfloat16(static_cast<float>(val)) {}
+
+    constexpr bfloat16(from_raw_t, uint16_t value) noexcept : value_(value) {}
+
+    operator float() const noexcept {
+        fp32 result;
+        result.u32 = 0;
+        result.u16() = value_;
+        return result.f32;
+    }
+
+    const uint16_t &raw() const noexcept { return value_; }
+    uint16_t &raw() noexcept { return value_; }
+
+    static constexpr bfloat16 from_raw(uint16_t v) noexcept {
+        return bfloat16(nncase::from_raw, v);
+    }
+
+    static bfloat16 truncate_to_bfloat16(const float v) noexcept {
+        bfloat16 output;
+
+        if (!std::isnan(v)) {
+            fp32 f;
+            f.f32 = v;
+            output.value_ = f.u16();
+        } else {
+            output.value_ = NAN_VALUE;
+        }
+
+        return output;
+    }
+
+    // Converts a float point to bfloat16, with round-nearest-to-even as
+    // rounding method.
+    static bfloat16 round_to_bfloat16(float v) {
+        uint32_t input;
+        fp32 f;
+        f.f32 = v;
+        input = f.u32;
+        bfloat16 output;
+
+        if (!std::isnan(v)) {
+            // Least significant bit of resulting bfloat.
+            uint32_t lsb = (input >> 16) & 1;
+            uint32_t rounding_bias = 0x7fff + lsb;
+            input += rounding_bias;
+            output.value_ = static_cast<uint16_t>(input >> 16);
+        } else {
+            // If the value is a NaN, squash it to a qNaN with msb of fraction
+            // set, this makes sure after truncation we don't end up with an
+            // inf.
+            //
+            // qNaN magic: All exponent bits set + most significant bit of
+            // fraction set.
+            output.value_ = NAN_VALUE;
+        }
+
+        return output;
+    }
+
+    static constexpr bfloat16 epsilon() noexcept {
+        // 0x1.0p-7
+        return from_raw(0x3c00);
+    }
+
+    static constexpr bfloat16 highest() noexcept {
+        // 0x1.FEp127
+        return from_raw(0x7F7F);
+    }
+
+    static constexpr bfloat16 min() noexcept {
+        // 0x1p-126
+        return from_raw(0x0080);
+    }
+
+    static constexpr bfloat16 lowest() noexcept {
+        // -0x1.FEp127
+        return from_raw(0xFF7F);
+    }
+
+    static constexpr bfloat16 nan() noexcept { return from_raw(0x7fc0); }
+
+    static constexpr bfloat16 quiet_NaN() noexcept { return from_raw(0x7fc0); }
+
+    static constexpr bfloat16 signaling_NaN() noexcept {
+        return from_raw(0x7f81);
+    }
+
+    static constexpr bfloat16 infinity() noexcept { return from_raw(0x7f80); }
+
+    constexpr bool zero() const noexcept {
+        return (value_ & 0x7FFF) == ZERO_VALUE;
+    }
+
+    void operator=(const float &v) noexcept {
+        value_ = (round_to_bfloat16(v).value_);
+    }
+
+  private:
+    uint16_t value_;
+};
+
+#define DEFINE_BF16_BINARY_BF16RET(x)                                          \
+    inline bfloat16 operator x(bfloat16 a, bfloat16 b) noexcept {              \
+        return bfloat16::round_to_bfloat16(float(a) x float(b));               \
+    }
+
+#define DEFINE_BF16_BINARY_BOOLRET(x)                                          \
+    inline bool operator x(bfloat16 a, bfloat16 b) noexcept {                  \
+        return float(a) x float(b);                                            \
+    }
+
+DEFINE_BF16_BINARY_BF16RET(+)
+DEFINE_BF16_BINARY_BF16RET(-)
+DEFINE_BF16_BINARY_BF16RET(*)
+DEFINE_BF16_BINARY_BF16RET(/)
+DEFINE_BF16_BINARY_BOOLRET(<)
+DEFINE_BF16_BINARY_BOOLRET(<=)
+DEFINE_BF16_BINARY_BOOLRET(>=)
+DEFINE_BF16_BINARY_BOOLRET(>)
+
+#define DEFINE_BF16_BINARY_SELF_MOD(x, op)                                     \
+    inline bfloat16 &operator x(bfloat16 &a, bfloat16 b) noexcept {            \
+        a = a op b;                                                            \
+        return a;                                                              \
+    }
+
+DEFINE_BF16_BINARY_SELF_MOD(+=, +)
+DEFINE_BF16_BINARY_SELF_MOD(-=, -)
+DEFINE_BF16_BINARY_SELF_MOD(*=, *)
+DEFINE_BF16_BINARY_SELF_MOD(/=, /)
+
+inline bfloat16 operator-(bfloat16 a) noexcept {
+    return bfloat16::round_to_bfloat16(-float(a));
+}
+
+inline bool operator==(const bfloat16 &lhs, const bfloat16 &rhs) noexcept {
+    return lhs.raw() == rhs.raw();
+}
+
+inline bool operator!=(const bfloat16 &lhs, const bfloat16 &rhs) noexcept {
+    return lhs.raw() != rhs.raw();
+}
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::bfloat16> {
+    size_t operator()(const nncase::bfloat16 &v) const {
+        return hash<float>()(static_cast<float>(v));
+    }
+};
+
+template <> struct numeric_limits<nncase::bfloat16> {
+    static constexpr float_denorm_style has_denorm = denorm_present;
+    static constexpr bool has_infinity = true;
+    static constexpr bool has_quiet_NaN = true;
+    static constexpr bool has_signaling_NaN = true;
+    static constexpr bool is_bounded = true;
+    static constexpr bool is_iec559 = true;
+    static constexpr bool is_signed = true;
+    static constexpr bool is_specialized = true;
+    static constexpr float_round_style round_style = round_to_nearest;
+    static constexpr int radix = FLT_RADIX;
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16(min)() noexcept {
+        return nncase::bfloat16::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16(max)() noexcept {
+        return nncase::bfloat16::highest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 lowest() noexcept {
+        return nncase::bfloat16::lowest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 epsilon() noexcept {
+        return nncase::bfloat16::epsilon();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 round_error() noexcept {
+        // 0.5
+        return nncase::bfloat16::from_raw(0x3f00);
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 denorm_min() noexcept {
+        return nncase::bfloat16::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 infinity() noexcept {
+        return nncase::bfloat16::infinity();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 quiet_NaN() noexcept {
+        return nncase::bfloat16::quiet_NaN();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 signaling_NaN() noexcept {
+        return nncase::bfloat16::signaling_NaN();
+    }
+
+    static constexpr int digits = 8;
+    static constexpr int max_exponent = FLT_MAX_EXP;
+    static constexpr int min_exponent = FLT_MIN_EXP;
+};
+
+using nncase::bfloat16;
+inline bool isinf(const bfloat16 &a) { return std::isinf(float(a)); }
+inline bool isnan(const bfloat16 &a) { return std::isnan(float(a)); }
+inline bool isfinite(const bfloat16 &a) { return std::isfinite(float(a)); }
+inline bfloat16 abs(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(fabsf(float(a)));
+}
+inline bfloat16 exp(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(expf(float(a)));
+}
+inline bfloat16 log(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(logf(float(a)));
+}
+inline bfloat16 log10(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(log10f(float(a)));
+}
+inline bfloat16 sqrt(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(sqrtf(float(a)));
+}
+inline bfloat16 pow(const bfloat16 &a, const bfloat16 &b) {
+    return bfloat16::round_to_bfloat16(powf(float(a), float(b)));
+}
+inline bfloat16 sin(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(sinf(float(a)));
+}
+inline bfloat16 cos(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(cosf(float(a)));
+}
+inline bfloat16 tan(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(tanf(float(a)));
+}
+inline bfloat16 tanh(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(tanhf(float(a)));
+}
+inline bfloat16 floor(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(floorf(float(a)));
+}
+inline bfloat16 ceil(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(ceilf(float(a)));
+}
+inline bfloat16 round(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(roundf(float(a)));
+}
+inline bfloat16 nearbyint(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(nearbyintf(float(a)));
+}
+inline long lrint(const bfloat16 &a) { return lrintf(float(a)); }
+} // namespace std
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/binary_writer.h b/third_party/nncase/riscv64/include/nncase/runtime/binary_writer.h
new file mode 100644
index 0000000..b3fb73a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/binary_writer.h
@@ -0,0 +1,74 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <iostream>
+#include <span>
+
+namespace nncase {
+class binary_writer {
+  public:
+    binary_writer(std::ostream &stream)
+        : stream_(stream), relative_offset_(0) {}
+
+    template <class T> void write(T &&value) {
+        stream_.write(reinterpret_cast<const char *>(&value), sizeof(value));
+        relative_offset_ += sizeof(value);
+    }
+
+    template <class T> void write_array(std::span<T const> value) {
+        stream_.write(reinterpret_cast<const char *>(value.data()),
+                      value.size_bytes());
+        relative_offset_ += value.size_bytes();
+    }
+
+    std::streampos position() const {
+        assert(stream_);
+        return stream_.tellp();
+    }
+
+    void position(std::streampos pos) {
+        auto old_pos = position();
+        stream_.seekp(pos);
+        assert(stream_);
+        relative_offset_ += pos - old_pos;
+    }
+
+    void skip(size_t len) {
+        char zero = 0;
+        for (size_t i = 0; i < len; i++)
+            stream_.write(&zero, 1);
+        relative_offset_ += len;
+    }
+
+    std::streamoff align_position(size_t alignment) {
+        auto pos = position();
+        auto rem = pos % alignment;
+        if (rem != 0) {
+            auto off = std::streamoff(alignment - rem);
+            skip(off);
+            return off;
+        }
+
+        return 0;
+    }
+
+    int64_t relative_offset() const noexcept { return relative_offset_; }
+
+  private:
+    std::ostream &stream_;
+    int64_t relative_offset_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/bitio.h b/third_party/nncase/riscv64/include/nncase/runtime/bitio.h
new file mode 100644
index 0000000..4803121
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/bitio.h
@@ -0,0 +1,146 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include <algorithm>
+#include <cassert>
+#include <cstdint>
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+
+namespace nncase::runtime {
+class bitreader {
+  public:
+    bitreader(gsl::span<const uint8_t> data)
+        : data_(data), buffer_(0), avail_(0) {}
+
+    void read(uint8_t *dest, size_t bits) {
+        while (bits) {
+            auto to_read = std::min(bits, size_t(8));
+            *dest++ = read_bits_le8(to_read);
+            bits -= to_read;
+        }
+    }
+
+    template <class T, size_t Bits> T read() {
+        T ret{};
+        read(reinterpret_cast<uint8_t *>(&ret), Bits);
+        return ret;
+    }
+
+  private:
+    uint8_t read_bits_le8(size_t bits) {
+        assert(bits <= 8);
+
+        fill_buffer_le8(bits);
+        uint8_t ret = buffer_ & ((size_t(1) << bits) - 1);
+        buffer_ >>= bits;
+        avail_ -= bits;
+        return ret;
+    }
+
+    void fill_buffer_le8(size_t bits) {
+        if (avail_ < bits) {
+            auto max_read_bytes =
+                std::min(data_.size() * 8, sizeof(buffer_) * 8 - avail_) / 8;
+            assert(max_read_bytes != 0);
+
+            uint64_t tmp = 0;
+            std::memcpy(&tmp, data_.data(), max_read_bytes);
+            data_ = data_.subspan(max_read_bytes);
+            buffer_ = buffer_ | (tmp << avail_);
+            avail_ += max_read_bytes * 8;
+        }
+    }
+
+  private:
+    gsl::span<const uint8_t> data_;
+    uint64_t buffer_;
+    size_t avail_;
+};
+
+class bitwriter {
+  public:
+    bitwriter(gsl::span<uint8_t> data, size_t bitoffset = 0)
+        : data_(data), buffer_(0), avail_(sizeof(buffer_) * 8) {
+        if (bitoffset) {
+            data_ = data_.subspan(bitoffset / 8);
+            bitoffset %= 8;
+            buffer_ = data_.front() & ((size_t(1) << bitoffset) - 1);
+            avail_ -= bitoffset;
+        }
+    }
+
+    ~bitwriter() { flush(); }
+
+    void write(const uint8_t *src, size_t bits) {
+        while (bits) {
+            auto to_write = std::min(bits, size_t(8));
+            write_bits_le8(*src++, to_write);
+            bits -= to_write;
+        }
+    }
+
+    template <size_t Bits, class T> void write(T value) {
+        write(reinterpret_cast<const uint8_t *>(&value), Bits);
+    }
+
+    void flush() {
+        auto write_bytes = (buffer_written_bits() + 7) / 8;
+        if (write_bytes) {
+            assert(data_.size() >= write_bytes);
+
+            std::memcpy(data_.data(), &buffer_, write_bytes);
+            data_ = data_.subspan(write_bytes);
+            buffer_ = 0;
+            avail_ = sizeof(buffer_) * 8;
+        }
+    }
+
+  private:
+    void write_bits_le8(uint8_t value, size_t bits) {
+        assert(bits <= 8);
+
+        reserve_buffer_8();
+        size_t new_value = value & ((size_t(1) << bits) - 1);
+        buffer_ = buffer_ | (new_value << buffer_written_bits());
+        avail_ -= bits;
+    }
+
+    void reserve_buffer_8() {
+        if (avail_ < 8) {
+            auto write_bytes = buffer_written_bits() / 8;
+            assert(data_.size() >= write_bytes);
+
+            std::memcpy(data_.data(), &buffer_, write_bytes);
+            data_ = data_.subspan(write_bytes);
+            if (write_bytes == sizeof(buffer_))
+                buffer_ = 0;
+            else
+                buffer_ >>= write_bytes * 8;
+            avail_ += write_bytes * 8;
+        }
+    }
+
+    size_t buffer_written_bits() const noexcept {
+        return sizeof(buffer_) * 8 - avail_;
+    }
+
+  private:
+    gsl::span<uint8_t> data_;
+    uint64_t buffer_;
+    size_t avail_;
+};
+} // namespace nncase::runtime
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/buffer.h b/third_party/nncase/riscv64/include/nncase/runtime/buffer.h
new file mode 100644
index 0000000..763dcf6
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/buffer.h
@@ -0,0 +1,81 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "result.h"
+#include <memory>
+#include <nncase/object.h>
+#include <nncase/runtime/datatypes.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class buffer_node;
+class buffer_allocator;
+class host_buffer_slice;
+
+using buffer_t = object_t<buffer_node>;
+
+class NNCASE_API buffer_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_buffer);
+
+  public:
+    buffer_node(size_t size_bytes, buffer_allocator &allocator);
+
+    size_t size_bytes() const noexcept { return size_bytes_; }
+    buffer_allocator &allocator() const noexcept { return allocator_; }
+
+    virtual result<void>
+    copy_to(buffer_t dest, size_t src_start, size_t dest_start,
+            datatype_t datatype, gsl::span<const size_t> shape,
+            gsl::span<const size_t> strides,
+            gsl::span<const size_t> dest_strides) noexcept = 0;
+
+  private:
+    size_t size_bytes_;
+    buffer_allocator &allocator_;
+};
+
+class NNCASE_API buffer_slice {
+  public:
+    buffer_slice() noexcept = default;
+    buffer_slice(buffer_t buffer) noexcept
+        : buffer_(std::move(buffer)),
+          start_(0),
+          length_(buffer_->size_bytes()) {}
+
+    buffer_slice(buffer_t buffer, size_t start, size_t length) noexcept
+        : buffer_(std::move(buffer)), start_(start), length_(length) {}
+
+    const buffer_t &buffer() const noexcept { return buffer_; }
+
+    size_t start() const noexcept { return start_; }
+    size_t size_bytes() const noexcept { return length_; }
+
+    buffer_allocator &allocator() const noexcept {
+        return buffer_->allocator();
+    }
+
+    result<host_buffer_slice> as_host() const noexcept;
+    result<void> copy_to(const buffer_slice &dest, datatype_t datatype,
+                         gsl::span<const size_t> shape,
+                         gsl::span<const size_t> src_strides,
+                         gsl::span<const size_t> dest_strides) const noexcept;
+
+  private:
+    buffer_t buffer_;
+    size_t start_;
+    size_t length_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/char_array_buffer.h b/third_party/nncase/riscv64/include/nncase/runtime/char_array_buffer.h
new file mode 100644
index 0000000..8dde31b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/char_array_buffer.h
@@ -0,0 +1,97 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <gsl/gsl-lite.hpp>
+#include <iostream>
+
+namespace nncase {
+class char_array_buffer : public std::streambuf {
+  public:
+    char_array_buffer(gsl::span<const char> data)
+        : begin_(data.begin()), end_(data.end()), current_(data.data()) {}
+
+  private:
+    int_type underflow() override {
+        if (current_ == end_)
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*current_);
+    }
+
+    int_type uflow() override {
+        if (current_ == end_)
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*current_++);
+    }
+
+    int_type pbackfail(int_type ch) override {
+        if (current_ == begin_ ||
+            (ch != traits_type::eof() && ch != current_[-1]))
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*--current_);
+    }
+
+    std::streamsize showmanyc() override {
+        assert(std::less_equal<const char *>()(current_, end_));
+        return end_ - current_;
+    }
+
+    std::streampos
+    seekoff(std::streamoff off, std::ios_base::seekdir way,
+            [[maybe_unused]] std::ios_base::openmode which) override {
+        if (way == std::ios_base::beg) {
+            current_ = begin_ + off;
+        } else if (way == std::ios_base::cur) {
+            current_ += off;
+        } else if (way == std::ios_base::end) {
+            current_ = end_ + off;
+        }
+
+        if (current_ < begin_ || current_ > end_)
+            return -1;
+
+        return current_ - begin_;
+    }
+
+    std::streampos
+    seekpos(std::streampos sp,
+            [[maybe_unused]] std::ios_base::openmode which) override {
+        current_ = begin_ + sp;
+
+        if (current_ < begin_ || current_ > end_)
+            return -1;
+
+        return current_ - begin_;
+    }
+
+    std::streamsize xsgetn(char_type *s, std::streamsize count) override {
+        std::streamsize available =
+            static_cast<std::streamsize>(end_ - current_);
+        std::streamsize n = (count > available) ? available : count;
+        if (n > 0) {
+            traits_type::copy(s, current_, static_cast<size_t>(n));
+            current_ += n;
+        }
+        return n;
+    }
+
+    const char *const begin_;
+    const char *const end_;
+    const char *current_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/datatypes.h b/third_party/nncase/riscv64/include/nncase/runtime/datatypes.h
new file mode 100644
index 0000000..f0ff9ad
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/datatypes.h
@@ -0,0 +1,146 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../object.h"
+#include "simple_types.h"
+
+namespace nncase {
+class NNCASE_API datatype_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_datatype)
+  public:
+    /** @brief Get size in bytes. */
+    virtual size_t size_bytes() const noexcept = 0;
+
+    /** @brief Get type code. */
+    virtual typecode_t typecode() const noexcept = 0;
+};
+
+class prim_type_node;
+using prim_type_t = object_t<prim_type_node>;
+
+class NNCASE_API datatype_t : public object_t<datatype_node> {
+  public:
+    using object_t::object_t;
+
+    static prim_type_t boolean;
+    static prim_type_t uint8;
+    static prim_type_t uint16;
+    static prim_type_t uint32;
+    static prim_type_t uint64;
+    static prim_type_t int8;
+    static prim_type_t int16;
+    static prim_type_t int32;
+    static prim_type_t int64;
+    static prim_type_t float16;
+    static prim_type_t float32;
+    static prim_type_t float64;
+    static prim_type_t bfloat16;
+
+    datatype_t(typecode_t typecode);
+
+    static result<prim_type_t> from_typecode(typecode_t typecode);
+
+    template <class T> static datatype_t from_type();
+};
+
+class NNCASE_API prim_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_prim_type)
+  public:
+    explicit prim_type_node(typecode_t typecode) noexcept
+        : typecode_(typecode) {}
+
+    size_t size_bytes() const noexcept override {
+        return typecode_bytes(typecode_);
+    }
+
+    typecode_t typecode() const noexcept override { return typecode_; }
+
+  private:
+    typecode_t typecode_;
+};
+
+class NNCASE_API pointer_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_pointer_type)
+  public:
+    explicit pointer_type_node(datatype_t elemtype) noexcept
+        : elemtype_(elemtype) {}
+
+    size_t size_bytes() const noexcept override {
+        return typecode_bytes(dt_pointer);
+    }
+
+    typecode_t typecode() const noexcept override { return dt_pointer; }
+    const datatype_t &elemtype() const noexcept { return elemtype_; }
+
+  private:
+    datatype_t elemtype_;
+};
+
+using pointer_type_t = object_t<pointer_type_node>;
+
+class NNCASE_API value_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_value_type)
+  public:
+    value_type_node(uuid_t uuid, size_t size_bytes) noexcept
+        : uuid_(uuid), size_bytes_(size_bytes) {}
+
+    size_t size_bytes() const noexcept override { return size_bytes_; }
+    typecode_t typecode() const noexcept override { return dt_valuetype; }
+    const uuid_t &uuid() const noexcept { return uuid_; }
+
+  private:
+    uuid_t uuid_;
+    size_t size_bytes_;
+};
+
+using value_type_t = object_t<value_type_node>;
+
+namespace detail {
+template <class T> struct datatype_of {};
+
+#define DEFINE_DATATYPE_OF(type, name)                                         \
+    template <> struct datatype_of<type> {                                     \
+        datatype_t operator()() const noexcept { return datatype_t::name; }    \
+    };
+
+DEFINE_DATATYPE_OF(bool, boolean)
+DEFINE_DATATYPE_OF(uint8_t, uint8)
+DEFINE_DATATYPE_OF(uint16_t, uint16)
+DEFINE_DATATYPE_OF(uint32_t, uint32)
+#ifdef __APPLE__
+DEFINE_DATATYPE_OF(size_t, uint64)
+#endif
+DEFINE_DATATYPE_OF(uint64_t, uint64)
+DEFINE_DATATYPE_OF(int8_t, int8)
+DEFINE_DATATYPE_OF(int16_t, int16)
+DEFINE_DATATYPE_OF(int32_t, int32)
+DEFINE_DATATYPE_OF(int64_t, int64)
+DEFINE_DATATYPE_OF(half, float16)
+DEFINE_DATATYPE_OF(float, float32)
+DEFINE_DATATYPE_OF(double, float64)
+DEFINE_DATATYPE_OF(bfloat16, bfloat16)
+
+#undef DEFINE_DATATYPE_OF
+} // namespace detail
+
+template <class T> datatype_t datatype_t::from_type() {
+    return detail::datatype_of<T>()();
+}
+
+inline result<typecode_t> to_typecode(const datatype_t &dtype) {
+    try_var(prim_type, dtype.as<prim_type_t>());
+    return ok(prim_type->typecode());
+}
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/dbg.h b/third_party/nncase/riscv64/include/nncase/runtime/dbg.h
new file mode 100644
index 0000000..81d6aa9
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/dbg.h
@@ -0,0 +1,952 @@
+/*****************************************************************************
+
+                                dbg(...) macro
+
+License (MIT):
+
+  Copyright (c) 2019 David Peter <mail@david-peter.de>
+
+  Permission is hereby granted, free of charge, to any person obtaining a copy
+  of this software and associated documentation files (the "Software"), to
+  deal in the Software without restriction, including without limitation the
+  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
+  sell copies of the Software, and to permit persons to whom the Software is
+  furnished to do so, subject to the following conditions:
+
+  The above copyright notice and this permission notice shall be included in
+  all copies or substantial portions of the Software.
+
+  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+  THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+  SOFTWARE.
+
+*****************************************************************************/
+
+#ifndef DBG_MACRO_DBG_H
+#define DBG_MACRO_DBG_H
+
+#if defined(__unix__) || (defined(__APPLE__) && defined(__MACH__))
+#define DBG_MACRO_UNIX
+#elif defined(_MSC_VER)
+#define DBG_MACRO_WINDOWS
+#endif
+
+#include "result.h"
+#include <algorithm>
+#include <chrono>
+#include <ctime>
+#include <iomanip>
+#include <ios>
+#include <iostream>
+#include <memory>
+#include <sstream>
+#include <string>
+#include <tuple>
+#include <type_traits>
+#include <vector>
+
+#ifdef DBG_MACRO_UNIX
+#include <unistd.h>
+#endif
+
+#if __cplusplus >= 201703L
+#define DBG_MACRO_CXX_STANDARD 17
+#elif __cplusplus >= 201402L
+#define DBG_MACRO_CXX_STANDARD 14
+#else
+#define DBG_MACRO_CXX_STANDARD 11
+#endif
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+#include <optional>
+#include <variant>
+#endif
+
+namespace dbg {
+
+#ifdef DBG_MACRO_UNIX
+inline bool isColorizedOutputEnabled() { return isatty(fileno(stderr)); }
+#else
+inline bool isColorizedOutputEnabled() { return true; }
+#endif
+
+struct time {};
+
+namespace pretty_function {
+
+// Compiler-agnostic version of __PRETTY_FUNCTION__ and constants to
+// extract the template argument in `type_name_impl`
+
+#if defined(__clang__)
+#define DBG_MACRO_PRETTY_FUNCTION __PRETTY_FUNCTION__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char *dbg::type_name_impl() [T = ") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof("]") - 1;
+#elif defined(__GNUC__) && !defined(__clang__)
+#define DBG_MACRO_PRETTY_FUNCTION __PRETTY_FUNCTION__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char* dbg::type_name_impl() [with T = ") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof("]") - 1;
+#elif defined(_MSC_VER)
+#define DBG_MACRO_PRETTY_FUNCTION __FUNCSIG__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char *__cdecl dbg::type_name_impl<") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof(">(void)") - 1;
+#else
+#error "This compiler is currently not supported by dbg_macro."
+#endif
+
+} // namespace pretty_function
+
+// Formatting helpers
+
+template <typename T> struct print_formatted {
+    static_assert(std::is_integral<T>::value,
+                  "Only integral types are supported.");
+
+    print_formatted(T value, int numeric_base)
+        : inner(value), base(numeric_base) {}
+
+    operator T() const { return inner; }
+
+    const char *prefix() const {
+        switch (base) {
+        case 8:
+            return "0o";
+        case 16:
+            return "0x";
+        case 2:
+            return "0b";
+        default:
+            return "";
+        }
+    }
+
+    T inner;
+    int base;
+};
+
+template <typename T> print_formatted<T> hex(T value) {
+    return print_formatted<T>{value, 16};
+}
+
+template <typename T> print_formatted<T> oct(T value) {
+    return print_formatted<T>{value, 8};
+}
+
+template <typename T> print_formatted<T> bin(T value) {
+    return print_formatted<T>{value, 2};
+}
+
+// Implementation of 'type_name<T>()'
+
+template <typename T> const char *type_name_impl() {
+    return DBG_MACRO_PRETTY_FUNCTION;
+}
+
+template <typename T> struct type_tag {};
+
+template <int &...ExplicitArgumentBarrier, typename T>
+std::string get_type_name(type_tag<T>) {
+    namespace pf = pretty_function;
+
+    std::string type = type_name_impl<T>();
+    return type.substr(pf::PREFIX_LENGTH,
+                       type.size() - pf::PREFIX_LENGTH - pf::SUFFIX_LENGTH);
+}
+
+template <typename T> std::string type_name() {
+    if (std::is_volatile<T>::value) {
+        if (std::is_pointer<T>::value) {
+            return type_name<typename std::remove_volatile<T>::type>() +
+                   " volatile";
+        } else {
+            return "volatile " +
+                   type_name<typename std::remove_volatile<T>::type>();
+        }
+    }
+    if (std::is_const<T>::value) {
+        if (std::is_pointer<T>::value) {
+            return type_name<typename std::remove_const<T>::type>() + " const";
+        } else {
+            return "const " + type_name<typename std::remove_const<T>::type>();
+        }
+    }
+    if (std::is_pointer<T>::value) {
+        return type_name<typename std::remove_pointer<T>::type>() + "*";
+    }
+    if (std::is_lvalue_reference<T>::value) {
+        return type_name<typename std::remove_reference<T>::type>() + "&";
+    }
+    if (std::is_rvalue_reference<T>::value) {
+        return type_name<typename std::remove_reference<T>::type>() + "&&";
+    }
+    return get_type_name(type_tag<T>{});
+}
+
+inline std::string get_type_name(type_tag<short>) { return "short"; }
+
+inline std::string get_type_name(type_tag<unsigned short>) {
+    return "unsigned short";
+}
+
+inline std::string get_type_name(type_tag<long>) { return "long"; }
+
+inline std::string get_type_name(type_tag<unsigned long>) {
+    return "unsigned long";
+}
+
+inline std::string get_type_name(type_tag<std::string>) {
+    return "std::string";
+}
+
+template <typename T>
+std::string get_type_name(type_tag<std::vector<T, std::allocator<T>>>) {
+    return "std::vector<" + type_name<T>() + ">";
+}
+
+template <typename T1, typename T2>
+std::string get_type_name(type_tag<std::pair<T1, T2>>) {
+    return "std::pair<" + type_name<T1>() + ", " + type_name<T2>() + ">";
+}
+
+template <typename... T> std::string type_list_to_string() {
+    std::string result;
+    auto unused = {(result += type_name<T>() + ", ", 0)..., 0};
+    static_cast<void>(unused);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+    if constexpr (sizeof...(T) > 0) {
+#else
+    if (sizeof...(T) > 0) {
+#endif
+        result.pop_back();
+        result.pop_back();
+    }
+    return result;
+} // namespace dbg
+
+template <typename... T> std::string get_type_name(type_tag<std::tuple<T...>>) {
+    return "std::tuple<" + type_list_to_string<T...>() + ">";
+}
+
+template <typename T>
+inline std::string get_type_name(type_tag<print_formatted<T>>) {
+    return type_name<T>();
+}
+
+// Implementation of 'is_detected' to specialize for container-like types
+
+namespace detail_detector {
+
+struct nonesuch {
+    nonesuch() = delete;
+    ~nonesuch() = delete;
+    nonesuch(nonesuch const &) = delete;
+    void operator=(nonesuch const &) = delete;
+};
+
+template <typename...> using void_t = void;
+
+template <class Default, class AlwaysVoid, template <class...> class Op,
+          class... Args>
+struct detector {
+    using value_t = std::false_type;
+    using type = Default;
+};
+
+template <class Default, template <class...> class Op, class... Args>
+struct detector<Default, void_t<Op<Args...>>, Op, Args...> {
+    using value_t = std::true_type;
+    using type = Op<Args...>;
+};
+
+} // namespace detail_detector
+
+template <template <class...> class Op, class... Args>
+using is_detected =
+    typename detail_detector::detector<detail_detector::nonesuch, void, Op,
+                                       Args...>::value_t;
+
+namespace detail {
+
+namespace {
+using std::begin;
+using std::end;
+#if DBG_MACRO_CXX_STANDARD < 17
+template <typename T> constexpr auto size(const T &c) -> decltype(c.size()) {
+    return c.size();
+}
+template <typename T, std::size_t N>
+constexpr std::size_t size(const T (&)[N]) {
+    return N;
+}
+#else
+using std::size;
+#endif
+} // namespace
+
+template <typename T>
+using detect_begin_t = decltype(detail::begin(std::declval<T>()));
+
+template <typename T>
+using detect_end_t = decltype(detail::end(std::declval<T>()));
+
+template <typename T>
+using detect_size_t = decltype(detail::size(std::declval<T>()));
+
+template <typename T> struct is_container {
+    static constexpr bool value =
+        is_detected<detect_begin_t, T>::value &&
+        is_detected<detect_end_t, T>::value &&
+        is_detected<detect_size_t, T>::value &&
+        !std::is_same<std::string,
+                      typename std::remove_cv<typename std::remove_reference<
+                          T>::type>::type>::value;
+};
+
+template <typename T>
+using ostream_operator_t =
+    decltype(std::declval<std::ostream &>() << std::declval<T>());
+
+template <typename T>
+struct has_ostream_operator : is_detected<ostream_operator_t, T> {};
+
+} // namespace detail
+
+// Helper to dbg(…)-print types
+template <typename T> struct print_type {};
+
+template <typename T> print_type<T> type() { return print_type<T>{}; }
+
+// Forward declarations of "pretty_print"
+
+template <typename T>
+inline void pretty_print(std::ostream &stream, const T &value, std::true_type);
+
+template <typename T>
+inline void pretty_print(std::ostream &, const T &, std::false_type);
+
+template <typename T>
+inline typename std::enable_if<!detail::is_container<const T &>::value &&
+                                   !std::is_enum<T>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const T &value);
+
+inline bool pretty_print(std::ostream &stream, const bool &value);
+
+inline bool pretty_print(std::ostream &stream, const char &value);
+
+template <typename P>
+inline bool pretty_print(std::ostream &stream, P *const &value);
+
+template <typename T, typename Deleter>
+inline bool pretty_print(std::ostream &stream,
+                         std::unique_ptr<T, Deleter> &value);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, std::shared_ptr<T> &value);
+
+template <size_t N>
+inline bool pretty_print(std::ostream &stream, const char (&value)[N]);
+
+template <>
+inline bool pretty_print(std::ostream &stream, const char *const &value);
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream, const std::tuple<Ts...> &value);
+
+template <>
+inline bool pretty_print(std::ostream &stream, const std::tuple<> &);
+
+template <> inline bool pretty_print(std::ostream &stream, const time &);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_formatted<T> &value);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_type<T> &);
+
+template <typename Enum>
+inline typename std::enable_if<std::is_enum<Enum>::value, bool>::type
+pretty_print(std::ostream &stream, Enum const &value);
+
+inline bool pretty_print(std::ostream &stream, const std::string &value);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+inline bool pretty_print(std::ostream &stream, const std::string_view &value);
+
+#endif
+
+template <typename T1, typename T2>
+inline bool pretty_print(std::ostream &stream, const std::pair<T1, T2> &value);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const std::optional<T> &value);
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream,
+                         const std::variant<Ts...> &value);
+
+#endif
+
+template <typename Container>
+inline typename std::enable_if<detail::is_container<const Container &>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const Container &value);
+
+// Specializations of "pretty_print"
+
+template <typename T>
+inline void pretty_print(std::ostream &stream, const T &value, std::true_type) {
+    stream << value;
+}
+
+template <typename T>
+inline void pretty_print(std::ostream &, const T &, std::false_type) {
+    static_assert(detail::has_ostream_operator<const T &>::value,
+                  "Type does not support the << ostream operator");
+}
+
+template <typename T>
+inline typename std::enable_if<!detail::is_container<const T &>::value &&
+                                   !std::is_enum<T>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const T &value) {
+    pretty_print(stream, value,
+                 typename detail::has_ostream_operator<const T &>::type{});
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const bool &value) {
+    stream << std::boolalpha << value;
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const char &value) {
+    const bool printable = value >= 0x20 && value <= 0x7E;
+
+    if (printable) {
+        stream << "'" << value << "'";
+    } else {
+        stream << "'\\x" << std::setw(2) << std::setfill('0') << std::hex
+               << std::uppercase << (0xFF & value) << "'";
+    }
+    return true;
+}
+
+template <typename P>
+inline bool pretty_print(std::ostream &stream, P *const &value) {
+    if (value == nullptr) {
+        stream << "nullptr";
+    } else {
+        stream << value;
+    }
+    return true;
+}
+
+template <typename T, typename Deleter>
+inline bool pretty_print(std::ostream &stream,
+                         std::unique_ptr<T, Deleter> &value) {
+    pretty_print(stream, value.get());
+    return true;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, std::shared_ptr<T> &value) {
+    pretty_print(stream, value.get());
+    stream << " (use_count = " << value.use_count() << ")";
+
+    return true;
+}
+
+template <size_t N>
+inline bool pretty_print(std::ostream &stream, const char (&value)[N]) {
+    stream << value;
+    return false;
+}
+
+template <>
+inline bool pretty_print(std::ostream &stream, const char *const &value) {
+    stream << '"' << value << '"';
+    return true;
+}
+
+template <size_t Idx> struct pretty_print_tuple {
+    template <typename... Ts>
+    static void print(std::ostream &stream, const std::tuple<Ts...> &tuple) {
+        pretty_print_tuple<Idx - 1>::print(stream, tuple);
+        stream << ", ";
+        pretty_print(stream, std::get<Idx>(tuple));
+    }
+};
+
+template <> struct pretty_print_tuple<0> {
+    template <typename... Ts>
+    static void print(std::ostream &stream, const std::tuple<Ts...> &tuple) {
+        pretty_print(stream, std::get<0>(tuple));
+    }
+};
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream, const std::tuple<Ts...> &value) {
+    stream << "{";
+    pretty_print_tuple<sizeof...(Ts) - 1>::print(stream, value);
+    stream << "}";
+
+    return true;
+}
+
+template <>
+inline bool pretty_print(std::ostream &stream, const std::tuple<> &) {
+    stream << "{}";
+
+    return true;
+}
+
+template <> inline bool pretty_print(std::ostream &stream, const time &) {
+    using namespace std::chrono;
+
+    const auto now = system_clock::now();
+    const auto us =
+        duration_cast<microseconds>(now.time_since_epoch()).count() % 1000000;
+    const auto hms = system_clock::to_time_t(now);
+    const std::tm *tm = std::localtime(&hms);
+    stream << "current time = " << std::put_time(tm, "%H:%M:%S") << '.'
+           << std::setw(6) << std::setfill('0') << us;
+
+    return false;
+}
+
+// Converts decimal integer to binary string
+template <typename T> std::string decimalToBinary(T n) {
+    const size_t length = 8 * sizeof(T);
+    std::string toRet;
+    toRet.resize(length);
+
+    for (size_t i = 0; i < length; ++i) {
+        const auto bit_at_index_i = static_cast<char>((n >> i) & 1);
+        toRet[length - 1 - i] = bit_at_index_i + '0';
+    }
+
+    return toRet;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream,
+                         const print_formatted<T> &value) {
+    if (value.inner < 0) {
+        stream << "-";
+    }
+    stream << value.prefix();
+
+    // Print using setbase
+    if (value.base != 2) {
+        stream << std::setw(sizeof(T)) << std::setfill('0')
+               << std::setbase(value.base) << std::uppercase;
+
+        if (value.inner >= 0) {
+            // The '+' sign makes sure that a uint_8 is printed as a number
+            stream << +value.inner;
+        } else {
+            using unsigned_type = typename std::make_unsigned<T>::type;
+            stream << +(static_cast<unsigned_type>(-(value.inner + 1)) + 1);
+        }
+    } else {
+        // Print for binary
+        if (value.inner >= 0) {
+            stream << decimalToBinary(value.inner);
+        } else {
+            using unsigned_type = typename std::make_unsigned<T>::type;
+            stream << decimalToBinary<unsigned_type>(
+                static_cast<unsigned_type>(-(value.inner + 1)) + 1);
+        }
+    }
+
+    return true;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_type<T> &) {
+    stream << type_name<T>();
+
+    stream << " [sizeof: " << sizeof(T) << " byte, ";
+
+    stream << "trivial: ";
+    if (std::is_trivial<T>::value) {
+        stream << "yes";
+    } else {
+        stream << "no";
+    }
+
+    stream << ", standard layout: ";
+    if (std::is_standard_layout<T>::value) {
+        stream << "yes";
+    } else {
+        stream << "no";
+    }
+    stream << "]";
+
+    return false;
+}
+
+template <typename Enum>
+inline typename std::enable_if<std::is_enum<Enum>::value, bool>::type
+pretty_print(std::ostream &stream, Enum const &value) {
+    using UnderlyingType = typename std::underlying_type<Enum>::type;
+    stream << static_cast<UnderlyingType>(value);
+
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const std::string &value) {
+    stream << '"' << value << '"';
+    return true;
+}
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+inline bool pretty_print(std::ostream &stream, const std::string_view &value) {
+    stream << '"' << std::string(value) << '"';
+    return true;
+}
+
+#endif
+
+template <typename T1, typename T2>
+inline bool pretty_print(std::ostream &stream, const std::pair<T1, T2> &value) {
+    stream << "{";
+    pretty_print(stream, value.first);
+    stream << ", ";
+    pretty_print(stream, value.second);
+    stream << "}";
+    return true;
+}
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const std::optional<T> &value) {
+    if (value) {
+        stream << '{';
+        pretty_print(stream, *value);
+        stream << '}';
+    } else {
+        stream << "nullopt";
+    }
+
+    return true;
+}
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream,
+                         const std::variant<Ts...> &value) {
+    stream << "{";
+    std::visit([&stream](auto &&arg) { pretty_print(stream, arg); }, value);
+    stream << "}";
+
+    return true;
+}
+
+#endif
+
+template <typename Container>
+inline typename std::enable_if<detail::is_container<const Container &>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const Container &value) {
+    stream << "{";
+    const size_t size = detail::size(value);
+    const size_t n = std::min(size_t{10}, size);
+    size_t i = 0;
+    using std::begin;
+    using std::end;
+    for (auto it = begin(value); it != end(value) && i < n; ++it, ++i) {
+        pretty_print(stream, *it);
+        if (i != n - 1) {
+            stream << ", ";
+        }
+    }
+
+    if (size > n) {
+        stream << ", ...";
+        stream << " size:" << size;
+    }
+
+    stream << "}";
+    return true;
+}
+
+template <typename T, typename... U> struct last {
+    using type = typename last<U...>::type;
+};
+
+template <typename T> struct last<T> { using type = T; };
+
+template <typename... T> using last_t = typename last<T...>::type;
+
+class DebugOutput {
+  public:
+    // Helper alias to avoid obscure type `const char* const*` in signature.
+    using expr_t = const char *;
+
+    DebugOutput(const char *filepath, int line, const char *function_name)
+        : m_use_colorized_output(isColorizedOutputEnabled()) {
+        std::string path = filepath;
+        const std::size_t path_length = path.length();
+        if (path_length > MAX_PATH_LENGTH) {
+            path = ".." +
+                   path.substr(path_length - MAX_PATH_LENGTH, MAX_PATH_LENGTH);
+        }
+        std::stringstream ss;
+        ss << ansi(ANSI_DEBUG) << "[" << path << ":" << line << " ("
+           << function_name << ")] " << ansi(ANSI_RESET);
+        m_location = ss.str();
+    }
+
+    template <typename... T>
+    auto print(std::initializer_list<expr_t> exprs,
+               std::initializer_list<std::string> types, T &&...values)
+        -> last_t<T...> {
+        if (exprs.size() != sizeof...(values)) {
+            std::cerr << m_location << ansi(ANSI_WARN)
+                      << "The number of arguments mismatch, please check "
+                         "unprotected comma"
+                      << ansi(ANSI_RESET) << std::endl;
+        }
+        return print_impl(exprs.begin(), types.begin(),
+                          std::forward<T>(values)...);
+    }
+
+    template <typename T> void print_err(T &&message) {
+        std::cerr << m_location << ansi(ANSI_WARN) << message
+                  << ansi(ANSI_RESET) << std::endl;
+    }
+
+    template <typename T>
+    T &&checked_print(std::initializer_list<expr_t> exprs,
+                      std::initializer_list<std::string> types, T &&value) {
+        if (!value) {
+            if (exprs.size() != 1) {
+                std::cerr << m_location << ansi(ANSI_WARN)
+                          << "The number of arguments mismatch, please check "
+                             "unprotected comma"
+                          << ansi(ANSI_RESET) << std::endl;
+            }
+            return print_impl(exprs.begin(), types.begin(),
+                              std::forward<T>(value));
+        } else {
+            return std::forward<T>(value);
+        }
+    }
+
+  private:
+    template <typename T>
+    T &&print_impl(const expr_t *expr, const std::string *type, T &&value) {
+        const T &ref = value;
+        std::stringstream stream_value;
+        const bool print_expr_and_type = pretty_print(stream_value, ref);
+
+        std::stringstream output;
+        output << m_location;
+        if (print_expr_and_type) {
+            output << ansi(ANSI_EXPRESSION) << *expr << ansi(ANSI_RESET)
+                   << " = ";
+        }
+        output << ansi(ANSI_VALUE) << stream_value.str() << ansi(ANSI_RESET);
+        if (print_expr_and_type) {
+            output << " (" << ansi(ANSI_TYPE) << *type << ansi(ANSI_RESET)
+                   << ")";
+        }
+        output << std::endl;
+        std::cerr << output.str();
+
+        return std::forward<T>(value);
+    }
+
+    template <typename T, typename... U>
+    auto print_impl(const expr_t *exprs, const std::string *types, T &&value,
+                    U &&...rest) -> last_t<T, U...> {
+        print_impl(exprs, types, std::forward<T>(value));
+        return print_impl(exprs + 1, types + 1, std::forward<U>(rest)...);
+    }
+
+    const char *ansi(const char *code) const {
+        if (m_use_colorized_output) {
+            return code;
+        } else {
+            return ANSI_EMPTY;
+        }
+    }
+
+    const bool m_use_colorized_output;
+
+    std::string m_location;
+
+    static constexpr std::size_t MAX_PATH_LENGTH = 20;
+
+    static constexpr const char *const ANSI_EMPTY = "";
+    static constexpr const char *const ANSI_DEBUG = "\x1b[02m";
+    static constexpr const char *const ANSI_WARN = "\x1b[33m";
+    static constexpr const char *const ANSI_EXPRESSION = "\x1b[36m";
+    static constexpr const char *const ANSI_VALUE = "\x1b[01m";
+    static constexpr const char *const ANSI_TYPE = "\x1b[32m";
+    static constexpr const char *const ANSI_RESET = "\x1b[0m";
+};
+
+// Identity function to suppress "-Wunused-value" warnings in DBG_MACRO_DISABLE
+// mode
+template <typename T> T &&identity(T &&t) { return std::forward<T>(t); }
+
+template <typename T, typename... U>
+auto identity(T &&, U &&...u) -> last_t<U...> {
+    return identity(std::forward<U>(u)...);
+}
+
+} // namespace dbg
+
+#ifndef DBG_MACRO_DISABLE
+
+// Force expanding argument with commas for MSVC, ref:
+// https://stackoverflow.com/questions/35210637/macro-expansion-argument-with-commas
+// Note that "args" should be a tuple with parentheses, such as "(e1, e2, ...)".
+#define DBG_IDENTITY(x) x
+#define DBG_CALL(fn, args) DBG_IDENTITY(fn args)
+
+#define DBG_CAT_IMPL(_1, _2) _1##_2
+#define DBG_CAT(_1, _2) DBG_CAT_IMPL(_1, _2)
+
+#define DBG_16TH_IMPL(_1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13,  \
+                      _14, _15, _16, ...)                                      \
+    _16
+#define DBG_16TH(args) DBG_CALL(DBG_16TH_IMPL, args)
+#define DBG_NARG(...)                                                          \
+    DBG_16TH(                                                                  \
+        (__VA_ARGS__, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0))
+
+// DBG_VARIADIC_CALL(fn, data, e1, e2, ...) => fn_N(data, (e1, e2, ...))
+#define DBG_VARIADIC_CALL(fn, data, ...)                                       \
+    DBG_CAT(fn##_, DBG_NARG(__VA_ARGS__))                                      \
+    (data, (__VA_ARGS__))
+
+// (e1, e2, e3, ...) => e1
+#define DBG_HEAD_IMPL(_1, ...) _1
+#define DBG_HEAD(args) DBG_CALL(DBG_HEAD_IMPL, args)
+
+// (e1, e2, e3, ...) => (e2, e3, ...)
+#define DBG_TAIL_IMPL(_1, ...) (__VA_ARGS__)
+#define DBG_TAIL(args) DBG_CALL(DBG_TAIL_IMPL, args)
+
+#define DBG_MAP_1(fn, args) DBG_CALL(fn, args)
+#define DBG_MAP_2(fn, args) fn(DBG_HEAD(args)), DBG_MAP_1(fn, DBG_TAIL(args))
+#define DBG_MAP_3(fn, args) fn(DBG_HEAD(args)), DBG_MAP_2(fn, DBG_TAIL(args))
+#define DBG_MAP_4(fn, args) fn(DBG_HEAD(args)), DBG_MAP_3(fn, DBG_TAIL(args))
+#define DBG_MAP_5(fn, args) fn(DBG_HEAD(args)), DBG_MAP_4(fn, DBG_TAIL(args))
+#define DBG_MAP_6(fn, args) fn(DBG_HEAD(args)), DBG_MAP_5(fn, DBG_TAIL(args))
+#define DBG_MAP_7(fn, args) fn(DBG_HEAD(args)), DBG_MAP_6(fn, DBG_TAIL(args))
+#define DBG_MAP_8(fn, args) fn(DBG_HEAD(args)), DBG_MAP_7(fn, DBG_TAIL(args))
+#define DBG_MAP_9(fn, args) fn(DBG_HEAD(args)), DBG_MAP_8(fn, DBG_TAIL(args))
+#define DBG_MAP_10(fn, args) fn(DBG_HEAD(args)), DBG_MAP_9(fn, DBG_TAIL(args))
+#define DBG_MAP_11(fn, args) fn(DBG_HEAD(args)), DBG_MAP_10(fn, DBG_TAIL(args))
+#define DBG_MAP_12(fn, args) fn(DBG_HEAD(args)), DBG_MAP_11(fn, DBG_TAIL(args))
+#define DBG_MAP_13(fn, args) fn(DBG_HEAD(args)), DBG_MAP_12(fn, DBG_TAIL(args))
+#define DBG_MAP_14(fn, args) fn(DBG_HEAD(args)), DBG_MAP_13(fn, DBG_TAIL(args))
+#define DBG_MAP_15(fn, args) fn(DBG_HEAD(args)), DBG_MAP_14(fn, DBG_TAIL(args))
+#define DBG_MAP_16(fn, args) fn(DBG_HEAD(args)), DBG_MAP_15(fn, DBG_TAIL(args))
+
+// DBG_MAP(fn, e1, e2, e3, ...) => fn(e1), fn(e2), fn(e3), ...
+#define DBG_MAP(fn, ...) DBG_VARIADIC_CALL(DBG_MAP, fn, __VA_ARGS__)
+
+#define DBG_STRINGIFY_IMPL(x) #x
+#define DBG_STRINGIFY(x) DBG_STRINGIFY_IMPL(x)
+
+#define DBG_TYPE_NAME(x) dbg::type_name<decltype(x)>()
+
+#define CHECK(x)                                                               \
+    dbg::DebugOutput(__FILE__, __LINE__, __func__)                             \
+        .checked_print({DBG_MAP(DBG_STRINGIFY, x)},                            \
+                       {DBG_MAP(DBG_TYPE_NAME, x)}, x)
+
+#define CHECK_WITH_ERR(x, e)                                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v) {                                                              \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print({DBG_MAP(DBG_STRINGIFY, x)},                            \
+                       {DBG_MAP(DBG_TYPE_NAME, x)}, v);                        \
+            return nncase::err(e);                                             \
+        }                                                                      \
+    }
+
+#define checked_dbg(x)                                                         \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok()) {                                                      \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+        }                                                                      \
+    }
+
+#define checked_try(x)                                                         \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok()) {                                                      \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define checked_try_var(name, x)                                               \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define checked_try_set(name, x)                                               \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define dbg(...)                                                               \
+    dbg::DebugOutput(__FILE__, __LINE__, __func__)                             \
+        .print({DBG_MAP(DBG_STRINGIFY, __VA_ARGS__)},                          \
+               {DBG_MAP(DBG_TYPE_NAME, __VA_ARGS__)}, __VA_ARGS__)
+
+#ifndef NDEBUG
+#define dbg_check(...)                                                         \
+    if (!(__VA_ARGS__)) {                                                      \
+        dbg::DebugOutput(__FILE__, __LINE__, __func__)                         \
+            .print({DBG_MAP(DBG_STRINGIFY, __VA_ARGS__)},                      \
+                   {DBG_MAP(DBG_TYPE_NAME, __VA_ARGS__)}, __VA_ARGS__);        \
+        nncase::fail_fast(#__VA_ARGS__);                                       \
+    }
+#else
+#define dbg_check(...)
+#endif
+
+#else
+#define dbg(...) dbg::identity(__VA_ARGS__)
+#endif // DBG_MACRO_DISABLE
+
+#endif // DBG_MACRO_DBG_H
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/debug.h b/third_party/nncase/riscv64/include/nncase/runtime/debug.h
new file mode 100644
index 0000000..461c029
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/debug.h
@@ -0,0 +1,30 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <string>
+
+namespace nncase {
+inline std::string to_string(typecode_t dt) {
+    switch (dt) {
+#define DEFINE_TYPECODE(id, name, value)                                       \
+    case dt_##id:                                                              \
+        return #name;
+#include <nncase/runtime/typecodes.def>
+#undef DEFINE_TYPECODE
+    default:
+        throw std::invalid_argument("invalid typecode.");
+    }
+}
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/dump_manager.h b/third_party/nncase/riscv64/include/nncase/runtime/dump_manager.h
new file mode 100644
index 0000000..e6caabf
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/dump_manager.h
@@ -0,0 +1,55 @@
+#pragma once
+#include <fstream>
+#include <iostream>
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/host_buffer.h>
+#include <nncase/runtime/stackvm/opcode.h>
+#include <nncase/tensor.h>
+#include <nncase/type.h>
+#include <nncase/value.h>
+#include <sstream>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class NNCASE_API dump_manager {
+
+  private:
+    bool append_;
+    int count_ = 1;
+    std::string current_op_;
+    std::string dump_root_;
+
+  public:
+    void set_current_op(const std::string &op) { current_op_ = op; }
+
+    std::string get_current_op() { return current_op_; }
+
+    std::string dump_path();
+
+    std::string get_dump_root() { return dump_root_; }
+
+    std::ofstream get_stream() { return get_stream(dump_path()); }
+
+    std::ofstream get_stream(const std::string &path);
+
+    int get_count() { return count_; }
+
+    void incr_count() {
+        count_++;
+        append_ = false;
+    }
+
+    void set_append(bool app) { append_ = app; }
+
+    void set_dump_root(std::string root);
+
+    void dump_op(nncase::runtime::stackvm::tensor_function_t tensor_funct);
+
+    void dump_op(const std::string &op);
+
+    void dump_output(nncase::value_t value);
+
+    void dump_input(nncase::value_t value, std::string name);
+};
+
+END_NS_NNCASE_RUNTIME
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/error.h b/third_party/nncase/riscv64/include/nncase/runtime/error.h
new file mode 100644
index 0000000..9d99869
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/error.h
@@ -0,0 +1,48 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <system_error>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+enum class nncase_errc {
+    invalid_model_indentifier = 0x01,
+    invalid_model_checksum = 0x02,
+    invalid_model_version = 0x03,
+    runtime_not_found = 0x04,
+    datatype_mismatch = 0x05,
+    shape_mismatch = 0x06,
+    invalid_memory_location = 0x07,
+    runtime_register_not_found = 0x08,
+    stackvm_illegal_instruction = 0x0100,
+    stackvm_illegal_target = 0x0101,
+    stackvm_stack_overflow = 0x0102,
+    stackvm_stack_underflow = 0x0103,
+    stackvm_unknow_custom_call = 0x0104,
+    stackvm_duplicate_custom_call = 0x0105,
+    nnil_illegal_instruction = 0x0200,
+};
+
+NNCASE_API const std::error_category &nncase_category() noexcept;
+NNCASE_API std::error_code make_error_code(nncase_errc code);
+NNCASE_API std::error_condition make_error_condition(nncase_errc code);
+
+END_NS_NNCASE_RUNTIME
+
+namespace std {
+template <>
+struct is_error_condition_enum<nncase::runtime::nncase_errc> : true_type {};
+} // namespace std
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/half.h b/third_party/nncase/riscv64/include/nncase/runtime/half.h
new file mode 100644
index 0000000..2a53417
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/half.h
@@ -0,0 +1,304 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cmath>
+#include <cstdint>
+#include <float.h>
+#include <functional>
+#include <limits>
+#include <nncase/compiler_defs.h>
+
+namespace nncase {
+struct fp16_from_raw_t {
+    explicit fp16_from_raw_t() = default;
+};
+
+NNCASE_INLINE_VAR constexpr fp16_from_raw_t fp16_from_raw{};
+
+struct half {
+  private:
+    union fp32 {
+        uint32_t u32;
+        float f32;
+
+        uint16_t u16() const noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<const uint16_t *>(&u32)[index];
+        }
+
+        uint16_t &u16() noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<uint16_t *>(&u32)[index];
+        }
+    };
+
+    static constexpr uint16_t ZERO_VALUE = 0;
+
+    // this is quiet NaN, sNaN only used for send signal
+    static constexpr uint16_t NAN_VALUE = 0x7e00;
+
+  public:
+    half() noexcept = default;
+
+    explicit half(float v) noexcept : value_(round_to_half(v).value_) {}
+
+    template <class T,
+              class = std::enable_if_t<std::is_integral<T>::value ||
+                                       std::is_floating_point<T>::value>>
+    explicit half(const T &val) noexcept : half(static_cast<float>(val)) {}
+
+    half(int &&val) noexcept : half(static_cast<float>(val)) {}
+
+    constexpr half(fp16_from_raw_t, uint16_t value) noexcept : value_(value) {}
+
+    operator float() const noexcept {
+        const fp32 magic = {113 << 23};
+        const unsigned int shifted_exp = 0x7c00
+                                         << 13; // exponent mask after shift
+        fp32 o;
+
+        o.u32 = (value_ & 0x7fff) << 13;        // exponent/mantissa bits
+        unsigned int exp = shifted_exp & o.u32; // just the exponent
+        o.u32 += (127 - 15) << 23;              // exponent adjust
+
+        // handle exponent special cases
+        if (exp == shifted_exp) {      // Inf/NaN?
+            o.u32 += (128 - 16) << 23; // extra exp adjust
+        } else if (exp == 0) {         // Zero/Denormal?
+            o.u32 += 1 << 23;          // extra exp adjust
+            o.f32 -= magic.f32;        // renormalize
+        }
+
+        o.u32 |= (value_ & 0x8000) << 16; // sign bit
+        return o.f32;
+    }
+
+    const uint16_t &raw() const noexcept { return value_; }
+    uint16_t &raw() noexcept { return value_; }
+
+    static constexpr half from_raw(uint16_t v) noexcept {
+        return half(nncase::fp16_from_raw, v);
+    }
+
+    static half round_to_half(float v) {
+        fp32 f;
+        f.f32 = v;
+        const fp32 f32infy = {255 << 23};
+        const fp32 f16max = {(127 + 16) << 23};
+        const fp32 denorm_magic = {((127 - 15) + (23 - 10) + 1) << 23};
+        unsigned int sign_mask = 0x80000000u;
+
+        unsigned int sign = f.u32 & sign_mask;
+        f.u32 ^= sign;
+
+        // NOTE all the integer compares in this function can be safely
+        // compiled into signed compares since all operands are below
+        // 0x80000000. Important if you want fast straight SSE2 code
+        // (since there's no unsigned PCMPGTD).
+        half o;
+        if (f.u32 >= f16max.u32) // result is Inf or NaN (all exponent bits set)
+        {
+            o.value_ = (f.u32 > f32infy.u32) ? 0x7e00
+                                             : 0x7c00; // NaN->qNaN and Inf->Inf
+        } else {
+            if (f.u32 < (113 << 23)) { // resulting FP16 is subnormal or zero
+                // use a magic value to align our 10 mantissa bits at the bottom
+                // of the float. as long as FP addition is round-to-nearest-even
+                // this just works.
+                f.f32 += denorm_magic.f32;
+
+                // and one integer subtract of the bias later, we have our final
+                // float!
+                o.value_ = static_cast<uint16_t>(f.u32 - denorm_magic.u32);
+            } else {
+                unsigned int mant_odd =
+                    (f.u32 >> 13) & 1; // resulting mantissa is odd
+
+                // update exponent, rounding bias part 1
+                // Equivalent to `f.u32 += ((unsigned int)(15 - 127) << 23) +
+                // 0xfff`, but without arithmetic overflow.
+                f.u32 += 0xc8000fffU;
+                // rounding bias part 2
+                f.u32 += mant_odd;
+                // take the bits!
+                o.value_ = static_cast<uint16_t>(f.u32 >> 13);
+            }
+        }
+        o.value_ |= static_cast<uint16_t>(sign >> 16);
+        return o;
+    }
+
+    static constexpr half epsilon() noexcept { return from_raw(0x0800); }
+
+    static constexpr half highest() noexcept { return from_raw(0x7bff); }
+
+    static constexpr half min() noexcept { return from_raw(0x0400); }
+
+    static constexpr half lowest() noexcept { return from_raw(0xfbff); }
+
+    static constexpr half quiet_NaN() noexcept { return from_raw(0x7e00); }
+
+    static constexpr half signaling_NaN() noexcept { return from_raw(0x7d00); }
+
+    static constexpr half infinity() noexcept { return from_raw(0x7c00); }
+
+    constexpr bool zero() const noexcept {
+        return (value_ & 0x7FFF) == ZERO_VALUE;
+    }
+
+    void operator=(const float &v) noexcept {
+        value_ = (round_to_half(v).value_);
+    }
+
+  private:
+    uint16_t value_;
+};
+
+#define DEFINE_FP16_BINARY_FP16RET(x)                                          \
+    inline half operator x(half a, half b) noexcept {                          \
+        return half::round_to_half(float(a) x float(b));                       \
+    }
+
+#define DEFINE_FP16_BINARY_BOOLRET(x)                                          \
+    inline bool operator x(half a, half b) noexcept {                          \
+        return float(a) x float(b);                                            \
+    }
+
+DEFINE_FP16_BINARY_FP16RET(+)
+DEFINE_FP16_BINARY_FP16RET(-)
+DEFINE_FP16_BINARY_FP16RET(*)
+DEFINE_FP16_BINARY_FP16RET(/)
+DEFINE_FP16_BINARY_BOOLRET(<)
+DEFINE_FP16_BINARY_BOOLRET(<=)
+DEFINE_FP16_BINARY_BOOLRET(>=)
+DEFINE_FP16_BINARY_BOOLRET(>)
+
+#define DEFINE_FP16_BINARY_SELF_MOD(x, op)                                     \
+    inline half &operator x(half &a, half b) noexcept {                        \
+        a = a op b;                                                            \
+        return a;                                                              \
+    }
+
+DEFINE_FP16_BINARY_SELF_MOD(+=, +)
+DEFINE_FP16_BINARY_SELF_MOD(-=, -)
+DEFINE_FP16_BINARY_SELF_MOD(*=, *)
+DEFINE_FP16_BINARY_SELF_MOD(/=, /)
+
+inline half operator-(half a) noexcept {
+    return half::round_to_half(-float(a));
+}
+
+inline bool operator==(const half &lhs, const half &rhs) noexcept {
+    return lhs.raw() == rhs.raw();
+}
+
+inline bool operator!=(const half &lhs, const half &rhs) noexcept {
+    return lhs.raw() != rhs.raw();
+}
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::half> {
+    size_t operator()(const nncase::half &v) const {
+        return hash<float>()(static_cast<float>(v));
+    }
+};
+
+template <> struct numeric_limits<nncase::half> {
+    static constexpr float_denorm_style has_denorm = std::denorm_present;
+    static constexpr bool has_infinity = true;
+    static constexpr bool has_quiet_NaN = true;
+    static constexpr bool has_signaling_NaN = true;
+    static constexpr bool is_bounded = false;
+    static constexpr bool is_iec559 = true;
+    static constexpr bool is_signed = true;
+    static constexpr bool is_specialized = true;
+    static constexpr float_round_style round_style = std::round_to_nearest;
+    static constexpr int radix = FLT_RADIX;
+
+    NNCASE_UNUSED static constexpr nncase::half(min)() noexcept {
+        return nncase::half::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half(max)() noexcept {
+        return nncase::half::highest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half lowest() noexcept {
+        return nncase::half::lowest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half epsilon() noexcept {
+        return nncase::half::epsilon();
+    }
+
+    NNCASE_UNUSED static nncase::half round_error() noexcept {
+        return nncase::half((double)0.5);
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half denorm_min() noexcept {
+        return nncase::half::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half infinity() noexcept {
+        return nncase::half::infinity();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half quiet_NaN() noexcept {
+        return nncase::half::quiet_NaN();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half signaling_NaN() noexcept {
+        return nncase::half::signaling_NaN();
+    }
+
+    static constexpr int digits = 11;
+    static const int min_exponent = -13;
+    static const int min_exponent10 = -4;
+    static const int max_exponent = 16;
+    static const int max_exponent10 = 4;
+};
+
+using nncase::half;
+inline bool isinf(const half &a) { return std::isinf(float(a)); }
+inline bool isnan(const half &a) { return std::isnan(float(a)); }
+inline bool isfinite(const half &a) { return std::isfinite(float(a)); }
+inline half abs(const half &a) { return half::round_to_half(fabsf(float(a))); }
+inline half exp(const half &a) { return half::round_to_half(expf(float(a))); }
+inline half log(const half &a) { return half::round_to_half(logf(float(a))); }
+inline half log10(const half &a) {
+    return half::round_to_half(log10f(float(a)));
+}
+inline half sqrt(const half &a) { return half::round_to_half(sqrtf(float(a))); }
+inline half pow(const half &a, const half &b) {
+    return half::round_to_half(powf(float(a), float(b)));
+}
+
+inline half sin(const half &a) { return half::round_to_half(sinf(float(a))); }
+inline half cos(const half &a) { return half::round_to_half(cosf(float(a))); }
+inline half tan(const half &a) { return half::round_to_half(tanf(float(a))); }
+inline half tanh(const half &a) { return half::round_to_half(tanhf(float(a))); }
+inline half floor(const half &a) {
+    return half::round_to_half(floorf(float(a)));
+}
+inline half ceil(const half &a) { return half::round_to_half(ceilf(float(a))); }
+inline half round(const half &a) {
+    return half::round_to_half(roundf(float(a)));
+}
+inline half nearbyint(const half &a) {
+    return half::round_to_half(nearbyintf(float(a)));
+}
+inline long lrint(const half &a) { return lrintf(float(a)); }
+} // namespace std
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/host_buffer.h b/third_party/nncase/riscv64/include/nncase/runtime/host_buffer.h
new file mode 100644
index 0000000..360ccbe
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/host_buffer.h
@@ -0,0 +1,108 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "buffer.h"
+#include <nncase/runtime/small_vector.hpp>
+#include <stack>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class host_buffer_node;
+using host_buffer_t = object_t<host_buffer_node>;
+
+class NNCASE_API mapped_buffer {
+  public:
+    mapped_buffer() noexcept;
+    mapped_buffer(host_buffer_t buffer, gsl::span<gsl::byte> span) noexcept;
+    mapped_buffer(mapped_buffer &&other) noexcept;
+    mapped_buffer(const mapped_buffer &) = delete;
+    ~mapped_buffer();
+
+    mapped_buffer &operator=(mapped_buffer &&) noexcept;
+    mapped_buffer &operator=(const mapped_buffer &) = delete;
+
+    result<void> unmap() noexcept;
+    void release() noexcept;
+
+    gsl::span<gsl::byte> buffer() const noexcept { return span_; }
+
+  private:
+    host_buffer_t buffer_;
+    gsl::span<gsl::byte> span_;
+};
+
+class NNCASE_API host_buffer_node : public buffer_node {
+    DEFINE_OBJECT_KIND(buffer_node, object_host_buffer);
+
+  public:
+    host_buffer_node(
+        size_t size_bytes, buffer_allocator &allocator,
+        host_sync_status_t host_sync_status = host_sync_status_t::valid);
+
+    host_sync_status_t host_sync_status() const noexcept {
+        return host_sync_status_;
+    }
+
+    void host_sync_status(host_sync_status_t status) noexcept {
+        host_sync_status_ = status;
+    }
+
+    result<mapped_buffer> map(map_access_t access) noexcept;
+    result<void> unmap() noexcept;
+    result<void> sync(sync_op_t op, bool force = false) noexcept;
+
+    virtual bool has_physical_address() const noexcept = 0;
+    virtual result<uintptr_t> physical_address() noexcept = 0;
+
+    result<void>
+    copy_to(buffer_t dest, size_t src_start, size_t dest_start,
+            datatype_t datatype, gsl::span<const size_t> shape,
+            gsl::span<const size_t> src_strides,
+            gsl::span<const size_t> dest_strides) noexcept override;
+
+  protected:
+    virtual result<gsl::span<gsl::byte>> map_core(map_access_t access) = 0;
+    virtual result<void> unmap_core(map_access_t access) = 0;
+    virtual result<void> sync_core(sync_op_t op) = 0;
+
+  private:
+    host_sync_status_t host_sync_status_;
+    std::stack<map_access_t, itlib::small_vector<map_access_t, 2>>
+        access_history_;
+};
+
+class NNCASE_API host_buffer_slice : public buffer_slice {
+  public:
+    host_buffer_slice() noexcept = default;
+    host_buffer_slice(host_buffer_t buffer) noexcept
+        : buffer_slice(std::move(buffer)) {}
+
+    host_buffer_slice(host_buffer_t buffer, size_t start,
+                      size_t length) noexcept
+        : buffer_slice(std::move(buffer), start, length) {}
+
+    const host_buffer_t &buffer() const noexcept {
+        return reinterpret_cast<const host_buffer_t &>(buffer_slice::buffer());
+    }
+
+    result<mapped_buffer> map(map_access_t access) noexcept;
+    result<void> unmap() noexcept;
+    result<void> sync(sync_op_t op, bool force = false) noexcept;
+
+    bool has_physical_address() const noexcept;
+    result<uintptr_t> physical_address() noexcept;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/incbin.h b/third_party/nncase/riscv64/include/nncase/runtime/incbin.h
new file mode 100644
index 0000000..bb2348b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/incbin.h
@@ -0,0 +1,369 @@
+/**
+ * @file incbin.h
+ * @author Dale Weiler
+ * @brief Utility for including binary files
+ *
+ * Facilities for including binary files into the current translation unit and
+ * making use from them externally in other translation units.
+ */
+// clang-format off
+#ifndef INCBIN_HDR
+#define INCBIN_HDR
+#include <limits.h>
+#if   defined(__AVX512BW__) || \
+      defined(__AVX512CD__) || \
+      defined(__AVX512DQ__) || \
+      defined(__AVX512ER__) || \
+      defined(__AVX512PF__) || \
+      defined(__AVX512VL__) || \
+      defined(__AVX512F__)
+# define INCBIN_ALIGNMENT_INDEX 6
+#elif defined(__AVX__)      || \
+      defined(__AVX2__)
+# define INCBIN_ALIGNMENT_INDEX 5
+#elif defined(__SSE__)      || \
+      defined(__SSE2__)     || \
+      defined(__SSE3__)     || \
+      defined(__SSSE3__)    || \
+      defined(__SSE4_1__)   || \
+      defined(__SSE4_2__)   || \
+      defined(__neon__)
+# define INCBIN_ALIGNMENT_INDEX 4
+#elif ULONG_MAX != 0xffffffffu
+# define INCBIN_ALIGNMENT_INDEX 3
+# else
+# define INCBIN_ALIGNMENT_INDEX 2
+#endif
+
+/* Lookup table of (1 << n) where `n' is `INCBIN_ALIGNMENT_INDEX' */
+#define INCBIN_ALIGN_SHIFT_0 1
+#define INCBIN_ALIGN_SHIFT_1 2
+#define INCBIN_ALIGN_SHIFT_2 4
+#define INCBIN_ALIGN_SHIFT_3 8
+#define INCBIN_ALIGN_SHIFT_4 16
+#define INCBIN_ALIGN_SHIFT_5 32
+#define INCBIN_ALIGN_SHIFT_6 64
+
+/* Actual alignment value */
+#define INCBIN_ALIGNMENT \
+    INCBIN_CONCATENATE( \
+        INCBIN_CONCATENATE(INCBIN_ALIGN_SHIFT, _), \
+        INCBIN_ALIGNMENT_INDEX)
+
+/* Stringize */
+#define INCBIN_STR(X) \
+    #X
+#define INCBIN_STRINGIZE(X) \
+    INCBIN_STR(X)
+/* Concatenate */
+#define INCBIN_CAT(X, Y) \
+    X ## Y
+#define INCBIN_CONCATENATE(X, Y) \
+    INCBIN_CAT(X, Y)
+/* Deferred macro expansion */
+#define INCBIN_EVAL(X) \
+    X
+#define INCBIN_INVOKE(N, ...) \
+    INCBIN_EVAL(N(__VA_ARGS__))
+
+/* Green Hills uses a different directive for including binary data */
+#if defined(__ghs__)
+#  if (__ghs_asm == 2)
+#    define INCBIN_MACRO ".file"
+/* Or consider the ".myrawdata" entry in the ld file */
+#  else
+#    define INCBIN_MACRO "\tINCBIN"
+#  endif
+#else
+#  define INCBIN_MACRO ".incbin"
+#endif
+
+#ifndef _MSC_VER
+#  define INCBIN_ALIGN \
+    __attribute__((aligned(INCBIN_ALIGNMENT)))
+#else
+#  define INCBIN_ALIGN __declspec(align(INCBIN_ALIGNMENT))
+#endif
+
+#if defined(__arm__) || /* GNU C and RealView */ \
+    defined(__arm) || /* Diab */ \
+    defined(_ARM) /* ImageCraft */
+#  define INCBIN_ARM
+#endif
+
+#ifdef __GNUC__
+/* Utilize .balign where supported */
+#  define INCBIN_ALIGN_HOST ".balign " INCBIN_STRINGIZE(INCBIN_ALIGNMENT) "\n"
+#  define INCBIN_ALIGN_BYTE ".balign 1\n"
+#elif defined(INCBIN_ARM)
+/*
+ * On arm assemblers, the alignment value is calculated as (1 << n) where `n' is
+ * the shift count. This is the value passed to `.align'
+ */
+#  define INCBIN_ALIGN_HOST ".align " INCBIN_STRINGIZE(INCBIN_ALIGNMENT_INDEX) "\n"
+#  define INCBIN_ALIGN_BYTE ".align 0\n"
+#else
+/* We assume other inline assembler's treat `.align' as `.balign' */
+#  define INCBIN_ALIGN_HOST ".align " INCBIN_STRINGIZE(INCBIN_ALIGNMENT) "\n"
+#  define INCBIN_ALIGN_BYTE ".align 1\n"
+#endif
+
+/* INCBIN_CONST is used by incbin.c generated files */
+#if defined(__cplusplus)
+#  define INCBIN_EXTERNAL extern "C"
+#  define INCBIN_CONST    extern const
+#else
+#  define INCBIN_EXTERNAL extern
+#  define INCBIN_CONST    const
+#endif
+
+/**
+ * @brief Optionally override the linker section into which data is emitted.
+ *
+ * @warning If you use this facility, you'll have to deal with platform-specific linker output
+ * section naming on your own
+ *
+ * Overriding the default linker output section, e.g for esp8266/Arduino:
+ * @code
+ * #define INCBIN_OUTPUT_SECTION ".irom.text"
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ * // Data is emitted into program memory that never gets copied to RAM
+ * @endcode
+ */
+#if !defined(INCBIN_OUTPUT_SECTION)
+#  if defined(__APPLE__)
+#    define INCBIN_OUTPUT_SECTION         ".const_data"
+#  else
+#    define INCBIN_OUTPUT_SECTION         ".rodata"
+#  endif
+#endif
+
+#if defined(__APPLE__)
+/* The directives are different for Apple branded compilers */
+#  define INCBIN_SECTION         INCBIN_OUTPUT_SECTION "\n"
+#  define INCBIN_GLOBAL(NAME)    ".globl " INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME "\n"
+#  define INCBIN_INT             ".long "
+#  define INCBIN_MANGLE          "_"
+#  define INCBIN_BYTE            ".byte "
+#  define INCBIN_TYPE(...)
+#else
+#  define INCBIN_SECTION         ".section " INCBIN_OUTPUT_SECTION "\n"
+#  define INCBIN_GLOBAL(NAME)    ".global " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME "\n"
+#  if defined(__ghs__)
+#    define INCBIN_INT           ".word "
+#  else
+#    define INCBIN_INT           ".int "
+#  endif
+#  if defined(__USER_LABEL_PREFIX__)
+#    define INCBIN_MANGLE        INCBIN_STRINGIZE(__USER_LABEL_PREFIX__)
+#  else
+#    define INCBIN_MANGLE        ""
+#  endif
+#  if defined(INCBIN_ARM)
+/* On arm assemblers, `@' is used as a line comment token */
+#    define INCBIN_TYPE(NAME)    ".type " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME ", %object\n"
+#  elif defined(__MINGW32__) || defined(__MINGW64__)
+/* Mingw doesn't support this directive either */
+#    define INCBIN_TYPE(NAME)
+#  else
+/* It's safe to use `@' on other architectures */
+#    define INCBIN_TYPE(NAME)    ".type " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME ", @object\n"
+#  endif
+#  define INCBIN_BYTE            ".byte "
+#endif
+
+/* List of style types used for symbol names */
+#define INCBIN_STYLE_CAMEL 0
+#define INCBIN_STYLE_SNAKE 1
+
+/**
+ * @brief Specify the prefix to use for symbol names.
+ *
+ * By default this is `g', producing symbols of the form:
+ * @code
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char gFooData[];
+ * // const unsigned char *const gFooEnd;
+ * // const unsigned int gFooSize;
+ * @endcode
+ *
+ * If however you specify a prefix before including: e.g:
+ * @code
+ * #define INCBIN_PREFIX incbin
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols instead:
+ * // const unsigned char incbinFooData[];
+ * // const unsigned char *const incbinFooEnd;
+ * // const unsigned int incbinFooSize;
+ * @endcode
+ */
+#if !defined(INCBIN_PREFIX)
+#  define INCBIN_PREFIX g
+#endif
+
+/**
+ * @brief Specify the style used for symbol names.
+ *
+ * Possible options are
+ * - INCBIN_STYLE_CAMEL "CamelCase"
+ * - INCBIN_STYLE_SNAKE "snake_case"
+ *
+ * Default option is *INCBIN_STYLE_CAMEL* producing symbols of the form:
+ * @code
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>FooData[];
+ * // const unsigned char *const <prefix>FooEnd;
+ * // const unsigned int <prefix>FooSize;
+ * @endcode
+ *
+ * If however you specify a style before including: e.g:
+ * @code
+ * #define INCBIN_STYLE INCBIN_STYLE_SNAKE
+ * #include "incbin.h"
+ * INCBIN(foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>foo_data[];
+ * // const unsigned char *const <prefix>foo_end;
+ * // const unsigned int <prefix>foo_size;
+ * @endcode
+ */
+#if !defined(INCBIN_STYLE)
+#  define INCBIN_STYLE INCBIN_STYLE_CAMEL
+#endif
+
+/* Style lookup tables */
+#define INCBIN_STYLE_0_DATA Data
+#define INCBIN_STYLE_0_END End
+#define INCBIN_STYLE_0_SIZE Size
+#define INCBIN_STYLE_1_DATA _data
+#define INCBIN_STYLE_1_END _end
+#define INCBIN_STYLE_1_SIZE _size
+
+/* Style lookup: returning identifier */
+#define INCBIN_STYLE_IDENT(TYPE) \
+    INCBIN_CONCATENATE( \
+        INCBIN_STYLE_, \
+        INCBIN_CONCATENATE( \
+            INCBIN_EVAL(INCBIN_STYLE), \
+            INCBIN_CONCATENATE(_, TYPE)))
+
+/* Style lookup: returning string literal */
+#define INCBIN_STYLE_STRING(TYPE) \
+    INCBIN_STRINGIZE( \
+        INCBIN_STYLE_IDENT(TYPE)) \
+
+/* Generate the global labels by indirectly invoking the macro with our style
+ * type and concatenating the name against them. */
+#define INCBIN_GLOBAL_LABELS(NAME, TYPE) \
+    INCBIN_INVOKE( \
+        INCBIN_GLOBAL, \
+        INCBIN_CONCATENATE( \
+            NAME, \
+            INCBIN_INVOKE( \
+                INCBIN_STYLE_IDENT, \
+                TYPE))) \
+    INCBIN_INVOKE( \
+        INCBIN_TYPE, \
+        INCBIN_CONCATENATE( \
+            NAME, \
+            INCBIN_INVOKE( \
+                INCBIN_STYLE_IDENT, \
+                TYPE)))
+
+/**
+ * @brief Externally reference binary data included in another translation unit.
+ *
+ * Produces three external symbols that reference the binary data included in
+ * another translation unit.
+ *
+ * The symbol names are a concatenation of `INCBIN_PREFIX' before *NAME*; with
+ * "Data", as well as "End" and "Size" after. An example is provided below.
+ *
+ * @param NAME The name given for the binary data
+ *
+ * @code
+ * INCBIN_EXTERN(Foo);
+ *
+ * // Now you have the following symbols:
+ * // extern const unsigned char <prefix>FooData[];
+ * // extern const unsigned char *const <prefix>FooEnd;
+ * // extern const unsigned int <prefix>FooSize;
+ * @endcode
+ */
+#define INCBIN_EXTERN(NAME) \
+    INCBIN_EXTERNAL const INCBIN_ALIGN unsigned char \
+        INCBIN_CONCATENATE( \
+            INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+            INCBIN_STYLE_IDENT(DATA))[]; \
+    INCBIN_EXTERNAL const INCBIN_ALIGN unsigned char *const \
+    INCBIN_CONCATENATE( \
+        INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+        INCBIN_STYLE_IDENT(END)); \
+    INCBIN_EXTERNAL const unsigned int \
+        INCBIN_CONCATENATE( \
+            INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+            INCBIN_STYLE_IDENT(SIZE))
+
+/**
+ * @brief Include a binary file into the current translation unit.
+ *
+ * Includes a binary file into the current translation unit, producing three symbols
+ * for objects that encode the data and size respectively.
+ *
+ * The symbol names are a concatenation of `INCBIN_PREFIX' before *NAME*; with
+ * "Data", as well as "End" and "Size" after. An example is provided below.
+ *
+ * @param NAME The name to associate with this binary data (as an identifier.)
+ * @param FILENAME The file to include (as a string literal.)
+ *
+ * @code
+ * INCBIN(Icon, "icon.png");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>IconData[];
+ * // const unsigned char *const <prefix>IconEnd;
+ * // const unsigned int <prefix>IconSize;
+ * @endcode
+ *
+ * @warning This must be used in global scope
+ * @warning The identifiers may be different if INCBIN_STYLE is not default
+ *
+ * To externally reference the data included by this in another translation unit
+ * please @see INCBIN_EXTERN.
+ */
+#ifdef _MSC_VER
+#define INCBIN(NAME, FILENAME) \
+    INCBIN_EXTERN(NAME)
+#else
+#define INCBIN(NAME, FILENAME) \
+    __asm__(INCBIN_SECTION \
+            INCBIN_GLOBAL_LABELS(NAME, DATA) \
+            INCBIN_ALIGN_HOST \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(DATA) ":\n" \
+            INCBIN_MACRO " \"" FILENAME "\"\n" \
+            INCBIN_GLOBAL_LABELS(NAME, END) \
+            INCBIN_ALIGN_BYTE \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(END) ":\n" \
+                INCBIN_BYTE "1\n" \
+            INCBIN_GLOBAL_LABELS(NAME, SIZE) \
+            INCBIN_ALIGN_HOST \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(SIZE) ":\n" \
+                INCBIN_INT INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(END) " - " \
+                           INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(DATA) "\n" \
+            INCBIN_ALIGN_HOST \
+            ".text\n" \
+    ); \
+    INCBIN_EXTERN(NAME)
+
+#endif
+#endif
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/interpreter.h b/third_party/nncase/riscv64/include/nncase/runtime/interpreter.h
new file mode 100644
index 0000000..a8f5814
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/interpreter.h
@@ -0,0 +1,120 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "allocator.h"
+#include "dump_manager.h"
+#include "model.h"
+#include "result.h"
+#include "runtime_module.h"
+#include "runtime_tensor.h"
+#include <gsl/gsl-lite.hpp>
+#include <istream>
+#include <memory>
+#include <nncase/shape.h>
+#include <nncase/tensor.h>
+#include <nncase/type.h>
+#include <unordered_map>
+#include <variant>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class NNCASE_API options_dict {
+  public:
+    template <class T> result<T> get_scalar_opt(const char *name) {
+        try_var(value, get<scalar>(name));
+        return value.template as<T>();
+    }
+
+    template <class T> result<T> get(const char *name) {
+        auto it = values_.find(name);
+        if (it != values_.end())
+            return ok(std::get<T>(it->second));
+        else
+            return err(std::errc::result_out_of_range);
+    }
+
+    template <class T> result<void> set(const char *name, T value) {
+        values_[name] = value;
+        return ok();
+    }
+
+  private:
+    std::unordered_map<const char *, std::variant<scalar, std::string>> values_;
+};
+
+struct tensor_desc {
+    typecode_t datatype;
+    size_t start;
+    size_t size;
+};
+
+class NNCASE_API interpreter {
+  public:
+    interpreter() noexcept;
+    interpreter(interpreter &) = delete;
+    interpreter(interpreter &&) = default;
+
+    [[nodiscard]] result<void> load_model(gsl::span<const gsl::byte> buffer,
+                                          bool copy_buffer = false) noexcept;
+
+    [[nodiscard]] result<void> load_model(std::istream &stream) noexcept;
+
+    options_dict &options() noexcept;
+    result<runtime_module *> find_module_by_id(size_t index) noexcept;
+    result<size_t> find_id_by_module(runtime_module *module) noexcept;
+
+    /* V1 APIs */
+
+    size_t inputs_size() const noexcept;
+    size_t outputs_size() const noexcept;
+    tensor_desc input_desc(size_t index) const noexcept;
+    tensor_desc output_desc(size_t index) const noexcept;
+    dims_t input_shape(size_t index) const noexcept;
+    dims_t output_shape(size_t index) const noexcept;
+    result<runtime_tensor> input_tensor(size_t index) noexcept;
+    result<void> input_tensor(size_t index, runtime_tensor tensor) noexcept;
+    result<runtime_tensor> output_tensor(size_t index) noexcept;
+    result<void> output_tensor(size_t index, runtime_tensor tensor) noexcept;
+
+    result<void> run() noexcept;
+
+    /* V2 APIs */
+
+    result<runtime_function *>
+    find_function_by_name(std::string_view name) noexcept;
+    result<runtime_function *> entry_function() noexcept;
+    std::shared_ptr<nncase::runtime::dump_manager> dump_manager() noexcept {
+        if (!dump_manager_) {
+            dump_manager_ = std::make_shared<nncase::runtime::dump_manager>();
+        }
+        return dump_manager_;
+    }
+
+  private:
+    tensor_type input_tensor_type(size_t index) const noexcept;
+    tensor_type output_tensor_type(size_t index) const noexcept;
+
+    result<void> initialize_model(const model_header &header) noexcept;
+
+  private:
+    std::shared_ptr<nncase::runtime::dump_manager> dump_manager_;
+    std::vector<std::unique_ptr<runtime_module>> modules_;
+    runtime_function *entry_function_;
+    options_dict options_;
+    std::vector<runtime_tensor> input_tensors_;
+    std::vector<runtime_tensor> output_tensors_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/compiler_defs.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/compiler_defs.h
new file mode 100644
index 0000000..eb9632b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/compiler_defs.h
@@ -0,0 +1,63 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/compiler_defs.h>
+
+#if defined(_MSC_VER)
+#ifdef NNCASE_MODULES_K230_DLL
+#define NNCASE_MODULES_K230_API __declspec(dllexport)
+#else
+#define NNCASE_MODULES_K230_API __declspec(dllimport)
+#endif
+#else
+#define NNCASE_MODULES_K230_API
+#endif
+
+#define BEGIN_NS_NNCASE_RT_K230 \
+    namespace nncase            \
+    {                           \
+    namespace runtime           \
+    {                           \
+        namespace k230          \
+        {
+#define END_NS_NNCASE_RT_K230 \
+    }                         \
+    }                         \
+    }
+
+#define BEGIN_NS_NNCASE_KERNELS_K230 \
+    namespace nncase                 \
+    {                                \
+    namespace kernels                \
+    {                                \
+        namespace k230               \
+        {
+#define END_NS_NNCASE_KERNELS_K230 \
+    }                              \
+    }                              \
+    }
+
+#define BEGIN_NS_NNCASE_FUNCTIONAL_K230 \
+    namespace nncase                    \
+    {                                   \
+    namespace functional                \
+    {                                   \
+        namespace k230                  \
+        {
+
+#define END_NS_NNCASE_FUNCTIONAL_K230 \
+    }                                 \
+    }                                 \
+    }
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/error.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/error.h
new file mode 100644
index 0000000..da1aa29
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/error.h
@@ -0,0 +1,37 @@
+/* Copyright 2019-2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <nncase/runtime/error.h>
+
+BEGIN_NS_NNCASE_RT_K230
+
+enum class nncase_k230_errc
+{
+    k230_illegal_instruction = 0x01
+};
+
+NNCASE_MODULES_K230_API const std::error_category &nncase_k230_category() noexcept;
+NNCASE_MODULES_K230_API std::error_condition make_error_condition(nncase_k230_errc code);
+
+END_NS_NNCASE_RT_K230
+
+namespace std
+{
+template <>
+struct is_error_condition_enum<nncase::runtime::k230::nncase_k230_errc> : true_type
+{
+};
+}
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/fp24.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/fp24.h
new file mode 100644
index 0000000..ce600c5
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/fp24.h
@@ -0,0 +1,412 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <bit>
+#include <cmath>
+#include <compare>
+#include <cstdint>
+#include <functional>
+#include <iostream>
+#include <limits>
+
+namespace nncase
+{
+struct fp24
+{
+    fp24()
+        : value(ZERO_VALUE) { }
+
+    static fp24 truncate_to_fp24(const float v)
+    {
+        fp24 output;
+        if (float_isnan(v))
+        {
+            output.value = NAN_VALUE;
+            return output;
+        }
+
+        FP32 f;
+        f.f = v;
+
+        const uint32_t *p = reinterpret_cast<const uint32_t *>(&f.u);
+        output.value = ((*p) >> 8);
+        return output;
+    }
+
+    explicit fp24(const float v)
+    {
+        value = round_to_fp24(v).value;
+    }
+
+    explicit fp24(const double val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit fp24(const unsigned short val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit fp24(const unsigned int val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit fp24(const int val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit fp24(const long val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit fp24(const long long val)
+        : fp24(static_cast<float>(val)) { }
+
+    template <class T>
+    explicit fp24(const T &val)
+        : fp24(static_cast<float>(val)) { }
+
+    explicit operator float() const
+    {
+        FP32 result;
+        result.f = 0;
+
+        uint32_t *q = reinterpret_cast<uint32_t *>(&result.u);
+
+        *q = value << 8;
+
+        return result.f;
+    }
+
+    explicit operator bool() const
+    {
+        return static_cast<bool>(float(*this));
+    }
+
+    explicit operator short() const
+    {
+        return static_cast<short>(float(*this));
+    }
+
+    explicit operator int() const
+    {
+        return static_cast<int>(float(*this));
+    }
+
+    explicit operator long() const
+    {
+        return static_cast<long>(float(*this));
+    }
+
+    explicit operator char() const
+    {
+        return static_cast<char>(float(*this));
+    }
+
+    explicit operator signed char() const
+    {
+        return static_cast<signed char>(float(*this));
+    }
+
+    explicit operator unsigned char() const
+    {
+        return static_cast<unsigned char>(float(*this));
+    }
+
+    explicit operator unsigned short() const
+    {
+        return static_cast<unsigned short>(float(*this));
+    }
+
+    explicit operator unsigned int() const
+    {
+        return static_cast<unsigned int>(float(*this));
+    }
+
+    explicit operator unsigned long() const
+    {
+        return static_cast<unsigned long>(float(*this));
+    }
+
+    explicit operator unsigned long long() const
+    {
+        return static_cast<unsigned long long>(float(*this));
+    }
+
+    explicit operator long long() const
+    {
+        return static_cast<long long>(float(*this));
+    }
+
+    explicit operator double() const
+    {
+        return static_cast<double>(float(*this));
+    }
+
+    union FP32
+    {
+        unsigned int u;
+        float f;
+    };
+
+    // Converts a float point to fp24, with round-nearest-to-even as rounding
+    // method.
+    static fp24 round_to_fp24(float v)
+    {
+        uint32_t input;
+        FP32 f;
+        f.f = v;
+        input = f.u;
+        fp24 output;
+
+        if (float_isnan(v))
+        {
+            // If the value is a NaN, squash it to a qNaN with msb of fraction set,
+            // this makes sure after truncation we don't end up with an inf.
+            //
+            // qNaN magic: All exponent bits set + most significant bit of fraction
+            // set.
+            output.value = 0x7fc000;
+        }
+        else
+        {
+            // Least significant bit of resulting bfloat.
+            uint32_t lsb = (input >> 8) & 1;
+            uint32_t rounding_bias = 0x7f + lsb;
+            input += rounding_bias;
+            output.value = static_cast<uint32_t>(input >> 8);
+        }
+
+        return output;
+    }
+
+    static fp24 epsilon()
+    {
+        fp24 x;
+        x.value = 0x3c0000; // 0x1.0p-7
+        return x;
+    }
+
+    static fp24 highest()
+    {
+        fp24 x;
+        x.value = 0x7F7FFF; // 0x1.FFFEp127
+        return x;
+    }
+
+    static fp24 lowest()
+    {
+        fp24 x;
+        x.value = 0xFF7FFF; // -0x1.FFFEp127
+        return x;
+    }
+
+    static fp24 min_positive_normal()
+    {
+        fp24 x;
+        x.value = 0x008000; // 0x1p-126
+        return x;
+    }
+
+    bool IsZero() const { return (value & 0x7FFFFF) == ZERO_VALUE; }
+
+    uint32_t value;
+
+    // A value that represents "not a number".
+    static const uint32_t NAN_VALUE = 0x7FC000;
+
+private:
+    // A value that represents "zero".
+    static const uint32_t ZERO_VALUE = 0;
+
+    static bool float_isnan(const float &x)
+    {
+        return std::isnan(x);
+    }
+};
+
+inline std::ostream &operator<<(std::ostream &os, const fp24 &dt)
+{
+    os << static_cast<float>(dt);
+    return os;
+}
+
+inline int32_t component(uint32_t v, uint8_t s)
+{
+    return (1 - 2 * s) * (int32_t)v;
+}
+
+inline fp24 operator+(fp24 a, fp24 b)
+{
+    return fp24(static_cast<float>(a) + static_cast<float>(b));
+    // return AddTwoFp24(a, b);
+    // return AddTwoFp24Simp(a, b);
+}
+inline fp24 operator+(fp24 a, int b)
+{
+    return fp24(static_cast<float>(a) + static_cast<float>(b));
+}
+inline fp24 operator+(int a, fp24 b)
+{
+    return fp24(static_cast<float>(a) + static_cast<float>(b));
+}
+
+inline fp24 operator-(fp24 a, fp24 b)
+{
+    return fp24(static_cast<float>(a) - static_cast<float>(b));
+}
+
+inline fp24 operator*(fp24 a, fp24 b)
+{
+    return fp24(static_cast<float>(a) * static_cast<float>(b));
+}
+
+inline fp24 operator/(fp24 a, fp24 b)
+{
+    return fp24(static_cast<float>(a) / static_cast<float>(b));
+}
+
+inline fp24 operator-(fp24 a)
+{
+    a.value ^= 0x800000;
+    return a;
+}
+
+inline bool operator<(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) < static_cast<float>(b);
+}
+
+inline bool operator<=(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) <= static_cast<float>(b);
+}
+
+inline bool operator==(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) == static_cast<float>(b);
+}
+
+inline bool operator!=(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) != static_cast<float>(b);
+}
+
+inline bool operator>(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) > static_cast<float>(b);
+}
+
+inline bool operator>=(fp24 a, fp24 b)
+{
+    return static_cast<float>(a) >= static_cast<float>(b);
+}
+
+inline fp24 &operator+=(fp24 &a, fp24 b)
+{
+    a = a + b;
+    return a;
+}
+
+inline fp24 &operator-=(fp24 &a, fp24 b)
+{
+    a = a - b;
+    return a;
+}
+
+inline fp24 operator++(fp24 &a)
+{
+    a += fp24(1);
+    return a;
+}
+
+inline fp24 operator--(fp24 &a)
+{
+    a -= fp24(1);
+    return a;
+}
+
+inline fp24 operator++(fp24 &a, int)
+{
+    fp24 original_value = a;
+    ++a;
+    return original_value;
+}
+
+inline fp24 operator--(fp24 &a, int)
+{
+    fp24 original_value = a;
+    --a;
+    return original_value;
+}
+
+inline fp24 &operator*=(fp24 &a, fp24 b)
+{
+    a = a * b;
+    return a;
+}
+
+inline fp24 &operator/=(fp24 &a, fp24 b)
+{
+    a = a / b;
+    return a;
+}
+} // namespace nncase
+
+namespace std
+{
+template <>
+struct hash<nncase::fp24>
+{
+    size_t operator()(const nncase::fp24 &v) const
+    {
+        return hash<float>()(static_cast<float>(v));
+    }
+};
+
+using nncase::fp24;
+inline bool isinf(const fp24 &a) { return std::isinf(float(a)); }
+inline bool isnan(const fp24 &a) { return std::isnan(float(a)); }
+inline bool isfinite(const fp24 &a) { return std::isfinite(float(a)); }
+inline fp24 abs(const fp24 &a) { return fp24(std::abs(float(a))); }
+inline fp24 exp(const fp24 &a) { return fp24(std::exp(float(a))); }
+inline fp24 log(const fp24 &a) { return fp24(std::log(float(a))); }
+inline fp24 log10(const fp24 &a)
+{
+    return fp24(std::log10(float(a)));
+}
+inline fp24 sqrt(const fp24 &a)
+{
+    return fp24(std::sqrt(float(a)));
+}
+inline fp24 pow(const fp24 &a, const fp24 &b)
+{
+    return fp24(std::pow(float(a), float(b)));
+}
+inline fp24 sin(const fp24 &a) { return fp24(std::sin(float(a))); }
+inline fp24 cos(const fp24 &a) { return fp24(std::cos(float(a))); }
+inline fp24 tan(const fp24 &a) { return fp24(std::tan(float(a))); }
+inline fp24 tanh(const fp24 &a)
+{
+    return fp24(std::tanh(float(a)));
+}
+inline fp24 floor(const fp24 &a)
+{
+    return fp24(std::floor(float(a)));
+}
+inline fp24 ceil(const fp24 &a)
+{
+    return fp24(std::ceil(float(a)));
+}
+inline fp24 round(const fp24 &a)
+{
+    // return fp24(std::round(float(a)));
+    return fp24(std::nearbyint(float(a)));
+}
+} // namespace std
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne.h
new file mode 100644
index 0000000..d8d45ef
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne.h
@@ -0,0 +1,328 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef _GNNE_H_
+#define _GNNE_H_
+
+#include <stdint.h>
+
+#undef L2_BASE_ADDR
+#define L2_BASE_ADDR 0x80000000
+
+#undef GNNE_BASE_ADDR
+#define GNNE_BASE_ADDR 0x80400000
+#define GNNE_ICACHE_CFG_OFFSET 0xf0
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+    typedef enum _gnne_status
+    {
+        GNNE_STATUS_IDLE,
+        GNNE_STATUS_RUNNING,
+        GNNE_STATUS_PENDING,
+        GNNE_STATUS_ERROR
+    } gnne_status_t;
+
+    typedef enum _gnne_reset_status
+    {
+        GNNE_RESET_STATUS_NORMAL,
+        GNNE_RESET_STATUS_FLUSHING_BUS_INTERFACE,
+        GNNE_RESET_STATUS_INITIALIZING_SUB_MODULE,
+        GNNE_RESET_STATUS_TURNING_ON_CLK
+    } gnne_reset_status_t;
+
+    typedef enum _gnne_exception
+    {
+        GNNE_EXCEPTION_OK,
+        GNNE_EXCEPTION_ILLEGAL_INSTRUCTION,
+        GNNE_EXCEPTION_CCR_ERROR,
+        GNNE_EXCEPTION_TIME_OUT_ERROR
+    } gnne_exception_t;
+
+    typedef enum
+#ifdef __cplusplus
+        : uint64_t
+#endif
+    {
+        GNNE_CTRL_ENABLE_SET = (0x0001ULL << 32) | (0x0001),
+        GNNE_CTRL_ENABLE_CLEAR = (0x0001ULL << 32) | (0x0000),
+        GNNE_CTRL_CPU_INTR_CLEAR = (0x0001ULL << 34) | (0x0001ULL << 2),
+        GNNE_CTRL_DEBUG_MODE_SET = (0x0001ULL << 35) | (0x0001ULL << 3),
+        GNNE_CTRL_CG_OFF_SET = (0x0001ULL << 36) | (0x0001ULL << 4),
+        GNNE_CTRL_CG_OFF_CLEAR = (0x0001ULL << 36) | (0x0000),
+        GNNE_CTRL_CPU_RESUME_MODE_0 = (0x0001ULL << 39) | (0x0001ULL << 38) | (0x0001ULL << 37) | (0x0001ULL << 5),
+        GNNE_CTRL_CPU_RESUME_MODE_1 = (0x0001ULL << 39) | (0x0001ULL << 38) | (0x0001ULL << 37) | (0x0001ULL << 6) | (0x0001ULL << 5),
+        GNNE_CTRL_CPU_RESUME_MODE_2 = (0x0001ULL << 39) | (0x0001ULL << 38) | (0x0001ULL << 37) | (0x0001ULL << 7) | (0x0001ULL << 5),
+        GNNE_CTRL_CPU_RESUME_MODE_3 = (0x0001ULL << 39) | (0x0001ULL << 38) | (0x0001ULL << 37) | (0x0001ULL << 7) | (0x0001ULL << 6) | (0x0001ULL << 5)
+    } gnne_ctrl_function_t;
+
+    typedef union
+    {
+        struct icache
+        {
+            uint64_t gb_pre_pc_byte_len : 32;
+            uint64_t gb_pos_pc_byte_len : 32;
+            uint64_t gb_fet_len_when_miss : 32;
+            uint64_t gb_fet_len_when_pre : 32;
+        } bits;
+        uint64_t data[2];
+    } gnne_icache_cfg;
+
+    typedef union
+    {
+        struct gnne_pc
+        {
+            uint64_t start_pc_addr_reg : 32;
+            uint64_t end_pc_addr_reg : 32;
+            uint64_t breakpoint_pc_addr_reg : 32;
+            uint64_t reserved : 32;
+        } bits;
+        uint64_t data[2];
+    } gnne_pc_cfg;
+
+    typedef union
+    {
+        struct ctrl
+        {
+            uint64_t reserved0 : 64;
+            uint64_t gnne_enable : 1;
+            uint64_t reserved1 : 1;
+            uint64_t cpu_intr_clr : 1;
+            uint64_t debug_mode_en : 1;
+            uint64_t gnne_cg_off : 1;
+            uint64_t gb_cpu_resume_en : 1;
+            uint64_t cpu_resume_mode : 2;
+            uint64_t reserved2 : 24;
+            uint64_t gnne_enable_wmask : 1;
+            uint64_t reserved3 : 1;
+            uint64_t cpu_intr_clr_wmask : 1;
+            uint64_t debug_mode_en_wmask : 1;
+            uint64_t gnne_cg_off_wmask : 1;
+            uint64_t cpu_resume_wmask : 1;
+            uint64_t cpu_resume_mode_wmask : 2;
+            uint64_t reserved4 : 24;
+        } bits;
+        uint64_t data[2];
+    } gnne_ctrl;
+
+    typedef union
+    {
+        struct status
+        {
+            uint64_t load_que_satus : 1;
+            uint64_t store_que_status : 1;
+            uint64_t dm_que_status : 1;
+            uint64_t pu_que_status : 1;
+            uint64_t mfu_que_status : 1;
+            uint64_t load_module_status : 1;
+            uint64_t store_module_status : 1;
+            uint64_t dm_module_status : 1;
+            uint64_t pu_module_status : 1;
+            uint64_t mfu_module_status : 1;
+            uint64_t version : 4;
+            uint64_t kpu_work_status : 2;
+            uint64_t noc_rx_status : 1;
+            uint64_t noc_tx_status : 1;
+            uint64_t reserved0 : 1;
+            uint64_t store_biu_status : 1;
+            uint64_t load_biu_status : 1;
+            uint64_t all_biu_status : 1;
+            uint64_t exception_status : 2;
+            uint64_t reset_status : 2;
+            uint64_t axi_bresp_error : 1;
+            uint64_t ai2d_que_no_empty : 1;
+            uint64_t ai2d_busy : 1;
+            uint64_t reserved1 : 2;
+            uint64_t intr_status : 1;
+            uint64_t intr_num : 32;
+            uint64_t dm_w_status : 1;
+            uint64_t dm_if_status : 1;
+            uint64_t dm_psum_status : 1;
+            uint64_t dm_act_status : 1;
+            uint64_t pu_pe_status : 1;
+            uint64_t pu_dw_status : 1;
+            uint64_t pu_act0_status : 1;
+            uint64_t pu_act1_status : 1;
+            uint64_t reserved2 : 56;
+        } bits;
+        uint64_t data[2];
+    } gnne_status;
+
+    typedef union
+    {
+        struct dec_ld_st_mfu_pc
+        {
+            uint64_t dec_pc : 32;
+            uint64_t load_pc : 32;
+            uint64_t store_pc : 32;
+            uint64_t mfu_pc : 32;
+        } bits;
+        uint64_t data[2];
+    } gnne_dec_ld_st_mfu_pc;
+
+    typedef union
+    {
+        struct pu_pc_
+        {
+            uint64_t pu_pc : 32;
+            uint64_t dw_pc : 32;
+            uint64_t act0_pc : 32;
+            uint64_t act1_pc : 32;
+        } bits;
+        uint64_t data[2];
+    } gnne_pu_pc;
+
+    typedef union
+    {
+        struct dm_pc
+        {
+            uint64_t dm_w_pc : 32;
+            uint64_t dm_if_pc : 32;
+            uint64_t dm_psum_pc : 32;
+            uint64_t dm_act_pc : 32;
+        } bits;
+        uint64_t data[2];
+    } gnne_dm_pc;
+    typedef union
+    {
+        struct ccr_status
+        {
+            uint64_t ccr0 : 4;
+            uint64_t ccr1 : 4;
+            uint64_t ccr2 : 4;
+            uint64_t ccr3 : 4;
+            uint64_t ccr4 : 4;
+            uint64_t ccr5 : 4;
+            uint64_t ccr6 : 4;
+            uint64_t ccr7 : 4;
+            uint64_t ccr8 : 4;
+            uint64_t ccr9 : 4;
+            uint64_t ccr10 : 4;
+            uint64_t ccr11 : 4;
+            uint64_t ccr12 : 4;
+            uint64_t ccr13 : 4;
+            uint64_t ccr14 : 4;
+            uint64_t ccr15 : 4;
+            uint64_t ccr16 : 4;
+            uint64_t ccr17 : 4;
+            uint64_t ccr18 : 4;
+            uint64_t ccr19 : 4;
+            uint64_t ccr20 : 4;
+            uint64_t ccr21 : 4;
+            uint64_t ccr22 : 4;
+            uint64_t ccr23 : 4;
+            uint64_t ccr24 : 4;
+            uint64_t ccr25 : 4;
+            uint64_t ccr26 : 4;
+            uint64_t ccr27 : 4;
+            uint64_t ccr28 : 4;
+            uint64_t ccr29 : 4;
+            uint64_t ccr30 : 4;
+            uint64_t ccr31 : 4;
+        } bits;
+        uint64_t data[2];
+    } gnne_ccr_status;
+
+    typedef union
+    {
+        struct ai2d_pc
+        {
+            uint64_t ai2d_pc_addr : 32;
+            uint64_t reserved0 : 32;
+            uint64_t reserved1 : 64;
+        } bits;
+        uint64_t data[2];
+    } gnne_ai2d_pc;
+
+    typedef union
+    {
+        struct time_out
+        {
+            uint64_t time_out_value : 32;
+            uint64_t reserved0 : 32;
+            uint64_t reserved1 : 64;
+        } bits;
+        uint64_t data[2];
+    } gnne_time_out;
+
+    typedef union
+    {
+        struct clk_gate
+        {
+            uint64_t gb_disable_dm_act_cg : 1;
+            uint64_t gb_disable_dm_w_cg : 1;
+            uint64_t gb_disable_dm_of_cg : 1;
+            uint64_t gb_disable_dm_if_cg : 1;
+            uint64_t gb_disable_act_cg : 1;
+            uint64_t gb_disable_dw_cg : 1;
+            uint64_t reserved0 : 58;
+            uint64_t reserved1 : 64;
+        } bits;
+        uint64_t data[2];
+    } gnne_clk_gate_switch;
+
+    typedef struct _gnne_reg_file
+    {
+        gnne_icache_cfg icache_cfg;
+        gnne_pc_cfg pc_cfg;
+        uint64_t reserved0[2];
+        gnne_ctrl ctrl;
+        gnne_status status;
+        gnne_dec_ld_st_mfu_pc dec_ld_st_mfu_pc;
+        gnne_pu_pc pu_pc;
+        gnne_dm_pc dm_pc;
+        gnne_ccr_status ccr_status;
+        gnne_ai2d_pc ai2d_pc;
+        gnne_time_out time_out;
+        uint64_t reserved1[12];
+        gnne_clk_gate_switch clk_gate_switch;
+    } gnne_reg_file_t;
+
+#if !defined(__linux__)
+    void flush_cache();
+    void clean_cache();
+    void invalidate_cache();
+#endif
+    void gnne_set_base(volatile void *addr);
+    int gnne_enable(uint64_t pc_start, uint64_t pc_end, uint64_t pc_breakpoint);
+    void gnne_init();
+    void gnne_disable();
+    void gnne_clear_cpu_intr();
+    int gnne_resume(gnne_ctrl_function_t resume_mode, uint64_t pc_start);
+    gnne_status gnne_get_status();
+    void gnne_dump_status();
+    void gnne_dump_pc();
+    void gnne_dump_ccr();
+    uint64_t gnne_get_pc();
+    gnne_ctrl gnne_get_ctrl();
+    gnne_dec_ld_st_mfu_pc gnne_get_dec_ld_st_mfu_pc();
+    gnne_pu_pc gnne_get_pu_pc();
+    gnne_dm_pc gnne_get_dm_pc();
+    gnne_ccr_status gnne_get_ccr_status();
+
+    uint32_t gnne_get_time_out();
+    void gnne_set_time_out(uint32_t val);
+
+    // ai2d
+    uint32_t gnne_get_ai2d_pc();
+    void gnne_set_ai2d_pc(uint32_t val);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_il.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_il.h
new file mode 100644
index 0000000..994550f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_il.h
@@ -0,0 +1,711 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <cstdint>
+#include <iterator>
+#include <tuple>
+
+namespace nncase::runtime::k230::dsp
+{
+enum datatype_t
+{
+    DT_INT8 = 0x00,
+    DT_INT32 = 0x01,
+    DT_UINT8 = 0x02,
+    DT_UINT32 = 0x03,
+    DT_BF16 = 0x04,
+    DT_FP32 = 0x05
+};
+
+template <datatype_t>
+struct value_type;
+
+template <>
+struct value_type<DT_INT8>
+{
+    using type = int8_t;
+};
+template <>
+struct value_type<DT_INT32>
+{
+    using type = int32_t;
+};
+template <>
+struct value_type<DT_UINT8>
+{
+    using type = uint8_t;
+};
+template <>
+struct value_type<DT_UINT32>
+{
+    using type = uint32_t;
+};
+template <>
+struct value_type<DT_BF16>
+{
+    using type = bfloat16;
+};
+template <>
+struct value_type<DT_FP32>
+{
+    using type = float;
+};
+
+template <datatype_t Type>
+using value_type_t = typename value_type<Type>::type;
+
+inline size_t get_bytes(datatype_t type) noexcept
+{
+    switch (type)
+    {
+    case DT_INT8:
+    case DT_UINT8:
+        return 1;
+    case DT_BF16:
+        return 2;
+    case DT_INT32:
+    case DT_UINT32:
+    case DT_FP32:
+        return 4;
+    default:
+        return 0;
+    }
+}
+struct scalar_t
+{
+    datatype_t type;
+    std::array<uint8_t, 4> storage;
+
+    scalar_t() = default;
+
+    scalar_t(int8_t value) noexcept
+    {
+        type = DT_INT8;
+        as<int8_t>() = value;
+    }
+
+    scalar_t(uint8_t value) noexcept
+    {
+        type = DT_UINT8;
+        as<uint8_t>() = value;
+    }
+
+    scalar_t(float value) noexcept
+    {
+        type = DT_FP32;
+        as<float>() = value;
+    }
+
+    template <class T>
+    T &as() noexcept { return *reinterpret_cast<T *>(storage.data()); }
+
+    template <class T>
+    const T &as() const noexcept { return *reinterpret_cast<const T *>(storage.data()); }
+};
+
+struct runtime_index_t
+{
+    uint32_t n;
+    uint32_t c;
+    uint32_t h;
+    uint32_t w;
+
+    uint32_t &operator[](size_t i) noexcept
+    {
+        switch (i)
+        {
+        case 0:
+            return n;
+        case 1:
+            return c;
+        case 2:
+            return h;
+        case 3:
+            return w;
+        default:
+            assert(!"Invalid index");
+            return w;
+        }
+    }
+};
+
+struct runtime_stride_t
+{
+    uint32_t c_stride;
+    uint32_t h_stride;
+    uint32_t w_stride;
+};
+
+struct runtime_shape_t
+{
+    uint32_t n : 32;
+    uint32_t c : 32;
+    uint32_t h : 32;
+    uint32_t w : 32;
+
+    uint32_t c_stride : 32;
+    uint32_t h_stride : 32;
+    uint32_t w_stride : 32;
+
+    runtime_stride_t stride() const noexcept
+    {
+        return { c_stride, h_stride, w_stride };
+    }
+
+    constexpr uint32_t get(size_t i) const noexcept
+    {
+        switch (i)
+        {
+        case 0:
+            return n;
+        case 1:
+            return c;
+        case 2:
+            return h;
+        case 3:
+            return w;
+        default:
+            return 1;
+        }
+    }
+
+    constexpr void set(size_t i, uint32_t value) noexcept
+    {
+        switch (i)
+        {
+        case 0:
+            n = value;
+            break;
+        case 1:
+            c = value;
+            break;
+        case 2:
+            h = value;
+            break;
+        case 3:
+            w = value;
+            break;
+        default:
+            break;
+        }
+    }
+};
+
+struct padding_config_dim_t
+{
+    int32_t low : 32;
+    int32_t high : 32;
+    int32_t interior : 32;
+};
+
+struct slice_config_dim_t
+{
+    uint32_t start : 32;
+    uint32_t end : 32;
+    int32_t stride : 32;
+};
+
+struct perm_t
+{
+    uint8_t d0 : 2;
+    uint8_t d1 : 2;
+    uint8_t d2 : 2;
+    uint8_t d3 : 2;
+};
+
+enum DSP_OPCODE
+{
+#define DEFINE_OPCODE(name, value, unused1) name = value,
+#include "gnne_dsp_opcode.def"
+#undef DEFINE_OPCODE
+};
+
+#pragma pack(push, 1)
+
+struct nop
+{
+    uint8_t opcode = DSP_OPCODE::NOP;
+};
+
+struct ldc_i4
+{
+    uint8_t opcode = DSP_OPCODE::LDC_I4;
+    int32_t value;
+
+    ldc_i4(int32_t value)
+        : value(value) { }
+};
+
+struct ldc_r4
+{
+    uint8_t opcode = DSP_OPCODE::LDC_R4;
+    float value;
+
+    ldc_r4(float value)
+        : value(value) { }
+};
+
+struct ldind_i1
+{
+    uint8_t opcode = DSP_OPCODE::LDIND_I1;
+    int32_t address;
+
+    ldind_i1(int32_t address)
+        : address(address) { }
+};
+
+struct ldind_i4
+{
+    uint8_t opcode = DSP_OPCODE::LDIND_I4;
+    int32_t address;
+
+    ldind_i4(int32_t address)
+        : address(address) { }
+};
+
+struct ldind_u1
+{
+    uint8_t opcode = DSP_OPCODE::LDIND_U1;
+    int32_t address;
+
+    ldind_u1(int32_t address)
+        : address(address) { }
+};
+
+struct ldind_br2
+{
+    uint8_t opcode = DSP_OPCODE::LDIND_BR2;
+    int32_t address;
+
+    ldind_br2(int32_t address)
+        : address(address) { }
+};
+
+struct ldind_r4
+{
+    uint8_t opcode = DSP_OPCODE::LDIND_R4;
+    int32_t address;
+
+    ldind_r4(int32_t address)
+        : address(address) { }
+};
+
+struct stind_i1
+{
+    uint8_t opcode = DSP_OPCODE::STIND_I1;
+    int32_t address;
+
+    stind_i1(int32_t address)
+        : address(address) { }
+};
+
+struct stind_i4
+{
+    uint8_t opcode = DSP_OPCODE::STIND_I4;
+    int32_t address;
+
+    stind_i4(int32_t address)
+        : address(address) { }
+};
+
+struct stind_br2
+{
+    uint8_t opcode = DSP_OPCODE::STIND_BR2;
+    int32_t address;
+
+    stind_br2(int32_t address)
+        : address(address) { }
+};
+
+struct stind_r4
+{
+    uint8_t opcode = DSP_OPCODE::STIND_R4;
+    int32_t address;
+
+    stind_r4(int32_t address)
+        : address(address) { }
+};
+
+struct lda_s
+{
+    uint8_t opcode = DSP_OPCODE::LDA_S;
+    int32_t reg : 8;
+    int32_t offset : 24;
+
+    lda_s(uint8_t reg, int32_t address)
+        : reg(reg), offset(address) { }
+};
+
+struct dup
+{
+    uint8_t opcode = DSP_OPCODE::DUP;
+};
+
+struct pop
+{
+    uint8_t opcode = DSP_OPCODE::POP;
+};
+
+struct ldarg
+{
+    uint8_t opcode = DSP_OPCODE::LDARG;
+    uint8_t index;
+    ldarg(uint8_t index)
+        : index(index) { }
+};
+
+struct ldarga
+{
+    uint8_t opcode = DSP_OPCODE::LDARGA;
+    uint8_t index;
+    uint8_t type;
+    ldarga(uint8_t index, datatype_t type)
+        : index(index), type(type) { }
+};
+
+struct str_i4
+{
+    uint8_t opcode = DSP_OPCODE::STR_I4;
+    uint8_t reg;
+
+    str_i4(uint8_t reg)
+        : reg(reg) { }
+};
+
+struct neg_
+{
+    uint8_t opcode = DSP_OPCODE::NEG;
+};
+
+struct not_
+{
+    uint8_t opcode = DSP_OPCODE::NOT;
+};
+
+struct add_
+{
+    uint8_t opcode = DSP_OPCODE::ADD;
+};
+
+struct sub_
+{
+    uint8_t opcode = DSP_OPCODE::SUB;
+};
+
+struct mul_
+{
+    uint8_t opcode = DSP_OPCODE::MUL;
+};
+
+struct div_
+{
+    uint8_t opcode = DSP_OPCODE::DIV;
+};
+
+struct div_u
+{
+    uint8_t opcode = DSP_OPCODE::DIV_U;
+};
+
+struct rem_
+{
+    uint8_t opcode = DSP_OPCODE::REM;
+};
+
+struct rem_u
+{
+    uint8_t opcode = DSP_OPCODE::REM_U;
+};
+
+struct clt
+{
+    uint8_t opcode = DSP_OPCODE::CLT;
+};
+
+struct clt_u
+{
+    uint8_t opcode = DSP_OPCODE::CLT_U;
+};
+
+struct cle
+{
+    uint8_t opcode = DSP_OPCODE::CLE;
+};
+
+struct cle_u
+{
+    uint8_t opcode = DSP_OPCODE::CLE_U;
+};
+
+struct ceq
+{
+    uint8_t opcode = DSP_OPCODE::CEQ;
+};
+
+struct cge
+{
+    uint8_t opcode = DSP_OPCODE::CGE;
+};
+
+struct cge_u
+{
+    uint8_t opcode = DSP_OPCODE::CGE_U;
+};
+
+struct cgt
+{
+    uint8_t opcode = DSP_OPCODE::CGT;
+};
+
+struct cgt_u
+{
+    uint8_t opcode = DSP_OPCODE::CGT_U;
+};
+
+struct cne
+{
+    uint8_t opcode = DSP_OPCODE::CNE;
+};
+
+struct conv_i1
+{
+    uint8_t opcode = DSP_OPCODE::CONV_I1;
+};
+
+struct conv_i4
+{
+    uint8_t opcode = DSP_OPCODE::CONV_I4;
+};
+
+struct conv_u1
+{
+    uint8_t opcode = DSP_OPCODE::CONV_U1;
+};
+
+struct conv_u4
+{
+    uint8_t opcode = DSP_OPCODE::CONV_U4;
+};
+
+struct conv_br2
+{
+    uint8_t opcode = DSP_OPCODE::CONV_BR2;
+};
+
+struct conv_r4
+{
+    uint8_t opcode = DSP_OPCODE::CONV_R4;
+};
+
+struct br
+{
+    int32_t opcode : 8;
+    int32_t offset : 24;
+    br()
+        : opcode((int8_t)DSP_OPCODE::BR) { }
+};
+
+struct br_true
+{
+    int32_t opcode : 8;
+    int32_t offset : 24;
+    br_true()
+        : opcode((int8_t)DSP_OPCODE::BR_TRUE) { }
+};
+
+struct br_false
+{
+    int32_t opcode : 8;
+    int32_t offset : 24;
+    br_false()
+        : opcode((int8_t)DSP_OPCODE::BR_FALSE) { }
+};
+
+struct ret
+{
+    uint8_t opcode = DSP_OPCODE::RET;
+};
+
+struct call
+{
+    int32_t opcode : 8;
+    int32_t offset : 24;
+    int32_t args_count : 8;
+    call()
+        : opcode((int8_t)DSP_OPCODE::CALL) { }
+};
+
+struct throw_
+{
+    uint8_t opcode = DSP_OPCODE::THROW;
+};
+
+struct pad_t
+{
+    uint8_t opcode = DSP_OPCODE::PAD_T;
+    uint8_t type;
+    scalar_t pad_value;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+    padding_config_dim_t dim0;
+    padding_config_dim_t dim1;
+    padding_config_dim_t dim2;
+    padding_config_dim_t dim3;
+
+    pad_t(datatype_t type, scalar_t value, runtime_shape_t src_shape, runtime_shape_t dest_shape,
+        padding_config_dim_t dim0, padding_config_dim_t dim1,
+        padding_config_dim_t dim2, padding_config_dim_t dim3)
+        : type(type), pad_value(value), src_shape(src_shape), dest_shape(dest_shape), dim0(dim0), dim1(dim1), dim2(dim2), dim3(dim3) { }
+};
+
+struct sort_asc_t
+{
+    uint8_t opcode = DSP_OPCODE::SORT_ASC_T;
+    uint8_t type;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+    uint8_t dim;
+
+    sort_asc_t(datatype_t type, runtime_shape_t src_shape,
+        runtime_shape_t dest_shape, uint8_t dim)
+        : type(type), src_shape(src_shape), dest_shape(dest_shape), dim(dim) { }
+};
+
+struct sort_desc_t
+{
+    uint8_t opcode = DSP_OPCODE::SORT_DESC_T;
+    uint8_t type;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+    uint8_t dim;
+
+    sort_desc_t(datatype_t type, runtime_shape_t src_shape,
+        runtime_shape_t dest_shape, uint8_t dim)
+        : type(type), src_shape(src_shape), dest_shape(dest_shape), dim(dim) { }
+};
+
+struct transpose_t
+{
+    uint8_t opcode = DSP_OPCODE::TRANSPOSE_T;
+    uint8_t type;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+    perm_t perm;
+
+    transpose_t(datatype_t type, runtime_shape_t src_shape,
+        runtime_shape_t dest_shape, perm_t perm)
+        : type(type), src_shape(src_shape), dest_shape(dest_shape), perm(perm) { }
+};
+
+struct slice_t
+{
+    uint8_t opcode = DSP_OPCODE::SLICE_T;
+    uint8_t type;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+    slice_config_dim_t dim0;
+    slice_config_dim_t dim1;
+    slice_config_dim_t dim2;
+    slice_config_dim_t dim3;
+
+    slice_t(datatype_t type, runtime_shape_t src_shape,
+        runtime_shape_t dest_shape, slice_config_dim_t dim0,
+        slice_config_dim_t dim1, slice_config_dim_t dim2,
+        slice_config_dim_t dim3)
+        : type(type), src_shape(src_shape), dest_shape(dest_shape), dim0(dim0), dim1(dim1), dim2(dim2), dim3(dim3) { }
+};
+
+struct convert_t
+{
+    uint8_t opcode = DSP_OPCODE::CONVERT_T;
+    uint8_t src_type;
+    runtime_shape_t src_shape;
+    uint8_t dest_type;
+    runtime_shape_t dest_shape;
+
+    convert_t(datatype_t src_type, runtime_shape_t src_shape,
+        datatype_t dest_type, runtime_shape_t dest_shape)
+        : src_type(src_type), src_shape(src_shape), dest_type(dest_type), dest_shape(dest_shape) { }
+};
+
+struct broadcast_t
+{
+    uint8_t opcode = DSP_OPCODE::BROADCAST_T;
+    uint8_t type;
+    runtime_shape_t src_shape;
+    runtime_shape_t dest_shape;
+
+    broadcast_t(datatype_t type, runtime_shape_t src_shape,
+        runtime_shape_t dest_shape)
+        : type(type), src_shape(src_shape), dest_shape(dest_shape) { }
+};
+
+struct quantize_t
+{
+    uint8_t opcode = DSP_OPCODE::QUANTIZE_T;
+    uint8_t src_type;
+    runtime_shape_t src_shape;
+    uint8_t dest_type;
+    runtime_shape_t dest_shape;
+
+    quantize_t(datatype_t src_type, runtime_shape_t src_shape,
+        datatype_t dest_type, runtime_shape_t dest_shape)
+        : src_type(src_type), src_shape(src_shape), dest_type(dest_type), dest_shape(dest_shape) { }
+};
+
+struct dequantize_t
+{
+    uint8_t opcode = DSP_OPCODE::DEQUANTIZE_T;
+    uint8_t src_type;
+    runtime_shape_t src_shape;
+    uint8_t dest_type;
+    runtime_shape_t dest_shape;
+
+    dequantize_t(datatype_t src_type, runtime_shape_t src_shape,
+        datatype_t dest_type, runtime_shape_t dest_shape)
+        : src_type(src_type), src_shape(src_shape), dest_type(dest_type), dest_shape(dest_shape) { }
+};
+
+struct clamp_t
+{
+    uint8_t opcode = DSP_OPCODE::CLAMP_T;
+    uint8_t src_type;
+    runtime_shape_t src_shape;
+    uint8_t dest_type;
+    runtime_shape_t dest_shape;
+
+    clamp_t(datatype_t src_type, runtime_shape_t src_shape,
+        datatype_t dest_type, runtime_shape_t dest_shape)
+        : src_type(src_type), src_shape(src_shape), dest_type(dest_type), dest_shape(dest_shape) { }
+};
+
+#pragma pack(pop)
+
+template <DSP_OPCODE Op>
+struct dsp_inst;
+
+#define DEFINE_OPCODE(name, value, id) \
+    template <>                        \
+    struct dsp_inst<name>              \
+    {                                  \
+        using type = id;               \
+    };
+#include "gnne_dsp_opcode.def"
+#undef DEFINE_OPCODE
+
+template <DSP_OPCODE Op>
+using dsp_inst_t = typename dsp_inst<Op>::type;
+}
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_opcode.def b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_opcode.def
new file mode 100644
index 0000000..9d25e40
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_dsp_opcode.def
@@ -0,0 +1,64 @@
+DEFINE_OPCODE(NOP, 0x00, nop) // 无操作
+DEFINE_OPCODE(LDC_I4, 0x01, ldc_i4) // load int32，立即数到栈顶
+DEFINE_OPCODE(LDC_R4, 0x02, ldc_r4) // load float32，立即数到栈顶
+DEFINE_OPCODE(LDIND_I1, 0x03, ldind_i1) // load int8，从地址到栈顶
+DEFINE_OPCODE(LDIND_I4, 0x04, ldind_i4) // load int32，从地址到栈顶
+DEFINE_OPCODE(LDIND_U1, 0x05, ldind_u1) // load uint8，从地址到栈顶
+DEFINE_OPCODE(LDIND_BR2, 0x06, ldind_br2) // load bf16，从地址到栈顶
+DEFINE_OPCODE(LDIND_R4, 0x07, ldind_r4) // load float32，从地址到栈顶
+DEFINE_OPCODE(STIND_I1, 0x08, stind_i1) // store int8，从栈顶到地址
+DEFINE_OPCODE(STIND_I4, 0x09, stind_i4) // store int32，从栈顶到地址
+DEFINE_OPCODE(STIND_BR2, 0x0A, stind_br2) // store bf16，从栈顶到地址
+DEFINE_OPCODE(STIND_R4, 0x0B, stind_r4) // store float32，从栈顶到地址
+DEFINE_OPCODE(LDA_S, 0x0C, lda_s) // 间接寻址地址到栈顶
+DEFINE_OPCODE(DUP, 0x0D, dup) // 复制栈顶
+DEFINE_OPCODE(POP, 0x0E, pop) // 弹出栈顶
+DEFINE_OPCODE(LDARG, 0x0F, ldarg) // load 参数到栈顶
+DEFINE_OPCODE(LDARGA, 0x10, ldarga) // load 参数地址到栈顶
+DEFINE_OPCODE(STR_I4, 0x11, str_i4) // store 栈顶到 GNNE 寄存器
+
+DEFINE_OPCODE(NEG, 0x21, neg_) // 取负数
+DEFINE_OPCODE(NOT, 0x22, not_) // 取二进制反
+DEFINE_OPCODE(ADD, 0x23, add_) // 求和
+DEFINE_OPCODE(SUB, 0x24, sub_) // 求差
+DEFINE_OPCODE(MUL, 0x25, mul_) // 求积
+DEFINE_OPCODE(DIV, 0x26, div_) // 求商
+DEFINE_OPCODE(DIV_U, 0x27, div_u) // 无符号求商
+DEFINE_OPCODE(REM, 0x28, rem_) // 求余
+DEFINE_OPCODE(REM_U, 0x29, rem_u) // 无符号求余
+
+DEFINE_OPCODE(CLT, 0x41, clt) // operator <
+DEFINE_OPCODE(CLT_U, 0x42, clt_u) // 无符号 operator <
+DEFINE_OPCODE(CLE, 0x43, cle) // operator <=
+DEFINE_OPCODE(CLE_U, 0x44, cle_u) // 无符号 operator <=
+DEFINE_OPCODE(CEQ, 0x45, ceq) // operator ==
+DEFINE_OPCODE(CGE, 0x46, cge) // operator >=
+DEFINE_OPCODE(CGE_U, 0x47, cge_u) // 无符号 operator >=
+DEFINE_OPCODE(CGT, 0x48, cgt) // operator >
+DEFINE_OPCODE(CGT_U, 0x49, cgt_u) // 无符号 operator >
+DEFINE_OPCODE(CNE, 0x4A, cne) // operator !=
+
+DEFINE_OPCODE(CONV_I1, 0x61, conv_i1) // 转换到 int8
+DEFINE_OPCODE(CONV_I4, 0x62, conv_i4) // 转换到 int32
+DEFINE_OPCODE(CONV_U1, 0x63, conv_u1) // 转换到 uint8
+DEFINE_OPCODE(CONV_U4, 0x64, conv_u4) // 转换到 uint32
+DEFINE_OPCODE(CONV_BR2, 0x65, conv_br2) // 转换到 bfloat16
+DEFINE_OPCODE(CONV_R4, 0x66, conv_r4) // 转换到 float32
+
+DEFINE_OPCODE(BR, 0x81, br) // 无条件转移
+DEFINE_OPCODE(BR_TRUE, 0x82, br_true) // 转条件为 True，则转移
+DEFINE_OPCODE(BR_FALSE, 0x83, br_false) // 条件为 False，则转移
+DEFINE_OPCODE(RET, 0x84, ret) // 函数返回
+DEFINE_OPCODE(CALL, 0x85, call) // 调用函数
+DEFINE_OPCODE(THROW, 0x86, throw_) // 抛出异常
+
+DEFINE_OPCODE(PAD_T, 0xA1, pad_t) // Tensor Pad
+DEFINE_OPCODE(SORT_ASC_T, 0xA2, sort_asc_t) // Tensor Sort Ascending
+DEFINE_OPCODE(SORT_DESC_T, 0xA3, sort_desc_t) // Tensor Sort Descending
+DEFINE_OPCODE(TRANSPOSE_T, 0xA4, transpose_t) // Tensor Transpose
+DEFINE_OPCODE(SLICE_T, 0xA5, slice_t) // Tensor Slice
+DEFINE_OPCODE(CONVERT_T, 0xA6, convert_t) // Tensor Convert
+DEFINE_OPCODE(BROADCAST_T, 0xA7, broadcast_t) // Tensor Broadcast
+DEFINE_OPCODE(QUANTIZE_T, 0xA8, quantize_t) // Tensor Quantize
+DEFINE_OPCODE(DEQUANTIZE_T, 0xA9, dequantize_t) // Tensor DeQuantize
+DEFINE_OPCODE(CLAMP_T, 0xAA, clamp_t) // Tensor Clamp
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_instructions.hpp b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_instructions.hpp
new file mode 100644
index 0000000..ce3fa9a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_instructions.hpp
@@ -0,0 +1,10009 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <cmath>
+#include <cstdint>
+#include <iostream>
+#include <memory>
+#include <nncase/codegen/binary_writer.h>
+#include <nncase/runtime/bitio.h>
+#include <sstream>
+#include <vector>
+
+#define GNNE_INST_ASSERT assert
+
+namespace nncase::runtime::k230::isa
+{
+typedef uint64_t ADDR;
+typedef uint16_t REG;
+typedef uint32_t BF24;
+
+namespace DATA_STRUCT
+{
+    /////////////////////////////////
+    // auto generated structs
+
+    /**
+    STRIDE_GLB
+    @brief 在寻址的时候每增加一行需要跳跃的byte数
+    - uint64_t stride_glb_h 在寻址的时候每增加一行需要跳跃的byte数
+    - uint64_t stride_glb_c 在寻址的时候每增加一列需要跳跃的byte数
+    - uint64_t stride_glb_n 在寻址的时候每增加一通道需要跳跃的byte数
+**/
+    typedef struct stride_glb_t
+    {
+        uint64_t stride_glb_h : 21; /** 在寻址的时候每增加一行需要跳跃的byte数 **/
+        uint64_t stride_glb_c : 21; /** 在寻址的时候每增加一列需要跳跃的byte数 **/
+        uint64_t stride_glb_n : 21; /** 在寻址的时候每增加一通道需要跳跃的byte数 **/
+
+        stride_glb_t()
+        {
+            stride_glb_h = 0;
+            stride_glb_c = 0;
+            stride_glb_n = 0;
+        }
+
+    } STRIDE_GLB;
+
+    /**
+    CCRCLR
+    @brief 是否需要将某个 CCR 减 1
+    - uint64_t ccr_clr 是否需要将某个 CCR 减 1
+    - uint64_t ccr 指明使用哪个 CCR
+    - uint64_t ccr_acq 是否需要等待某个ccr
+**/
+    typedef struct ccrclr_t
+    {
+        uint64_t ccr_clr : 1; /** 是否需要将某个 CCR 减 1 **/
+        uint64_t ccr : 6; /** 指明使用哪个 CCR **/
+        uint64_t ccr_acq : 1; /** 是否需要等待某个ccr **/
+
+        ccrclr_t()
+        {
+            ccr_clr = 0;
+            ccr = 0;
+            ccr_acq = 0;
+        }
+
+    } CCRCLR;
+
+    /**
+    CCRSET
+    @brief 是否需要设置 CCR
+    - uint64_t ccr_set 是否需要设置 CCR
+    - uint64_t ccr 指明使用哪个 CCR
+    - uint64_t ccr_value ccr 置值
+**/
+    typedef struct ccrset_t
+    {
+        uint64_t ccr_set : 1; /** 是否需要设置 CCR **/
+        uint64_t ccr : 6; /** 指明使用哪个 CCR **/
+        uint64_t ccr_value : 4; /** ccr 置值 **/
+
+        ccrset_t()
+        {
+            ccr_set = 0;
+            ccr = 0;
+            ccr_value = 0;
+        }
+
+    } CCRSET;
+
+    /**
+    QARG
+    @brief 某个通道的scale数值
+    - uint64_t scale_chan 某个通道的scale数值
+    - uint64_t bias_chan 某个通道的偏置
+    - uint64_t shift_chan 某个通道的shift量
+**/
+    typedef struct qarg_t
+    {
+        uint64_t scale_chan : 16; /** 某个通道的scale数值 **/
+        uint64_t bias_chan : 8; /** 某个通道的偏置 **/
+        uint64_t shift_chan : 8; /** 某个通道的shift量 **/
+
+        qarg_t()
+        {
+            scale_chan = 0;
+            bias_chan = 0;
+            shift_chan = 0;
+        }
+
+    } QARG;
+
+    /**
+    MNCFG
+    @brief 如果是1的话，某个输入就取反
+    - uint64_t add_sub_0 如果是1的话，某个输入就取反
+    - uint64_t add_sub_1 如果是1的话，某个输入就取反
+    - uint64_t add_sub_2 如果是1的话，某个输入就取反
+    - uint64_t add_sub_3 如果是1的话，某个输入就取反
+    - uint64_t mul_neg_0 如果是1输出取反
+    - uint64_t mul_neg_1 如果是1输出取反
+    - uint64_t mul_neg_2 如果是1输出取反
+    - uint64_t mul_neg_3 如果是1输出取反
+    - uint64_t div_neg_0 如果是1输出取反
+    - uint64_t binary_logic_isLogic 0：按位运算
+1：按照WORD进行逻辑运算
+    - uint64_t binary_logic_mode 0：And
+1：Or
+2：NOT
+3：XOR
+    - uint64_t round_mode 0：round
+1：floor
+2：ceil
+    - uint64_t sqrt_mode 0：输入符号位直接认为是0，一定是正数
+1：如果是输入符号位位负的，返回NaN
+2：如果输入是正数，正常输出。否者输出负数
+    - uint64_t tran_mode 0：sin
+1：cos
+    - uint64_t log_mod 0：输入符号位直接认为是0，一定是正数
+1：如果是输入符号位位负的，返回NaN
+2：如果输入是正数，正常输出。否者输出负数
+    - uint64_t unary_logic_mode 0：abs
+1：sign
+2：neg
+    - uint64_t cmp_mode_0 0：MIN
+1：MAX
+2：>
+3：>=
+4：<
+5：<=
+6：==
+    - uint64_t cmp_mode_1 0：MIN
+1：MAX
+2：>
+3：>=
+4：<
+5：<=
+6：==
+**/
+    typedef struct mncfg_t
+    {
+        uint64_t add_sub_0 : 2; /** 如果是1的话，某个输入就取反 **/
+        uint64_t add_sub_1 : 2; /** 如果是1的话，某个输入就取反 **/
+        uint64_t add_sub_2 : 2; /** 如果是1的话，某个输入就取反 **/
+        uint64_t add_sub_3 : 2; /** 如果是1的话，某个输入就取反 **/
+        uint64_t mul_neg_0 : 1; /** 如果是1输出取反 **/
+        uint64_t mul_neg_1 : 1; /** 如果是1输出取反 **/
+        uint64_t mul_neg_2 : 1; /** 如果是1输出取反 **/
+        uint64_t mul_neg_3 : 1; /** 如果是1输出取反 **/
+        uint64_t div_neg_0 : 1; /** 如果是1输出取反 **/
+        uint64_t round_mode : 2; /** 0：round
+     1：floor
+     2：ceil **/
+        uint64_t sqrt_mode : 2; /** 0：输入符号位直接认为是0，一定是正数
+1：如果是输入符号位位负的，返回NaN
+2：如果输入是正数，正常输出。否者输出负数 **/
+        uint64_t tran_mode : 1; /** 0：sin
+1：cos **/
+        uint64_t log_mode : 2; /** 0：输入符号位直接认为是0，一定是正数
+1：如果是输入符号位位负的，返回NaN
+2：如果输入是正数，正常输出。否者输出负数 **/
+        uint64_t unary_logic_mode : 2; /** 0：abs
+1：sign
+2：neg **/
+        uint64_t cmp_mode_0 : 3; /** 0：MIN
+ 1：MAX
+ 2：>
+ 3：>=
+ 4：<
+ 5：<=
+ 6：== **/
+        uint64_t cmp_mode_1 : 3; /** 0：MIN
+ 1：MAX
+ 2：>
+ 3：>=
+ 4：<
+ 5：<=
+ 6：== **/
+
+        mncfg_t()
+        {
+            add_sub_0 = 0;
+            add_sub_1 = 0;
+            add_sub_2 = 0;
+            add_sub_3 = 0;
+            mul_neg_0 = 0;
+            mul_neg_1 = 0;
+            mul_neg_2 = 0;
+            mul_neg_3 = 0;
+            div_neg_0 = 0;
+            round_mode = 0;
+            sqrt_mode = 0;
+            tran_mode = 0;
+            log_mode = 0;
+            unary_logic_mode = 0;
+            cmp_mode_0 = 0;
+            cmp_mode_1 = 0;
+        }
+
+    } MNCFG;
+
+} // namespace DATA_STRUCT
+
+class CCRCLR
+{
+    typedef DATA_STRUCT::CCRCLR T_CCRCLR;
+    T_CCRCLR data;
+
+public:
+    CCRCLR(uint64_t value)
+    {
+        data.ccr_clr = value & 0x1;
+        data.ccr = (value >> 1) & 0x3f;
+        data.ccr_acq = (value >> 7) & 0x1;
+    }
+
+    CCRCLR(uint64_t ccr, bool acq, bool clr = true)
+    {
+        this->data.ccr = ccr;
+        this->data.ccr_acq = acq;
+        this->data.ccr_clr = clr;
+    }
+
+    uint64_t inline value() const
+    {
+        uint64_t val = 0;
+        val += data.ccr_clr;
+        val += (data.ccr) << 1;
+        val += (data.ccr_acq) << 7;
+        return val;
+    }
+
+    operator uint64_t() const { return value(); }
+
+    friend std::ostream &operator<<(std::ostream &os, const CCRCLR &ccrclr)
+    {
+        os << "ccrclr(ccr: " << ccrclr.data.ccr
+           << " , ccr_acq: " << ccrclr.data.ccr_acq
+           << " , ccr_clr: " << ccrclr.data.ccr_clr << ")";
+        return os;
+    }
+};
+
+class CCRSET
+{
+    typedef DATA_STRUCT::CCRSET T_CCRSET;
+    T_CCRSET data;
+
+public:
+    CCRSET(uint64_t value)
+    {
+        data.ccr_set = value & 0x1;
+        data.ccr = (value >> 1) & 0x3f;
+        data.ccr_value = (value >> 7) & 0xf;
+    }
+
+    CCRSET(uint16_t ccr, uint16_t value, bool ccr_set = true)
+    {
+        this->data.ccr_set = ccr_set;
+        this->data.ccr = ccr;
+        this->data.ccr_value = value;
+    }
+
+    uint64_t inline value() const
+    {
+        uint64_t val = 0;
+        val += data.ccr_set;
+        val += (data.ccr << 1);
+        val += (data.ccr_value) << 7;
+        return val;
+    }
+
+    operator uint64_t() const { return value(); }
+
+    friend std::ostream &operator<<(std::ostream &os, const CCRSET &ccrset)
+    {
+        os << "ccrset(ccr: " << ccrset.data.ccr
+           << " , ccr_value: " << ccrset.data.ccr_value
+           << " , ccr_set: " << ccrset.data.ccr_set << ")";
+        return os;
+    }
+};
+
+template <int SHIFT, int ADDR_WIDTH, int MMU_ITEM_WIDTH>
+class GLB_ADDR
+{
+#pragma pack(1)
+    struct T_ADDR
+    {
+        uint64_t addr : ADDR_WIDTH;
+        uint64_t mmu_item : 4;
+    };
+#pragma pack()
+    T_ADDR data;
+
+public:
+    inline GLB_ADDR(uint64_t value)
+    {
+        data.addr = value & ((1 << ADDR_WIDTH) - 1);
+        data.mmu_item = (value >> ADDR_WIDTH) & 0xf;
+    }
+
+    uint64_t inline value() const
+    {
+        uint64_t val = 0;
+        val += (data.mmu_item << ADDR_WIDTH);
+        val += data.addr;
+        return val;
+    }
+
+    uint64_t inline mmu_item() const
+    {
+        if (MMU_ITEM_WIDTH)
+        {
+            return data.mmu_item;
+        }
+        return 0;
+    }
+
+    void inline mmu_item(uint64_t mmu_item)
+    {
+        if (MMU_ITEM_WIDTH)
+        {
+            data.mmu_item = mmu_item;
+        }
+    }
+
+    uint64_t inline addr() const { return data.addr << SHIFT; }
+
+    void inline addr(uint64_t value) { data.addr = value >> SHIFT; }
+
+    operator uint64_t() const { return value(); }
+
+    GLB_ADDR<SHIFT, ADDR_WIDTH, MMU_ITEM_WIDTH> &
+    operator+=(const GLB_ADDR<SHIFT, ADDR_WIDTH, MMU_ITEM_WIDTH> &c)
+    {
+        this->addr(this->addr() + c.addr());
+        return *this;
+    }
+};
+template <int SHIFT, int ADDR_WIDTH, int MMU_ITEM_WIDTH>
+std::ostream &operator<<(std::ostream &out,
+    const GLB_ADDR<SHIFT, ADDR_WIDTH, MMU_ITEM_WIDTH> &c)
+{
+    if (MMU_ITEM_WIDTH)
+        out << "(mmu: " << c.mmu_item() << ", addr: " << c.addr() << ")";
+    else
+        out << "(addr: " << c.addr() << ")";
+    return out;
+}
+
+typedef GLB_ADDR<0, 21, 0> ADDR_GLB_8_WITHOUT_BANK;
+typedef GLB_ADDR<3, 17, 0> ADDR_GLB_64_WITHOUT_BANK;
+typedef GLB_ADDR<0, 21, 4> ADDR_GLB_8_WITH_BANK;
+typedef GLB_ADDR<3, 17, 4> ADDR_GLB_64_WITH_BANK;
+
+class UNION_ADDR
+{
+    union union_data
+    {
+        ADDR_GLB_8_WITH_BANK glb;
+        ADDR ddr;
+        uint64_t u64;
+        union_data()
+            : u64(0) { }
+    };
+
+    union union_data data;
+
+public:
+    inline UNION_ADDR(uint64_t data) { this->data.u64 = data; }
+
+    bool inline is_ddr() const { return (data.u64 >> 31) & 1; }
+
+    ADDR_GLB_8_WITH_BANK inline glb() const
+    {
+        GNNE_INST_ASSERT(!is_ddr());
+        return data.glb;
+    }
+
+    void inline glb(ADDR_GLB_8_WITH_BANK addr) { data.glb = addr; }
+
+    ADDR inline ddr() const
+    {
+        GNNE_INST_ASSERT(is_ddr());
+        return data.ddr & 0x7FFFFFFF;
+    }
+
+    void inline ddr(ADDR addr) { data.ddr = 0x80000000 | addr; }
+
+    uint64_t inline value() const { return data.u64; }
+
+    operator uint64_t() const { return value(); }
+};
+
+class STRIDE_GLB
+{
+protected:
+    struct stride_glb_t
+    {
+        uint64_t stride_glb_h : 21;
+        uint64_t stride_glb_c : 21;
+        uint64_t stride_glb_n : 21;
+        stride_glb_t() = default;
+    };
+
+    struct stride_glb_t data;
+
+public:
+    STRIDE_GLB(uint64_t value = 0)
+    {
+        data.stride_glb_h = value & 0x1fffff;
+        data.stride_glb_c = (value >> 21) & 0x1fffff;
+        data.stride_glb_n = (value >> 42) & 0x1fffff;
+    }
+
+    void stride_glb_c(uint64_t value) { data.stride_glb_c = value; }
+
+    void stride_glb_n(uint64_t value) { data.stride_glb_n = value; }
+
+    void stride_glb_h(uint64_t value) { data.stride_glb_h = value; }
+
+    uint64_t stride_glb_c() const { return data.stride_glb_c; }
+
+    uint64_t stride_glb_n() const { return data.stride_glb_n; }
+
+    uint64_t stride_glb_h() const { return data.stride_glb_h; }
+
+    uint64_t inline value() const
+    {
+        uint64_t val = data.stride_glb_n;
+        uint64_t tmp = data.stride_glb_c;
+        val = val << 42;
+        val += (tmp << 21);
+        val += data.stride_glb_h;
+        return val;
+    }
+
+    operator uint64_t() const { return value(); }
+};
+
+union stride_union
+{
+    STRIDE_GLB stride;
+    struct layout
+    {
+        uint64_t w : 16;
+        uint64_t h : 16;
+        uint64_t c : 16;
+        uint64_t n : 16;
+    } layout;
+    uint64_t value = 0;
+    stride_union()
+        : value(0) {};
+};
+
+inline std::ostream &operator<<(std::ostream &out, const STRIDE_GLB &c)
+{
+    stride_union tmp;
+    tmp.stride = c;
+    out << "stride_glb: ( n:" << c.stride_glb_n() << " , c:" << c.stride_glb_c()
+        << ", h:" << c.stride_glb_h() << " ) "
+        << "layout:("
+        << "n: " << tmp.layout.n << ", "
+        << "c: " << tmp.layout.c << ", "
+        << "h: " << tmp.layout.h << ", "
+        << "w: " << tmp.layout.w << ") ";
+    return out;
+}
+
+inline std::ostream &operator<<(std::ostream &out, const UNION_ADDR &c)
+{
+    if (c.is_ddr())
+    {
+        out << "(ddr : " << c.ddr() << ")";
+    }
+    else
+    {
+        out << c.glb();
+    }
+    return out;
+}
+
+/////////////////////////////////
+// auto generated enums
+
+/**
+    MMU.CONF.WIDTH
+    @brief
+    - 1 : 0x0(0)  1 bank
+    - 2 : 0x1(1)  2 banks
+    - 4 : 0x2(2)  4 banks
+    - 8 : 0x3(3)  8 banks
+**/
+typedef enum mmu_conf_width_t : uint8_t
+{
+    MMU_CONF_WIDTH_1 = 0x0, /* 0:1 bank*/
+    MMU_CONF_WIDTH_2 = 0x1, /* 1:2 banks*/
+    MMU_CONF_WIDTH_4 = 0x2, /* 2:4 banks*/
+    MMU_CONF_WIDTH_8 = 0x3 /* 3:8 banks*/
+} MMU_CONF_WIDTH;
+
+std::ostream &operator<<(std::ostream &out, const MMU_CONF_WIDTH &c);
+
+/**
+    COMPRESSED
+    @brief
+    - UNCOMPRESSED : 0x0(0)  直接存储
+    - COMPRESSED : 0x1(1)  霍夫曼压缩
+**/
+typedef enum compressed_t : uint8_t
+{
+    COMPRESSED_UNCOMPRESSED = 0x0, /* 0:直接存储*/
+    COMPRESSED_COMPRESSED = 0x1 /* 1:霍夫曼压缩*/
+} COMPRESSED;
+
+std::ostream &operator<<(std::ostream &out, const COMPRESSED &c);
+
+/**
+    MFU.REDUCE.DIM
+    @brief
+    - W : 0x0(0)  None
+    - HW : 0x1(1)  None
+    - CHW : 0x2(2)  None
+    - NCHW : 0x3(3)  None
+**/
+typedef enum mfu_reduce_dim_t : uint8_t
+{
+    MFU_REDUCE_DIM_W = 0x0, /* 0:None*/
+    MFU_REDUCE_DIM_HW = 0x1, /* 1:None*/
+    MFU_REDUCE_DIM_CHW = 0x2, /* 2:None*/
+    MFU_REDUCE_DIM_NCHW = 0x3 /* 3:None*/
+} MFU_REDUCE_DIM;
+
+std::ostream &operator<<(std::ostream &out, const MFU_REDUCE_DIM &c);
+
+typedef enum mfu_mn_op_t : uint8_t
+{
+    MFU_MN_OP_NULL = 0x0, /* 0:无连接*/
+    MFU_MN_OP_VECTOR = 0x1, /* 1:向量*/
+    MFU_MN_OP_CONST1 = 0x2, /* 2:常量1*/
+    MFU_MN_OP_ADDSUB0 = 0x3, /* 3:加减法0*/
+    MFU_MN_OP_ADDSUB1 = 0x4, /* 4:加减法1*/
+    MFU_MN_OP_ADDSUB2 = 0x5, /* 5:加减法2*/
+    MFU_MN_OP_ADDSUB3 = 0x6, /* 6:加减法3*/
+    MFU_MN_OP_MUL0 = 0x7, /* 7:乘法0*/
+    MFU_MN_OP_MUL1 = 0x8, /* 8:乘法1*/
+    MFU_MN_OP_MUL2 = 0x9, /* 9:乘法2*/
+    MFU_MN_OP_MUL3 = 0xa, /* 10:乘法3*/
+    MFU_MN_OP_DIV = 0xb, /* 11:除法*/
+    MFU_MN_OP_ROUND = 0xc, /* 12:取整*/
+    MFU_MN_OP_SQRT = 0xd, /* 13:开方*/
+    MFU_MN_OP_TRANGLE = 0xe, /* 14:三角函数*/
+    MFU_MN_OP_LOG = 0xf, /* 15:对数函数*/
+    MFU_MN_OP_UNARY_LOGIC = 0x10, /* 16:单目逻辑*/
+    MFU_MN_OP_EXP = 0x11, /* 17:指数函数*/
+    MFU_MN_OP_CMP0 = 0x12, /* 18:比较0*/
+    MFU_MN_OP_CMP1 = 0x13, /* 19:比较1*/
+    MFU_MN_OP_REG0 = 0x14, /* 20:十六段拟合0*/
+    MFU_MN_OP_SELECT0 = 0x15, /* 21:selcet 0，三目运算*/
+    MFU_MN_OP_CONST2 = 0x16 /* 22:常数输入2*/
+} MFU_MN_OP;
+
+std::ostream &operator<<(std::ostream &out, const MFU_MN_OP &c);
+
+/**
+    PRECISION
+    @brief
+    - INT8 : 0x0(0)  INT8
+    - BF16 : 0x1(1)  BF16
+    - FP32 : 0x2(2)  FP32
+**/
+typedef enum precision_t : uint8_t
+{
+    PRECISION_INT8 = 0x0, /* 0:INT8*/
+    PRECISION_BF16 = 0x1, /* 1:BF16*/
+    PRECISION_FP32 = 0x2 /* 2:FP32*/
+} PRECISION;
+
+std::ostream &operator<<(std::ostream &out, const PRECISION &c);
+
+/**
+    QUAN_TYPE
+    @brief
+    - BY_CHANNEL : 0x0(0)  分通道量化
+    - BY_BATCH : 0x1(1)  分batch量化
+**/
+typedef enum quan_type_t : uint8_t
+{
+    QUAN_TYPE_BY_CHANNEL = 0x0, /* 0:分通道量化*/
+    QUAN_TYPE_BY_BATCH = 0x1 /* 1:分batch量化*/
+} QUAN_TYPE;
+
+std::ostream &operator<<(std::ostream &out, const QUAN_TYPE &c);
+
+/**
+    MFU.TRANS.PERMUTE
+    @brief
+    - NCHW : 0x0(0)  重要
+    - NCWH : 0x1(1)  重要
+    - NHCW : 0x2(2)  重要
+    - NHWC : 0x3(3)  重要
+    - NWCH : 0x4(4)  None
+    - NWHC : 0x5(5)  None
+    - CNHW : 0x6(6)  None
+    - CNWH : 0x7(7)  None
+    - CHNW : 0x8(8)  None
+    - CHWN : 0x9(9)  None
+    - CWNH : 0xa(10)  None
+    - CWHN : 0xb(11)  None
+    - HNCW : 0xc(12)  None
+    - HNWC : 0xd(13)  None
+    - HCNW : 0xe(14)  None
+    - HCWN : 0xf(15)  None
+    - HWNC : 0x10(16)  None
+    - HWCN : 0x11(17)  None
+    - WNCH : 0x12(18)  None
+    - WNHC : 0x13(19)  None
+    - WCNH : 0x14(20)  None
+    - WCHN : 0x15(21)  None
+    - WHNC : 0x16(22)  None
+    - WHCN : 0x17(23)  None
+**/
+typedef enum mfu_trans_permute_t : uint8_t
+{
+    MFU_TRANS_PERMUTE_NCHW = 0x0, /* 0:重要*/
+    MFU_TRANS_PERMUTE_NCWH = 0x1, /* 1:重要*/
+    MFU_TRANS_PERMUTE_NHCW = 0x2, /* 2:重要*/
+    MFU_TRANS_PERMUTE_NHWC = 0x3, /* 3:重要*/
+    MFU_TRANS_PERMUTE_NWCH = 0x4, /* 4:None*/
+    MFU_TRANS_PERMUTE_NWHC = 0x5, /* 5:None*/
+    MFU_TRANS_PERMUTE_CNHW = 0x6, /* 6:None*/
+    MFU_TRANS_PERMUTE_CNWH = 0x7, /* 7:None*/
+    MFU_TRANS_PERMUTE_CHNW = 0x8, /* 8:None*/
+    MFU_TRANS_PERMUTE_CHWN = 0x9, /* 9:None*/
+    MFU_TRANS_PERMUTE_CWNH = 0xa, /* 10:None*/
+    MFU_TRANS_PERMUTE_CWHN = 0xb, /* 11:None*/
+    MFU_TRANS_PERMUTE_HNCW = 0xc, /* 12:None*/
+    MFU_TRANS_PERMUTE_HNWC = 0xd, /* 13:None*/
+    MFU_TRANS_PERMUTE_HCNW = 0xe, /* 14:None*/
+    MFU_TRANS_PERMUTE_HCWN = 0xf, /* 15:None*/
+    MFU_TRANS_PERMUTE_HWNC = 0x10, /* 16:None*/
+    MFU_TRANS_PERMUTE_HWCN = 0x11, /* 17:None*/
+    MFU_TRANS_PERMUTE_WNCH = 0x12, /* 18:None*/
+    MFU_TRANS_PERMUTE_WNHC = 0x13, /* 19:None*/
+    MFU_TRANS_PERMUTE_WCNH = 0x14, /* 20:None*/
+    MFU_TRANS_PERMUTE_WCHN = 0x15, /* 21:None*/
+    MFU_TRANS_PERMUTE_WHNC = 0x16, /* 22:None*/
+    MFU_TRANS_PERMUTE_WHCN = 0x17 /* 23:None*/
+} MFU_TRANS_PERMUTE;
+
+std::ostream &operator<<(std::ostream &out, const MFU_TRANS_PERMUTE &c);
+
+/**
+    STORE.ORDER
+    @brief
+    - NCHW : 0x0(0)  None
+    - NHCW : 0x1(1)  None
+**/
+typedef enum store_order_t : uint8_t
+{
+    STORE_ORDER_NCHW = 0x0, /* 0:None*/
+    STORE_ORDER_NHCW = 0x1 /* 1:None*/
+} STORE_ORDER;
+
+std::ostream &operator<<(std::ostream &out, const STORE_ORDER &c);
+
+/**
+    MFU.REDUCE.OP
+    @brief
+    - MAX : 0x0(0)  两者取最大值
+    - MIN : 0x1(1)  两者取最小值
+    - ADD : 0x2(2)  两者求和
+    - SUB : 0x3(3)  左操作数减去右操作数
+    - MUL : 0x4(4)  两者求其点积
+**/
+typedef enum mfu_reduce_op_t : uint8_t
+{
+    MFU_REDUCE_OP_MAX = 0x0, /* 0:两者取最大值*/
+    MFU_REDUCE_OP_MIN = 0x1, /* 1:两者取最小值*/
+    MFU_REDUCE_OP_ADD = 0x2, /* 2:两者求和*/
+    MFU_REDUCE_OP_SUB = 0x3, /* 3:左操作数减去右操作数*/
+    MFU_REDUCE_OP_MUL = 0x4 /* 4:两者求其点积*/
+} MFU_REDUCE_OP;
+
+std::ostream &operator<<(std::ostream &out, const MFU_REDUCE_OP &c);
+
+/**
+    ALIGNED
+    @brief
+    - DENSE : 0x0(0)  紧密存储
+    - ALIGNED : 0x1(1)  对齐到64bit
+**/
+typedef enum aligned_t : uint8_t
+{
+    ALIGNED_DENSE = 0x0, /* 0:紧密存储*/
+    ALIGNED_ALIGNED = 0x1 /* 1:对齐到64bit*/
+} ALIGNED;
+
+std::ostream &operator<<(std::ostream &out, const ALIGNED &c);
+
+/**
+    PRECISION_DDR
+    @brief
+    - INT8 : 0x0(0)  INT8
+    - BF16 : 0x1(1)  BF16
+    - FP32 : 0x2(2)  FP32
+    - INT4 : 0x3(3)  INT4
+    - INT6 : 0x4(4)  INT6
+**/
+typedef enum precision_ddr_t : uint8_t
+{
+    PRECISION_DDR_INT8 = 0x0, /* 0:INT8*/
+    PRECISION_DDR_BF16 = 0x1, /* 1:BF16*/
+    PRECISION_DDR_FP32 = 0x2, /* 2:FP32*/
+    PRECISION_DDR_INT4 = 0x3, /* 3:INT4*/
+    PRECISION_DDR_INT6 = 0x4 /* 4:INT6*/
+} PRECISION_DDR;
+
+std::ostream &operator<<(std::ostream &out, const PRECISION_DDR &c);
+
+typedef enum mfu_mn_portin_t : uint8_t
+{
+    MFU_MN_PORTIN_DUMMY = 0x0,
+    MFU_MN_PORTIN_VECTOR_OUT_0 = 0x1,
+    MFU_MN_PORTIN_VECTOR_OUT_1 = 0x2,
+    MFU_MN_PORTIN_CONST1_OUT_0 = 0x3,
+    MFU_MN_PORTIN_CONST1_OUT_1 = 0x4,
+    MFU_MN_PORTIN_CONST2_OUT_0 = 0x5,
+    MFU_MN_PORTIN_CONST2_OUT_1 = 0x6,
+    MFU_MN_PORTIN_ADDSUB0_OUT_0 = 0x7,
+    MFU_MN_PORTIN_ADDSUB1_OUT_0 = 0x8,
+    MFU_MN_PORTIN_ADDSUB2_OUT_0 = 0x9,
+    MFU_MN_PORTIN_ADDSUB3_OUT_0 = 0xa,
+    MFU_MN_PORTIN_MUL0_OUT_0 = 0xb,
+    MFU_MN_PORTIN_MUL1_OUT_0 = 0xc,
+    MFU_MN_PORTIN_MUL2_OUT_0 = 0xd,
+    MFU_MN_PORTIN_MUL3_OUT_0 = 0xe,
+    MFU_MN_PORTIN_DIV_OUT_0 = 0xf,
+    MFU_MN_PORTIN_ROUND_OUT_0 = 0x10,
+    MFU_MN_PORTIN_SQRT_OUT_0 = 0x11,
+    MFU_MN_PORTIN_TRANGLE_OUT_0 = 0x12,
+    MFU_MN_PORTIN_LOG_OUT_0 = 0x13,
+    MFU_MN_PORTIN_UNARY_LOGIC_OUT_0 = 0x14,
+    MFU_MN_PORTIN_EXP_OUT_0 = 0x15,
+    MFU_MN_PORTIN_CMP0_OUT_0 = 0x16,
+    MFU_MN_PORTIN_CMP1_OUT_0 = 0x17,
+    MFU_MN_PORTIN_REG0_OUT_0 = 0x18,
+    MFU_MN_PORTIN_SELECT0_OUT_0 = 0x19,
+    MFU_MN_PORTIN_NOP0_OUT_0 = 0x1a,
+    MFU_MN_PORTIN_NOP0_OUT_1 = 0x1b,
+    MFU_MN_PORTIN_NOP0_OUT_2 = 0x1c,
+    MFU_MN_PORTIN_NOP0_OUT_3 = 0x1d,
+    MFU_MN_PORTIN_NOP0_OUT_4 = 0x1e,
+    MFU_MN_PORTIN_NOP0_OUT_5 = 0x1f,
+    MFU_MN_PORTIN_NOP0_OUT_6 = 0x20,
+    MFU_MN_PORTIN_NOP0_OUT_7 = 0x21
+} MFU_MN_PORTIN;
+
+std::ostream &operator<<(std::ostream &out, const MFU_MN_PORTIN &c);
+
+/**
+    MFU.PDP.OP
+    @brief
+    - MIN : 0x1(1)  取最小值
+    - MAX : 0x0(0)  取最大值
+    - AVERAGE : 0x2(2)  取平均值
+    - SUM : 0x3(3)  求和
+**/
+typedef enum mfu_pdp_op_t : uint8_t
+{
+    MFU_PDP_OP_MIN = 0x1, /* 1:取最小值*/
+    MFU_PDP_OP_MAX = 0x0, /* 0:取最大值*/
+    MFU_PDP_OP_AVERAGE = 0x2, /* 2:取平均值*/
+    MFU_PDP_OP_SUM = 0x3 /* 3:求和*/
+} MFU_PDP_OP;
+
+std::ostream &operator<<(std::ostream &out, const MFU_PDP_OP &c);
+
+/**
+    LOAD.ORDER
+    @brief
+    - NCHW : 0x0(0)  None
+    - RGBA : 0x1(1)  None
+    - RBGA : 0x2(2)  None
+    - GRBA : 0x3(3)  None
+    - GBRA : 0x4(4)  None
+    - BRGA : 0x5(5)  None
+    - BGRA : 0x6(6)  None
+    - ARGB : 0x7(7)  None
+    - ARBG : 0x8(8)  None
+    - AGRB : 0x9(9)  None
+    - AGBR : 0xa(10)  None
+    - ABRG : 0xb(11)  None
+    - ABGR : 0xc(12)  None
+    - RGB : 0xd(13)  None
+    - RBG : 0xe(14)  None
+    - GRB : 0xf(15)  None
+    - GBR : 0x10(16)  None
+    - BRG : 0x11(17)  None
+    - BGR : 0x12(18)  None
+**/
+typedef enum load_order_t : uint8_t
+{
+    LOAD_ORDER_NCHW = 0x0, /* 0:None*/
+    LOAD_ORDER_RGBA = 0x1, /* 1:None*/
+    LOAD_ORDER_RBGA = 0x2, /* 2:None*/
+    LOAD_ORDER_GRBA = 0x3, /* 3:None*/
+    LOAD_ORDER_GBRA = 0x4, /* 4:None*/
+    LOAD_ORDER_BRGA = 0x5, /* 5:None*/
+    LOAD_ORDER_BGRA = 0x6, /* 6:None*/
+    LOAD_ORDER_ARGB = 0x7, /* 7:None*/
+    LOAD_ORDER_ARBG = 0x8, /* 8:None*/
+    LOAD_ORDER_AGRB = 0x9, /* 9:None*/
+    LOAD_ORDER_AGBR = 0xa, /* 10:None*/
+    LOAD_ORDER_ABRG = 0xb, /* 11:None*/
+    LOAD_ORDER_ABGR = 0xc, /* 12:None*/
+    LOAD_ORDER_RGB = 0xd, /* 13:None*/
+    LOAD_ORDER_RBG = 0xe, /* 14:None*/
+    LOAD_ORDER_GRB = 0xf, /* 15:None*/
+    LOAD_ORDER_GBR = 0x10, /* 16:None*/
+    LOAD_ORDER_BRG = 0x11, /* 17:None*/
+    LOAD_ORDER_BGR = 0x12 /* 18:None*/
+} LOAD_ORDER;
+
+std::ostream &operator<<(std::ostream &out, const LOAD_ORDER &c);
+
+/**
+    QUAN.SIGNED
+    @brief
+    - UNSIGNED : 0x0(0)  无符号量化
+    - SIGNED : 0x1(1)  有符号量化
+**/
+typedef enum quan_signed_t : uint8_t
+{
+    QUAN_SIGNED_UNSIGNED = 0x0, /* 0:无符号量化*/
+    QUAN_SIGNED_SIGNED = 0x1 /* 1:有符号量化*/
+} QUAN_SIGNED;
+
+std::ostream &operator<<(std::ostream &out, const QUAN_SIGNED &c);
+
+/**
+    SPARSIFIED
+    @brief
+    - DENSE : 0x0(0)  直接存储
+    - SPARSIFIED : 0x1(1)  对0进行压缩编码
+**/
+typedef enum sparsified_t : uint8_t
+{
+    SPARSIFIED_DENSE = 0x0, /* 0:直接存储*/
+    SPARSIFIED_SPARSIFIED = 0x1 /* 1:对0进行压缩编码*/
+} SPARSIFIED;
+
+std::ostream &operator<<(std::ostream &out, const SPARSIFIED &c);
+
+typedef enum mfu_mn_portout_t : uint8_t
+{
+    MFU_MN_PORTOUT_DUMMY = 0x0,
+    MFU_MN_PORTOUT_VECTOR_IN_0 = 0x1,
+    MFU_MN_PORTOUT_ADDSUB0_IN_0 = 0x2,
+    MFU_MN_PORTOUT_ADDSUB0_IN_1 = 0x3,
+    MFU_MN_PORTOUT_ADDSUB1_IN_0 = 0x4,
+    MFU_MN_PORTOUT_ADDSUB1_IN_1 = 0x5,
+    MFU_MN_PORTOUT_ADDSUB2_IN_0 = 0x6,
+    MFU_MN_PORTOUT_ADDSUB2_IN_1 = 0x7,
+    MFU_MN_PORTOUT_ADDSUB3_IN_0 = 0x8,
+    MFU_MN_PORTOUT_ADDSUB3_IN_1 = 0x9,
+    MFU_MN_PORTOUT_MUL0_IN_0 = 0xa,
+    MFU_MN_PORTOUT_MUL0_IN_1 = 0xb,
+    MFU_MN_PORTOUT_MUL1_IN_0 = 0xc,
+    MFU_MN_PORTOUT_MUL1_IN_1 = 0xd,
+    MFU_MN_PORTOUT_MUL2_IN_0 = 0xe,
+    MFU_MN_PORTOUT_MUL2_IN_1 = 0xf,
+    MFU_MN_PORTOUT_MUL3_IN_0 = 0x10,
+    MFU_MN_PORTOUT_MUL3_IN_1 = 0x11,
+    MFU_MN_PORTOUT_DIV_IN_0 = 0x12,
+    MFU_MN_PORTOUT_DIV_IN_1 = 0x13,
+    MFU_MN_PORTOUT_ROUND_IN_0 = 0x14,
+    MFU_MN_PORTOUT_SQRT_IN_0 = 0x15,
+    MFU_MN_PORTOUT_TRANGLE_IN_0 = 0x16,
+    MFU_MN_PORTOUT_LOG_IN_0 = 0x17,
+    MFU_MN_PORTOUT_UNARY_LOGIC_IN_0 = 0x18,
+    MFU_MN_PORTOUT_EXP_IN_0 = 0x19,
+    MFU_MN_PORTOUT_CMP0_IN_0 = 0x1a,
+    MFU_MN_PORTOUT_CMP0_IN_1 = 0x1b,
+    MFU_MN_PORTOUT_CMP1_IN_0 = 0x1c,
+    MFU_MN_PORTOUT_CMP1_IN_1 = 0x1d,
+    MFU_MN_PORTOUT_REG0_IN_0 = 0x1e,
+    MFU_MN_PORTOUT_SELECT0_IN_0 = 0x1f,
+    MFU_MN_PORTOUT_SELECT0_IN_1 = 0x20,
+    MFU_MN_PORTOUT_SELECT0_IN_2 = 0x21,
+    MFU_MN_PORTOUT_NOP0_IN_0 = 0x22,
+    MFU_MN_PORTOUT_NOP1_IN_0 = 0x23,
+    MFU_MN_PORTOUT_NOP2_IN_0 = 0x24,
+    MFU_MN_PORTOUT_NOP3_IN_0 = 0x25,
+    MFU_MN_PORTOUT_NOP4_IN_0 = 0x26,
+    MFU_MN_PORTOUT_NOP5_IN_0 = 0x27,
+    MFU_MN_PORTOUT_NOP6_IN_0 = 0x28,
+    MFU_MN_PORTOUT_NOP7_IN_0 = 0x29,
+    MFU_MN_PORTOUT_CLEAR_IN_0 = 0x2a,
+} MFU_MN_PORTOUT;
+
+std::ostream &operator<<(std::ostream &out, const MFU_MN_PORTOUT &c);
+
+/**
+    MFU.CROP.RESIZE
+    @brief
+    - biliner : 0x0(0)  双线性插值
+    - nearest : 0x1(1)  最邻近插值
+**/
+typedef enum mfu_crop_resize_t : uint8_t
+{
+    MFU_CROP_RESIZE_BILINER = 0x0, /* 0:双线性插值*/
+    MFU_CROP_RESIZE_NEAREST = 0x1 /* 1:最邻近插值*/
+} MFU_CROP_RESIZE;
+
+std::ostream &operator<<(std::ostream &out, const MFU_CROP_RESIZE &c);
+
+/**
+    TCU_MODE
+    @brief
+    - CONV : 0x0(0)  CONV
+    - DEPTHWISECONV : 0x1(1)  DEPTHWISECONV
+    - DECONV : 0x2(2)  DECONV
+    - MATMUL : 0x3(3)  MATMUL
+**/
+typedef enum tcu_mode_t : uint8_t
+{
+    TCU_MODE_CONV = 0x0, /* 0:CONV*/
+    TCU_MODE_DEPTHWISECONV = 0x1, /* 1:DEPTHWISECONV*/
+    TCU_MODE_DECONV = 0x2, /* 2:DECONV*/
+    TCU_MODE_MATMUL = 0x3 /* 3:MATMUL*/
+} TCU_MODE;
+
+std::ostream &operator<<(std::ostream &out, const TCU_MODE &c);
+
+/**
+    OPCODE
+    @brief
+    - NOP : 0x0(0)  NOP
+    - LI : 0x1(1)  LI
+    - INTR : 0x2(2)  INTR
+    - END : 0x3(3)  END
+    - FENCE : 0x4(4)  FENCE
+    - MMU.CONF : 0x5(5)  MMU.CONF
+    - FENCE.CCR : 0x8(8)  FENCE.CCR
+    - LOADIF.CONFIG : 0x10(16)  LOADIF.CONFIG
+    - LOADIF : 0x11(17)  LOADIF
+    - LOAD : 0x12(18)  LOAD
+    - LOAD.R : 0x13(19)  LOAD.R
+    - LOADIF.COMPRESS.CONF : 0x14(20)  LOADIF.COMPRESS.CONF
+    - LOAD.COMPRESS.CONF : 0x15(21)  LOAD.COMPRESS.CONF
+    - STORE : 0x20(32)  STORE
+    - STORE.T.CONFIG : 0x21(33)  STORE.T.CONFIG
+    - STORE.T : 0x22(34)  STORE.T
+    - STORE.R : 0x23(35)  STORE.R
+    - STORE.T.COMPRESS.CONF : 0x24(36)  STORE.T.COMPRESS.CONF
+    - STORE.COMPRESS.CONF : 0x25(37)  STORE.COMPRESS.CONF
+    - TCU.DM.BROADCAST : 0x41(65)  TCU.DM.BROADCAST
+    - TCU.DM.CONF.IF : 0x42(66)  TCU.DM.CONF.IF
+    - TCU.DM.FETCHIF : 0x43(67)  TCU.DM.FETCHIF
+    - TCU.DM.CONF.W : 0x44(68)  TCU.DM.CONF.W
+    - TCU.DM.FETCHW : 0x45(69)  TCU.DM.FETCHW
+    - TCU.DM.CONF.OF : 0x46(70)  TCU.DM.CONF.OF
+    - TCU.PU.CONF : 0x47(71)  TCU.PU.CONF
+    - TCU.PU.CONF.ACT : 0x48(72)  TCU.PU.CONF.ACT
+    - TCU.PU.COMPUTE : 0x49(73)  TCU.PU.COMPUTE
+    - TCU.DOT.DM.IF.CONF : 0x4a(74)  TCU.DOT.DM.IF.CONF
+    - TCU.DOT.DM.OF.CONF : 0x4b(75)  TCU.DOT.DM.OF.CONF
+    - TCU.DOT.DM.FETCH.SRC1 : 0x4c(76)  TCU.DOT.DM.FETCH.SRC1
+    - TCU.DOT.DM.FETCH.SRC2 : 0x4d(77)  TCU.DOT.DM.FETCH.SRC2
+    - TCU.DM.QARG.CONF : 0x4e(78)  TCU.DM.QARG.CONF
+    - TCU.PU.COMPUTE.DUMMY : 0x4f(79)  TCU.PU.COMPUTE.DUMMY
+    - MFU.MN.MAP.COMPUTE : 0x81(129)  MFU.MN.MAP.COMPUTE
+    - MFU.MN.VMAP.COMPUTE : 0x82(130)  MFU.MN.VMAP.COMPUTE
+    - MFU.REDUCE : 0x83(131)  MFU.REDUCE
+    - MFU.VREDUCE : 0x84(132)  MFU.VREDUCE
+    - MFU.MN.BROADCAST.COMPUTE : 0x85(133)  MFU.MN.BROADCAST.COMPUTE
+    - MFU.MN.REDUCE : 0x86(134)  MFU.MN.REDUCE
+    - MFU.MN.CONF : 0x87(135)  MFU.MN.CONF
+    - MFU.MNOP.CONF : 0x88(136)  MFU.MNOP.CONF
+    - MFU.PDP.CONF : 0x89(137)  MFU.PDP.CONF
+    - MFU.PDP.SRC.CONF : 0x8a(138)  MFU.PDP.SRC.CONF
+    - MFU.PDP.REDUCE : 0x8b(139)  MFU.PDP.REDUCE
+    - MFU.MN.BROADCAST.CONF : 0x8c(140)  MFU.MN.BROADCAST.CONF
+    - MFU.CROP : 0x8d(141)  MFU.CROP
+    - MFU.MEMSET : 0x8e(142)  MFU.MEMSET
+    - MFU.MEMCPY : 0x8f(143)  MFU.MEMCPY
+    - MFU.TRANS : 0x90(144)  MFU.TRANS
+    - MFU.MN.CONF2 : 0x91(145)  MFU.MN.CONF2
+**/
+typedef enum opcode_t : uint8_t
+{
+    OPCODE_NOP = 0x0, /* 0:NOP*/
+    OPCODE_LI = 0x1, /* 1:LI*/
+    OPCODE_INTR = 0x2, /* 2:INTR*/
+    OPCODE_END = 0x3, /* 3:END*/
+    OPCODE_FENCE = 0x4, /* 4:FENCE*/
+    OPCODE_MMU_CONF = 0x5, /* 5:MMU.CONF*/
+    OPCODE_FENCE_CCR = 0x8, /* 8:FENCE.CCR*/
+    OPCODE_LOADIF_CONFIG = 0x10, /* 16:LOADIF.CONFIG*/
+    OPCODE_LOADIF = 0x11, /* 17:LOADIF*/
+    OPCODE_LOAD = 0x12, /* 18:LOAD*/
+    OPCODE_LOAD_R = 0x13, /* 19:LOAD.R*/
+    OPCODE_LOADIF_COMPRESS_CONF = 0x14, /* 20:LOADIF.COMPRESS.CONF*/
+    OPCODE_LOAD_COMPRESS_CONF = 0x15, /* 21:LOAD.COMPRESS.CONF*/
+    OPCODE_STORE = 0x20, /* 32:STORE*/
+    OPCODE_STORE_T_CONFIG = 0x21, /* 33:STORE.T.CONFIG*/
+    OPCODE_STORE_T = 0x22, /* 34:STORE.T*/
+    OPCODE_STORE_R = 0x23, /* 35:STORE.R*/
+    OPCODE_STORE_T_COMPRESS_CONF = 0x24, /* 36:STORE.T.COMPRESS.CONF*/
+    OPCODE_STORE_COMPRESS_CONF = 0x25, /* 37:STORE.COMPRESS.CONF*/
+    OPCODE_TCU_DM_BROADCAST = 0x41, /* 65:TCU.DM.BROADCAST*/
+    OPCODE_TCU_DM_CONF_IF = 0x42, /* 66:TCU.DM.CONF.IF*/
+    OPCODE_TCU_DM_FETCHIF = 0x43, /* 67:TCU.DM.FETCHIF*/
+    OPCODE_TCU_DM_CONF_W = 0x44, /* 68:TCU.DM.CONF.W*/
+    OPCODE_TCU_DM_FETCHW = 0x45, /* 69:TCU.DM.FETCHW*/
+    OPCODE_TCU_DM_CONF_OF = 0x46, /* 70:TCU.DM.CONF.OF*/
+    OPCODE_TCU_PU_CONF = 0x47, /* 71:TCU.PU.CONF*/
+    OPCODE_TCU_PU_CONF_ACT = 0x48, /* 72:TCU.PU.CONF.ACT*/
+    OPCODE_TCU_PU_COMPUTE = 0x49, /* 73:TCU.PU.COMPUTE*/
+    OPCODE_TCU_DOT_DM_IF_CONF = 0x4a, /* 74:TCU.DOT.DM.IF.CONF*/
+    OPCODE_TCU_DOT_DM_OF_CONF = 0x4b, /* 75:TCU.DOT.DM.OF.CONF*/
+    OPCODE_TCU_DOT_DM_FETCH_SRC1 = 0x4c, /* 76:TCU.DOT.DM.FETCH.SRC1*/
+    OPCODE_TCU_DOT_DM_FETCH_SRC2 = 0x4d, /* 77:TCU.DOT.DM.FETCH.SRC2*/
+    OPCODE_TCU_DM_QARG_CONF = 0x4e, /* 78:TCU.DM.QARG.CONF*/
+    OPCODE_TCU_PU_COMPUTE_DUMMY = 0x4f, /* 79:TCU.PU.COMPUTE.DUMMY*/
+    OPCODE_MFU_MN_MAP_COMPUTE = 0x81, /* 129:MFU.MN.MAP.COMPUTE*/
+    OPCODE_MFU_MN_VMAP_COMPUTE = 0x82, /* 130:MFU.MN.VMAP.COMPUTE*/
+    OPCODE_MFU_REDUCE = 0x83, /* 131:MFU.REDUCE*/
+    OPCODE_MFU_VREDUCE = 0x84, /* 132:MFU.VREDUCE*/
+    OPCODE_MFU_MN_BROADCAST_COMPUTE = 0x85, /* 133:MFU.MN.BROADCAST.COMPUTE*/
+    OPCODE_MFU_MN_REDUCE = 0x86, /* 134:MFU.MN.REDUCE*/
+    OPCODE_MFU_MN_CONF = 0x87, /* 135:MFU.MN.CONF*/
+    OPCODE_MFU_MNOP_CONF = 0x88, /* 136:MFU.MNOP.CONF*/
+    OPCODE_MFU_PDP_CONF = 0x89, /* 137:MFU.PDP.CONF*/
+    OPCODE_MFU_PDP_SRC_CONF = 0x8a, /* 138:MFU.PDP.SRC.CONF*/
+    OPCODE_MFU_PDP_REDUCE = 0x8b, /* 139:MFU.PDP.REDUCE*/
+    OPCODE_MFU_MN_BROADCAST_CONF = 0x8c, /* 140:MFU.MN.BROADCAST.CONF*/
+    OPCODE_MFU_CROP = 0x8d, /* 141:MFU.CROP*/
+    OPCODE_MFU_MEMSET = 0x8e, /* 142:MFU.MEMSET*/
+    OPCODE_MFU_MEMCPY = 0x8f, /* 143:MFU.MEMCPY*/
+    OPCODE_MFU_TRANS = 0x90, /* 144:MFU.TRANS*/
+    OPCODE_MFU_MN_CONF2 = 0x91 /* 145:MFU.MN.CONF2*/
+} OPCODE;
+
+std::ostream &operator<<(std::ostream &out, const OPCODE &c);
+
+/**
+    MFU.CROP.ALIGN
+    @brief
+    - none : 0x0(0)  tensorflow align_corner=false
+    - corner : 0x1(1)  tensorflow align_corner=True
+    - center : 0x2(2)  open cv，中心对齐
+**/
+typedef enum mfu_crop_align_t : uint8_t
+{
+    MFU_CROP_ALIGN_NONE = 0x0, /* 0:tensorflow align_corner=false*/
+    MFU_CROP_ALIGN_CORNER = 0x1, /* 1:tensorflow align_corner=True*/
+    MFU_CROP_ALIGN_CENTER = 0x2 /* 2:open cv，中心对齐*/
+} MFU_CROP_ALIGN;
+
+std::ostream &operator<<(std::ostream &out, const MFU_CROP_ALIGN &c);
+
+/**
+    BROADCAST
+    @brief
+    - SINGLE : 0x0(0)  单播
+    - BROADCAST : 0x1(1)  广播
+**/
+typedef enum broadcast_t : uint8_t
+{
+    BROADCAST_SINGLE = 0x0, /* 0:单播*/
+    BROADCAST_BROADCAST = 0x1 /* 1:广播*/
+} BROADCAST;
+
+std::ostream &operator<<(std::ostream &out, const BROADCAST &c);
+
+/////////////////////////////////////
+// auto generated inst pack
+/**
+    NOP
+    @brief 无操作
+    - OPCODE opcode : 8  无操作
+**/
+struct INST_NOP
+{
+    OPCODE opcode : 8; /** 无操作 **/
+
+    void serialize(bitwriter &bw) const { bw.write<8>(opcode); }
+
+    void deserialize(bitreader &br) { opcode = br.read<decltype(opcode), 8>(); }
+};
+
+/**
+    LI
+    @brief Load 一个 64bit 的立即数到指定的寄存器
+    - OPCODE opcode : 8  Load 一个 64bit 的立即数到指定的寄存器
+    - REG regid : 5  寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==}
+    - uint64_t imm : 64  立即数
+**/
+struct INST_LI
+{
+    OPCODE opcode : 8; /** Load 一个 64bit 的立即数到指定的寄存器 **/
+    REG regid : 5; /** 寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==} **/
+    uint64_t imm : 64; /** 立即数 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<5>(regid);
+        bw.write<64>(imm);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        regid = br.read<decltype(regid), 5>();
+        imm = br.read<decltype(imm), 64>();
+    }
+};
+
+/**
+    INTR
+    @brief 触发向DSP的软中断
+    - OPCODE opcode : 8  触发向DSP的软中断
+    - uint64_t intr_number : 32  中断号，用于设置inptr寄存器
+    - uint64_t regmask : 32  标记哪些寄存器被用于传参，用于设置regmask寄存器
+    - uint64_t ptrmask : 32
+标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器
+**/
+struct INST_INTR
+{
+    OPCODE opcode : 8; /** 触发向DSP的软中断 **/
+    uint64_t intr_number : 32; /** 中断号，用于设置inptr寄存器 **/
+    uint64_t regmask : 32; /** 标记哪些寄存器被用于传参，用于设置regmask寄存器 **/
+    uint64_t ptrmask : 32; /**
+                            标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器
+                            **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(intr_number);
+        bw.write<32>(regmask);
+        bw.write<32>(ptrmask);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        intr_number = br.read<decltype(intr_number), 32>();
+        regmask = br.read<decltype(regmask), 32>();
+        ptrmask = br.read<decltype(ptrmask), 32>();
+    }
+};
+
+/**
+    END
+    @brief 表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+    - OPCODE opcode : 8  表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+    - uint64_t intr_number : 32  中断号，用于设置inptr寄存器
+**/
+struct INST_END
+{
+    OPCODE opcode : 8; /** 表示GNNE程序执行结束，GNNE向总中断控制器发起中断 **/
+    uint64_t intr_number : 32; /** 中断号，用于设置inptr寄存器 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(intr_number);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        intr_number = br.read<decltype(intr_number), 32>();
+    }
+};
+
+/**
+    FENCE
+    @brief 设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+    - OPCODE opcode : 8
+设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+**/
+struct INST_FENCE
+{
+    OPCODE opcode : 8; /**
+                        设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+                        **/
+
+    void serialize(bitwriter &bw) const { bw.write<8>(opcode); }
+
+    void deserialize(bitreader &br) { opcode = br.read<decltype(opcode), 8>(); }
+};
+
+/**
+    MMU.CONF
+    @brief 配置某条MMU规则
+    - OPCODE opcode : 8  配置某条MMU规则
+    - uint64_t mmu_item : 4  当前配置的MMU规则项编号，0-15
+    - uint64_t start_bank : 3  当前规则开始的bank
+    - MMU_CONF_WIDTH width : 2  当前配置宽度信息
+    - uint64_t start_depth : 14  当前规则开始的纵坐标
+    - uint64_t depth : 14
+当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+**/
+struct INST_MMU_CONF
+{
+    OPCODE opcode : 8; /** 配置某条MMU规则 **/
+    uint64_t mmu_item : 4; /** 当前配置的MMU规则项编号，0-15 **/
+    uint64_t start_bank : 3; /** 当前规则开始的bank **/
+    MMU_CONF_WIDTH width : 2; /** 当前配置宽度信息 **/
+    uint64_t start_depth : 14; /** 当前规则开始的纵坐标 **/
+    uint64_t depth : 14; /**
+                                当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+                                **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(mmu_item);
+        bw.write<3>(start_bank);
+        bw.write<2>(width);
+        bw.write<14>(start_depth);
+        bw.write<14>(depth);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        mmu_item = br.read<decltype(mmu_item), 4>();
+        start_bank = br.read<decltype(start_bank), 3>();
+        width = br.read<decltype(width), 2>();
+        start_depth = br.read<decltype(start_depth), 14>();
+        depth = br.read<decltype(depth), 14>();
+    }
+};
+
+/**
+    FENCE.CCR
+    @brief
+CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+    - OPCODE opcode : 8
+CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+    - uint64_t ccr : 6  CCR寄存器id
+    - uint64_t mode : 1  0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr
+**/
+struct INST_FENCE_CCR
+{
+    OPCODE opcode : 8; /**
+                        CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+                        **/
+    uint64_t ccr : 6; /** CCR寄存器id **/
+    uint64_t mode : 1; /** 0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<6>(ccr);
+        bw.write<1>(mode);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccr = br.read<decltype(ccr), 6>();
+        mode = br.read<decltype(mode), 1>();
+    }
+};
+
+/**
+    LOADIF.CONFIG
+    @brief 用于配置从 DDR 中加载 input featuremap 的一些基础参数
+    - OPCODE opcode : 8  用于配置从 DDR 中加载 input featuremap 的一些基础参数
+    - uint64_t layout_ddr_n : 16  输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_c : 16  输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_h : 16  输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_w : 16  输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - STRIDE_GLB stride_glb : 64  输出 Tensor 的尺寸信息，用于计算输出地址跳转
+    - uint64_t mmu_item : 4  使用的内存映射方案
+    - ADDR_GLB_8_WITH_BANK addr_qarg : 25  量化参数地址
+    - QUAN_SIGNED input_signed : 1  量化数据是否是有符号数据
+    - PRECISION precision_glb : 2  GLB中数据的类型
+    - PRECISION_DDR precision_ddr : 3  DDR 中的数据类型
+    - QUAN_TYPE quan_type : 1  量化类型，bychennel or by batch
+**/
+struct INST_LOADIF_CONFIG
+{
+    OPCODE
+    opcode : 8; /** 用于配置从 DDR 中加载 input featuremap 的一些基础参数 **/
+    uint64_t
+        layout_ddr_n : 16; /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t
+        layout_ddr_c : 16; /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t
+        layout_ddr_h : 16; /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t
+        layout_ddr_w : 16; /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t stride_glb : 64; /** 输出 Tensor 的尺寸信息，用于计算输出地址跳转 **/
+    uint64_t mmu_item : 4; /** 使用的内存映射方案 **/
+    uint64_t addr_qarg : 25; /** 量化参数地址 **/
+    QUAN_SIGNED input_signed : 1; /** 量化数据是否是有符号数据 **/
+    PRECISION precision_glb : 2; /** GLB中数据的类型  **/
+    PRECISION_DDR precision_ddr : 3; /** DDR 中的数据类型 **/
+    QUAN_TYPE quan_type : 1; /** 量化类型，bychennel or by batch **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<16>(layout_ddr_n);
+        bw.write<16>(layout_ddr_c);
+        bw.write<16>(layout_ddr_h);
+        bw.write<16>(layout_ddr_w);
+        bw.write<64>(stride_glb);
+        bw.write<4>(mmu_item);
+        bw.write<25>(addr_qarg);
+        bw.write<1>(input_signed);
+        bw.write<2>(precision_glb);
+        bw.write<3>(precision_ddr);
+        bw.write<1>(quan_type);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        layout_ddr_n = br.read<decltype(layout_ddr_n), 16>();
+        layout_ddr_c = br.read<decltype(layout_ddr_c), 16>();
+        layout_ddr_h = br.read<decltype(layout_ddr_h), 16>();
+        layout_ddr_w = br.read<decltype(layout_ddr_w), 16>();
+        stride_glb = br.read<decltype(stride_glb), 64>();
+        mmu_item = br.read<decltype(mmu_item), 4>();
+        addr_qarg = br.read<decltype(addr_qarg), 25>();
+        input_signed = br.read<decltype(input_signed), 1>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+        precision_ddr = br.read<decltype(precision_ddr), 3>();
+        quan_type = br.read<decltype(quan_type), 1>();
+    }
+};
+
+/**
+    LOADIF
+    @brief 从 DDR 中加载张量到 GLB 中
+    - OPCODE opcode : 8  从 DDR 中加载张量到 GLB 中
+    - CCRCLR ccrclr : 8  None
+    - CCRCLR ccrclr_qarg : 8  None
+    - CCRSET ccrset : 11  数据依赖配置
+    - ADDR addr_src : 32  DDR 中 张量当前数据 的起始地址。
+    - ADDR_GLB_8_WITHOUT_BANK addr_dest : 21  存储到 GLB 中的地址
+    - uint64_t shape_n : 16  取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_c : 16  取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_h : 16  取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_w : 16  取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t basement : 2  DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+**/
+struct INST_LOADIF
+{
+    OPCODE opcode : 8; /** 从 DDR 中加载张量到 GLB 中 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrclr_qarg : 8; /** None **/
+    uint64_t ccrset : 11; /** 数据依赖配置 **/
+    ADDR addr_src : 32; /** DDR 中 张量当前数据 的起始地址。 **/
+    uint64_t addr_dest : 21; /** 存储到 GLB 中的地址 **/
+    uint64_t shape_n : 16; /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_c : 16; /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_h : 16; /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_w : 16; /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t basement : 2; /** DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<8>(ccrclr_qarg);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<21>(addr_dest);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<2>(basement);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrclr_qarg = br.read<decltype(ccrclr_qarg), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 21>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        basement = br.read<decltype(basement), 2>();
+    }
+};
+
+/**
+    LOAD
+    @brief 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+指定的位置上，可用来加载 weights 和其他数据
+    - OPCODE opcode : 8  从 DDR 中加载一段给定长度的一维数据数据到 GLB
+指定的位置上，可用来加载 weights 和其他数据
+    - CCRCLR ccrclr : 8  None
+    - CCRCLR ccrclr_qarg : 8  None
+    - CCRSET ccrset : 11  数据依赖配置
+    - ADDR addr_src : 32  DDR 中数据的地址
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  GLB 中的地址
+    - uint64_t length : 21  数据的长度
+    - ADDR_GLB_8_WITH_BANK addr_qarg : 25  量化参数地
+    - uint64_t chan_qarg : 16  每个量化参数持续作用的个数
+    - uint64_t shape_c : 16
+量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+    - uint64_t basement : 2  DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+    - QUAN_SIGNED input_signed : 1  None
+    - PRECISION precision_glb : 2  GLB中数据的类型
+    - PRECISION_DDR precision_ddr : 3  DDR 中的数据类型
+    - uint64_t stream : 1  是否为流式输入
+**/
+struct INST_LOAD
+{
+    OPCODE opcode : 8; /** 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+                        指定的位置上，可用来加载 weights 和其他数据 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrclr_qarg : 8; /** None **/
+    uint64_t ccrset : 11; /** 数据依赖配置 **/
+    ADDR addr_src : 32; /** DDR 中数据的地址 **/
+    uint64_t addr_dest : 25; /** GLB 中的地址 **/
+    uint64_t length : 21; /** 数据的长度 **/
+    uint64_t addr_qarg : 25; /** 量化参数地 **/
+    uint64_t chan_qarg : 16; /** 每个量化参数持续作用的个数 **/
+    uint64_t shape_c : 16; /**
+                                   量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+                                   **/
+    uint64_t basement : 2; /** DDR寻址偏移寄存器编号。
+  DDR访问的地址需要加上这个寄存器指示的寄存器的值 **/
+    QUAN_SIGNED input_signed : 1; /** None **/
+    PRECISION precision_glb : 2; /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr : 3; /** DDR 中的数据类型 **/
+    uint64_t stream : 1; /** 是否为流式输入 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<8>(ccrclr_qarg);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<25>(addr_dest);
+        bw.write<21>(length);
+        bw.write<25>(addr_qarg);
+        bw.write<16>(chan_qarg);
+        bw.write<16>(shape_c);
+        bw.write<2>(basement);
+        bw.write<1>(input_signed);
+        bw.write<2>(precision_glb);
+        bw.write<3>(precision_ddr);
+        bw.write<1>(stream);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrclr_qarg = br.read<decltype(ccrclr_qarg), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        length = br.read<decltype(length), 21>();
+        addr_qarg = br.read<decltype(addr_qarg), 25>();
+        chan_qarg = br.read<decltype(chan_qarg), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        basement = br.read<decltype(basement), 2>();
+        input_signed = br.read<decltype(input_signed), 1>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+        precision_ddr = br.read<decltype(precision_ddr), 3>();
+        stream = br.read<decltype(stream), 1>();
+    }
+};
+
+/**
+    LOADIF.COMPRESS.CONF
+    @brief 配置loadif的稀疏、压缩、参数
+    - OPCODE opcode : 8  配置loadif的稀疏、压缩、参数
+    - ADDR addr_bmp : 32  bitmap的地址
+    - ADDR addr_code_len : 32  每一行编码之后的长度存放的地址
+    - ADDR addr_block_len : 32  码块编码之后长度的存放地址
+    - uint64_t code_lines : 4  每次编码的行数
+    - SPARSIFIED sparsified_ddr : 1  是否稀疏
+    - COMPRESSED compress_ddr : 1  是否压缩
+**/
+struct INST_LOADIF_COMPRESS_CONF
+{
+    OPCODE opcode : 8; /** 配置loadif的稀疏、压缩、参数 **/
+    ADDR addr_bmp : 32; /** bitmap的地址 **/
+    ADDR addr_code_len : 32; /** 每一行编码之后的长度存放的地址 **/
+    ADDR addr_block_len : 32; /** 码块编码之后长度的存放地址 **/
+    uint64_t code_lines : 4; /** 每次编码的行数 **/
+    SPARSIFIED sparsified_ddr : 1; /** 是否稀疏 **/
+    COMPRESSED compress_ddr : 1; /** 是否压缩 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(addr_bmp);
+        bw.write<32>(addr_code_len);
+        bw.write<32>(addr_block_len);
+        bw.write<4>(code_lines);
+        bw.write<1>(sparsified_ddr);
+        bw.write<1>(compress_ddr);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        addr_bmp = br.read<decltype(addr_bmp), 32>();
+        addr_code_len = br.read<decltype(addr_code_len), 32>();
+        addr_block_len = br.read<decltype(addr_block_len), 32>();
+        code_lines = br.read<decltype(code_lines), 4>();
+        sparsified_ddr = br.read<decltype(sparsified_ddr), 1>();
+        compress_ddr = br.read<decltype(compress_ddr), 1>();
+    }
+};
+
+/**
+    LOAD.COMPRESS.CONF
+    @brief 配置load的稀疏、压缩、参数
+    - OPCODE opcode : 8  配置load的稀疏、压缩、参数
+    - ADDR addr_bmp : 32  bitmap的地址
+    - ADDR addr_code_len : 32  每一行编码之后的长度存放的地址
+    - SPARSIFIED sparsified_ddr : 1  是否稀疏
+**/
+struct INST_LOAD_COMPRESS_CONF
+{
+    OPCODE opcode : 8; /** 配置load的稀疏、压缩、参数 **/
+    ADDR addr_bmp : 32; /** bitmap的地址 **/
+    ADDR addr_code_len : 32; /** 每一行编码之后的长度存放的地址 **/
+    SPARSIFIED sparsified_ddr : 1; /** 是否稀疏 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(addr_bmp);
+        bw.write<32>(addr_code_len);
+        bw.write<1>(sparsified_ddr);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        addr_bmp = br.read<decltype(addr_bmp), 32>();
+        addr_code_len = br.read<decltype(addr_code_len), 32>();
+        sparsified_ddr = br.read<decltype(sparsified_ddr), 1>();
+    }
+};
+
+/**
+    STORE
+    @brief 将 GLB 中的给定长度的一维数据写回 DDR
+    - OPCODE opcode : 8  将 GLB 中的给定长度的一维数据写回 DDR
+    - CCRCLR ccrclr : 8  数据依赖配置
+    - CCRCLR ccrclr_qarg : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_src : 25  数据在 GLB 中的起始位置
+    - ADDR addr_dest : 32  输出到 DDR 的位置
+    - PRECISION precision_glb : 2  GLB中数据的类型
+    - PRECISION_DDR precision_ddr : 3  输出数据精度
+    - QUAN_SIGNED output_signed : 1  量化数据是否是有符号数据
+    - uint64_t length : 21  数据长度
+    - ADDR_GLB_8_WITH_BANK addr_qarg : 25  量化参数地
+    - uint64_t chan_qarg : 16  每个量化参数持续作用的个数
+    - uint64_t shape_c : 16
+量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+    - uint64_t clamp_hi : 16  None
+    - uint64_t clamp_lo : 16  None
+    - uint64_t basement : 2  DDR寻址偏移寄存器编号
+**/
+struct INST_STORE
+{
+    OPCODE opcode : 8; /** 将 GLB 中的给定长度的一维数据写回 DDR **/
+    uint64_t ccrclr : 8; /** 数据依赖配置 **/
+    uint64_t ccrclr_qarg : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 25; /** 数据在 GLB 中的起始位置 **/
+    ADDR addr_dest : 32; /** 输出到 DDR 的位置 **/
+    PRECISION precision_glb : 2; /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr : 3; /** 输出数据精度 **/
+    QUAN_SIGNED output_signed : 1; /** 量化数据是否是有符号数据 **/
+    uint64_t length : 21; /** 数据长度 **/
+    uint64_t addr_qarg : 25; /** 量化参数地 **/
+    uint64_t chan_qarg : 16; /** 每个量化参数持续作用的个数 **/
+    uint64_t shape_c : 16; /**
+                              量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+                              **/
+    uint64_t clamp_hi : 16; /** None **/
+    uint64_t clamp_lo : 16; /** None **/
+    uint64_t basement : 2; /** DDR寻址偏移寄存器编号 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<8>(ccrclr_qarg);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<2>(precision_glb);
+        bw.write<3>(precision_ddr);
+        bw.write<1>(output_signed);
+        bw.write<21>(length);
+        bw.write<25>(addr_qarg);
+        bw.write<16>(chan_qarg);
+        bw.write<16>(shape_c);
+        bw.write<16>(clamp_hi);
+        bw.write<16>(clamp_lo);
+        bw.write<2>(basement);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrclr_qarg = br.read<decltype(ccrclr_qarg), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 25>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+        precision_ddr = br.read<decltype(precision_ddr), 3>();
+        output_signed = br.read<decltype(output_signed), 1>();
+        length = br.read<decltype(length), 21>();
+        addr_qarg = br.read<decltype(addr_qarg), 25>();
+        chan_qarg = br.read<decltype(chan_qarg), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        clamp_hi = br.read<decltype(clamp_hi), 16>();
+        clamp_lo = br.read<decltype(clamp_lo), 16>();
+        basement = br.read<decltype(basement), 2>();
+    }
+};
+
+/**
+    STORE.T.CONFIG
+    @brief 将 GLB 中 Tensor 的数据写回 DDR 的配置
+    - OPCODE opcode : 8  将 GLB 中 Tensor 的数据写回 DDR 的配置
+    - uint64_t layout_ddr_n : 16  DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_c : 16  DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_h : 16  DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_w : 16  DDR中的Tensor的尺寸信息，用用计算跳转
+    - STRIDE_GLB stride_glb : 64  GLB中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t mmu_item : 4  使用的内存映射方案
+    - ADDR_GLB_8_WITH_BANK addr_qarg : 25  量化参数地址
+    - QUAN_SIGNED output_signed : 1  量化数据是否是有符号数据
+    - PRECISION precision_glb : 2  GLB中数据的类型
+    - PRECISION_DDR precision_ddr : 3  输出数据精度
+    - QUAN_TYPE quan_type : 1  None
+    - uint64_t clamp_hi : 16  None
+    - uint64_t clamp_lo : 16  None
+**/
+struct INST_STORE_T_CONFIG
+{
+    OPCODE opcode : 8; /** 将 GLB 中 Tensor 的数据写回 DDR 的配置 **/
+    uint64_t layout_ddr_n : 16; /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_c : 16; /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_h : 16; /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_w : 16; /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t stride_glb : 64; /** GLB中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t mmu_item : 4; /** 使用的内存映射方案 **/
+    uint64_t addr_qarg : 25; /** 量化参数地址 **/
+    QUAN_SIGNED output_signed : 1; /** 量化数据是否是有符号数据 **/
+    PRECISION precision_glb : 2; /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr : 3; /** 输出数据精度 **/
+    QUAN_TYPE quan_type : 1; /** None **/
+    uint64_t clamp_hi : 16; /** None **/
+    uint64_t clamp_lo : 16; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<16>(layout_ddr_n);
+        bw.write<16>(layout_ddr_c);
+        bw.write<16>(layout_ddr_h);
+        bw.write<16>(layout_ddr_w);
+        bw.write<64>(stride_glb);
+        bw.write<4>(mmu_item);
+        bw.write<25>(addr_qarg);
+        bw.write<1>(output_signed);
+        bw.write<2>(precision_glb);
+        bw.write<3>(precision_ddr);
+        bw.write<1>(quan_type);
+        bw.write<16>(clamp_hi);
+        bw.write<16>(clamp_lo);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        layout_ddr_n = br.read<decltype(layout_ddr_n), 16>();
+        layout_ddr_c = br.read<decltype(layout_ddr_c), 16>();
+        layout_ddr_h = br.read<decltype(layout_ddr_h), 16>();
+        layout_ddr_w = br.read<decltype(layout_ddr_w), 16>();
+        stride_glb = br.read<decltype(stride_glb), 64>();
+        mmu_item = br.read<decltype(mmu_item), 4>();
+        addr_qarg = br.read<decltype(addr_qarg), 25>();
+        output_signed = br.read<decltype(output_signed), 1>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+        precision_ddr = br.read<decltype(precision_ddr), 3>();
+        quan_type = br.read<decltype(quan_type), 1>();
+        clamp_hi = br.read<decltype(clamp_hi), 16>();
+        clamp_lo = br.read<decltype(clamp_lo), 16>();
+    }
+};
+
+/**
+    STORE.T
+    @brief 将 GLB 中 Tensor 的数据写回 DDR，并且可能发生转置或者数据类型转换
+    - OPCODE opcode : 8  将 GLB 中 Tensor 的数据写回
+DDR，并且可能发生转置或者数据类型转换
+    - CCRCLR ccrclr : 8  数据依赖配置
+    - CCRCLR ccrclr_qarg : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITHOUT_BANK addr_src : 21  Tensor 在 GLB 中的起始位置
+    - ADDR addr_dest : 32  输出到 DDR 的位置
+    - uint64_t shape_n : 16  Slice 长度信息
+    - uint64_t shape_c : 16  Slice 长度信息
+    - uint64_t shape_h : 16  Slice 长度信息
+    - uint64_t shape_w : 16  Slice 长度信息
+    - uint64_t basement : 2  DDR寻址偏移寄存器编号
+**/
+struct INST_STORE_T
+{
+    OPCODE opcode : 8; /** 将 GLB 中 Tensor 的数据写回
+                               DDR，并且可能发生转置或者数据类型转换 **/
+    uint64_t ccrclr : 8; /** 数据依赖配置 **/
+    uint64_t ccrclr_qarg : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 21; /** Tensor 在 GLB 中的起始位置 **/
+    ADDR addr_dest : 32; /** 输出到 DDR 的位置 **/
+    uint64_t shape_n : 16; /** Slice 长度信息 **/
+    uint64_t shape_c : 16; /** Slice 长度信息 **/
+    uint64_t shape_h : 16; /** Slice 长度信息 **/
+    uint64_t shape_w : 16; /** Slice 长度信息 **/
+    uint64_t basement : 2; /** DDR寻址偏移寄存器编号 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<8>(ccrclr_qarg);
+        bw.write<11>(ccrset);
+        bw.write<21>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<2>(basement);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrclr_qarg = br.read<decltype(ccrclr_qarg), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 21>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        basement = br.read<decltype(basement), 2>();
+    }
+};
+
+/**
+    STORE.T.COMPRESS.CONF
+    @brief 配置store.t的稀疏、压缩、参数
+    - OPCODE opcode : 8  配置store.t的稀疏、压缩、参数
+    - ADDR addr_bmp : 32  bitmap的地址
+    - ADDR addr_code_len : 32  每一行编码之后的长度存放的地址
+    - ADDR addr_block_len : 32  码块编码之后长度的存放地址
+    - uint64_t code_lines : 4  每次编码的行数
+    - SPARSIFIED sparsified_ddr : 1  是否稀疏
+    - COMPRESSED compress_ddr : 1  是否压缩
+**/
+struct INST_STORE_T_COMPRESS_CONF
+{
+    OPCODE opcode : 8; /** 配置store.t的稀疏、压缩、参数 **/
+    ADDR addr_bmp : 32; /** bitmap的地址 **/
+    ADDR addr_code_len : 32; /** 每一行编码之后的长度存放的地址 **/
+    ADDR addr_block_len : 32; /** 码块编码之后长度的存放地址 **/
+    uint64_t code_lines : 4; /** 每次编码的行数 **/
+    SPARSIFIED sparsified_ddr : 1; /** 是否稀疏 **/
+    COMPRESSED compress_ddr : 1; /** 是否压缩 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(addr_bmp);
+        bw.write<32>(addr_code_len);
+        bw.write<32>(addr_block_len);
+        bw.write<4>(code_lines);
+        bw.write<1>(sparsified_ddr);
+        bw.write<1>(compress_ddr);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        addr_bmp = br.read<decltype(addr_bmp), 32>();
+        addr_code_len = br.read<decltype(addr_code_len), 32>();
+        addr_block_len = br.read<decltype(addr_block_len), 32>();
+        code_lines = br.read<decltype(code_lines), 4>();
+        sparsified_ddr = br.read<decltype(sparsified_ddr), 1>();
+        compress_ddr = br.read<decltype(compress_ddr), 1>();
+    }
+};
+
+/**
+    STORE.COMPRESS.CONF
+    @brief 配置store的稀疏、压缩、参数
+    - OPCODE opcode : 8  配置store的稀疏、压缩、参数
+    - ADDR addr_bmp : 32  bitmap的地址
+    - ADDR addr_code_len : 32  每一行编码之后的长度存放的地址
+    - SPARSIFIED sparsified_ddr : 1  是否稀疏
+**/
+struct INST_STORE_COMPRESS_CONF
+{
+    OPCODE opcode : 8; /** 配置store的稀疏、压缩、参数 **/
+    ADDR addr_bmp : 32; /** bitmap的地址 **/
+    ADDR addr_code_len : 32; /** 每一行编码之后的长度存放的地址 **/
+    SPARSIFIED sparsified_ddr : 1; /** 是否稀疏 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<32>(addr_bmp);
+        bw.write<32>(addr_code_len);
+        bw.write<1>(sparsified_ddr);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        addr_bmp = br.read<decltype(addr_bmp), 32>();
+        addr_code_len = br.read<decltype(addr_code_len), 32>();
+        sparsified_ddr = br.read<decltype(sparsified_ddr), 1>();
+    }
+};
+
+/**
+    TCU.DM.BROADCAST
+    @brief 配置DM是否在广播模式
+    - OPCODE opcode : 8  配置DM是否在广播模式
+    - BROADCAST broadcast_if : 1  配置input featuremap是否在广播模式
+    - BROADCAST broadcast_weight : 1  配置weight是否在广播模式
+    - uint64_t psum_cascade : 1  是否为psum级联模式（用来加速1*1卷积计算） 0：否
+4个TCU 1：是
+**/
+struct INST_TCU_DM_BROADCAST
+{
+    OPCODE opcode : 8; /** 配置DM是否在广播模式 **/
+    BROADCAST broadcast_if : 1; /** 配置input featuremap是否在广播模式 **/
+    BROADCAST broadcast_weight : 1; /** 配置weight是否在广播模式 **/
+    uint64_t psum_cascade : 1; /** 是否为psum级联模式（用来加速1*1卷积计算） 0：否
+                                4个TCU 1：是 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<1>(broadcast_if);
+        bw.write<1>(broadcast_weight);
+        bw.write<1>(psum_cascade);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        broadcast_if = br.read<decltype(broadcast_if), 1>();
+        broadcast_weight = br.read<decltype(broadcast_weight), 1>();
+        psum_cascade = br.read<decltype(psum_cascade), 1>();
+    }
+};
+
+/**
+    TCU.DM.CONF.IF
+    @brief 配置 FETCHIF 的一些基础信息
+    - OPCODE opcode : 8  配置 FETCHIF 的一些基础信息
+    - uint64_t tcu_id : 4  选择配置第几个TCU的DM
+    - STRIDE_GLB stride_input_glb : 64  GLB中大tensor的排布的信息，用于计算跳转
+    - uint64_t stride_w : 16  input featuremap 在 W 方向上的 stride
+    - uint64_t stride_h : 16  input featuremap 在 H 方向上的 stride
+    - uint64_t padding_top : 8  input featuremap 在 HxW 平面上顶部的 zero
+padding 行数
+    - uint64_t padding_bottom : 8  input featuremap 在 HxW 平面下底部的 zero
+padding 行数
+    - uint64_t padding_left : 8  input featuremap 在 HxW 平面左边的 zero padding
+列数
+    - uint64_t padding_right : 8  input featuremap 在 HxW 平面右边的 zero
+padding 列数
+    - uint64_t input_c_per_pu : 5  每个PU计算的输入通道数，根据高度映射除出来的
+    - uint64_t dilation_h : 8  input featuremap 的在 H 方向上的膨胀率
+    - uint64_t transpose_if : 1  是否对输入的 input featuremap 进行转置，仅在
+通道上有效
+    - uint64_t mmu_item : 4  使用的内存映射方案
+**/
+struct INST_TCU_DM_CONF_IF
+{
+    OPCODE opcode : 8; /** 配置 FETCHIF 的一些基础信息 **/
+    uint64_t tcu_id : 4; /** 选择配置第几个TCU的DM **/
+    uint64_t
+        stride_input_glb : 64; /** GLB中大tensor的排布的信息，用于计算跳转 **/
+    uint64_t stride_w : 16; /** input featuremap 在 W 方向上的 stride **/
+    uint64_t stride_h : 16; /** input featuremap 在 H 方向上的 stride **/
+    uint64_t padding_top : 8; /** input featuremap 在 HxW 平面上顶部的 zero
+                               padding 行数 **/
+    uint64_t padding_bottom : 8; /** input featuremap 在 HxW 平面下底部的 zero
+                                  padding 行数 **/
+    uint64_t padding_left : 8; /** input featuremap 在 HxW 平面左边的 zero padding
+                                列数 **/
+    uint64_t padding_right : 8; /** input featuremap 在 HxW 平面右边的 zero
+                                 padding 列数 **/
+    uint64_t
+        input_c_per_pu : 5; /** 每个PU计算的输入通道数，根据高度映射除出来的 **/
+    uint64_t dilation_h : 8; /** input featuremap 的在 H 方向上的膨胀率 **/
+    uint64_t transpose_if : 1; /** 是否对输入的 input featuremap 进行转置，仅在
+                                通道上有效 **/
+    uint64_t mmu_item : 4; /** 使用的内存映射方案 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<64>(stride_input_glb);
+        bw.write<16>(stride_w);
+        bw.write<16>(stride_h);
+        bw.write<8>(padding_top);
+        bw.write<8>(padding_bottom);
+        bw.write<8>(padding_left);
+        bw.write<8>(padding_right);
+        bw.write<5>(input_c_per_pu);
+        bw.write<8>(dilation_h);
+        bw.write<1>(transpose_if);
+        bw.write<4>(mmu_item);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        stride_input_glb = br.read<decltype(stride_input_glb), 64>();
+        stride_w = br.read<decltype(stride_w), 16>();
+        stride_h = br.read<decltype(stride_h), 16>();
+        padding_top = br.read<decltype(padding_top), 8>();
+        padding_bottom = br.read<decltype(padding_bottom), 8>();
+        padding_left = br.read<decltype(padding_left), 8>();
+        padding_right = br.read<decltype(padding_right), 8>();
+        input_c_per_pu = br.read<decltype(input_c_per_pu), 5>();
+        dilation_h = br.read<decltype(dilation_h), 8>();
+        transpose_if = br.read<decltype(transpose_if), 1>();
+        mmu_item = br.read<decltype(mmu_item), 4>();
+    }
+};
+
+/**
+    TCU.DM.FETCHIF
+    @brief 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+    - OPCODE opcode : 8  从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+    - CCRCLR ccrclr_if : 8  None
+    - uint64_t tcu_id : 4  TCU ID
+    - ADDR_GLB_8_WITHOUT_BANK addr_if : 21  输入slice的起始地址
+    - uint64_t shape_input_n : 16  当前计算输入Slice的形状信息
+    - uint64_t shape_input_c : 16  当前计算输入Slice的形状信息
+    - uint64_t shape_input_h : 16  当前计算输入Slice的形状信息
+    - uint64_t shape_input_w : 16  当前计算输入Slice的形状信息
+**/
+struct INST_TCU_DM_FETCHIF
+{
+    OPCODE opcode : 8; /** 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+                        **/
+    uint64_t ccrclr_if : 8; /** None **/
+    uint64_t tcu_id : 4; /** TCU ID **/
+    uint64_t addr_if : 21; /** 输入slice的起始地址 **/
+    uint64_t shape_input_n : 16; /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_c : 16; /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_h : 16; /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_w : 16; /** 当前计算输入Slice的形状信息 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_if);
+        bw.write<4>(tcu_id);
+        bw.write<21>(addr_if);
+        bw.write<16>(shape_input_n);
+        bw.write<16>(shape_input_c);
+        bw.write<16>(shape_input_h);
+        bw.write<16>(shape_input_w);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_if = br.read<decltype(ccrclr_if), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        addr_if = br.read<decltype(addr_if), 21>();
+        shape_input_n = br.read<decltype(shape_input_n), 16>();
+        shape_input_c = br.read<decltype(shape_input_c), 16>();
+        shape_input_h = br.read<decltype(shape_input_h), 16>();
+        shape_input_w = br.read<decltype(shape_input_w), 16>();
+    }
+};
+
+/**
+    TCU.DM.CONF.W
+    @brief 配置 TCU 读取 weights 时的行为
+    - OPCODE opcode : 8  配置 TCU 读取 weights 时的行为
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - uint64_t mmu_item : 4  使用的内存映射方案
+    - uint64_t load_direction : 1  是否对输入的 input featuremap
+进行转置，仅在HxW通道上有效
+**/
+struct INST_TCU_DM_CONF_W
+{
+    OPCODE opcode : 8; /** 配置 TCU 读取 weights 时的行为 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t mmu_item : 4; /** 使用的内存映射方案 **/
+    uint64_t load_direction : 1; /** 是否对输入的 input featuremap
+                                  进行转置，仅在HxW通道上有效 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<4>(mmu_item);
+        bw.write<1>(load_direction);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        mmu_item = br.read<decltype(mmu_item), 4>();
+        load_direction = br.read<decltype(load_direction), 1>();
+    }
+};
+
+/**
+    TCU.DM.FETCHW
+    @brief 从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+    - OPCODE opcode : 8  从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+    - CCRCLR ccrclr_weight : 8  数据依赖配置
+    - uint64_t tcu_id : 4  TCU ID
+    - ADDR_GLB_8_WITHOUT_BANK addr_src : 21  GLB 中 weights
+的地址,byte的偏移地址
+**/
+struct INST_TCU_DM_FETCHW
+{
+    OPCODE opcode : 8; /** 从 GLB 中加载 weights 到 PU 或者广播到多个PU中 **/
+    uint64_t ccrclr_weight : 8; /** 数据依赖配置 **/
+    uint64_t tcu_id : 4; /** TCU ID **/
+    uint64_t addr_src : 21; /** GLB 中 weights 的地址,byte的偏移地址 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_weight);
+        bw.write<4>(tcu_id);
+        bw.write<21>(addr_src);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_weight = br.read<decltype(ccrclr_weight), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        addr_src = br.read<decltype(addr_src), 21>();
+    }
+};
+
+/**
+    TCU.DM.CONF.OF
+    @brief 配置 TCU 输出信息
+    - OPCODE opcode : 8  配置 TCU 输出信息
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - ADDR_GLB_8_WITH_BANK addr_psum : 25  中间结果的 GLB 中的地址
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  输出结果的GLB中的地址
+    - uint64_t shape_output_n : 16  当前计算输出Slice的形状信息
+    - uint64_t shape_output_c : 16  当前计算输出Slice的形状信息
+    - uint64_t shape_output_h : 16  当前计算输出Slice的形状信息
+    - uint64_t shape_output_w : 16  当前计算输出Slice的形状信息
+    - STRIDE_GLB stride_output_glb : 64  输出featuremap在GLB的形状信息，决定寻址
+    - STRIDE_GLB stride_psum_glb : 64  输出PSUM在GLB的形状信息，决定寻址
+    - uint64_t x_cut : 4
+水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+    - PRECISION output_precision : 2  None
+    - QUAN_SIGNED output_signed : 1  None
+**/
+struct INST_TCU_DM_CONF_OF
+{
+    OPCODE opcode : 8; /** 配置 TCU 输出信息 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t addr_psum : 25; /** 中间结果的 GLB 中的地址 **/
+    uint64_t addr_dest : 25; /** 输出结果的GLB中的地址 **/
+    uint64_t shape_output_n : 16; /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_c : 16; /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_h : 16; /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_w : 16; /** 当前计算输出Slice的形状信息 **/
+    uint64_t
+        stride_output_glb : 64; /** 输出featuremap在GLB的形状信息，决定寻址 **/
+    uint64_t stride_psum_glb : 64; /** 输出PSUM在GLB的形状信息，决定寻址 **/
+    uint64_t x_cut : 4; /**
+                                    水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+                                    **/
+    PRECISION output_precision : 2; /** None **/
+    QUAN_SIGNED output_signed : 1; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<25>(addr_psum);
+        bw.write<25>(addr_dest);
+        bw.write<16>(shape_output_n);
+        bw.write<16>(shape_output_c);
+        bw.write<16>(shape_output_h);
+        bw.write<16>(shape_output_w);
+        bw.write<64>(stride_output_glb);
+        bw.write<64>(stride_psum_glb);
+        bw.write<4>(x_cut);
+        bw.write<2>(output_precision);
+        bw.write<1>(output_signed);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        addr_psum = br.read<decltype(addr_psum), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        shape_output_n = br.read<decltype(shape_output_n), 16>();
+        shape_output_c = br.read<decltype(shape_output_c), 16>();
+        shape_output_h = br.read<decltype(shape_output_h), 16>();
+        shape_output_w = br.read<decltype(shape_output_w), 16>();
+        stride_output_glb = br.read<decltype(stride_output_glb), 64>();
+        stride_psum_glb = br.read<decltype(stride_psum_glb), 64>();
+        x_cut = br.read<decltype(x_cut), 4>();
+        output_precision = br.read<decltype(output_precision), 2>();
+        output_signed = br.read<decltype(output_signed), 1>();
+    }
+};
+
+/**
+    TCU.PU.CONF
+    @brief 配置给定的 TCU 的 PU 所使用的 PE 资源数量
+    - OPCODE opcode : 8  配置给定的 TCU 的 PU 所使用的 PE 资源数量
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - uint64_t pe_w : 5  TCU 的 PU 使用的 pe 列数
+    - uint64_t pe_h : 5  使用的 pe 行数
+    - uint64_t pe_last_w : 5  保留位置，不使用
+    - uint64_t pe_last_h : 5  在不能被整除的模式的时候PE最后一次计算的激活高度
+    - uint64_t kernel_h : 8  kernel 高度，如果是矩阵乘模式无效
+    - uint64_t kernel_w : 8  kernel 宽度，如果是矩阵乘模式无效
+    - uint64_t group : 5  分组卷积的组数，对应了TCU每个小块的宽度
+    - uint64_t pu_loop_w : 16  硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用
+    - uint64_t pu_loop_h : 16  硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu )
+    - TCU_MODE mode : 2  指定PU的工作模式
+**/
+struct INST_TCU_PU_CONF
+{
+    OPCODE opcode : 8; /** 配置给定的 TCU 的 PU 所使用的 PE 资源数量 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t pe_w : 5; /** TCU 的 PU 使用的 pe 列数 **/
+    uint64_t pe_h : 5; /** 使用的 pe 行数 **/
+    uint64_t pe_last_w : 5; /** 保留位置，不使用 **/
+    uint64_t
+        pe_last_h : 5; /** 在不能被整除的模式的时候PE最后一次计算的激活高度 **/
+    uint64_t kernel_h : 8; /** kernel 高度，如果是矩阵乘模式无效 **/
+    uint64_t kernel_w : 8; /** kernel 宽度，如果是矩阵乘模式无效 **/
+    uint64_t group : 5; /** 分组卷积的组数，对应了TCU每个小块的宽度 **/
+    uint64_t pu_loop_w : 16; /** 硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用 **/
+    uint64_t pu_loop_h : 16; /** 硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu ) **/
+    TCU_MODE mode : 2; /** 指定PU的工作模式 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<5>(pe_w);
+        bw.write<5>(pe_h);
+        bw.write<5>(pe_last_w);
+        bw.write<5>(pe_last_h);
+        bw.write<8>(kernel_h);
+        bw.write<8>(kernel_w);
+        bw.write<5>(group);
+        bw.write<16>(pu_loop_w);
+        bw.write<16>(pu_loop_h);
+        bw.write<2>(mode);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        pe_w = br.read<decltype(pe_w), 5>();
+        pe_h = br.read<decltype(pe_h), 5>();
+        pe_last_w = br.read<decltype(pe_last_w), 5>();
+        pe_last_h = br.read<decltype(pe_last_h), 5>();
+        kernel_h = br.read<decltype(kernel_h), 8>();
+        kernel_w = br.read<decltype(kernel_w), 8>();
+        group = br.read<decltype(group), 5>();
+        pu_loop_w = br.read<decltype(pu_loop_w), 16>();
+        pu_loop_h = br.read<decltype(pu_loop_h), 16>();
+        mode = br.read<decltype(mode), 2>();
+    }
+};
+
+/**
+    TCU.PU.CONF.ACT
+    @brief 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数
+    - OPCODE opcode : 8  配置给定的 TCU 的 PU 使用的 fused
+的两段式激活函数的参数
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - uint64_t clamp_max : 16  上饱和数值
+    - uint64_t clamp_min : 16  下饱和数值
+    - ADDR_GLB_8_WITH_BANK addr_act : 25
+每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+**/
+struct INST_TCU_PU_CONF_ACT
+{
+    OPCODE opcode : 8; /** 配置给定的 TCU 的 PU 使用的 fused
+                              的两段式激活函数的参数 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t clamp_max : 16; /** 上饱和数值 **/
+    uint64_t clamp_min : 16; /** 下饱和数值 **/
+    uint64_t addr_act : 25; /**
+                              每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+                              **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<16>(clamp_max);
+        bw.write<16>(clamp_min);
+        bw.write<25>(addr_act);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        clamp_max = br.read<decltype(clamp_max), 16>();
+        clamp_min = br.read<decltype(clamp_min), 16>();
+        addr_act = br.read<decltype(addr_act), 25>();
+    }
+};
+
+/**
+    TCU.PU.COMPUTE
+    @brief 启动PU一次计算
+    - OPCODE opcode : 8  启动PU一次计算
+    - CCRCLR ccrclr_act : 8  None
+    - CCRCLR ccrclr_psum : 8  None
+    - CCRSET ccrset : 11  数据依赖配置
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - uint64_t act_enable : 1 是否在这次计算完之后将结果做一次两段拟合的激活函数
+    - uint64_t of_enable : 1  决定输出是psum还是output featuremap
+    - uint64_t load_psum : 1  是否从 GLB 加载中间结果
+    - uint64_t weight_switching : 4  是否切换 PU 的 weights
+**/
+struct INST_TCU_PU_COMPUTE
+{
+    OPCODE opcode : 8; /** 启动PU一次计算 **/
+    uint64_t ccrclr_act : 8; /** None **/
+    uint64_t ccrclr_psum : 8; /** None **/
+    uint64_t ccrset : 11; /** 数据依赖配置 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t
+        act_enable : 1; /** 是否在这次计算完之后将结果做一次两段拟合的激活函数 **/
+    uint64_t of_enable : 1; /** 决定输出是psum还是output featuremap **/
+    uint64_t load_psum : 1; /** 是否从 GLB 加载中间结果 **/
+    uint64_t weight_switching : 4; /** 是否切换 PU 的 weights **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_act);
+        bw.write<8>(ccrclr_psum);
+        bw.write<11>(ccrset);
+        bw.write<4>(tcu_id);
+        bw.write<1>(act_enable);
+        bw.write<1>(of_enable);
+        bw.write<1>(load_psum);
+        bw.write<4>(weight_switching);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_act = br.read<decltype(ccrclr_act), 8>();
+        ccrclr_psum = br.read<decltype(ccrclr_psum), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        act_enable = br.read<decltype(act_enable), 1>();
+        of_enable = br.read<decltype(of_enable), 1>();
+        load_psum = br.read<decltype(load_psum), 1>();
+        weight_switching = br.read<decltype(weight_switching), 4>();
+    }
+};
+
+/**
+    TCU.DOT.DM.IF.CONF
+    @brief None
+    - OPCODE opcode : 8  None
+    - uint64_t tcu_id : 4  None
+    - STRIDE_GLB stride_src1_glb : 64  None
+    - STRIDE_GLB stride_src2_glb : 64  None
+**/
+struct INST_TCU_DOT_DM_IF_CONF
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t tcu_id : 4; /** None **/
+    uint64_t stride_src1_glb : 64; /** None **/
+    uint64_t stride_src2_glb : 64; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<64>(stride_src1_glb);
+        bw.write<64>(stride_src2_glb);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        stride_src1_glb = br.read<decltype(stride_src1_glb), 64>();
+        stride_src2_glb = br.read<decltype(stride_src2_glb), 64>();
+    }
+};
+
+/**
+    TCU.DOT.DM.OF.CONF
+    @brief None
+    - OPCODE opcode : 8  None
+    - uint64_t tcu_id : 4  None
+    - uint64_t stride_psum_glb : 64  None
+    - ADDR_GLB_8_WITH_BANK addr_psum : 25  None
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  None
+    - STRIDE_GLB stride_dest_glb : 64  None
+    - uint64_t shape_dest_n : 16  None
+    - uint64_t shape_dest_h : 16  None
+    - uint64_t shape_dest_w : 16  None
+    - uint64_t shape_src1_w : 16  None
+    - PRECISION output_precision : 2  None
+    - QUAN_SIGNED output_signed : 1  None
+**/
+struct INST_TCU_DOT_DM_OF_CONF
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t tcu_id : 4; /** None **/
+    uint64_t stride_psum_glb : 64; /** None **/
+    uint64_t addr_psum : 25; /** None **/
+    uint64_t addr_dest : 25; /** None **/
+    uint64_t stride_dest_glb : 64; /** None **/
+    uint64_t shape_dest_n : 16; /** None **/
+    uint64_t shape_dest_h : 16; /** None **/
+    uint64_t shape_dest_w : 16; /** None **/
+    uint64_t shape_src1_w : 16; /** None **/
+    PRECISION output_precision : 2; /** None **/
+    QUAN_SIGNED output_signed : 1; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<4>(tcu_id);
+        bw.write<64>(stride_psum_glb);
+        bw.write<25>(addr_psum);
+        bw.write<25>(addr_dest);
+        bw.write<64>(stride_dest_glb);
+        bw.write<16>(shape_dest_n);
+        bw.write<16>(shape_dest_h);
+        bw.write<16>(shape_dest_w);
+        bw.write<16>(shape_src1_w);
+        bw.write<2>(output_precision);
+        bw.write<1>(output_signed);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        stride_psum_glb = br.read<decltype(stride_psum_glb), 64>();
+        addr_psum = br.read<decltype(addr_psum), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        stride_dest_glb = br.read<decltype(stride_dest_glb), 64>();
+        shape_dest_n = br.read<decltype(shape_dest_n), 16>();
+        shape_dest_h = br.read<decltype(shape_dest_h), 16>();
+        shape_dest_w = br.read<decltype(shape_dest_w), 16>();
+        shape_src1_w = br.read<decltype(shape_src1_w), 16>();
+        output_precision = br.read<decltype(output_precision), 2>();
+        output_signed = br.read<decltype(output_signed), 1>();
+    }
+};
+
+/**
+    TCU.DOT.DM.FETCH.SRC1
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRCLR ccrclr_src1 : 8  None
+    - uint64_t tcu_id : 4  None
+    - ADDR_GLB_8_WITH_BANK addr_src1 : 25  None
+**/
+struct INST_TCU_DOT_DM_FETCH_SRC1
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrclr_src1 : 8; /** None **/
+    uint64_t tcu_id : 4; /** None **/
+    uint64_t addr_src1 : 25; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_src1);
+        bw.write<4>(tcu_id);
+        bw.write<25>(addr_src1);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_src1 = br.read<decltype(ccrclr_src1), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        addr_src1 = br.read<decltype(addr_src1), 25>();
+    }
+};
+
+/**
+    TCU.DOT.DM.FETCH.SRC2
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRCLR ccrclr_src2 : 8  None
+    - uint64_t tcu_id : 4  None
+    - ADDR_GLB_8_WITH_BANK addr_src2 : 25  None
+**/
+struct INST_TCU_DOT_DM_FETCH_SRC2
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrclr_src2 : 8; /** None **/
+    uint64_t tcu_id : 4; /** None **/
+    uint64_t addr_src2 : 25; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_src2);
+        bw.write<4>(tcu_id);
+        bw.write<25>(addr_src2);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_src2 = br.read<decltype(ccrclr_src2), 8>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        addr_src2 = br.read<decltype(addr_src2), 25>();
+    }
+};
+
+/**
+    TCU.PU.COMPUTE.DUMMY
+    @brief 用来把PSUM转成output的指令
+    - OPCODE opcode : 8  用来把PSUM转成output的指令
+    - CCRCLR ccrclr_act : 8  None
+    - CCRCLR ccrclr_psum : 8  None
+    - CCRSET ccrset : 11  数据依赖配置
+    - uint64_t tcu_id : 4  TCU 的 ID
+    - uint64_t act_enable : 1 是否在这次计算完之后将结果做一次两段拟合的激活函数
+**/
+struct INST_TCU_PU_COMPUTE_DUMMY
+{
+    OPCODE opcode : 8; /** 用来把PSUM转成output的指令 **/
+    uint64_t ccrclr_act : 8; /** None **/
+    uint64_t ccrclr_psum : 8; /** None **/
+    uint64_t ccrset : 11; /** 数据依赖配置 **/
+    uint64_t tcu_id : 4; /** TCU 的 ID **/
+    uint64_t
+        act_enable : 1; /** 是否在这次计算完之后将结果做一次两段拟合的激活函数 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_act);
+        bw.write<8>(ccrclr_psum);
+        bw.write<11>(ccrset);
+        bw.write<4>(tcu_id);
+        bw.write<1>(act_enable);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_act = br.read<decltype(ccrclr_act), 8>();
+        ccrclr_psum = br.read<decltype(ccrclr_psum), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        tcu_id = br.read<decltype(tcu_id), 4>();
+        act_enable = br.read<decltype(act_enable), 1>();
+    }
+};
+
+/**
+    MFU.MN.MAP.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算对于tensor的map运算
+    - OPCODE opcode : 8  配置MFU的DM模块，准备开始计算对于tensor的map运算
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - UNION_ADDR addr_src : 32  输入向量slice地址 (GLB or DDR)
+    - UNION_ADDR addr_dest : 32  输出向量地址 (GLB or DDR)
+    - STRIDE_GLB stride_input_glb : 64  Tensor 的 shape
+    - STRIDE_GLB stride_output_glb : 64  None
+    - uint64_t shape_n : 16  Slice 长度信息
+    - uint64_t shape_c : 16  Slice 长度信息
+    - uint64_t shape_h : 16  Slice 长度信息
+    - uint64_t shape_w : 16  Slice 长度信息
+    - uint64_t basement_src1 : 2  None
+    - uint64_t basement_dest : 2  None
+**/
+struct INST_MFU_MN_MAP_COMPUTE
+{
+    OPCODE opcode : 8; /** 配置MFU的DM模块，准备开始计算对于tensor的map运算 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 32; /** 输入向量slice地址 (GLB or DDR) **/
+    uint64_t addr_dest : 32; /** 输出向量地址 (GLB or DDR) **/
+    uint64_t stride_input_glb : 64; /** Tensor 的 shape **/
+    uint64_t stride_output_glb : 64; /** None **/
+    uint64_t shape_n : 16; /** Slice 长度信息 **/
+    uint64_t shape_c : 16; /** Slice 长度信息 **/
+    uint64_t shape_h : 16; /** Slice 长度信息 **/
+    uint64_t shape_w : 16; /** Slice 长度信息 **/
+    uint64_t basement_src1 : 2; /** None **/
+    uint64_t basement_dest : 2; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<64>(stride_input_glb);
+        bw.write<64>(stride_output_glb);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<2>(basement_src1);
+        bw.write<2>(basement_dest);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        stride_input_glb = br.read<decltype(stride_input_glb), 64>();
+        stride_output_glb = br.read<decltype(stride_output_glb), 64>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        basement_src1 = br.read<decltype(basement_src1), 2>();
+        basement_dest = br.read<decltype(basement_dest), 2>();
+    }
+};
+
+/**
+    MFU.MN.VMAP.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算vector的map运算
+    - OPCODE opcode : 8  配置MFU的DM模块，准备开始计算vector的map运算
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - UNION_ADDR addr_src : 32  输入向量地址 (GLB or DDR)
+    - ADDR addr_dest : 32  输出向量地址 (GLB or DDR)
+    - uint64_t length : 32  向量长度
+    - uint64_t basement_src : 2  None
+    - uint64_t basement_dest : 2  None
+**/
+struct INST_MFU_MN_VMAP_COMPUTE
+{
+    OPCODE opcode : 8; /** 配置MFU的DM模块，准备开始计算vector的map运算 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 32; /** 输入向量地址 (GLB or DDR) **/
+    ADDR addr_dest : 32; /** 输出向量地址 (GLB or DDR) **/
+    uint64_t length : 32; /** 向量长度 **/
+    uint64_t basement_src : 2; /** None **/
+    uint64_t basement_dest : 2; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<32>(length);
+        bw.write<2>(basement_src);
+        bw.write<2>(basement_dest);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        length = br.read<decltype(length), 32>();
+        basement_src = br.read<decltype(basement_src), 2>();
+        basement_dest = br.read<decltype(basement_dest), 2>();
+    }
+};
+
+/**
+    MFU.REDUCE
+    @brief 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - OPCODE opcode : 8  计算reduce，这个指令相当于bypass
+meshnet的reduce的短版本
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - UNION_ADDR addr_src : 32  输入向量地址 (GLB or DDR)
+    - UNION_ADDR addr_dest : 32  输出到 GLB 或者 DDR 的位置
+    - uint64_t init_value : 16  need_init 为 True 时有效，此时上面的 a1 为
+init_value
+    - STRIDE_GLB stride_input_glb : 64  Tensor 的 shape
+    - uint64_t shape_n : 16  Slice 长度信息
+    - uint64_t shape_c : 16  Slice 长度信息
+    - uint64_t shape_h : 16  Slice 长度信息
+    - uint64_t shape_w : 16  Slice 长度信息
+    - MFU_REDUCE_OP op : 3  参与的运算 Scalar Binary Operator（含义见上方）
+    - MFU_REDUCE_DIM dimension : 2  None
+    - uint64_t basement_src : 2  是否是栈变量
+    - uint64_t basement_dest : 2  是否是栈变量
+**/
+struct INST_MFU_REDUCE
+{
+    OPCODE opcode : 8; /** 计算reduce，这个指令相当于bypass
+                              meshnet的reduce的短版本 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 32; /** 输入向量地址 (GLB or DDR) **/
+    uint64_t addr_dest : 32; /** 输出到 GLB 或者 DDR 的位置 **/
+    uint64_t init_value : 16; /** need_init 为 True 时有效，此时上面的 a1 为
+                               init_value **/
+    uint64_t stride_input_glb : 64; /** Tensor 的 shape **/
+    uint64_t shape_n : 16; /** Slice 长度信息 **/
+    uint64_t shape_c : 16; /** Slice 长度信息 **/
+    uint64_t shape_h : 16; /** Slice 长度信息 **/
+    uint64_t shape_w : 16; /** Slice 长度信息 **/
+    MFU_REDUCE_OP op : 3; /** 参与的运算 Scalar Binary Operator（含义见上方） **/
+    MFU_REDUCE_DIM dimension : 2; /** None **/
+    uint64_t basement_src : 2; /** 是否是栈变量 **/
+    uint64_t basement_dest : 2; /** 是否是栈变量 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<16>(init_value);
+        bw.write<64>(stride_input_glb);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<3>(op);
+        bw.write<2>(dimension);
+        bw.write<2>(basement_src);
+        bw.write<2>(basement_dest);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        init_value = br.read<decltype(init_value), 16>();
+        stride_input_glb = br.read<decltype(stride_input_glb), 64>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        op = br.read<decltype(op), 3>();
+        dimension = br.read<decltype(dimension), 2>();
+        basement_src = br.read<decltype(basement_src), 2>();
+        basement_dest = br.read<decltype(basement_dest), 2>();
+    }
+};
+
+/**
+    MFU.VREDUCE
+    @brief 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - OPCODE opcode : 8  计算reduce，这个指令相当于bypass
+meshnet的reduce的短版本
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - UNION_ADDR addr_src : 32  输入向量地址 (GLB or DDR)
+    - UNION_ADDR addr_dest : 32  输出到 GLB 或者 DDR 的位置
+    - uint64_t init_value : 16  need_init 为 True 时有效，此时上面的 a1 为
+init_value
+    - uint64_t length : 32  向量输出长度（总长度是length*reduce_length）
+    - uint64_t reduce_length : 16  每这么多个点输出一个点
+    - MFU_REDUCE_OP op : 3  参与的运算 Scalar Binary Operator（含义见上方）
+    - uint64_t basement_src : 2  是否是栈变量
+    - uint64_t basement_dest : 2  是否是栈变量
+**/
+struct INST_MFU_VREDUCE
+{
+    OPCODE opcode : 8; /** 计算reduce，这个指令相当于bypass
+                              meshnet的reduce的短版本 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 32; /** 输入向量地址 (GLB or DDR) **/
+    uint64_t addr_dest : 32; /** 输出到 GLB 或者 DDR 的位置 **/
+    uint64_t init_value : 16; /** need_init 为 True 时有效，此时上面的 a1 为
+                               init_value **/
+    uint64_t length : 32; /** 向量输出长度（总长度是length*reduce_length） **/
+    uint64_t reduce_length : 16; /** 每这么多个点输出一个点 **/
+    MFU_REDUCE_OP op : 3; /** 参与的运算 Scalar Binary Operator（含义见上方） **/
+    uint64_t basement_src : 2; /** 是否是栈变量 **/
+    uint64_t basement_dest : 2; /** 是否是栈变量 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src);
+        bw.write<32>(addr_dest);
+        bw.write<16>(init_value);
+        bw.write<32>(length);
+        bw.write<16>(reduce_length);
+        bw.write<3>(op);
+        bw.write<2>(basement_src);
+        bw.write<2>(basement_dest);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 32>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        init_value = br.read<decltype(init_value), 16>();
+        length = br.read<decltype(length), 32>();
+        reduce_length = br.read<decltype(reduce_length), 16>();
+        op = br.read<decltype(op), 3>();
+        basement_src = br.read<decltype(basement_src), 2>();
+        basement_dest = br.read<decltype(basement_dest), 2>();
+    }
+};
+
+/**
+    MFU.MN.BROADCAST.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算
+    - OPCODE opcode : 8  配置MFU的DM模块，准备开始计算
+    - CCRCLR ccrclr_src1 : 8  None
+    - CCRCLR ccrclr_src2 : 8  None
+    - CCRSET ccrset : 11  None
+    - UNION_ADDR addr_src1 : 32  向量输入1地址
+    - UNION_ADDR addr_src2 : 32  向量输入2地址
+    - UNION_ADDR addr_dest : 32  向量输出地址
+    - uint64_t len_src1 : 32  向量输入1长度
+    - uint64_t len_src2 : 32  向量输入2长度
+    - uint64_t len_dest : 32
+输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+    - uint64_t basement_src1 : 2  None
+    - uint64_t basement_src2 : 2  None
+    - uint64_t basement_dest : 2  None
+**/
+struct INST_MFU_MN_BROADCAST_COMPUTE
+{
+    OPCODE opcode : 8; /** 配置MFU的DM模块，准备开始计算 **/
+    uint64_t ccrclr_src1 : 8; /** None **/
+    uint64_t ccrclr_src2 : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src1 : 32; /** 向量输入1地址 **/
+    uint64_t addr_src2 : 32; /** 向量输入2地址 **/
+    uint64_t addr_dest : 32; /** 向量输出地址 **/
+    uint64_t len_src1 : 32; /** 向量输入1长度 **/
+    uint64_t len_src2 : 32; /** 向量输入2长度 **/
+    uint64_t len_dest : 32; /**
+                                 输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+                                 **/
+    uint64_t basement_src1 : 2; /** None **/
+    uint64_t basement_src2 : 2; /** None **/
+    uint64_t basement_dest : 2; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr_src1);
+        bw.write<8>(ccrclr_src2);
+        bw.write<11>(ccrset);
+        bw.write<32>(addr_src1);
+        bw.write<32>(addr_src2);
+        bw.write<32>(addr_dest);
+        bw.write<32>(len_src1);
+        bw.write<32>(len_src2);
+        bw.write<32>(len_dest);
+        bw.write<2>(basement_src1);
+        bw.write<2>(basement_src2);
+        bw.write<2>(basement_dest);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr_src1 = br.read<decltype(ccrclr_src1), 8>();
+        ccrclr_src2 = br.read<decltype(ccrclr_src2), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src1 = br.read<decltype(addr_src1), 32>();
+        addr_src2 = br.read<decltype(addr_src2), 32>();
+        addr_dest = br.read<decltype(addr_dest), 32>();
+        len_src1 = br.read<decltype(len_src1), 32>();
+        len_src2 = br.read<decltype(len_src2), 32>();
+        len_dest = br.read<decltype(len_dest), 32>();
+        basement_src1 = br.read<decltype(basement_src1), 2>();
+        basement_src2 = br.read<decltype(basement_src2), 2>();
+        basement_dest = br.read<decltype(basement_dest), 2>();
+    }
+};
+
+/**
+    MFU.MN.REDUCE
+    @brief 这条指令用于配置Fuse在Meshnet后面的Reduce
+    - OPCODE opcode : 8  这条指令用于配置Fuse在Meshnet后面的Reduce
+    - uint64_t init_value : 16  need_init 为 True 时有效，此时上面的 a1 为
+init_value
+    - uint64_t recude_length : 16  有多少个元素参与一次reduce
+    - uint64_t length : 29  reduce元素的次数
+    - MFU_REDUCE_OP op : 3  参与的运算 Scalar Binary Operator
+**/
+struct INST_MFU_MN_REDUCE
+{
+    OPCODE opcode : 8; /** 这条指令用于配置Fuse在Meshnet后面的Reduce **/
+    uint64_t init_value : 16; /** need_init 为 True 时有效，此时上面的 a1 为
+                               init_value **/
+    uint64_t recude_length : 16; /** 有多少个元素参与一次reduce **/
+    uint64_t length : 29; /** reduce元素的次数 **/
+    MFU_REDUCE_OP op : 3; /** 参与的运算 Scalar Binary Operator **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<16>(init_value);
+        bw.write<16>(recude_length);
+        bw.write<29>(length);
+        bw.write<3>(op);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        init_value = br.read<decltype(init_value), 16>();
+        recude_length = br.read<decltype(recude_length), 16>();
+        length = br.read<decltype(length), 29>();
+        op = br.read<decltype(op), 3>();
+    }
+};
+
+struct INST_MFU_MN_CONF
+{
+    OPCODE opcode : 8; /**
+                               配置互联网络。我们认为某个原件编号为0就是与网络断开连接并且gate掉。整个网络连接初始值都是0
+                               **/
+    MFU_MN_PORTOUT out1 : 6; /** VECTOR_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out2 : 6; /** VECTOR_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out3 : 6; /** CONST1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out4 : 6; /** CONST1_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out5 : 6; /** CONST2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out6 : 6; /** CONST2_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out7 : 6; /** ADDSUB0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out8 : 6; /** ADDSUB1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out9 : 6; /** ADDSUB2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out10 : 6; /** ADDSUB3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out11 : 6; /** MUL0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out12 : 6; /** MUL1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out13 : 6; /** MUL2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out14 : 6; /** MUL3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out15 : 6; /** DIV_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out16 : 6; /** ROUND_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out17 : 6; /** SQRT_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out18 : 6; /** TRANGLE_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out19 : 6; /** LOG_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out20 : 6; /** UNARY_LOGIC_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out21 : 6; /** EXP_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out22 : 6; /** CMP0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out23 : 6; /** CMP1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out24 : 6; /** REG0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out25 : 6; /** SELECT0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out26 : 6; /** NOP0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out27 : 6; /** NOP1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out28 : 6; /** NOP2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out29 : 6; /** NOP3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out30 : 6; /** NOP4_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out31 : 6; /** NOP5_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out32 : 6; /** NOP6_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out33 : 6; /** NOP7_OUT_0连接的端口 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<6>(out1);
+        bw.write<6>(out2);
+        bw.write<6>(out3);
+        bw.write<6>(out4);
+        bw.write<6>(out5);
+        bw.write<6>(out6);
+        bw.write<6>(out7);
+        bw.write<6>(out8);
+        bw.write<6>(out9);
+        bw.write<6>(out10);
+        bw.write<6>(out11);
+        bw.write<6>(out12);
+        bw.write<6>(out13);
+        bw.write<6>(out14);
+        bw.write<6>(out15);
+        bw.write<6>(out16);
+        bw.write<6>(out17);
+        bw.write<6>(out18);
+        bw.write<6>(out19);
+        bw.write<6>(out20);
+        bw.write<6>(out21);
+        bw.write<6>(out22);
+        bw.write<6>(out23);
+        bw.write<6>(out24);
+        bw.write<6>(out25);
+        bw.write<6>(out26);
+        bw.write<6>(out27);
+        bw.write<6>(out28);
+        bw.write<6>(out29);
+        bw.write<6>(out30);
+        bw.write<6>(out31);
+        bw.write<6>(out32);
+        bw.write<6>(out33);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        out1 = br.read<decltype(out1), 6>();
+        out2 = br.read<decltype(out2), 6>();
+        out3 = br.read<decltype(out3), 6>();
+        out4 = br.read<decltype(out4), 6>();
+        out5 = br.read<decltype(out5), 6>();
+        out6 = br.read<decltype(out6), 6>();
+        out7 = br.read<decltype(out7), 6>();
+        out8 = br.read<decltype(out8), 6>();
+        out9 = br.read<decltype(out9), 6>();
+        out10 = br.read<decltype(out10), 6>();
+        out11 = br.read<decltype(out11), 6>();
+        out12 = br.read<decltype(out12), 6>();
+        out13 = br.read<decltype(out13), 6>();
+        out14 = br.read<decltype(out14), 6>();
+        out15 = br.read<decltype(out15), 6>();
+        out16 = br.read<decltype(out16), 6>();
+        out17 = br.read<decltype(out17), 6>();
+        out18 = br.read<decltype(out18), 6>();
+        out19 = br.read<decltype(out19), 6>();
+        out20 = br.read<decltype(out20), 6>();
+        out21 = br.read<decltype(out21), 6>();
+        out22 = br.read<decltype(out22), 6>();
+        out23 = br.read<decltype(out23), 6>();
+        out24 = br.read<decltype(out24), 6>();
+        out25 = br.read<decltype(out25), 6>();
+        out26 = br.read<decltype(out26), 6>();
+        out27 = br.read<decltype(out27), 6>();
+        out28 = br.read<decltype(out28), 6>();
+        out29 = br.read<decltype(out29), 6>();
+        out30 = br.read<decltype(out30), 6>();
+        out31 = br.read<decltype(out31), 6>();
+        out32 = br.read<decltype(out32), 6>();
+        out33 = br.read<decltype(out33), 6>();
+    }
+};
+
+/**
+    MFU.MNOP.CONF
+    @brief
+这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+    - OPCODE opcode : 8
+这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+    - uint64_t mode : 2  模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址
+    - uint64_t val : 32  配置
+**/
+struct INST_MFU_MNOP_CONF
+{
+    OPCODE opcode : 8; /**
+                        这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+                        **/
+    uint64_t mode : 2; /** 模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址 **/
+    uint64_t val : 32; /** 配置 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<2>(mode);
+        bw.write<32>(val);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        mode = br.read<decltype(mode), 2>();
+        val = br.read<decltype(val), 32>();
+    }
+};
+
+/**
+    MFU.PDP.CONF
+    @brief 主要用于配置 PDP 模块计算中共用的一些全局配置
+    - OPCODE opcode : 8  主要用于配置 PDP 模块计算中共用的一些全局配置
+    - uint64_t multiple_channels : 8  是否在多个 channel
+上同时进行一样窗口和窗口移动规则。
+    - STRIDE_GLB stride_dest_glb : 64  None
+**/
+struct INST_MFU_PDP_CONF
+{
+    OPCODE opcode : 8; /** 主要用于配置 PDP 模块计算中共用的一些全局配置 **/
+    uint64_t multiple_channels : 8; /** 是否在多个 channel
+                                     上同时进行一样窗口和窗口移动规则。 **/
+    uint64_t stride_dest_glb : 64; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(multiple_channels);
+        bw.write<64>(stride_dest_glb);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        multiple_channels = br.read<decltype(multiple_channels), 8>();
+        stride_dest_glb = br.read<decltype(stride_dest_glb), 64>();
+    }
+};
+
+/**
+    MFU.PDP.SRC.CONF
+    @brief  主要用来配置待操作的 Tensor 的位置
+    - OPCODE opcode : 8   主要用来配置待操作的 Tensor 的位置
+    - STRIDE_GLB stride_glb : 64  Tensor 的 shape
+**/
+struct INST_MFU_PDP_SRC_CONF
+{
+    OPCODE opcode : 8; /**  主要用来配置待操作的 Tensor 的位置 **/
+    uint64_t stride_glb : 64; /** Tensor 的 shape **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<64>(stride_glb);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        stride_glb = br.read<decltype(stride_glb), 64>();
+    }
+};
+
+/**
+    MFU.PDP.REDUCE
+    @brief 进行PDP运算
+    - OPCODE opcode : 8  进行PDP运算
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_src : 25  输入向量地址 (GLB or
+DDR)（slice起始地址）
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  输出位置
+    - uint64_t window_w : 5  2D 窗口的宽
+    - uint64_t window_h : 5  2D 窗口的高
+    - uint64_t active_h : 5  PDP阵列硬件使能的高度（需要是window_h的整数倍）
+    - uint64_t shape_n : 16  None
+    - uint64_t shape_c : 16  None
+    - uint64_t shape_h : 16  None
+    - uint64_t shape_w : 16  None
+    - uint64_t count_w : 16  W 维度上做 N 次 ReduceWindow 操作
+    - uint64_t count_h : 16  H 维度上做 N 次 ReduceWindow操作
+    - uint64_t stride_w : 8  W 维度上每次取窗口的下标增加量
+    - uint64_t stride_h : 8  H 维度上每次取窗口的下标增加量
+    - uint64_t padding_top : 8  在 2D Tensor 的顶部加的 Zero padding 行数
+    - uint64_t padding_bottom : 8  在 2D Tensor 的底部加的 Zero padding 行数
+    - uint64_t padding_left : 8  在 2D Tensor 的左边加的 Zero padding 行数
+    - uint64_t padding_right : 8  在 2D Tensor 的右边加的 Zero padding 行数
+    - uint64_t pe_last_h : 8  来表明最后一次计算需要使能多少个pdp单元
+    - MFU_PDP_OP computation : 2  我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg
+三种
+    - uint64_t quantized : 1  是否是量化计算
+**/
+struct INST_MFU_PDP_REDUCE
+{
+    OPCODE opcode : 8; /** 进行PDP运算 **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 25; /** 输入向量地址 (GLB or DDR)（slice起始地址） **/
+    uint64_t addr_dest : 25; /** 输出位置 **/
+    uint64_t window_w : 5; /** 2D 窗口的宽 **/
+    uint64_t window_h : 5; /** 2D 窗口的高 **/
+    uint64_t active_h : 5; /** PDP阵列硬件使能的高度（需要是window_h的整数倍） **/
+    uint64_t shape_n : 16; /** None **/
+    uint64_t shape_c : 16; /** None **/
+    uint64_t shape_h : 16; /** None **/
+    uint64_t shape_w : 16; /** None **/
+    uint64_t count_w : 16; /** W 维度上做 N 次 ReduceWindow 操作 **/
+    uint64_t count_h : 16; /** H 维度上做 N 次 ReduceWindow操作 **/
+    uint64_t stride_w : 8; /** W 维度上每次取窗口的下标增加量 **/
+    uint64_t stride_h : 8; /** H 维度上每次取窗口的下标增加量 **/
+    uint64_t padding_top : 8; /** 在 2D Tensor 的顶部加的 Zero padding 行数 **/
+    uint64_t padding_bottom : 8; /** 在 2D Tensor 的底部加的 Zero padding 行数 **/
+    uint64_t padding_left : 8; /** 在 2D Tensor 的左边加的 Zero padding 行数 **/
+    uint64_t padding_right : 8; /** 在 2D Tensor 的右边加的 Zero padding 行数 **/
+    uint64_t pe_last_h : 8; /** 来表明最后一次计算需要使能多少个pdp单元 **/
+    MFU_PDP_OP computation : 2; /** 我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg
+                                 三种 **/
+    uint64_t quantized : 1; /** 是否是量化计算 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_src);
+        bw.write<25>(addr_dest);
+        bw.write<5>(window_w);
+        bw.write<5>(window_h);
+        bw.write<5>(active_h);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<16>(count_w);
+        bw.write<16>(count_h);
+        bw.write<8>(stride_w);
+        bw.write<8>(stride_h);
+        bw.write<8>(padding_top);
+        bw.write<8>(padding_bottom);
+        bw.write<8>(padding_left);
+        bw.write<8>(padding_right);
+        bw.write<8>(pe_last_h);
+        bw.write<2>(computation);
+        bw.write<1>(quantized);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        window_w = br.read<decltype(window_w), 5>();
+        window_h = br.read<decltype(window_h), 5>();
+        active_h = br.read<decltype(active_h), 5>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        count_w = br.read<decltype(count_w), 16>();
+        count_h = br.read<decltype(count_h), 16>();
+        stride_w = br.read<decltype(stride_w), 8>();
+        stride_h = br.read<decltype(stride_h), 8>();
+        padding_top = br.read<decltype(padding_top), 8>();
+        padding_bottom = br.read<decltype(padding_bottom), 8>();
+        padding_left = br.read<decltype(padding_left), 8>();
+        padding_right = br.read<decltype(padding_right), 8>();
+        pe_last_h = br.read<decltype(pe_last_h), 8>();
+        computation = br.read<decltype(computation), 2>();
+        quantized = br.read<decltype(quantized), 1>();
+    }
+};
+
+/**
+    MFU.MN.BROADCAST.CONF
+    @brief None
+    - OPCODE opcode : 8  None
+    - uint64_t slice_src1 : 16  向量输入1 slice长度
+    - uint64_t slice_src2 : 16  向量输入2 slice长度
+    - uint64_t repeats_src1 : 16  向量输入1每个元素重复的次数（在右面广播）
+    - uint64_t repeats_src2 : 16  向量输入2每个元素重复的次数（在右面广播）
+    - uint64_t slice_repeats_src1 : 16  向量输入1 slice次数（实现在中间广播）
+    - uint64_t slice_repeats_src2 : 16  向量输入2 slice次数（实现在中间广播）
+    - STRIDE_GLB stride_src1_glb : 64  None
+    - uint64_t shape_src1_n : 16  None
+    - uint64_t shape_src1_c : 16  None
+    - uint64_t shape_src1_h : 16  None
+    - uint64_t shape_src1_w : 16  None
+    - STRIDE_GLB stride_src2_glb : 64  None
+    - uint64_t shape_src2_n : 16  None
+    - uint64_t shape_src2_c : 16  None
+    - uint64_t shape_src2_h : 16  None
+    - uint64_t shape_src2_w : 16  None
+    - uint64_t const1 : 16  常量1
+    - uint64_t const2 : 16  常量2
+    - uint64_t const3 : 16  常量3
+    - uint64_t const4 : 16  常量4
+**/
+struct INST_MFU_MN_BROADCAST_CONF
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t slice_src1 : 16; /** 向量输入1 slice长度 **/
+    uint64_t slice_src2 : 16; /** 向量输入2 slice长度 **/
+    uint64_t repeats_src1 : 16; /** 向量输入1每个元素重复的次数（在右面广播） **/
+    uint64_t repeats_src2 : 16; /** 向量输入2每个元素重复的次数（在右面广播） **/
+    uint64_t
+        slice_repeats_src1 : 16; /** 向量输入1 slice次数（实现在中间广播） **/
+    uint64_t
+        slice_repeats_src2 : 16; /** 向量输入2 slice次数（实现在中间广播） **/
+    uint64_t stride_src1_glb : 64; /** None **/
+    uint64_t shape_src1_n : 16; /** None **/
+    uint64_t shape_src1_c : 16; /** None **/
+    uint64_t shape_src1_h : 16; /** None **/
+    uint64_t shape_src1_w : 16; /** None **/
+    uint64_t stride_src2_glb : 64; /** None **/
+    uint64_t shape_src2_n : 16; /** None **/
+    uint64_t shape_src2_c : 16; /** None **/
+    uint64_t shape_src2_h : 16; /** None **/
+    uint64_t shape_src2_w : 16; /** None **/
+    uint64_t const1 : 16; /** 常量1 **/
+    uint64_t const2 : 16; /** 常量2 **/
+    uint64_t const3 : 16; /** 常量3 **/
+    uint64_t const4 : 16; /** 常量4 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<16>(slice_src1);
+        bw.write<16>(slice_src2);
+        bw.write<16>(repeats_src1);
+        bw.write<16>(repeats_src2);
+        bw.write<16>(slice_repeats_src1);
+        bw.write<16>(slice_repeats_src2);
+        bw.write<64>(stride_src1_glb);
+        bw.write<16>(shape_src1_n);
+        bw.write<16>(shape_src1_c);
+        bw.write<16>(shape_src1_h);
+        bw.write<16>(shape_src1_w);
+        bw.write<64>(stride_src2_glb);
+        bw.write<16>(shape_src2_n);
+        bw.write<16>(shape_src2_c);
+        bw.write<16>(shape_src2_h);
+        bw.write<16>(shape_src2_w);
+        bw.write<16>(const1);
+        bw.write<16>(const2);
+        bw.write<16>(const3);
+        bw.write<16>(const4);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        slice_src1 = br.read<decltype(slice_src1), 16>();
+        slice_src2 = br.read<decltype(slice_src2), 16>();
+        repeats_src1 = br.read<decltype(repeats_src1), 16>();
+        repeats_src2 = br.read<decltype(repeats_src2), 16>();
+        slice_repeats_src1 = br.read<decltype(slice_repeats_src1), 16>();
+        slice_repeats_src2 = br.read<decltype(slice_repeats_src2), 16>();
+        stride_src1_glb = br.read<decltype(stride_src1_glb), 64>();
+        shape_src1_n = br.read<decltype(shape_src1_n), 16>();
+        shape_src1_c = br.read<decltype(shape_src1_c), 16>();
+        shape_src1_h = br.read<decltype(shape_src1_h), 16>();
+        shape_src1_w = br.read<decltype(shape_src1_w), 16>();
+        stride_src2_glb = br.read<decltype(stride_src2_glb), 64>();
+        shape_src2_n = br.read<decltype(shape_src2_n), 16>();
+        shape_src2_c = br.read<decltype(shape_src2_c), 16>();
+        shape_src2_h = br.read<decltype(shape_src2_h), 16>();
+        shape_src2_w = br.read<decltype(shape_src2_w), 16>();
+        const1 = br.read<decltype(const1), 16>();
+        const2 = br.read<decltype(const2), 16>();
+        const3 = br.read<decltype(const3), 16>();
+        const4 = br.read<decltype(const4), 16>();
+    }
+};
+
+/**
+    MFU.CROP
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_src : 25  None
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  None
+    - ADDR_GLB_8_WITH_BANK addr_bbox : 25  None
+    - uint64_t reserve : 16  None
+    - uint64_t shape_src_c : 16  None
+    - uint64_t shape_src_h : 16  None
+    - uint64_t shape_src_w : 16  None
+    - STRIDE_GLB stride_src_glb : 64  None
+    - STRIDE_GLB stride_dest_glb : 64  None
+    - uint64_t roi_amount : 16  None
+    - uint64_t dest_h : 16  None
+    - uint64_t dest_w : 16  None
+    - BF24 step_h : 24  None
+    - BF24 step_w : 24  None
+    - MFU_CROP_ALIGN align_method : 2  None
+    - MFU_CROP_RESIZE resize_method : 1  None
+**/
+struct INST_MFU_CROP
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 25; /** None **/
+    uint64_t addr_dest : 25; /** None **/
+    uint64_t addr_bbox : 25; /** None **/
+    uint64_t reserve : 16; /** None **/
+    uint64_t shape_src_c : 16; /** None **/
+    uint64_t shape_src_h : 16; /** None **/
+    uint64_t shape_src_w : 16; /** None **/
+    uint64_t stride_src_glb : 64; /** None **/
+    uint64_t stride_dest_glb : 64; /** None **/
+    uint64_t roi_amount : 16; /** None **/
+    uint64_t dest_h : 16; /** None **/
+    uint64_t dest_w : 16; /** None **/
+    BF24 step_h : 24; /** None **/
+    BF24 step_w : 24; /** None **/
+    MFU_CROP_ALIGN align_method : 2; /** None **/
+    MFU_CROP_RESIZE resize_method : 1; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_src);
+        bw.write<25>(addr_dest);
+        bw.write<25>(addr_bbox);
+        bw.write<16>(reserve);
+        bw.write<16>(shape_src_c);
+        bw.write<16>(shape_src_h);
+        bw.write<16>(shape_src_w);
+        bw.write<64>(stride_src_glb);
+        bw.write<64>(stride_dest_glb);
+        bw.write<16>(roi_amount);
+        bw.write<16>(dest_h);
+        bw.write<16>(dest_w);
+        bw.write<24>(step_h);
+        bw.write<24>(step_w);
+        bw.write<2>(align_method);
+        bw.write<1>(resize_method);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        addr_bbox = br.read<decltype(addr_bbox), 25>();
+        reserve = br.read<decltype(reserve), 16>();
+        shape_src_c = br.read<decltype(shape_src_c), 16>();
+        shape_src_h = br.read<decltype(shape_src_h), 16>();
+        shape_src_w = br.read<decltype(shape_src_w), 16>();
+        stride_src_glb = br.read<decltype(stride_src_glb), 64>();
+        stride_dest_glb = br.read<decltype(stride_dest_glb), 64>();
+        roi_amount = br.read<decltype(roi_amount), 16>();
+        dest_h = br.read<decltype(dest_h), 16>();
+        dest_w = br.read<decltype(dest_w), 16>();
+        step_h = br.read<decltype(step_h), 24>();
+        step_w = br.read<decltype(step_w), 24>();
+        align_method = br.read<decltype(align_method), 2>();
+        resize_method = br.read<decltype(resize_method), 1>();
+    }
+};
+
+/**
+    MFU.MEMSET
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  None
+    - uint64_t imm : 16  None
+    - uint64_t len : 20  None
+**/
+struct INST_MFU_MEMSET
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_dest : 25; /** None **/
+    uint64_t imm : 16; /** None **/
+    uint64_t len : 20; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_dest);
+        bw.write<16>(imm);
+        bw.write<20>(len);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        imm = br.read<decltype(imm), 16>();
+        len = br.read<decltype(len), 20>();
+    }
+};
+
+/**
+    MFU.MEMCPY
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_src : 25  None
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  None
+    - STRIDE_GLB stride_src_glb : 64  None
+    - STRIDE_GLB stride_dest_glb : 64  None
+    - uint64_t shape_n : 16  None
+    - uint64_t shape_c : 16  None
+    - uint64_t shape_h : 16  None
+    - uint64_t shape_w : 16  None
+    - PRECISION precision_glb : 2  None
+**/
+struct INST_MFU_MEMCPY
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 25; /** None **/
+    uint64_t addr_dest : 25; /** None **/
+    uint64_t stride_src_glb : 64; /** None **/
+    uint64_t stride_dest_glb : 64; /** None **/
+    uint64_t shape_n : 16; /** None **/
+    uint64_t shape_c : 16; /** None **/
+    uint64_t shape_h : 16; /** None **/
+    uint64_t shape_w : 16; /** None **/
+    PRECISION precision_glb : 2; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_src);
+        bw.write<25>(addr_dest);
+        bw.write<64>(stride_src_glb);
+        bw.write<64>(stride_dest_glb);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<2>(precision_glb);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        stride_src_glb = br.read<decltype(stride_src_glb), 64>();
+        stride_dest_glb = br.read<decltype(stride_dest_glb), 64>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+    }
+};
+
+/**
+    MFU.TRANS
+    @brief None
+    - OPCODE opcode : 8  None
+    - CCRCLR ccrclr : 8  None
+    - CCRSET ccrset : 11  None
+    - ADDR_GLB_8_WITH_BANK addr_src : 25  None
+    - ADDR_GLB_8_WITH_BANK addr_dest : 25  None
+    - STRIDE_GLB stride_src_glb : 64  None
+    - STRIDE_GLB stride_dest_glb : 64  None
+    - uint64_t shape_n : 16  None
+    - uint64_t shape_c : 16  None
+    - uint64_t shape_h : 16  None
+    - uint64_t shape_w : 16  None
+    - PRECISION precision_glb : 2  None
+    - MFU_TRANS_PERMUTE permute : 5  None
+**/
+struct INST_MFU_TRANS
+{
+    OPCODE opcode : 8; /** None **/
+    uint64_t ccrclr : 8; /** None **/
+    uint64_t ccrset : 11; /** None **/
+    uint64_t addr_src : 25; /** None **/
+    uint64_t addr_dest : 25; /** None **/
+    uint64_t stride_src_glb : 64; /** None **/
+    uint64_t stride_dest_glb : 64; /** None **/
+    uint64_t shape_n : 16; /** None **/
+    uint64_t shape_c : 16; /** None **/
+    uint64_t shape_h : 16; /** None **/
+    uint64_t shape_w : 16; /** None **/
+    PRECISION precision_glb : 2; /** None **/
+    MFU_TRANS_PERMUTE permute : 5; /** None **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<8>(ccrclr);
+        bw.write<11>(ccrset);
+        bw.write<25>(addr_src);
+        bw.write<25>(addr_dest);
+        bw.write<64>(stride_src_glb);
+        bw.write<64>(stride_dest_glb);
+        bw.write<16>(shape_n);
+        bw.write<16>(shape_c);
+        bw.write<16>(shape_h);
+        bw.write<16>(shape_w);
+        bw.write<2>(precision_glb);
+        bw.write<5>(permute);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        ccrclr = br.read<decltype(ccrclr), 8>();
+        ccrset = br.read<decltype(ccrset), 11>();
+        addr_src = br.read<decltype(addr_src), 25>();
+        addr_dest = br.read<decltype(addr_dest), 25>();
+        stride_src_glb = br.read<decltype(stride_src_glb), 64>();
+        stride_dest_glb = br.read<decltype(stride_dest_glb), 64>();
+        shape_n = br.read<decltype(shape_n), 16>();
+        shape_c = br.read<decltype(shape_c), 16>();
+        shape_h = br.read<decltype(shape_h), 16>();
+        shape_w = br.read<decltype(shape_w), 16>();
+        precision_glb = br.read<decltype(precision_glb), 2>();
+        permute = br.read<decltype(permute), 5>();
+    }
+};
+
+struct INST_MFU_MN_CONF2
+{
+    OPCODE opcode : 8; /** 这条指令用来反向配置meshnet连接关系 **/
+    MFU_MN_PORTIN in1 : 6; /** VECTOR_IN_0连接的端口 **/
+    MFU_MN_PORTIN in2 : 6; /** ADDSUB0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in3 : 6; /** ADDSUB0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in4 : 6; /** ADDSUB1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in5 : 6; /** ADDSUB1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in6 : 6; /** ADDSUB2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in7 : 6; /** ADDSUB2_IN_1连接的端口 **/
+    MFU_MN_PORTIN in8 : 6; /** ADDSUB3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in9 : 6; /** ADDSUB3_IN_1连接的端口 **/
+    MFU_MN_PORTIN in10 : 6; /** MUL0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in11 : 6; /** MUL0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in12 : 6; /** MUL1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in13 : 6; /** MUL1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in14 : 6; /** MUL2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in15 : 6; /** MUL2_IN_1连接的端口 **/
+    MFU_MN_PORTIN in16 : 6; /** MUL3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in17 : 6; /** MUL3_IN_1连接的端口 **/
+    MFU_MN_PORTIN in18 : 6; /** DIV_IN_0连接的端口 **/
+    MFU_MN_PORTIN in19 : 6; /** DIV_IN_1连接的端口 **/
+    MFU_MN_PORTIN in20 : 6; /** ROUND_IN_0连接的端口 **/
+    MFU_MN_PORTIN in21 : 6; /** SQRT_IN_0连接的端口 **/
+    MFU_MN_PORTIN in22 : 6; /** TRANGLE_IN_0连接的端口 **/
+    MFU_MN_PORTIN in23 : 6; /** LOG_IN_0连接的端口 **/
+    MFU_MN_PORTIN in24 : 6; /** UNARY_LOGIC_IN_0连接的端口 **/
+    MFU_MN_PORTIN in25 : 6; /** EXP_IN_0连接的端口 **/
+    MFU_MN_PORTIN in26 : 6; /** CMP0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in27 : 6; /** CMP0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in28 : 6; /** CMP1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in29 : 6; /** CMP1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in30 : 6; /** REG0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in31 : 6; /** SELECT0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in32 : 6; /** SELECT0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in33 : 6; /** SELECT0_IN_2连接的端口 **/
+    MFU_MN_PORTIN in34 : 6; /** NOP0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in35 : 6; /** NOP1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in36 : 6; /** NOP2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in37 : 6; /** NOP3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in38 : 6; /** NOP4_IN_0连接的端口 **/
+    MFU_MN_PORTIN in39 : 6; /** NOP5_IN_0连接的端口 **/
+    MFU_MN_PORTIN in40 : 6; /** NOP6_IN_0连接的端口 **/
+    MFU_MN_PORTIN in41 : 6; /** NOP7_IN_0连接的端口 **/
+    MFU_MN_PORTIN in42 : 6; /** CLEAR0_IN_0连接的端口 **/
+
+    void serialize(bitwriter &bw) const
+    {
+        bw.write<8>(opcode);
+        bw.write<6>(in1);
+        bw.write<6>(in2);
+        bw.write<6>(in3);
+        bw.write<6>(in4);
+        bw.write<6>(in5);
+        bw.write<6>(in6);
+        bw.write<6>(in7);
+        bw.write<6>(in8);
+        bw.write<6>(in9);
+        bw.write<6>(in10);
+        bw.write<6>(in11);
+        bw.write<6>(in12);
+        bw.write<6>(in13);
+        bw.write<6>(in14);
+        bw.write<6>(in15);
+        bw.write<6>(in16);
+        bw.write<6>(in17);
+        bw.write<6>(in18);
+        bw.write<6>(in19);
+        bw.write<6>(in20);
+        bw.write<6>(in21);
+        bw.write<6>(in22);
+        bw.write<6>(in23);
+        bw.write<6>(in24);
+        bw.write<6>(in25);
+        bw.write<6>(in26);
+        bw.write<6>(in27);
+        bw.write<6>(in28);
+        bw.write<6>(in29);
+        bw.write<6>(in30);
+        bw.write<6>(in31);
+        bw.write<6>(in32);
+        bw.write<6>(in33);
+        bw.write<6>(in34);
+        bw.write<6>(in35);
+        bw.write<6>(in36);
+        bw.write<6>(in37);
+        bw.write<6>(in38);
+        bw.write<6>(in39);
+        bw.write<6>(in40);
+        bw.write<6>(in41);
+        bw.write<6>(in42);
+    }
+
+    void deserialize(bitreader &br)
+    {
+        opcode = br.read<decltype(opcode), 8>();
+        in1 = br.read<decltype(in1), 6>();
+        in2 = br.read<decltype(in2), 6>();
+        in3 = br.read<decltype(in3), 6>();
+        in4 = br.read<decltype(in4), 6>();
+        in5 = br.read<decltype(in5), 6>();
+        in6 = br.read<decltype(in6), 6>();
+        in7 = br.read<decltype(in7), 6>();
+        in8 = br.read<decltype(in8), 6>();
+        in9 = br.read<decltype(in9), 6>();
+        in10 = br.read<decltype(in10), 6>();
+        in11 = br.read<decltype(in11), 6>();
+        in12 = br.read<decltype(in12), 6>();
+        in13 = br.read<decltype(in13), 6>();
+        in14 = br.read<decltype(in14), 6>();
+        in15 = br.read<decltype(in15), 6>();
+        in16 = br.read<decltype(in16), 6>();
+        in17 = br.read<decltype(in17), 6>();
+        in18 = br.read<decltype(in18), 6>();
+        in19 = br.read<decltype(in19), 6>();
+        in20 = br.read<decltype(in20), 6>();
+        in21 = br.read<decltype(in21), 6>();
+        in22 = br.read<decltype(in22), 6>();
+        in23 = br.read<decltype(in23), 6>();
+        in24 = br.read<decltype(in24), 6>();
+        in25 = br.read<decltype(in25), 6>();
+        in26 = br.read<decltype(in26), 6>();
+        in27 = br.read<decltype(in27), 6>();
+        in28 = br.read<decltype(in28), 6>();
+        in29 = br.read<decltype(in29), 6>();
+        in30 = br.read<decltype(in30), 6>();
+        in31 = br.read<decltype(in31), 6>();
+        in32 = br.read<decltype(in32), 6>();
+        in33 = br.read<decltype(in33), 6>();
+        in34 = br.read<decltype(in34), 6>();
+        in35 = br.read<decltype(in35), 6>();
+        in36 = br.read<decltype(in36), 6>();
+        in37 = br.read<decltype(in37), 6>();
+        in38 = br.read<decltype(in38), 6>();
+        in39 = br.read<decltype(in39), 6>();
+        in40 = br.read<decltype(in40), 6>();
+        in41 = br.read<decltype(in41), 6>();
+        in42 = br.read<decltype(in42), 6>();
+    }
+};
+
+////////////////////////////
+class gnne_instruction;
+class inst_nop;
+class inst_li;
+class inst_intr;
+class inst_end;
+class inst_fence;
+class inst_mmu_conf;
+class inst_fence_ccr;
+class inst_loadif_config;
+class inst_loadif;
+class inst_load;
+class inst_loadif_compress_conf;
+class inst_load_compress_conf;
+class inst_store;
+class inst_store_t_config;
+class inst_store_t;
+class inst_store_t_compress_conf;
+class inst_store_compress_conf;
+class inst_tcu_dm_broadcast;
+class inst_tcu_dm_conf_if;
+class inst_tcu_dm_fetchif;
+class inst_tcu_dm_conf_w;
+class inst_tcu_dm_fetchw;
+class inst_tcu_dm_conf_of;
+class inst_tcu_pu_conf;
+class inst_tcu_pu_conf_act;
+class inst_tcu_pu_compute;
+class inst_tcu_dot_dm_if_conf;
+class inst_tcu_dot_dm_of_conf;
+class inst_tcu_dot_dm_fetch_src1;
+class inst_tcu_dot_dm_fetch_src2;
+class inst_tcu_pu_compute_dummy;
+class inst_mfu_mn_map_compute;
+class inst_mfu_mn_vmap_compute;
+class inst_mfu_reduce;
+class inst_mfu_vreduce;
+class inst_mfu_mn_broadcast_compute;
+class inst_mfu_mn_reduce;
+class inst_mfu_mn_conf;
+class inst_mfu_mnop_conf;
+class inst_mfu_pdp_conf;
+class inst_mfu_pdp_src_conf;
+class inst_mfu_pdp_reduce;
+class inst_mfu_mn_broadcast_conf;
+class inst_mfu_crop;
+class inst_mfu_memset;
+class inst_mfu_memcpy;
+class inst_mfu_trans;
+class inst_mfu_mn_conf2;
+class gnne_instruction
+{
+public:
+    virtual ~gnne_instruction() = default;
+    virtual void serialize(binary_writer &writer) const = 0;
+    virtual void to_string(std::ostream &out) const = 0;
+    [[nodiscard]] virtual OPCODE opcode() const = 0;
+    [[nodiscard]] std::string to_string() const;
+};
+
+std::ostream &operator<<(std::ostream &out, const gnne_instruction &c);
+
+//////////////////////////////////
+// auto generated instructions
+
+/**
+    NOP
+    @brief 无操作
+    - OPCODE opcode 无操作
+**/
+class inst_nop : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 无操作 **/
+public:
+    inst_nop();
+
+    explicit inst_nop(const INST_NOP &ref);
+
+    [[nodiscard]] struct INST_NOP to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 无操作
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 无操作
+  */
+    void opcode(const OPCODE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_nop &c);
+
+/**
+    LI
+    @brief Load 一个 64bit 的立即数到指定的寄存器
+    - OPCODE opcode Load 一个 64bit 的立即数到指定的寄存器
+    - REG regid 寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==}
+    - uint64_t imm 立即数
+**/
+class inst_li : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** Load 一个 64bit 的立即数到指定的寄存器 **/
+    REG regid_ = REG(0); /** 寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==} **/
+    uint64_t imm_ = uint64_t(0); /** 立即数 **/
+public:
+    inst_li(REG regid = REG(0), uint64_t imm = uint64_t(0));
+
+    explicit inst_li(const INST_LI &ref);
+
+    [[nodiscard]] struct INST_LI to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode Load 一个 64bit 的立即数到指定的寄存器
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode Load 一个 64bit 的立即数到指定的寄存器
+  */
+    void opcode(const OPCODE &value);
+    /**
+      REG regid 寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==}
+  */
+    [[nodiscard]] REG regid() const;
+    /**
+      REG regid 寄存器编号。
+这个寄存器的编号只能编码32个寄存器区域。
+{== TODO：是否要编码其他内容 ==}
+  */
+    void regid(const REG &value);
+    /**
+      uint64_t imm 立即数
+  */
+    [[nodiscard]] uint64_t imm() const;
+    /**
+      uint64_t imm 立即数
+  */
+    void imm(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_li &c);
+
+/**
+    INTR
+    @brief 触发向DSP的软中断
+    - OPCODE opcode 触发向DSP的软中断
+    - uint64_t intr_number 中断号，用于设置inptr寄存器
+    - uint64_t regmask 标记哪些寄存器被用于传参，用于设置regmask寄存器
+    - uint64_t ptrmask
+标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器
+**/
+class inst_intr : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 触发向DSP的软中断 **/
+    uint64_t intr_number_ = uint64_t(0); /** 中断号，用于设置inptr寄存器 **/
+    uint64_t regmask_ = uint64_t(0); /** 标记哪些寄存器被用于传参，用于设置regmask寄存器 **/
+    uint64_t ptrmask_ = uint64_t(
+        0); /** 标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器 **/
+public:
+    inst_intr(uint64_t intr_number = uint64_t(0), uint64_t regmask = uint64_t(0),
+        uint64_t ptrmask = uint64_t(0));
+
+    explicit inst_intr(const INST_INTR &ref);
+
+    [[nodiscard]] struct INST_INTR to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 触发向DSP的软中断
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 触发向DSP的软中断
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t intr_number 中断号，用于设置inptr寄存器
+  */
+    [[nodiscard]] uint64_t intr_number() const;
+    /**
+      uint64_t intr_number 中断号，用于设置inptr寄存器
+  */
+    void intr_number(const uint64_t &value);
+    /**
+      uint64_t regmask 标记哪些寄存器被用于传参，用于设置regmask寄存器
+  */
+    [[nodiscard]] uint64_t regmask() const;
+    /**
+      uint64_t regmask 标记哪些寄存器被用于传参，用于设置regmask寄存器
+  */
+    void regmask(const uint64_t &value);
+    /**
+      uint64_t ptrmask
+     标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器
+  */
+    [[nodiscard]] uint64_t ptrmask() const;
+    /**
+      uint64_t ptrmask
+     标记寄存器里的内容是指针类型还是数据，用于设置ptrmask寄存器
+  */
+    void ptrmask(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_intr &c);
+
+/**
+    END
+    @brief 表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+    - OPCODE opcode 表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+    - uint64_t intr_number 中断号，用于设置inptr寄存器
+**/
+class inst_end : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 表示GNNE程序执行结束，GNNE向总中断控制器发起中断 **/
+    uint64_t intr_number_ = uint64_t(0); /** 中断号，用于设置inptr寄存器 **/
+public:
+    inst_end(uint64_t intr_number = uint64_t(0));
+
+    explicit inst_end(const INST_END &ref);
+
+    [[nodiscard]] struct INST_END to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 表示GNNE程序执行结束，GNNE向总中断控制器发起中断
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t intr_number 中断号，用于设置inptr寄存器
+  */
+    [[nodiscard]] uint64_t intr_number() const;
+    /**
+      uint64_t intr_number 中断号，用于设置inptr寄存器
+  */
+    void intr_number(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_end &c);
+
+/**
+    FENCE
+    @brief 设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+    - OPCODE opcode
+设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+**/
+class inst_fence : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(
+        0); /** 设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+             **/
+public:
+    inst_fence();
+
+    explicit inst_fence(const INST_FENCE &ref);
+
+    [[nodiscard]] struct INST_FENCE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode
+     设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode
+     设置内存屏障。在屏障前面的指令一定都执行完成，后面的指令才会被执行
+  */
+    void opcode(const OPCODE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_fence &c);
+
+/**
+    MMU.CONF
+    @brief 配置某条MMU规则
+    - OPCODE opcode 配置某条MMU规则
+    - uint64_t mmu_item 当前配置的MMU规则项编号，0-15
+    - uint64_t start_bank 当前规则开始的bank
+    - MMU_CONF_WIDTH width 当前配置宽度信息
+    - uint64_t start_depth 当前规则开始的纵坐标
+    - uint64_t depth
+当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+**/
+class inst_mmu_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置某条MMU规则 **/
+    uint64_t mmu_item_ = uint64_t(0); /** 当前配置的MMU规则项编号，0-15 **/
+    uint64_t start_bank_ = uint64_t(0); /** 当前规则开始的bank **/
+    MMU_CONF_WIDTH width_ = MMU_CONF_WIDTH(0); /** 当前配置宽度信息 **/
+    uint64_t start_depth_ = uint64_t(0); /** 当前规则开始的纵坐标 **/
+    uint64_t depth_ = uint64_t(0); /**
+                                          当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+                                          **/
+public:
+    inst_mmu_conf(uint64_t mmu_item = uint64_t(0),
+        uint64_t start_bank = uint64_t(0),
+        MMU_CONF_WIDTH width = MMU_CONF_WIDTH(0),
+        uint64_t start_depth = uint64_t(0),
+        uint64_t depth = uint64_t(0));
+
+    explicit inst_mmu_conf(const INST_MMU_CONF &ref);
+
+    [[nodiscard]] struct INST_MMU_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置某条MMU规则
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置某条MMU规则
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t mmu_item 当前配置的MMU规则项编号，0-15
+  */
+    [[nodiscard]] uint64_t mmu_item() const;
+    /**
+      uint64_t mmu_item 当前配置的MMU规则项编号，0-15
+  */
+    void mmu_item(const uint64_t &value);
+    /**
+      uint64_t start_bank 当前规则开始的bank
+  */
+    [[nodiscard]] uint64_t start_bank() const;
+    /**
+      uint64_t start_bank 当前规则开始的bank
+  */
+    void start_bank(const uint64_t &value);
+    /**
+      MMU_CONF_WIDTH width 当前配置宽度信息
+  */
+    [[nodiscard]] MMU_CONF_WIDTH width() const;
+    /**
+      MMU_CONF_WIDTH width 当前配置宽度信息
+  */
+    void width(const MMU_CONF_WIDTH &value);
+    /**
+      uint64_t start_depth 当前规则开始的纵坐标
+  */
+    [[nodiscard]] uint64_t start_depth() const;
+    /**
+      uint64_t start_depth 当前规则开始的纵坐标
+  */
+    void start_depth(const uint64_t &value);
+    /**
+      uint64_t depth
+     当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+  */
+    [[nodiscard]] uint64_t depth() const;
+    /**
+      uint64_t depth
+     当前规则深度。这个值是相对与开始深度的差值，注意是深度而不是结束深度。
+  */
+    void depth(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mmu_conf &c);
+
+/**
+    FENCE.CCR
+    @brief
+CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+    - OPCODE opcode
+CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+    - uint64_t ccr CCR寄存器id
+    - uint64_t mode 0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr
+**/
+class inst_fence_ccr : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /**
+                                   CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+                                   **/
+    uint64_t ccr_ = uint64_t(0); /** CCR寄存器id **/
+    uint64_t mode_ = uint64_t(0); /** 0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr **/
+public:
+    inst_fence_ccr(uint64_t ccr = uint64_t(0), uint64_t mode = uint64_t(0));
+
+    explicit inst_fence_ccr(const INST_FENCE_CCR &ref);
+
+    [[nodiscard]] struct INST_FENCE_CCR to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode
+     CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode
+     CCR屏障，用来阻挡使用到本CCR的指令的分发，可以用来实现给CCR重新分配空间等作用
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t ccr CCR寄存器id
+  */
+    [[nodiscard]] uint64_t ccr() const;
+    /**
+      uint64_t ccr CCR寄存器id
+  */
+    void ccr(const uint64_t &value);
+    /**
+      uint64_t mode 0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr
+  */
+    [[nodiscard]] uint64_t mode() const;
+    /**
+      uint64_t mode 0: wait ccr is 0
+1: wait ccr is not 0 and clear ccr
+  */
+    void mode(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_fence_ccr &c);
+
+/**
+    LOADIF.CONFIG
+    @brief 用于配置从 DDR 中加载 input featuremap 的一些基础参数
+    - OPCODE opcode 用于配置从 DDR 中加载 input featuremap 的一些基础参数
+    - uint64_t layout_ddr_n 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_c 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_h 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - uint64_t layout_ddr_w 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+    - STRIDE_GLB stride_glb 输出 Tensor 的尺寸信息，用于计算输出地址跳转
+    - uint64_t mmu_item 使用的内存映射方案
+    - ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+    - QUAN_SIGNED input_signed 量化数据是否是有符号数据
+    - PRECISION precision_glb GLB中数据的类型
+    - PRECISION_DDR precision_ddr DDR 中的数据类型
+    - QUAN_TYPE quan_type 量化类型，bychennel or by batch
+**/
+class inst_loadif_config : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 用于配置从 DDR 中加载 input featuremap 的一些基础参数 **/
+    uint64_t layout_ddr_n_ = uint64_t(0); /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t layout_ddr_c_ = uint64_t(0); /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t layout_ddr_h_ = uint64_t(0); /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    uint64_t layout_ddr_w_ = uint64_t(0); /** 输入 Tensor 的尺寸信息，用于计算输入地址跳转 **/
+    STRIDE_GLB stride_glb_ = STRIDE_GLB(0); /** 输出 Tensor 的尺寸信息，用于计算输出地址跳转 **/
+    uint64_t mmu_item_ = uint64_t(0); /** 使用的内存映射方案 **/
+    ADDR_GLB_8_WITH_BANK addr_qarg_ = ADDR_GLB_8_WITH_BANK(0); /** 量化参数地址 **/
+    QUAN_SIGNED input_signed_ = QUAN_SIGNED(0); /** 量化数据是否是有符号数据 **/
+    PRECISION precision_glb_ = PRECISION(0); /** GLB中数据的类型  **/
+    PRECISION_DDR precision_ddr_ = PRECISION_DDR(0); /** DDR 中的数据类型 **/
+    QUAN_TYPE quan_type_ = QUAN_TYPE(0); /** 量化类型，bychennel or by batch **/
+public:
+    inst_loadif_config(uint64_t layout_ddr_n = uint64_t(0),
+        uint64_t layout_ddr_c = uint64_t(0),
+        uint64_t layout_ddr_h = uint64_t(0),
+        uint64_t layout_ddr_w = uint64_t(0),
+        STRIDE_GLB stride_glb = STRIDE_GLB(0),
+        uint64_t mmu_item = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_qarg = ADDR_GLB_8_WITH_BANK(0),
+        QUAN_SIGNED input_signed = QUAN_SIGNED(0),
+        PRECISION precision_glb = PRECISION(0),
+        PRECISION_DDR precision_ddr = PRECISION_DDR(0),
+        QUAN_TYPE quan_type = QUAN_TYPE(0));
+
+    explicit inst_loadif_config(const INST_LOADIF_CONFIG &ref);
+
+    [[nodiscard]] struct INST_LOADIF_CONFIG to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 用于配置从 DDR 中加载 input featuremap 的一些基础参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 用于配置从 DDR 中加载 input featuremap 的一些基础参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t layout_ddr_n 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_n() const;
+    /**
+      uint64_t layout_ddr_n 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    void layout_ddr_n(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_c 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_c() const;
+    /**
+      uint64_t layout_ddr_c 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    void layout_ddr_c(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_h 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_h() const;
+    /**
+      uint64_t layout_ddr_h 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    void layout_ddr_h(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_w 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_w() const;
+    /**
+      uint64_t layout_ddr_w 输入 Tensor 的尺寸信息，用于计算输入地址跳转
+  */
+    void layout_ddr_w(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_glb 输出 Tensor 的尺寸信息，用于计算输出地址跳转
+  */
+    [[nodiscard]] STRIDE_GLB stride_glb() const;
+    /**
+      STRIDE_GLB stride_glb 输出 Tensor 的尺寸信息，用于计算输出地址跳转
+  */
+    void stride_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    [[nodiscard]] uint64_t mmu_item() const;
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    void mmu_item(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_qarg() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+  */
+    void addr_qarg(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      QUAN_SIGNED input_signed 量化数据是否是有符号数据
+  */
+    [[nodiscard]] QUAN_SIGNED input_signed() const;
+    /**
+      QUAN_SIGNED input_signed 量化数据是否是有符号数据
+  */
+    void input_signed(const QUAN_SIGNED &value);
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    void precision_glb(const PRECISION &value);
+    /**
+      PRECISION_DDR precision_ddr DDR 中的数据类型
+  */
+    [[nodiscard]] PRECISION_DDR precision_ddr() const;
+    /**
+      PRECISION_DDR precision_ddr DDR 中的数据类型
+  */
+    void precision_ddr(const PRECISION_DDR &value);
+    /**
+      QUAN_TYPE quan_type 量化类型，bychennel or by batch
+  */
+    [[nodiscard]] QUAN_TYPE quan_type() const;
+    /**
+      QUAN_TYPE quan_type 量化类型，bychennel or by batch
+  */
+    void quan_type(const QUAN_TYPE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_loadif_config &c);
+
+/**
+    LOADIF
+    @brief 从 DDR 中加载张量到 GLB 中
+    - OPCODE opcode 从 DDR 中加载张量到 GLB 中
+    - CCRCLR ccrclr None
+    - CCRCLR ccrclr_qarg None
+    - CCRSET ccrset 数据依赖配置
+    - ADDR addr_src DDR 中 张量当前数据 的起始地址。
+    - ADDR_GLB_8_WITHOUT_BANK addr_dest 存储到 GLB 中的地址
+    - uint64_t shape_n 取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_c 取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_h 取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t shape_w 取 Tensor 的形状的配置，用来决定实际搬运的数据
+    - uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+**/
+class inst_loadif : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 从 DDR 中加载张量到 GLB 中 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRCLR ccrclr_qarg_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** 数据依赖配置 **/
+    ADDR addr_src_ = ADDR(0); /** DDR 中 张量当前数据 的起始地址。 **/
+    ADDR_GLB_8_WITHOUT_BANK addr_dest_ = ADDR_GLB_8_WITHOUT_BANK(0); /** 存储到 GLB 中的地址 **/
+    uint64_t shape_n_ = uint64_t(0); /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_c_ = uint64_t(0); /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_h_ = uint64_t(0); /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t shape_w_ = uint64_t(0); /** 取 Tensor 的形状的配置，用来决定实际搬运的数据 **/
+    uint64_t basement_ = uint64_t(0); /** DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值 **/
+public:
+    inst_loadif(CCRCLR ccrclr = CCRCLR(0), CCRCLR ccrclr_qarg = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0), ADDR addr_src = ADDR(0),
+        ADDR_GLB_8_WITHOUT_BANK addr_dest = ADDR_GLB_8_WITHOUT_BANK(0),
+        uint64_t shape_n = uint64_t(0), uint64_t shape_c = uint64_t(0),
+        uint64_t shape_h = uint64_t(0), uint64_t shape_w = uint64_t(0),
+        uint64_t basement = uint64_t(0));
+
+    explicit inst_loadif(const INST_LOADIF &ref);
+
+    [[nodiscard]] struct INST_LOADIF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 从 DDR 中加载张量到 GLB 中
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 从 DDR 中加载张量到 GLB 中
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    [[nodiscard]] CCRCLR ccrclr_qarg() const;
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    void ccrclr_qarg(const CCRCLR &value);
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR addr_src DDR 中 张量当前数据 的起始地址。
+  */
+    [[nodiscard]] ADDR addr_src() const;
+    /**
+      ADDR addr_src DDR 中 张量当前数据 的起始地址。
+  */
+    void addr_src(const ADDR &value);
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_dest 存储到 GLB 中的地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITHOUT_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_dest 存储到 GLB 中的地址
+  */
+    void addr_dest(const ADDR_GLB_8_WITHOUT_BANK &value);
+    /**
+      uint64_t shape_n 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w 取 Tensor 的形状的配置，用来决定实际搬运的数据
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+  */
+    [[nodiscard]] uint64_t basement() const;
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+  */
+    void basement(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_loadif &c);
+
+/**
+    LOAD
+    @brief 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+指定的位置上，可用来加载 weights 和其他数据
+    - OPCODE opcode 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+指定的位置上，可用来加载 weights 和其他数据
+    - CCRCLR ccrclr None
+    - CCRCLR ccrclr_qarg None
+    - CCRSET ccrset 数据依赖配置
+    - ADDR addr_src DDR 中数据的地址
+    - ADDR_GLB_8_WITH_BANK addr_dest GLB 中的地址
+    - uint64_t length 数据的长度
+    - ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+    - uint64_t chan_qarg 每个量化参数持续作用的个数
+    - uint64_t shape_c
+量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+    - uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+    - QUAN_SIGNED input_signed None
+    - PRECISION precision_glb GLB中数据的类型
+    - PRECISION_DDR precision_ddr DDR 中的数据类型
+    - uint64_t stream 是否为流式输入
+**/
+class inst_load : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+                                 指定的位置上，可用来加载 weights 和其他数据 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRCLR ccrclr_qarg_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** 数据依赖配置 **/
+    ADDR addr_src_ = ADDR(0); /** DDR 中数据的地址 **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** GLB 中的地址 **/
+    uint64_t length_ = uint64_t(0); /** 数据的长度 **/
+    ADDR_GLB_8_WITH_BANK addr_qarg_ = ADDR_GLB_8_WITH_BANK(0); /** 量化参数地 **/
+    uint64_t chan_qarg_ = uint64_t(0); /** 每个量化参数持续作用的个数 **/
+    uint64_t shape_c_ = uint64_t(
+        0); /** 量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+             **/
+    uint64_t basement_ = uint64_t(0); /** DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值 **/
+    QUAN_SIGNED input_signed_ = QUAN_SIGNED(0); /** None **/
+    PRECISION precision_glb_ = PRECISION(0); /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr_ = PRECISION_DDR(0); /** DDR 中的数据类型 **/
+    uint64_t stream_ = uint64_t(0); /** 是否为流式输入 **/
+public:
+    inst_load(CCRCLR ccrclr = CCRCLR(0), CCRCLR ccrclr_qarg = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0), ADDR addr_src = ADDR(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t length = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_qarg = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t chan_qarg = uint64_t(0), uint64_t shape_c = uint64_t(0),
+        uint64_t basement = uint64_t(0),
+        QUAN_SIGNED input_signed = QUAN_SIGNED(0),
+        PRECISION precision_glb = PRECISION(0),
+        PRECISION_DDR precision_ddr = PRECISION_DDR(0),
+        uint64_t stream = uint64_t(0));
+
+    explicit inst_load(const INST_LOAD &ref);
+
+    [[nodiscard]] struct INST_LOAD to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+     指定的位置上，可用来加载 weights 和其他数据
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 从 DDR 中加载一段给定长度的一维数据数据到 GLB
+     指定的位置上，可用来加载 weights 和其他数据
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    [[nodiscard]] CCRCLR ccrclr_qarg() const;
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    void ccrclr_qarg(const CCRCLR &value);
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR addr_src DDR 中数据的地址
+  */
+    [[nodiscard]] ADDR addr_src() const;
+    /**
+      ADDR addr_src DDR 中数据的地址
+  */
+    void addr_src(const ADDR &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest GLB 中的地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest GLB 中的地址
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t length 数据的长度
+  */
+    [[nodiscard]] uint64_t length() const;
+    /**
+      uint64_t length 数据的长度
+  */
+    void length(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_qarg() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+  */
+    void addr_qarg(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t chan_qarg 每个量化参数持续作用的个数
+  */
+    [[nodiscard]] uint64_t chan_qarg() const;
+    /**
+      uint64_t chan_qarg 每个量化参数持续作用的个数
+  */
+    void chan_qarg(const uint64_t &value);
+    /**
+      uint64_t shape_c
+     量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c
+     量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+  */
+    [[nodiscard]] uint64_t basement() const;
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号。
+DDR访问的地址需要加上这个寄存器指示的寄存器的值
+  */
+    void basement(const uint64_t &value);
+    /**
+      QUAN_SIGNED input_signed None
+  */
+    [[nodiscard]] QUAN_SIGNED input_signed() const;
+    /**
+      QUAN_SIGNED input_signed None
+  */
+    void input_signed(const QUAN_SIGNED &value);
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    void precision_glb(const PRECISION &value);
+    /**
+      PRECISION_DDR precision_ddr DDR 中的数据类型
+  */
+    [[nodiscard]] PRECISION_DDR precision_ddr() const;
+    /**
+      PRECISION_DDR precision_ddr DDR 中的数据类型
+  */
+    void precision_ddr(const PRECISION_DDR &value);
+    /**
+      uint64_t stream 是否为流式输入
+  */
+    [[nodiscard]] uint64_t stream() const;
+    /**
+      uint64_t stream 是否为流式输入
+  */
+    void stream(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_load &c);
+
+/**
+    LOADIF.COMPRESS.CONF
+    @brief 配置loadif的稀疏、压缩、参数
+    - OPCODE opcode 配置loadif的稀疏、压缩、参数
+    - ADDR addr_bmp bitmap的地址
+    - ADDR addr_code_len 每一行编码之后的长度存放的地址
+    - ADDR addr_block_len 码块编码之后长度的存放地址
+    - uint64_t code_lines 每次编码的行数
+    - SPARSIFIED sparsified_ddr 是否稀疏
+    - COMPRESSED compress_ddr 是否压缩
+**/
+class inst_loadif_compress_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置loadif的稀疏、压缩、参数 **/
+    ADDR addr_bmp_ = ADDR(0); /** bitmap的地址 **/
+    ADDR addr_code_len_ = ADDR(0); /** 每一行编码之后的长度存放的地址 **/
+    ADDR addr_block_len_ = ADDR(0); /** 码块编码之后长度的存放地址 **/
+    uint64_t code_lines_ = uint64_t(0); /** 每次编码的行数 **/
+    SPARSIFIED sparsified_ddr_ = SPARSIFIED(0); /** 是否稀疏 **/
+    COMPRESSED compress_ddr_ = COMPRESSED(0); /** 是否压缩 **/
+public:
+    inst_loadif_compress_conf(ADDR addr_bmp = ADDR(0),
+        ADDR addr_code_len = ADDR(0),
+        ADDR addr_block_len = ADDR(0),
+        uint64_t code_lines = uint64_t(0),
+        SPARSIFIED sparsified_ddr = SPARSIFIED(0),
+        COMPRESSED compress_ddr = COMPRESSED(0));
+
+    explicit inst_loadif_compress_conf(const INST_LOADIF_COMPRESS_CONF &ref);
+
+    [[nodiscard]] struct INST_LOADIF_COMPRESS_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置loadif的稀疏、压缩、参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置loadif的稀疏、压缩、参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    [[nodiscard]] ADDR addr_bmp() const;
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    void addr_bmp(const ADDR &value);
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    [[nodiscard]] ADDR addr_code_len() const;
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    void addr_code_len(const ADDR &value);
+    /**
+      ADDR addr_block_len 码块编码之后长度的存放地址
+  */
+    [[nodiscard]] ADDR addr_block_len() const;
+    /**
+      ADDR addr_block_len 码块编码之后长度的存放地址
+  */
+    void addr_block_len(const ADDR &value);
+    /**
+      uint64_t code_lines 每次编码的行数
+  */
+    [[nodiscard]] uint64_t code_lines() const;
+    /**
+      uint64_t code_lines 每次编码的行数
+  */
+    void code_lines(const uint64_t &value);
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    [[nodiscard]] SPARSIFIED sparsified_ddr() const;
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    void sparsified_ddr(const SPARSIFIED &value);
+    /**
+      COMPRESSED compress_ddr 是否压缩
+  */
+    [[nodiscard]] COMPRESSED compress_ddr() const;
+    /**
+      COMPRESSED compress_ddr 是否压缩
+  */
+    void compress_ddr(const COMPRESSED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_loadif_compress_conf &c);
+
+/**
+    LOAD.COMPRESS.CONF
+    @brief 配置load的稀疏、压缩、参数
+    - OPCODE opcode 配置load的稀疏、压缩、参数
+    - ADDR addr_bmp bitmap的地址
+    - ADDR addr_code_len 每一行编码之后的长度存放的地址
+    - SPARSIFIED sparsified_ddr 是否稀疏
+**/
+class inst_load_compress_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置load的稀疏、压缩、参数 **/
+    ADDR addr_bmp_ = ADDR(0); /** bitmap的地址 **/
+    ADDR addr_code_len_ = ADDR(0); /** 每一行编码之后的长度存放的地址 **/
+    SPARSIFIED sparsified_ddr_ = SPARSIFIED(0); /** 是否稀疏 **/
+public:
+    inst_load_compress_conf(ADDR addr_bmp = ADDR(0), ADDR addr_code_len = ADDR(0),
+        SPARSIFIED sparsified_ddr = SPARSIFIED(0));
+
+    explicit inst_load_compress_conf(const INST_LOAD_COMPRESS_CONF &ref);
+
+    [[nodiscard]] struct INST_LOAD_COMPRESS_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置load的稀疏、压缩、参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置load的稀疏、压缩、参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    [[nodiscard]] ADDR addr_bmp() const;
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    void addr_bmp(const ADDR &value);
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    [[nodiscard]] ADDR addr_code_len() const;
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    void addr_code_len(const ADDR &value);
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    [[nodiscard]] SPARSIFIED sparsified_ddr() const;
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    void sparsified_ddr(const SPARSIFIED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_load_compress_conf &c);
+
+/**
+    STORE
+    @brief 将 GLB 中的给定长度的一维数据写回 DDR
+    - OPCODE opcode 将 GLB 中的给定长度的一维数据写回 DDR
+    - CCRCLR ccrclr 数据依赖配置
+    - CCRCLR ccrclr_qarg None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_src 数据在 GLB 中的起始位置
+    - ADDR addr_dest 输出到 DDR 的位置
+    - PRECISION precision_glb GLB中数据的类型
+    - PRECISION_DDR precision_ddr 输出数据精度
+    - QUAN_SIGNED output_signed 量化数据是否是有符号数据
+    - uint64_t length 数据长度
+    - ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+    - uint64_t chan_qarg 每个量化参数持续作用的个数
+    - uint64_t shape_c
+量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+    - uint64_t clamp_hi None
+    - uint64_t clamp_lo None
+    - uint64_t basement DDR寻址偏移寄存器编号
+**/
+class inst_store : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 将 GLB 中的给定长度的一维数据写回 DDR **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** 数据依赖配置 **/
+    CCRCLR ccrclr_qarg_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src_ = ADDR_GLB_8_WITH_BANK(0); /** 数据在 GLB 中的起始位置 **/
+    ADDR addr_dest_ = ADDR(0); /** 输出到 DDR 的位置 **/
+    PRECISION precision_glb_ = PRECISION(0); /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr_ = PRECISION_DDR(0); /** 输出数据精度 **/
+    QUAN_SIGNED output_signed_ = QUAN_SIGNED(0); /** 量化数据是否是有符号数据 **/
+    uint64_t length_ = uint64_t(0); /** 数据长度 **/
+    ADDR_GLB_8_WITH_BANK addr_qarg_ = ADDR_GLB_8_WITH_BANK(0); /** 量化参数地 **/
+    uint64_t chan_qarg_ = uint64_t(0); /** 每个量化参数持续作用的个数 **/
+    uint64_t shape_c_ = uint64_t(
+        0); /** 量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+             **/
+    uint64_t clamp_hi_ = uint64_t(0); /** None **/
+    uint64_t clamp_lo_ = uint64_t(0); /** None **/
+    uint64_t basement_ = uint64_t(0); /** DDR寻址偏移寄存器编号 **/
+public:
+    inst_store(CCRCLR ccrclr = CCRCLR(0), CCRCLR ccrclr_qarg = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_src = ADDR_GLB_8_WITH_BANK(0),
+        ADDR addr_dest = ADDR(0), PRECISION precision_glb = PRECISION(0),
+        PRECISION_DDR precision_ddr = PRECISION_DDR(0),
+        QUAN_SIGNED output_signed = QUAN_SIGNED(0),
+        uint64_t length = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_qarg = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t chan_qarg = uint64_t(0), uint64_t shape_c = uint64_t(0),
+        uint64_t clamp_hi = uint64_t(0), uint64_t clamp_lo = uint64_t(0),
+        uint64_t basement = uint64_t(0));
+
+    explicit inst_store(const INST_STORE &ref);
+
+    [[nodiscard]] struct INST_STORE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 将 GLB 中的给定长度的一维数据写回 DDR
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 将 GLB 中的给定长度的一维数据写回 DDR
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr 数据依赖配置
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr 数据依赖配置
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    [[nodiscard]] CCRCLR ccrclr_qarg() const;
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    void ccrclr_qarg(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src 数据在 GLB 中的起始位置
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src 数据在 GLB 中的起始位置
+  */
+    void addr_src(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR addr_dest 输出到 DDR 的位置
+  */
+    [[nodiscard]] ADDR addr_dest() const;
+    /**
+      ADDR addr_dest 输出到 DDR 的位置
+  */
+    void addr_dest(const ADDR &value);
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    void precision_glb(const PRECISION &value);
+    /**
+      PRECISION_DDR precision_ddr 输出数据精度
+  */
+    [[nodiscard]] PRECISION_DDR precision_ddr() const;
+    /**
+      PRECISION_DDR precision_ddr 输出数据精度
+  */
+    void precision_ddr(const PRECISION_DDR &value);
+    /**
+      QUAN_SIGNED output_signed 量化数据是否是有符号数据
+  */
+    [[nodiscard]] QUAN_SIGNED output_signed() const;
+    /**
+      QUAN_SIGNED output_signed 量化数据是否是有符号数据
+  */
+    void output_signed(const QUAN_SIGNED &value);
+    /**
+      uint64_t length 数据长度
+  */
+    [[nodiscard]] uint64_t length() const;
+    /**
+      uint64_t length 数据长度
+  */
+    void length(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_qarg() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地
+  */
+    void addr_qarg(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t chan_qarg 每个量化参数持续作用的个数
+  */
+    [[nodiscard]] uint64_t chan_qarg() const;
+    /**
+      uint64_t chan_qarg 每个量化参数持续作用的个数
+  */
+    void chan_qarg(const uint64_t &value);
+    /**
+      uint64_t shape_c
+     量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c
+     量化参数的个数，等于总长度除以量化参数持续个数，硬件需要的冗余信息
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t clamp_hi None
+  */
+    [[nodiscard]] uint64_t clamp_hi() const;
+    /**
+      uint64_t clamp_hi None
+  */
+    void clamp_hi(const uint64_t &value);
+    /**
+      uint64_t clamp_lo None
+  */
+    [[nodiscard]] uint64_t clamp_lo() const;
+    /**
+      uint64_t clamp_lo None
+  */
+    void clamp_lo(const uint64_t &value);
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号
+  */
+    [[nodiscard]] uint64_t basement() const;
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号
+  */
+    void basement(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_store &c);
+
+/**
+    STORE.T.CONFIG
+    @brief 将 GLB 中 Tensor 的数据写回 DDR 的配置
+    - OPCODE opcode 将 GLB 中 Tensor 的数据写回 DDR 的配置
+    - uint64_t layout_ddr_n DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_c DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_h DDR中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t layout_ddr_w DDR中的Tensor的尺寸信息，用用计算跳转
+    - STRIDE_GLB stride_glb GLB中的Tensor的尺寸信息，用用计算跳转
+    - uint64_t mmu_item 使用的内存映射方案
+    - ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+    - QUAN_SIGNED output_signed 量化数据是否是有符号数据
+    - PRECISION precision_glb GLB中数据的类型
+    - PRECISION_DDR precision_ddr 输出数据精度
+    - QUAN_TYPE quan_type None
+    - uint64_t clamp_hi None
+    - uint64_t clamp_lo None
+**/
+class inst_store_t_config : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 将 GLB 中 Tensor 的数据写回 DDR 的配置 **/
+    uint64_t layout_ddr_n_ = uint64_t(0); /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_c_ = uint64_t(0); /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_h_ = uint64_t(0); /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t layout_ddr_w_ = uint64_t(0); /** DDR中的Tensor的尺寸信息，用用计算跳转 **/
+    STRIDE_GLB stride_glb_ = STRIDE_GLB(0); /** GLB中的Tensor的尺寸信息，用用计算跳转 **/
+    uint64_t mmu_item_ = uint64_t(0); /** 使用的内存映射方案 **/
+    ADDR_GLB_8_WITH_BANK addr_qarg_ = ADDR_GLB_8_WITH_BANK(0); /** 量化参数地址 **/
+    QUAN_SIGNED output_signed_ = QUAN_SIGNED(0); /** 量化数据是否是有符号数据 **/
+    PRECISION precision_glb_ = PRECISION(0); /** GLB中数据的类型 **/
+    PRECISION_DDR precision_ddr_ = PRECISION_DDR(0); /** 输出数据精度 **/
+    QUAN_TYPE quan_type_ = QUAN_TYPE(0); /** None **/
+    uint64_t clamp_hi_ = uint64_t(0); /** None **/
+    uint64_t clamp_lo_ = uint64_t(0); /** None **/
+public:
+    inst_store_t_config(
+        uint64_t layout_ddr_n = uint64_t(0), uint64_t layout_ddr_c = uint64_t(0),
+        uint64_t layout_ddr_h = uint64_t(0), uint64_t layout_ddr_w = uint64_t(0),
+        STRIDE_GLB stride_glb = STRIDE_GLB(0), uint64_t mmu_item = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_qarg = ADDR_GLB_8_WITH_BANK(0),
+        QUAN_SIGNED output_signed = QUAN_SIGNED(0),
+        PRECISION precision_glb = PRECISION(0),
+        PRECISION_DDR precision_ddr = PRECISION_DDR(0),
+        QUAN_TYPE quan_type = QUAN_TYPE(0), uint64_t clamp_hi = uint64_t(0),
+        uint64_t clamp_lo = uint64_t(0));
+
+    explicit inst_store_t_config(const INST_STORE_T_CONFIG &ref);
+
+    [[nodiscard]] struct INST_STORE_T_CONFIG to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 将 GLB 中 Tensor 的数据写回 DDR 的配置
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 将 GLB 中 Tensor 的数据写回 DDR 的配置
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t layout_ddr_n DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_n() const;
+    /**
+      uint64_t layout_ddr_n DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    void layout_ddr_n(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_c DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_c() const;
+    /**
+      uint64_t layout_ddr_c DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    void layout_ddr_c(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_h DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_h() const;
+    /**
+      uint64_t layout_ddr_h DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    void layout_ddr_h(const uint64_t &value);
+    /**
+      uint64_t layout_ddr_w DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    [[nodiscard]] uint64_t layout_ddr_w() const;
+    /**
+      uint64_t layout_ddr_w DDR中的Tensor的尺寸信息，用用计算跳转
+  */
+    void layout_ddr_w(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_glb GLB中的Tensor的尺寸信息，用用计算跳转
+  */
+    [[nodiscard]] STRIDE_GLB stride_glb() const;
+    /**
+      STRIDE_GLB stride_glb GLB中的Tensor的尺寸信息，用用计算跳转
+  */
+    void stride_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    [[nodiscard]] uint64_t mmu_item() const;
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    void mmu_item(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_qarg() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_qarg 量化参数地址
+  */
+    void addr_qarg(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      QUAN_SIGNED output_signed 量化数据是否是有符号数据
+  */
+    [[nodiscard]] QUAN_SIGNED output_signed() const;
+    /**
+      QUAN_SIGNED output_signed 量化数据是否是有符号数据
+  */
+    void output_signed(const QUAN_SIGNED &value);
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb GLB中数据的类型
+  */
+    void precision_glb(const PRECISION &value);
+    /**
+      PRECISION_DDR precision_ddr 输出数据精度
+  */
+    [[nodiscard]] PRECISION_DDR precision_ddr() const;
+    /**
+      PRECISION_DDR precision_ddr 输出数据精度
+  */
+    void precision_ddr(const PRECISION_DDR &value);
+    /**
+      QUAN_TYPE quan_type None
+  */
+    [[nodiscard]] QUAN_TYPE quan_type() const;
+    /**
+      QUAN_TYPE quan_type None
+  */
+    void quan_type(const QUAN_TYPE &value);
+    /**
+      uint64_t clamp_hi None
+  */
+    [[nodiscard]] uint64_t clamp_hi() const;
+    /**
+      uint64_t clamp_hi None
+  */
+    void clamp_hi(const uint64_t &value);
+    /**
+      uint64_t clamp_lo None
+  */
+    [[nodiscard]] uint64_t clamp_lo() const;
+    /**
+      uint64_t clamp_lo None
+  */
+    void clamp_lo(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_store_t_config &c);
+
+/**
+    STORE.T
+    @brief 将 GLB 中 Tensor 的数据写回 DDR，并且可能发生转置或者数据类型转换
+    - OPCODE opcode 将 GLB 中 Tensor 的数据写回
+DDR，并且可能发生转置或者数据类型转换
+    - CCRCLR ccrclr 数据依赖配置
+    - CCRCLR ccrclr_qarg None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITHOUT_BANK addr_src Tensor 在 GLB 中的起始位置
+    - ADDR addr_dest 输出到 DDR 的位置
+    - uint64_t shape_n Slice 长度信息
+    - uint64_t shape_c Slice 长度信息
+    - uint64_t shape_h Slice 长度信息
+    - uint64_t shape_w Slice 长度信息
+    - uint64_t basement DDR寻址偏移寄存器编号
+**/
+class inst_store_t : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 将 GLB 中 Tensor 的数据写回
+                                      DDR，并且可能发生转置或者数据类型转换 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** 数据依赖配置 **/
+    CCRCLR ccrclr_qarg_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITHOUT_BANK addr_src_ = ADDR_GLB_8_WITHOUT_BANK(0); /** Tensor 在 GLB 中的起始位置 **/
+    ADDR addr_dest_ = ADDR(0); /** 输出到 DDR 的位置 **/
+    uint64_t shape_n_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_c_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_h_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_w_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t basement_ = uint64_t(0); /** DDR寻址偏移寄存器编号 **/
+public:
+    inst_store_t(CCRCLR ccrclr = CCRCLR(0), CCRCLR ccrclr_qarg = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITHOUT_BANK addr_src = ADDR_GLB_8_WITHOUT_BANK(0),
+        ADDR addr_dest = ADDR(0), uint64_t shape_n = uint64_t(0),
+        uint64_t shape_c = uint64_t(0), uint64_t shape_h = uint64_t(0),
+        uint64_t shape_w = uint64_t(0), uint64_t basement = uint64_t(0));
+
+    explicit inst_store_t(const INST_STORE_T &ref);
+
+    [[nodiscard]] struct INST_STORE_T to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 将 GLB 中 Tensor 的数据写回
+     DDR，并且可能发生转置或者数据类型转换
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 将 GLB 中 Tensor 的数据写回
+     DDR，并且可能发生转置或者数据类型转换
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr 数据依赖配置
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr 数据依赖配置
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    [[nodiscard]] CCRCLR ccrclr_qarg() const;
+    /**
+      CCRCLR ccrclr_qarg None
+  */
+    void ccrclr_qarg(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_src Tensor 在 GLB 中的起始位置
+  */
+    [[nodiscard]] ADDR_GLB_8_WITHOUT_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_src Tensor 在 GLB 中的起始位置
+  */
+    void addr_src(const ADDR_GLB_8_WITHOUT_BANK &value);
+    /**
+      ADDR addr_dest 输出到 DDR 的位置
+  */
+    [[nodiscard]] ADDR addr_dest() const;
+    /**
+      ADDR addr_dest 输出到 DDR 的位置
+  */
+    void addr_dest(const ADDR &value);
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号
+  */
+    [[nodiscard]] uint64_t basement() const;
+    /**
+      uint64_t basement DDR寻址偏移寄存器编号
+  */
+    void basement(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_store_t &c);
+
+/**
+    STORE.T.COMPRESS.CONF
+    @brief 配置store.t的稀疏、压缩、参数
+    - OPCODE opcode 配置store.t的稀疏、压缩、参数
+    - ADDR addr_bmp bitmap的地址
+    - ADDR addr_code_len 每一行编码之后的长度存放的地址
+    - ADDR addr_block_len 码块编码之后长度的存放地址
+    - uint64_t code_lines 每次编码的行数
+    - SPARSIFIED sparsified_ddr 是否稀疏
+    - COMPRESSED compress_ddr 是否压缩
+**/
+class inst_store_t_compress_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置store.t的稀疏、压缩、参数 **/
+    ADDR addr_bmp_ = ADDR(0); /** bitmap的地址 **/
+    ADDR addr_code_len_ = ADDR(0); /** 每一行编码之后的长度存放的地址 **/
+    ADDR addr_block_len_ = ADDR(0); /** 码块编码之后长度的存放地址 **/
+    uint64_t code_lines_ = uint64_t(0); /** 每次编码的行数 **/
+    SPARSIFIED sparsified_ddr_ = SPARSIFIED(0); /** 是否稀疏 **/
+    COMPRESSED compress_ddr_ = COMPRESSED(0); /** 是否压缩 **/
+public:
+    inst_store_t_compress_conf(ADDR addr_bmp = ADDR(0),
+        ADDR addr_code_len = ADDR(0),
+        ADDR addr_block_len = ADDR(0),
+        uint64_t code_lines = uint64_t(0),
+        SPARSIFIED sparsified_ddr = SPARSIFIED(0),
+        COMPRESSED compress_ddr = COMPRESSED(0));
+
+    explicit inst_store_t_compress_conf(const INST_STORE_T_COMPRESS_CONF &ref);
+
+    [[nodiscard]] struct INST_STORE_T_COMPRESS_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置store.t的稀疏、压缩、参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置store.t的稀疏、压缩、参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    [[nodiscard]] ADDR addr_bmp() const;
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    void addr_bmp(const ADDR &value);
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    [[nodiscard]] ADDR addr_code_len() const;
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    void addr_code_len(const ADDR &value);
+    /**
+      ADDR addr_block_len 码块编码之后长度的存放地址
+  */
+    [[nodiscard]] ADDR addr_block_len() const;
+    /**
+      ADDR addr_block_len 码块编码之后长度的存放地址
+  */
+    void addr_block_len(const ADDR &value);
+    /**
+      uint64_t code_lines 每次编码的行数
+  */
+    [[nodiscard]] uint64_t code_lines() const;
+    /**
+      uint64_t code_lines 每次编码的行数
+  */
+    void code_lines(const uint64_t &value);
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    [[nodiscard]] SPARSIFIED sparsified_ddr() const;
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    void sparsified_ddr(const SPARSIFIED &value);
+    /**
+      COMPRESSED compress_ddr 是否压缩
+  */
+    [[nodiscard]] COMPRESSED compress_ddr() const;
+    /**
+      COMPRESSED compress_ddr 是否压缩
+  */
+    void compress_ddr(const COMPRESSED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out,
+    const inst_store_t_compress_conf &c);
+
+/**
+    STORE.COMPRESS.CONF
+    @brief 配置store的稀疏、压缩、参数
+    - OPCODE opcode 配置store的稀疏、压缩、参数
+    - ADDR addr_bmp bitmap的地址
+    - ADDR addr_code_len 每一行编码之后的长度存放的地址
+    - SPARSIFIED sparsified_ddr 是否稀疏
+**/
+class inst_store_compress_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置store的稀疏、压缩、参数 **/
+    ADDR addr_bmp_ = ADDR(0); /** bitmap的地址 **/
+    ADDR addr_code_len_ = ADDR(0); /** 每一行编码之后的长度存放的地址 **/
+    SPARSIFIED sparsified_ddr_ = SPARSIFIED(0); /** 是否稀疏 **/
+public:
+    inst_store_compress_conf(ADDR addr_bmp = ADDR(0),
+        ADDR addr_code_len = ADDR(0),
+        SPARSIFIED sparsified_ddr = SPARSIFIED(0));
+
+    explicit inst_store_compress_conf(const INST_STORE_COMPRESS_CONF &ref);
+
+    [[nodiscard]] struct INST_STORE_COMPRESS_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置store的稀疏、压缩、参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置store的稀疏、压缩、参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    [[nodiscard]] ADDR addr_bmp() const;
+    /**
+      ADDR addr_bmp bitmap的地址
+  */
+    void addr_bmp(const ADDR &value);
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    [[nodiscard]] ADDR addr_code_len() const;
+    /**
+      ADDR addr_code_len 每一行编码之后的长度存放的地址
+  */
+    void addr_code_len(const ADDR &value);
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    [[nodiscard]] SPARSIFIED sparsified_ddr() const;
+    /**
+      SPARSIFIED sparsified_ddr 是否稀疏
+  */
+    void sparsified_ddr(const SPARSIFIED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_store_compress_conf &c);
+
+/**
+    TCU.DM.BROADCAST
+    @brief 配置DM是否在广播模式
+    - OPCODE opcode 配置DM是否在广播模式
+    - BROADCAST broadcast_if 配置input featuremap是否在广播模式
+    - BROADCAST broadcast_weight 配置weight是否在广播模式
+    - uint64_t psum_cascade 是否为psum级联模式（用来加速1*1卷积计算） 0：否
+4个TCU 1：是
+**/
+class inst_tcu_dm_broadcast : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置DM是否在广播模式 **/
+    BROADCAST broadcast_if_ = BROADCAST(0); /** 配置input featuremap是否在广播模式 **/
+    BROADCAST broadcast_weight_ = BROADCAST(0); /** 配置weight是否在广播模式 **/
+    uint64_t psum_cascade_ = uint64_t(
+        0); /** 是否为psum级联模式（用来加速1*1卷积计算） 0：否 4个TCU 1：是 **/
+public:
+    inst_tcu_dm_broadcast(BROADCAST broadcast_if = BROADCAST(0),
+        BROADCAST broadcast_weight = BROADCAST(0),
+        uint64_t psum_cascade = uint64_t(0));
+
+    explicit inst_tcu_dm_broadcast(const INST_TCU_DM_BROADCAST &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_BROADCAST to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置DM是否在广播模式
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置DM是否在广播模式
+  */
+    void opcode(const OPCODE &value);
+    /**
+      BROADCAST broadcast_if 配置input featuremap是否在广播模式
+  */
+    [[nodiscard]] BROADCAST broadcast_if() const;
+    /**
+      BROADCAST broadcast_if 配置input featuremap是否在广播模式
+  */
+    void broadcast_if(const BROADCAST &value);
+    /**
+      BROADCAST broadcast_weight 配置weight是否在广播模式
+  */
+    [[nodiscard]] BROADCAST broadcast_weight() const;
+    /**
+      BROADCAST broadcast_weight 配置weight是否在广播模式
+  */
+    void broadcast_weight(const BROADCAST &value);
+    /**
+      uint64_t psum_cascade 是否为psum级联模式（用来加速1*1卷积计算） 0：否
+     4个TCU 1：是
+  */
+    [[nodiscard]] uint64_t psum_cascade() const;
+    /**
+      uint64_t psum_cascade 是否为psum级联模式（用来加速1*1卷积计算） 0：否
+     4个TCU 1：是
+  */
+    void psum_cascade(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_broadcast &c);
+
+/**
+    TCU.DM.CONF.IF
+    @brief 配置 FETCHIF 的一些基础信息
+    - OPCODE opcode 配置 FETCHIF 的一些基础信息
+    - uint64_t tcu_id 选择配置第几个TCU的DM
+    - STRIDE_GLB stride_input_glb GLB中大tensor的排布的信息，用于计算跳转
+    - uint64_t stride_w input featuremap 在 W 方向上的 stride
+    - uint64_t stride_h input featuremap 在 H 方向上的 stride
+    - uint64_t padding_top input featuremap 在 HxW 平面上顶部的 zero padding
+行数
+    - uint64_t padding_bottom input featuremap 在 HxW 平面下底部的 zero padding
+行数
+    - uint64_t padding_left input featuremap 在 HxW 平面左边的 zero padding 列数
+    - uint64_t padding_right input featuremap 在 HxW 平面右边的 zero padding
+列数
+    - uint64_t input_c_per_pu 每个PU计算的输入通道数，根据高度映射除出来的
+    - uint64_t dilation_h input featuremap 的在 H 方向上的膨胀率
+    - uint64_t transpose_if 是否对输入的 input featuremap 进行转置，仅在
+通道上有效
+    - uint64_t mmu_item 使用的内存映射方案
+**/
+class inst_tcu_dm_conf_if : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置 FETCHIF 的一些基础信息 **/
+    uint64_t tcu_id_ = uint64_t(0); /** 选择配置第几个TCU的DM **/
+    STRIDE_GLB stride_input_glb_ = STRIDE_GLB(0); /** GLB中大tensor的排布的信息，用于计算跳转 **/
+    uint64_t stride_w_ = uint64_t(0); /** input featuremap 在 W 方向上的 stride **/
+    uint64_t stride_h_ = uint64_t(0); /** input featuremap 在 H 方向上的 stride **/
+    uint64_t padding_top_ = uint64_t(
+        0); /** input featuremap 在 HxW 平面上顶部的 zero padding 行数 **/
+    uint64_t padding_bottom_ = uint64_t(
+        0); /** input featuremap 在 HxW 平面下底部的 zero padding 行数 **/
+    uint64_t padding_left_ = uint64_t(0); /** input featuremap 在 HxW 平面左边的 zero padding 列数 **/
+    uint64_t padding_right_ = uint64_t(0); /** input featuremap 在 HxW 平面右边的 zero padding 列数 **/
+    uint64_t input_c_per_pu_ = uint64_t(0); /** 每个PU计算的输入通道数，根据高度映射除出来的 **/
+    uint64_t dilation_h_ = uint64_t(0); /** input featuremap 的在 H 方向上的膨胀率 **/
+    uint64_t transpose_if_ = uint64_t(
+        0); /** 是否对输入的 input featuremap 进行转置，仅在 通道上有效 **/
+    uint64_t mmu_item_ = uint64_t(0); /** 使用的内存映射方案 **/
+public:
+    inst_tcu_dm_conf_if(
+        uint64_t tcu_id = uint64_t(0),
+        STRIDE_GLB stride_input_glb = STRIDE_GLB(0),
+        uint64_t stride_w = uint64_t(0), uint64_t stride_h = uint64_t(0),
+        uint64_t padding_top = uint64_t(0), uint64_t padding_bottom = uint64_t(0),
+        uint64_t padding_left = uint64_t(0), uint64_t padding_right = uint64_t(0),
+        uint64_t input_c_per_pu = uint64_t(0), uint64_t dilation_h = uint64_t(0),
+        uint64_t transpose_if = uint64_t(0), uint64_t mmu_item = uint64_t(0));
+
+    explicit inst_tcu_dm_conf_if(const INST_TCU_DM_CONF_IF &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_CONF_IF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置 FETCHIF 的一些基础信息
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置 FETCHIF 的一些基础信息
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id 选择配置第几个TCU的DM
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id 选择配置第几个TCU的DM
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_input_glb GLB中大tensor的排布的信息，用于计算跳转
+  */
+    [[nodiscard]] STRIDE_GLB stride_input_glb() const;
+    /**
+      STRIDE_GLB stride_input_glb GLB中大tensor的排布的信息，用于计算跳转
+  */
+    void stride_input_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t stride_w input featuremap 在 W 方向上的 stride
+  */
+    [[nodiscard]] uint64_t stride_w() const;
+    /**
+      uint64_t stride_w input featuremap 在 W 方向上的 stride
+  */
+    void stride_w(const uint64_t &value);
+    /**
+      uint64_t stride_h input featuremap 在 H 方向上的 stride
+  */
+    [[nodiscard]] uint64_t stride_h() const;
+    /**
+      uint64_t stride_h input featuremap 在 H 方向上的 stride
+  */
+    void stride_h(const uint64_t &value);
+    /**
+      uint64_t padding_top input featuremap 在 HxW 平面上顶部的 zero padding
+     行数
+  */
+    [[nodiscard]] uint64_t padding_top() const;
+    /**
+      uint64_t padding_top input featuremap 在 HxW 平面上顶部的 zero padding
+     行数
+  */
+    void padding_top(const uint64_t &value);
+    /**
+      uint64_t padding_bottom input featuremap 在 HxW 平面下底部的 zero padding
+     行数
+  */
+    [[nodiscard]] uint64_t padding_bottom() const;
+    /**
+      uint64_t padding_bottom input featuremap 在 HxW 平面下底部的 zero padding
+     行数
+  */
+    void padding_bottom(const uint64_t &value);
+    /**
+      uint64_t padding_left input featuremap 在 HxW 平面左边的 zero padding 列数
+  */
+    [[nodiscard]] uint64_t padding_left() const;
+    /**
+      uint64_t padding_left input featuremap 在 HxW 平面左边的 zero padding 列数
+  */
+    void padding_left(const uint64_t &value);
+    /**
+      uint64_t padding_right input featuremap 在 HxW 平面右边的 zero padding
+     列数
+  */
+    [[nodiscard]] uint64_t padding_right() const;
+    /**
+      uint64_t padding_right input featuremap 在 HxW 平面右边的 zero padding
+     列数
+  */
+    void padding_right(const uint64_t &value);
+    /**
+      uint64_t input_c_per_pu 每个PU计算的输入通道数，根据高度映射除出来的
+  */
+    [[nodiscard]] uint64_t input_c_per_pu() const;
+    /**
+      uint64_t input_c_per_pu 每个PU计算的输入通道数，根据高度映射除出来的
+  */
+    void input_c_per_pu(const uint64_t &value);
+    /**
+      uint64_t dilation_h input featuremap 的在 H 方向上的膨胀率
+  */
+    [[nodiscard]] uint64_t dilation_h() const;
+    /**
+      uint64_t dilation_h input featuremap 的在 H 方向上的膨胀率
+  */
+    void dilation_h(const uint64_t &value);
+    /**
+      uint64_t transpose_if 是否对输入的 input featuremap 进行转置，仅在
+     通道上有效
+  */
+    [[nodiscard]] uint64_t transpose_if() const;
+    /**
+      uint64_t transpose_if 是否对输入的 input featuremap 进行转置，仅在
+     通道上有效
+  */
+    void transpose_if(const uint64_t &value);
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    [[nodiscard]] uint64_t mmu_item() const;
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    void mmu_item(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_conf_if &c);
+
+/**
+    TCU.DM.FETCHIF
+    @brief 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+    - OPCODE opcode 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+    - CCRCLR ccrclr_if None
+    - uint64_t tcu_id TCU ID
+    - ADDR_GLB_8_WITHOUT_BANK addr_if 输入slice的起始地址
+    - uint64_t shape_input_n 当前计算输入Slice的形状信息
+    - uint64_t shape_input_c 当前计算输入Slice的形状信息
+    - uint64_t shape_input_h 当前计算输入Slice的形状信息
+    - uint64_t shape_input_w 当前计算输入Slice的形状信息
+**/
+class inst_tcu_dm_fetchif : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中 **/
+    CCRCLR ccrclr_if_ = CCRCLR(0); /** None **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU ID **/
+    ADDR_GLB_8_WITHOUT_BANK addr_if_ = ADDR_GLB_8_WITHOUT_BANK(0); /** 输入slice的起始地址 **/
+    uint64_t shape_input_n_ = uint64_t(0); /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_c_ = uint64_t(0); /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_h_ = uint64_t(0); /** 当前计算输入Slice的形状信息 **/
+    uint64_t shape_input_w_ = uint64_t(0); /** 当前计算输入Slice的形状信息 **/
+public:
+    inst_tcu_dm_fetchif(
+        CCRCLR ccrclr_if = CCRCLR(0), uint64_t tcu_id = uint64_t(0),
+        ADDR_GLB_8_WITHOUT_BANK addr_if = ADDR_GLB_8_WITHOUT_BANK(0),
+        uint64_t shape_input_n = uint64_t(0),
+        uint64_t shape_input_c = uint64_t(0),
+        uint64_t shape_input_h = uint64_t(0),
+        uint64_t shape_input_w = uint64_t(0));
+
+    explicit inst_tcu_dm_fetchif(const INST_TCU_DM_FETCHIF &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_FETCHIF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 从 GLB 中加载 input featuremap 到 PU 或者广播到多个PU中
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_if None
+  */
+    [[nodiscard]] CCRCLR ccrclr_if() const;
+    /**
+      CCRCLR ccrclr_if None
+  */
+    void ccrclr_if(const CCRCLR &value);
+    /**
+      uint64_t tcu_id TCU ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_if 输入slice的起始地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITHOUT_BANK addr_if() const;
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_if 输入slice的起始地址
+  */
+    void addr_if(const ADDR_GLB_8_WITHOUT_BANK &value);
+    /**
+      uint64_t shape_input_n 当前计算输入Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_input_n() const;
+    /**
+      uint64_t shape_input_n 当前计算输入Slice的形状信息
+  */
+    void shape_input_n(const uint64_t &value);
+    /**
+      uint64_t shape_input_c 当前计算输入Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_input_c() const;
+    /**
+      uint64_t shape_input_c 当前计算输入Slice的形状信息
+  */
+    void shape_input_c(const uint64_t &value);
+    /**
+      uint64_t shape_input_h 当前计算输入Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_input_h() const;
+    /**
+      uint64_t shape_input_h 当前计算输入Slice的形状信息
+  */
+    void shape_input_h(const uint64_t &value);
+    /**
+      uint64_t shape_input_w 当前计算输入Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_input_w() const;
+    /**
+      uint64_t shape_input_w 当前计算输入Slice的形状信息
+  */
+    void shape_input_w(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_fetchif &c);
+
+/**
+    TCU.DM.CONF.W
+    @brief 配置 TCU 读取 weights 时的行为
+    - OPCODE opcode 配置 TCU 读取 weights 时的行为
+    - uint64_t tcu_id TCU 的 ID
+    - uint64_t mmu_item 使用的内存映射方案
+    - uint64_t load_direction 是否对输入的 input featuremap
+进行转置，仅在HxW通道上有效
+**/
+class inst_tcu_dm_conf_w : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置 TCU 读取 weights 时的行为 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    uint64_t mmu_item_ = uint64_t(0); /** 使用的内存映射方案 **/
+    uint64_t load_direction_ = uint64_t(
+        0); /** 是否对输入的 input featuremap 进行转置，仅在HxW通道上有效 **/
+public:
+    inst_tcu_dm_conf_w(uint64_t tcu_id = uint64_t(0),
+        uint64_t mmu_item = uint64_t(0),
+        uint64_t load_direction = uint64_t(0));
+
+    explicit inst_tcu_dm_conf_w(const INST_TCU_DM_CONF_W &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_CONF_W to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置 TCU 读取 weights 时的行为
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置 TCU 读取 weights 时的行为
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    [[nodiscard]] uint64_t mmu_item() const;
+    /**
+      uint64_t mmu_item 使用的内存映射方案
+  */
+    void mmu_item(const uint64_t &value);
+    /**
+      uint64_t load_direction 是否对输入的 input featuremap
+     进行转置，仅在HxW通道上有效
+  */
+    [[nodiscard]] uint64_t load_direction() const;
+    /**
+      uint64_t load_direction 是否对输入的 input featuremap
+     进行转置，仅在HxW通道上有效
+  */
+    void load_direction(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_conf_w &c);
+
+/**
+    TCU.DM.FETCHW
+    @brief 从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+    - OPCODE opcode 从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+    - CCRCLR ccrclr_weight 数据依赖配置
+    - uint64_t tcu_id TCU ID
+    - ADDR_GLB_8_WITHOUT_BANK addr_src GLB 中 weights 的地址,byte的偏移地址
+**/
+class inst_tcu_dm_fetchw : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 从 GLB 中加载 weights 到 PU 或者广播到多个PU中 **/
+    CCRCLR ccrclr_weight_ = CCRCLR(0); /** 数据依赖配置 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU ID **/
+    ADDR_GLB_8_WITHOUT_BANK addr_src_ = ADDR_GLB_8_WITHOUT_BANK(0); /** GLB 中 weights 的地址,byte的偏移地址 **/
+public:
+    inst_tcu_dm_fetchw(
+        CCRCLR ccrclr_weight = CCRCLR(0), uint64_t tcu_id = uint64_t(0),
+        ADDR_GLB_8_WITHOUT_BANK addr_src = ADDR_GLB_8_WITHOUT_BANK(0));
+
+    explicit inst_tcu_dm_fetchw(const INST_TCU_DM_FETCHW &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_FETCHW to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 从 GLB 中加载 weights 到 PU 或者广播到多个PU中
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_weight 数据依赖配置
+  */
+    [[nodiscard]] CCRCLR ccrclr_weight() const;
+    /**
+      CCRCLR ccrclr_weight 数据依赖配置
+  */
+    void ccrclr_weight(const CCRCLR &value);
+    /**
+      uint64_t tcu_id TCU ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_src GLB 中 weights 的地址,byte的偏移地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITHOUT_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITHOUT_BANK addr_src GLB 中 weights 的地址,byte的偏移地址
+  */
+    void addr_src(const ADDR_GLB_8_WITHOUT_BANK &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_fetchw &c);
+
+/**
+    TCU.DM.CONF.OF
+    @brief 配置 TCU 输出信息
+    - OPCODE opcode 配置 TCU 输出信息
+    - uint64_t tcu_id TCU 的 ID
+    - ADDR_GLB_8_WITH_BANK addr_psum 中间结果的 GLB 中的地址
+    - ADDR_GLB_8_WITH_BANK addr_dest 输出结果的GLB中的地址
+    - uint64_t shape_output_n 当前计算输出Slice的形状信息
+    - uint64_t shape_output_c 当前计算输出Slice的形状信息
+    - uint64_t shape_output_h 当前计算输出Slice的形状信息
+    - uint64_t shape_output_w 当前计算输出Slice的形状信息
+    - STRIDE_GLB stride_output_glb 输出featuremap在GLB的形状信息，决定寻址
+    - STRIDE_GLB stride_psum_glb 输出PSUM在GLB的形状信息，决定寻址
+    - uint64_t x_cut
+水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+    - PRECISION output_precision None
+    - QUAN_SIGNED output_signed None
+**/
+class inst_tcu_dm_conf_of : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置 TCU 输出信息 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    ADDR_GLB_8_WITH_BANK addr_psum_ = ADDR_GLB_8_WITH_BANK(0); /** 中间结果的 GLB 中的地址 **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** 输出结果的GLB中的地址 **/
+    uint64_t shape_output_n_ = uint64_t(0); /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_c_ = uint64_t(0); /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_h_ = uint64_t(0); /** 当前计算输出Slice的形状信息 **/
+    uint64_t shape_output_w_ = uint64_t(0); /** 当前计算输出Slice的形状信息 **/
+    STRIDE_GLB stride_output_glb_ = STRIDE_GLB(0); /** 输出featuremap在GLB的形状信息，决定寻址 **/
+    STRIDE_GLB stride_psum_glb_ = STRIDE_GLB(0); /** 输出PSUM在GLB的形状信息，决定寻址 **/
+    uint64_t x_cut_ = uint64_t(0); /**
+                                                  水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+                                                  **/
+    PRECISION output_precision_ = PRECISION(0); /** None **/
+    QUAN_SIGNED output_signed_ = QUAN_SIGNED(0); /** None **/
+public:
+    inst_tcu_dm_conf_of(uint64_t tcu_id = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_psum = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t shape_output_n = uint64_t(0),
+        uint64_t shape_output_c = uint64_t(0),
+        uint64_t shape_output_h = uint64_t(0),
+        uint64_t shape_output_w = uint64_t(0),
+        STRIDE_GLB stride_output_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_psum_glb = STRIDE_GLB(0),
+        uint64_t x_cut = uint64_t(0),
+        PRECISION output_precision = PRECISION(0),
+        QUAN_SIGNED output_signed = QUAN_SIGNED(0));
+
+    explicit inst_tcu_dm_conf_of(const INST_TCU_DM_CONF_OF &ref);
+
+    [[nodiscard]] struct INST_TCU_DM_CONF_OF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置 TCU 输出信息
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置 TCU 输出信息
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_psum 中间结果的 GLB 中的地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_psum() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_psum 中间结果的 GLB 中的地址
+  */
+    void addr_psum(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest 输出结果的GLB中的地址
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest 输出结果的GLB中的地址
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t shape_output_n 当前计算输出Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_output_n() const;
+    /**
+      uint64_t shape_output_n 当前计算输出Slice的形状信息
+  */
+    void shape_output_n(const uint64_t &value);
+    /**
+      uint64_t shape_output_c 当前计算输出Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_output_c() const;
+    /**
+      uint64_t shape_output_c 当前计算输出Slice的形状信息
+  */
+    void shape_output_c(const uint64_t &value);
+    /**
+      uint64_t shape_output_h 当前计算输出Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_output_h() const;
+    /**
+      uint64_t shape_output_h 当前计算输出Slice的形状信息
+  */
+    void shape_output_h(const uint64_t &value);
+    /**
+      uint64_t shape_output_w 当前计算输出Slice的形状信息
+  */
+    [[nodiscard]] uint64_t shape_output_w() const;
+    /**
+      uint64_t shape_output_w 当前计算输出Slice的形状信息
+  */
+    void shape_output_w(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_output_glb 输出featuremap在GLB的形状信息，决定寻址
+  */
+    [[nodiscard]] STRIDE_GLB stride_output_glb() const;
+    /**
+      STRIDE_GLB stride_output_glb 输出featuremap在GLB的形状信息，决定寻址
+  */
+    void stride_output_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_psum_glb 输出PSUM在GLB的形状信息，决定寻址
+  */
+    [[nodiscard]] STRIDE_GLB stride_psum_glb() const;
+    /**
+      STRIDE_GLB stride_psum_glb 输出PSUM在GLB的形状信息，决定寻址
+  */
+    void stride_psum_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t x_cut
+     水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+  */
+    [[nodiscard]] uint64_t x_cut() const;
+    /**
+      uint64_t x_cut
+     水平方向一行第一次卷积的偏移量，硬件会切掉这些数，为了在反卷积模式下和tensorflow的实现保持一致
+  */
+    void x_cut(const uint64_t &value);
+    /**
+      PRECISION output_precision None
+  */
+    [[nodiscard]] PRECISION output_precision() const;
+    /**
+      PRECISION output_precision None
+  */
+    void output_precision(const PRECISION &value);
+    /**
+      QUAN_SIGNED output_signed None
+  */
+    [[nodiscard]] QUAN_SIGNED output_signed() const;
+    /**
+      QUAN_SIGNED output_signed None
+  */
+    void output_signed(const QUAN_SIGNED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dm_conf_of &c);
+
+/**
+    TCU.PU.CONF
+    @brief 配置给定的 TCU 的 PU 所使用的 PE 资源数量
+    - OPCODE opcode 配置给定的 TCU 的 PU 所使用的 PE 资源数量
+    - uint64_t tcu_id TCU 的 ID
+    - uint64_t pe_w TCU 的 PU 使用的 pe 列数
+    - uint64_t pe_h 使用的 pe 行数
+    - uint64_t pe_last_w 保留位置，不使用
+    - uint64_t pe_last_h 在不能被整除的模式的时候PE最后一次计算的激活高度
+    - uint64_t kernel_h kernel 高度，如果是矩阵乘模式无效
+    - uint64_t kernel_w kernel 宽度，如果是矩阵乘模式无效
+    - uint64_t group 分组卷积的组数，对应了TCU每个小块的宽度
+    - uint64_t pu_loop_w 硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用
+    - uint64_t pu_loop_h 硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu )
+    - TCU_MODE mode 指定PU的工作模式
+**/
+class inst_tcu_pu_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置给定的 TCU 的 PU 所使用的 PE 资源数量 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    uint64_t pe_w_ = uint64_t(0); /** TCU 的 PU 使用的 pe 列数 **/
+    uint64_t pe_h_ = uint64_t(0); /** 使用的 pe 行数 **/
+    uint64_t pe_last_w_ = uint64_t(0); /** 保留位置，不使用 **/
+    uint64_t pe_last_h_ = uint64_t(0); /** 在不能被整除的模式的时候PE最后一次计算的激活高度 **/
+    uint64_t kernel_h_ = uint64_t(0); /** kernel 高度，如果是矩阵乘模式无效 **/
+    uint64_t kernel_w_ = uint64_t(0); /** kernel 宽度，如果是矩阵乘模式无效 **/
+    uint64_t group_ = uint64_t(0); /** 分组卷积的组数，对应了TCU每个小块的宽度 **/
+    uint64_t pu_loop_w_ = uint64_t(0); /** 硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用 **/
+    uint64_t pu_loop_h_ = uint64_t(0); /** 硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu ) **/
+    TCU_MODE mode_ = TCU_MODE(0); /** 指定PU的工作模式 **/
+public:
+    inst_tcu_pu_conf(
+        uint64_t tcu_id = uint64_t(0), uint64_t pe_w = uint64_t(0),
+        uint64_t pe_h = uint64_t(0), uint64_t pe_last_w = uint64_t(0),
+        uint64_t pe_last_h = uint64_t(0), uint64_t kernel_h = uint64_t(0),
+        uint64_t kernel_w = uint64_t(0), uint64_t group = uint64_t(0),
+        uint64_t pu_loop_w = uint64_t(0), uint64_t pu_loop_h = uint64_t(0),
+        TCU_MODE mode = TCU_MODE(0));
+
+    explicit inst_tcu_pu_conf(const INST_TCU_PU_CONF &ref);
+
+    [[nodiscard]] struct INST_TCU_PU_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置给定的 TCU 的 PU 所使用的 PE 资源数量
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置给定的 TCU 的 PU 所使用的 PE 资源数量
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t pe_w TCU 的 PU 使用的 pe 列数
+  */
+    [[nodiscard]] uint64_t pe_w() const;
+    /**
+      uint64_t pe_w TCU 的 PU 使用的 pe 列数
+  */
+    void pe_w(const uint64_t &value);
+    /**
+      uint64_t pe_h 使用的 pe 行数
+  */
+    [[nodiscard]] uint64_t pe_h() const;
+    /**
+      uint64_t pe_h 使用的 pe 行数
+  */
+    void pe_h(const uint64_t &value);
+    /**
+      uint64_t pe_last_w 保留位置，不使用
+  */
+    [[nodiscard]] uint64_t pe_last_w() const;
+    /**
+      uint64_t pe_last_w 保留位置，不使用
+  */
+    void pe_last_w(const uint64_t &value);
+    /**
+      uint64_t pe_last_h 在不能被整除的模式的时候PE最后一次计算的激活高度
+  */
+    [[nodiscard]] uint64_t pe_last_h() const;
+    /**
+      uint64_t pe_last_h 在不能被整除的模式的时候PE最后一次计算的激活高度
+  */
+    void pe_last_h(const uint64_t &value);
+    /**
+      uint64_t kernel_h kernel 高度，如果是矩阵乘模式无效
+  */
+    [[nodiscard]] uint64_t kernel_h() const;
+    /**
+      uint64_t kernel_h kernel 高度，如果是矩阵乘模式无效
+  */
+    void kernel_h(const uint64_t &value);
+    /**
+      uint64_t kernel_w kernel 宽度，如果是矩阵乘模式无效
+  */
+    [[nodiscard]] uint64_t kernel_w() const;
+    /**
+      uint64_t kernel_w kernel 宽度，如果是矩阵乘模式无效
+  */
+    void kernel_w(const uint64_t &value);
+    /**
+      uint64_t group 分组卷积的组数，对应了TCU每个小块的宽度
+  */
+    [[nodiscard]] uint64_t group() const;
+    /**
+      uint64_t group 分组卷积的组数，对应了TCU每个小块的宽度
+  */
+    void group(const uint64_t &value);
+    /**
+      uint64_t pu_loop_w 硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用
+  */
+    [[nodiscard]] uint64_t pu_loop_w() const;
+    /**
+      uint64_t pu_loop_w 硬件数值循环次数
+每个PE列的输出 channel 数，硬件内部循环用
+  */
+    void pu_loop_w(const uint64_t &value);
+    /**
+      uint64_t pu_loop_h 硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu )
+  */
+    [[nodiscard]] uint64_t pu_loop_h() const;
+    /**
+      uint64_t pu_loop_h 硬件水平循环次数
+硬件内部信号=ceil(IF_c / input_channel_per_pu )
+  */
+    void pu_loop_h(const uint64_t &value);
+    /**
+      TCU_MODE mode 指定PU的工作模式
+  */
+    [[nodiscard]] TCU_MODE mode() const;
+    /**
+      TCU_MODE mode 指定PU的工作模式
+  */
+    void mode(const TCU_MODE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_pu_conf &c);
+
+/**
+    TCU.PU.CONF.ACT
+    @brief 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数
+    - OPCODE opcode 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数
+    - uint64_t tcu_id TCU 的 ID
+    - uint64_t clamp_max 上饱和数值
+    - uint64_t clamp_min 下饱和数值
+    - ADDR_GLB_8_WITH_BANK addr_act
+每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+**/
+class inst_tcu_pu_conf_act : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(
+        0); /** 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    uint64_t clamp_max_ = uint64_t(0); /** 上饱和数值 **/
+    uint64_t clamp_min_ = uint64_t(0); /** 下饱和数值 **/
+    ADDR_GLB_8_WITH_BANK addr_act_ = ADDR_GLB_8_WITH_BANK(
+        0); /** 每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+             **/
+public:
+    inst_tcu_pu_conf_act(uint64_t tcu_id = uint64_t(0),
+        uint64_t clamp_max = uint64_t(0),
+        uint64_t clamp_min = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_act = ADDR_GLB_8_WITH_BANK(0));
+
+    explicit inst_tcu_pu_conf_act(const INST_TCU_PU_CONF_ACT &ref);
+
+    [[nodiscard]] struct INST_TCU_PU_CONF_ACT to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置给定的 TCU 的 PU 使用的 fused 的两段式激活函数的参数
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t clamp_max 上饱和数值
+  */
+    [[nodiscard]] uint64_t clamp_max() const;
+    /**
+      uint64_t clamp_max 上饱和数值
+  */
+    void clamp_max(const uint64_t &value);
+    /**
+      uint64_t clamp_min 下饱和数值
+  */
+    [[nodiscard]] uint64_t clamp_min() const;
+    /**
+      uint64_t clamp_min 下饱和数值
+  */
+    void clamp_min(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_act
+     每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_act() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_act
+     每个输出通道激活参数（分段点，两端的scale，bias，以及量化参数）
+  */
+    void addr_act(const ADDR_GLB_8_WITH_BANK &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_pu_conf_act &c);
+
+/**
+    TCU.PU.COMPUTE
+    @brief 启动PU一次计算
+    - OPCODE opcode 启动PU一次计算
+    - CCRCLR ccrclr_act None
+    - CCRCLR ccrclr_psum None
+    - CCRSET ccrset 数据依赖配置
+    - uint64_t tcu_id TCU 的 ID
+    - uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+    - uint64_t of_enable 决定输出是psum还是output featuremap
+    - uint64_t load_psum 是否从 GLB 加载中间结果
+    - uint64_t weight_switching 是否切换 PU 的 weights
+**/
+class inst_tcu_pu_compute : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 启动PU一次计算 **/
+    CCRCLR ccrclr_act_ = CCRCLR(0); /** None **/
+    CCRCLR ccrclr_psum_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** 数据依赖配置 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    uint64_t act_enable_ = uint64_t(0); /** 是否在这次计算完之后将结果做一次两段拟合的激活函数 **/
+    uint64_t of_enable_ = uint64_t(0); /** 决定输出是psum还是output featuremap **/
+    uint64_t load_psum_ = uint64_t(0); /** 是否从 GLB 加载中间结果 **/
+    uint64_t weight_switching_ = uint64_t(0); /** 是否切换 PU 的 weights **/
+public:
+    inst_tcu_pu_compute(CCRCLR ccrclr_act = CCRCLR(0),
+        CCRCLR ccrclr_psum = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        uint64_t tcu_id = uint64_t(0),
+        uint64_t act_enable = uint64_t(0),
+        uint64_t of_enable = uint64_t(0),
+        uint64_t load_psum = uint64_t(0),
+        uint64_t weight_switching = uint64_t(0));
+
+    explicit inst_tcu_pu_compute(const INST_TCU_PU_COMPUTE &ref);
+
+    [[nodiscard]] struct INST_TCU_PU_COMPUTE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 启动PU一次计算
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 启动PU一次计算
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_act None
+  */
+    [[nodiscard]] CCRCLR ccrclr_act() const;
+    /**
+      CCRCLR ccrclr_act None
+  */
+    void ccrclr_act(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_psum None
+  */
+    [[nodiscard]] CCRCLR ccrclr_psum() const;
+    /**
+      CCRCLR ccrclr_psum None
+  */
+    void ccrclr_psum(const CCRCLR &value);
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+  */
+    [[nodiscard]] uint64_t act_enable() const;
+    /**
+      uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+  */
+    void act_enable(const uint64_t &value);
+    /**
+      uint64_t of_enable 决定输出是psum还是output featuremap
+  */
+    [[nodiscard]] uint64_t of_enable() const;
+    /**
+      uint64_t of_enable 决定输出是psum还是output featuremap
+  */
+    void of_enable(const uint64_t &value);
+    /**
+      uint64_t load_psum 是否从 GLB 加载中间结果
+  */
+    [[nodiscard]] uint64_t load_psum() const;
+    /**
+      uint64_t load_psum 是否从 GLB 加载中间结果
+  */
+    void load_psum(const uint64_t &value);
+    /**
+      uint64_t weight_switching 是否切换 PU 的 weights
+  */
+    [[nodiscard]] uint64_t weight_switching() const;
+    /**
+      uint64_t weight_switching 是否切换 PU 的 weights
+  */
+    void weight_switching(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_pu_compute &c);
+
+/**
+    TCU.DOT.DM.IF.CONF
+    @brief None
+    - OPCODE opcode None
+    - uint64_t tcu_id None
+    - STRIDE_GLB stride_src1_glb None
+    - STRIDE_GLB stride_src2_glb None
+**/
+class inst_tcu_dot_dm_if_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    uint64_t tcu_id_ = uint64_t(0); /** None **/
+    STRIDE_GLB stride_src1_glb_ = STRIDE_GLB(0); /** None **/
+    STRIDE_GLB stride_src2_glb_ = STRIDE_GLB(0); /** None **/
+public:
+    inst_tcu_dot_dm_if_conf(uint64_t tcu_id = uint64_t(0),
+        STRIDE_GLB stride_src1_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_src2_glb = STRIDE_GLB(0));
+
+    explicit inst_tcu_dot_dm_if_conf(const INST_TCU_DOT_DM_IF_CONF &ref);
+
+    [[nodiscard]] struct INST_TCU_DOT_DM_IF_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id None
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id None
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_src1_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src1_glb() const;
+    /**
+      STRIDE_GLB stride_src1_glb None
+  */
+    void stride_src1_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_src2_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src2_glb() const;
+    /**
+      STRIDE_GLB stride_src2_glb None
+  */
+    void stride_src2_glb(const STRIDE_GLB &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dot_dm_if_conf &c);
+
+/**
+    TCU.DOT.DM.OF.CONF
+    @brief None
+    - OPCODE opcode None
+    - uint64_t tcu_id None
+    - uint64_t stride_psum_glb None
+    - ADDR_GLB_8_WITH_BANK addr_psum None
+    - ADDR_GLB_8_WITH_BANK addr_dest None
+    - STRIDE_GLB stride_dest_glb None
+    - uint64_t shape_dest_n None
+    - uint64_t shape_dest_h None
+    - uint64_t shape_dest_w None
+    - uint64_t shape_src1_w None
+    - PRECISION output_precision None
+    - QUAN_SIGNED output_signed None
+**/
+class inst_tcu_dot_dm_of_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    uint64_t tcu_id_ = uint64_t(0); /** None **/
+    uint64_t stride_psum_glb_ = uint64_t(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_psum_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    STRIDE_GLB stride_dest_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_dest_n_ = uint64_t(0); /** None **/
+    uint64_t shape_dest_h_ = uint64_t(0); /** None **/
+    uint64_t shape_dest_w_ = uint64_t(0); /** None **/
+    uint64_t shape_src1_w_ = uint64_t(0); /** None **/
+    PRECISION output_precision_ = PRECISION(0); /** None **/
+    QUAN_SIGNED output_signed_ = QUAN_SIGNED(0); /** None **/
+public:
+    inst_tcu_dot_dm_of_conf(
+        uint64_t tcu_id = uint64_t(0), uint64_t stride_psum_glb = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_psum = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        STRIDE_GLB stride_dest_glb = STRIDE_GLB(0),
+        uint64_t shape_dest_n = uint64_t(0), uint64_t shape_dest_h = uint64_t(0),
+        uint64_t shape_dest_w = uint64_t(0), uint64_t shape_src1_w = uint64_t(0),
+        PRECISION output_precision = PRECISION(0),
+        QUAN_SIGNED output_signed = QUAN_SIGNED(0));
+
+    explicit inst_tcu_dot_dm_of_conf(const INST_TCU_DOT_DM_OF_CONF &ref);
+
+    [[nodiscard]] struct INST_TCU_DOT_DM_OF_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t tcu_id None
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id None
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t stride_psum_glb None
+  */
+    [[nodiscard]] uint64_t stride_psum_glb() const;
+    /**
+      uint64_t stride_psum_glb None
+  */
+    void stride_psum_glb(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_psum None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_psum() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_psum None
+  */
+    void addr_psum(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_dest_glb() const;
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    void stride_dest_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_dest_n None
+  */
+    [[nodiscard]] uint64_t shape_dest_n() const;
+    /**
+      uint64_t shape_dest_n None
+  */
+    void shape_dest_n(const uint64_t &value);
+    /**
+      uint64_t shape_dest_h None
+  */
+    [[nodiscard]] uint64_t shape_dest_h() const;
+    /**
+      uint64_t shape_dest_h None
+  */
+    void shape_dest_h(const uint64_t &value);
+    /**
+      uint64_t shape_dest_w None
+  */
+    [[nodiscard]] uint64_t shape_dest_w() const;
+    /**
+      uint64_t shape_dest_w None
+  */
+    void shape_dest_w(const uint64_t &value);
+    /**
+      uint64_t shape_src1_w None
+  */
+    [[nodiscard]] uint64_t shape_src1_w() const;
+    /**
+      uint64_t shape_src1_w None
+  */
+    void shape_src1_w(const uint64_t &value);
+    /**
+      PRECISION output_precision None
+  */
+    [[nodiscard]] PRECISION output_precision() const;
+    /**
+      PRECISION output_precision None
+  */
+    void output_precision(const PRECISION &value);
+    /**
+      QUAN_SIGNED output_signed None
+  */
+    [[nodiscard]] QUAN_SIGNED output_signed() const;
+    /**
+      QUAN_SIGNED output_signed None
+  */
+    void output_signed(const QUAN_SIGNED &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_dot_dm_of_conf &c);
+
+/**
+    TCU.DOT.DM.FETCH.SRC1
+    @brief None
+    - OPCODE opcode None
+    - CCRCLR ccrclr_src1 None
+    - uint64_t tcu_id None
+    - ADDR_GLB_8_WITH_BANK addr_src1 None
+**/
+class inst_tcu_dot_dm_fetch_src1 : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRCLR ccrclr_src1_ = CCRCLR(0); /** None **/
+    uint64_t tcu_id_ = uint64_t(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src1_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+public:
+    inst_tcu_dot_dm_fetch_src1(
+        CCRCLR ccrclr_src1 = CCRCLR(0), uint64_t tcu_id = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_src1 = ADDR_GLB_8_WITH_BANK(0));
+
+    explicit inst_tcu_dot_dm_fetch_src1(const INST_TCU_DOT_DM_FETCH_SRC1 &ref);
+
+    [[nodiscard]] struct INST_TCU_DOT_DM_FETCH_SRC1 to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_src1 None
+  */
+    [[nodiscard]] CCRCLR ccrclr_src1() const;
+    /**
+      CCRCLR ccrclr_src1 None
+  */
+    void ccrclr_src1(const CCRCLR &value);
+    /**
+      uint64_t tcu_id None
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id None
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src1 None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src1() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src1 None
+  */
+    void addr_src1(const ADDR_GLB_8_WITH_BANK &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out,
+    const inst_tcu_dot_dm_fetch_src1 &c);
+
+/**
+    TCU.DOT.DM.FETCH.SRC2
+    @brief None
+    - OPCODE opcode None
+    - CCRCLR ccrclr_src2 None
+    - uint64_t tcu_id None
+    - ADDR_GLB_8_WITH_BANK addr_src2 None
+**/
+class inst_tcu_dot_dm_fetch_src2 : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRCLR ccrclr_src2_ = CCRCLR(0); /** None **/
+    uint64_t tcu_id_ = uint64_t(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src2_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+public:
+    inst_tcu_dot_dm_fetch_src2(
+        CCRCLR ccrclr_src2 = CCRCLR(0), uint64_t tcu_id = uint64_t(0),
+        ADDR_GLB_8_WITH_BANK addr_src2 = ADDR_GLB_8_WITH_BANK(0));
+
+    explicit inst_tcu_dot_dm_fetch_src2(const INST_TCU_DOT_DM_FETCH_SRC2 &ref);
+
+    [[nodiscard]] struct INST_TCU_DOT_DM_FETCH_SRC2 to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_src2 None
+  */
+    [[nodiscard]] CCRCLR ccrclr_src2() const;
+    /**
+      CCRCLR ccrclr_src2 None
+  */
+    void ccrclr_src2(const CCRCLR &value);
+    /**
+      uint64_t tcu_id None
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id None
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src2 None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src2() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src2 None
+  */
+    void addr_src2(const ADDR_GLB_8_WITH_BANK &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out,
+    const inst_tcu_dot_dm_fetch_src2 &c);
+
+/**
+    TCU.PU.COMPUTE.DUMMY
+    @brief 用来把PSUM转成output的指令
+    - OPCODE opcode 用来把PSUM转成output的指令
+    - CCRCLR ccrclr_act None
+    - CCRCLR ccrclr_psum None
+    - CCRSET ccrset 数据依赖配置
+    - uint64_t tcu_id TCU 的 ID
+    - uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+**/
+class inst_tcu_pu_compute_dummy : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 用来把PSUM转成output的指令 **/
+    CCRCLR ccrclr_act_ = CCRCLR(0); /** None **/
+    CCRCLR ccrclr_psum_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** 数据依赖配置 **/
+    uint64_t tcu_id_ = uint64_t(0); /** TCU 的 ID **/
+    uint64_t act_enable_ = uint64_t(0); /** 是否在这次计算完之后将结果做一次两段拟合的激活函数 **/
+public:
+    inst_tcu_pu_compute_dummy(CCRCLR ccrclr_act = CCRCLR(0),
+        CCRCLR ccrclr_psum = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0),
+        uint64_t tcu_id = uint64_t(0),
+        uint64_t act_enable = uint64_t(0));
+
+    explicit inst_tcu_pu_compute_dummy(const INST_TCU_PU_COMPUTE_DUMMY &ref);
+
+    [[nodiscard]] struct INST_TCU_PU_COMPUTE_DUMMY to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 用来把PSUM转成output的指令
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 用来把PSUM转成output的指令
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_act None
+  */
+    [[nodiscard]] CCRCLR ccrclr_act() const;
+    /**
+      CCRCLR ccrclr_act None
+  */
+    void ccrclr_act(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_psum None
+  */
+    [[nodiscard]] CCRCLR ccrclr_psum() const;
+    /**
+      CCRCLR ccrclr_psum None
+  */
+    void ccrclr_psum(const CCRCLR &value);
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset 数据依赖配置
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    [[nodiscard]] uint64_t tcu_id() const;
+    /**
+      uint64_t tcu_id TCU 的 ID
+  */
+    void tcu_id(const uint64_t &value);
+    /**
+      uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+  */
+    [[nodiscard]] uint64_t act_enable() const;
+    /**
+      uint64_t act_enable 是否在这次计算完之后将结果做一次两段拟合的激活函数
+  */
+    void act_enable(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_tcu_pu_compute_dummy &c);
+
+/**
+    MFU.MN.MAP.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算对于tensor的map运算
+    - OPCODE opcode 配置MFU的DM模块，准备开始计算对于tensor的map运算
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - UNION_ADDR addr_src 输入向量slice地址 (GLB or DDR)
+    - UNION_ADDR addr_dest 输出向量地址 (GLB or DDR)
+    - STRIDE_GLB stride_input_glb Tensor 的 shape
+    - STRIDE_GLB stride_output_glb None
+    - uint64_t shape_n Slice 长度信息
+    - uint64_t shape_c Slice 长度信息
+    - uint64_t shape_h Slice 长度信息
+    - uint64_t shape_w Slice 长度信息
+    - uint64_t basement_src1 None
+    - uint64_t basement_dest None
+**/
+class inst_mfu_mn_map_compute : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置MFU的DM模块，准备开始计算对于tensor的map运算 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    UNION_ADDR addr_src_ = UNION_ADDR(0); /** 输入向量slice地址 (GLB or DDR) **/
+    UNION_ADDR addr_dest_ = UNION_ADDR(0); /** 输出向量地址 (GLB or DDR) **/
+    STRIDE_GLB stride_input_glb_ = STRIDE_GLB(0); /** Tensor 的 shape **/
+    STRIDE_GLB stride_output_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_n_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_c_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_h_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_w_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t basement_src1_ = uint64_t(0); /** None **/
+    uint64_t basement_dest_ = uint64_t(0); /** None **/
+public:
+    inst_mfu_mn_map_compute(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        UNION_ADDR addr_src = UNION_ADDR(0),
+        UNION_ADDR addr_dest = UNION_ADDR(0),
+        STRIDE_GLB stride_input_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_output_glb = STRIDE_GLB(0),
+        uint64_t shape_n = uint64_t(0),
+        uint64_t shape_c = uint64_t(0),
+        uint64_t shape_h = uint64_t(0),
+        uint64_t shape_w = uint64_t(0),
+        uint64_t basement_src1 = uint64_t(0),
+        uint64_t basement_dest = uint64_t(0));
+
+    explicit inst_mfu_mn_map_compute(const INST_MFU_MN_MAP_COMPUTE &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_MAP_COMPUTE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算对于tensor的map运算
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算对于tensor的map运算
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      UNION_ADDR addr_src 输入向量slice地址 (GLB or DDR)
+  */
+    [[nodiscard]] UNION_ADDR addr_src() const;
+    /**
+      UNION_ADDR addr_src 输入向量slice地址 (GLB or DDR)
+  */
+    void addr_src(const UNION_ADDR &value);
+    /**
+      UNION_ADDR addr_dest 输出向量地址 (GLB or DDR)
+  */
+    [[nodiscard]] UNION_ADDR addr_dest() const;
+    /**
+      UNION_ADDR addr_dest 输出向量地址 (GLB or DDR)
+  */
+    void addr_dest(const UNION_ADDR &value);
+    /**
+      STRIDE_GLB stride_input_glb Tensor 的 shape
+  */
+    [[nodiscard]] STRIDE_GLB stride_input_glb() const;
+    /**
+      STRIDE_GLB stride_input_glb Tensor 的 shape
+  */
+    void stride_input_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_output_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_output_glb() const;
+    /**
+      STRIDE_GLB stride_output_glb None
+  */
+    void stride_output_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      uint64_t basement_src1 None
+  */
+    [[nodiscard]] uint64_t basement_src1() const;
+    /**
+      uint64_t basement_src1 None
+  */
+    void basement_src1(const uint64_t &value);
+    /**
+      uint64_t basement_dest None
+  */
+    [[nodiscard]] uint64_t basement_dest() const;
+    /**
+      uint64_t basement_dest None
+  */
+    void basement_dest(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mn_map_compute &c);
+
+/**
+    MFU.MN.VMAP.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算vector的map运算
+    - OPCODE opcode 配置MFU的DM模块，准备开始计算vector的map运算
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+    - ADDR addr_dest 输出向量地址 (GLB or DDR)
+    - uint64_t length 向量长度
+    - uint64_t basement_src None
+    - uint64_t basement_dest None
+**/
+class inst_mfu_mn_vmap_compute : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置MFU的DM模块，准备开始计算vector的map运算 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    UNION_ADDR addr_src_ = UNION_ADDR(0); /** 输入向量地址 (GLB or DDR) **/
+    ADDR addr_dest_ = ADDR(0); /** 输出向量地址 (GLB or DDR) **/
+    uint64_t length_ = uint64_t(0); /** 向量长度 **/
+    uint64_t basement_src_ = uint64_t(0); /** None **/
+    uint64_t basement_dest_ = uint64_t(0); /** None **/
+public:
+    inst_mfu_mn_vmap_compute(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        UNION_ADDR addr_src = UNION_ADDR(0),
+        ADDR addr_dest = ADDR(0),
+        uint64_t length = uint64_t(0),
+        uint64_t basement_src = uint64_t(0),
+        uint64_t basement_dest = uint64_t(0));
+
+    explicit inst_mfu_mn_vmap_compute(const INST_MFU_MN_VMAP_COMPUTE &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_VMAP_COMPUTE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算vector的map运算
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算vector的map运算
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    [[nodiscard]] UNION_ADDR addr_src() const;
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    void addr_src(const UNION_ADDR &value);
+    /**
+      ADDR addr_dest 输出向量地址 (GLB or DDR)
+  */
+    [[nodiscard]] ADDR addr_dest() const;
+    /**
+      ADDR addr_dest 输出向量地址 (GLB or DDR)
+  */
+    void addr_dest(const ADDR &value);
+    /**
+      uint64_t length 向量长度
+  */
+    [[nodiscard]] uint64_t length() const;
+    /**
+      uint64_t length 向量长度
+  */
+    void length(const uint64_t &value);
+    /**
+      uint64_t basement_src None
+  */
+    [[nodiscard]] uint64_t basement_src() const;
+    /**
+      uint64_t basement_src None
+  */
+    void basement_src(const uint64_t &value);
+    /**
+      uint64_t basement_dest None
+  */
+    [[nodiscard]] uint64_t basement_dest() const;
+    /**
+      uint64_t basement_dest None
+  */
+    void basement_dest(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mn_vmap_compute &c);
+
+/**
+    MFU.REDUCE
+    @brief 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+    - UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+    - uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+    - STRIDE_GLB stride_input_glb Tensor 的 shape
+    - uint64_t shape_n Slice 长度信息
+    - uint64_t shape_c Slice 长度信息
+    - uint64_t shape_h Slice 长度信息
+    - uint64_t shape_w Slice 长度信息
+    - MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+    - MFU_REDUCE_DIM dimension None
+    - uint64_t basement_src 是否是栈变量
+    - uint64_t basement_dest 是否是栈变量
+**/
+class inst_mfu_reduce : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(
+        0); /** 计算reduce，这个指令相当于bypass meshnet的reduce的短版本 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    UNION_ADDR addr_src_ = UNION_ADDR(0); /** 输入向量地址 (GLB or DDR) **/
+    UNION_ADDR addr_dest_ = UNION_ADDR(0); /** 输出到 GLB 或者 DDR 的位置 **/
+    uint64_t init_value_ = uint64_t(0); /** need_init 为 True 时有效，此时上面的 a1 为 init_value **/
+    STRIDE_GLB stride_input_glb_ = STRIDE_GLB(0); /** Tensor 的 shape **/
+    uint64_t shape_n_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_c_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_h_ = uint64_t(0); /** Slice 长度信息 **/
+    uint64_t shape_w_ = uint64_t(0); /** Slice 长度信息 **/
+    MFU_REDUCE_OP op_ = MFU_REDUCE_OP(0); /** 参与的运算 Scalar Binary Operator（含义见上方） **/
+    MFU_REDUCE_DIM dimension_ = MFU_REDUCE_DIM(0); /** None **/
+    uint64_t basement_src_ = uint64_t(0); /** 是否是栈变量 **/
+    uint64_t basement_dest_ = uint64_t(0); /** 是否是栈变量 **/
+public:
+    inst_mfu_reduce(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        UNION_ADDR addr_src = UNION_ADDR(0),
+        UNION_ADDR addr_dest = UNION_ADDR(0),
+        uint64_t init_value = uint64_t(0),
+        STRIDE_GLB stride_input_glb = STRIDE_GLB(0),
+        uint64_t shape_n = uint64_t(0),
+        uint64_t shape_c = uint64_t(0),
+        uint64_t shape_h = uint64_t(0),
+        uint64_t shape_w = uint64_t(0),
+        MFU_REDUCE_OP op = MFU_REDUCE_OP(0),
+        MFU_REDUCE_DIM dimension = MFU_REDUCE_DIM(0),
+        uint64_t basement_src = uint64_t(0),
+        uint64_t basement_dest = uint64_t(0));
+
+    explicit inst_mfu_reduce(const INST_MFU_REDUCE &ref);
+
+    [[nodiscard]] struct INST_MFU_REDUCE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    [[nodiscard]] UNION_ADDR addr_src() const;
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    void addr_src(const UNION_ADDR &value);
+    /**
+      UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+  */
+    [[nodiscard]] UNION_ADDR addr_dest() const;
+    /**
+      UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+  */
+    void addr_dest(const UNION_ADDR &value);
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    [[nodiscard]] uint64_t init_value() const;
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    void init_value(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_input_glb Tensor 的 shape
+  */
+    [[nodiscard]] STRIDE_GLB stride_input_glb() const;
+    /**
+      STRIDE_GLB stride_input_glb Tensor 的 shape
+  */
+    void stride_input_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n Slice 长度信息
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c Slice 长度信息
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h Slice 长度信息
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w Slice 长度信息
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+  */
+    [[nodiscard]] MFU_REDUCE_OP op() const;
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+  */
+    void op(const MFU_REDUCE_OP &value);
+    /**
+      MFU_REDUCE_DIM dimension None
+  */
+    [[nodiscard]] MFU_REDUCE_DIM dimension() const;
+    /**
+      MFU_REDUCE_DIM dimension None
+  */
+    void dimension(const MFU_REDUCE_DIM &value);
+    /**
+      uint64_t basement_src 是否是栈变量
+  */
+    [[nodiscard]] uint64_t basement_src() const;
+    /**
+      uint64_t basement_src 是否是栈变量
+  */
+    void basement_src(const uint64_t &value);
+    /**
+      uint64_t basement_dest 是否是栈变量
+  */
+    [[nodiscard]] uint64_t basement_dest() const;
+    /**
+      uint64_t basement_dest 是否是栈变量
+  */
+    void basement_dest(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_reduce &c);
+
+/**
+    MFU.VREDUCE
+    @brief 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+    - UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+    - uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+    - uint64_t length 向量输出长度（总长度是length*reduce_length）
+    - uint64_t reduce_length 每这么多个点输出一个点
+    - MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+    - uint64_t basement_src 是否是栈变量
+    - uint64_t basement_dest 是否是栈变量
+**/
+class inst_mfu_vreduce : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(
+        0); /** 计算reduce，这个指令相当于bypass meshnet的reduce的短版本 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    UNION_ADDR addr_src_ = UNION_ADDR(0); /** 输入向量地址 (GLB or DDR) **/
+    UNION_ADDR addr_dest_ = UNION_ADDR(0); /** 输出到 GLB 或者 DDR 的位置 **/
+    uint64_t init_value_ = uint64_t(0); /** need_init 为 True 时有效，此时上面的 a1 为 init_value **/
+    uint64_t length_ = uint64_t(0); /** 向量输出长度（总长度是length*reduce_length） **/
+    uint64_t reduce_length_ = uint64_t(0); /** 每这么多个点输出一个点 **/
+    MFU_REDUCE_OP op_ = MFU_REDUCE_OP(0); /** 参与的运算 Scalar Binary Operator（含义见上方） **/
+    uint64_t basement_src_ = uint64_t(0); /** 是否是栈变量 **/
+    uint64_t basement_dest_ = uint64_t(0); /** 是否是栈变量 **/
+public:
+    inst_mfu_vreduce(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        UNION_ADDR addr_src = UNION_ADDR(0),
+        UNION_ADDR addr_dest = UNION_ADDR(0),
+        uint64_t init_value = uint64_t(0),
+        uint64_t length = uint64_t(0),
+        uint64_t reduce_length = uint64_t(0),
+        MFU_REDUCE_OP op = MFU_REDUCE_OP(0),
+        uint64_t basement_src = uint64_t(0),
+        uint64_t basement_dest = uint64_t(0));
+
+    explicit inst_mfu_vreduce(const INST_MFU_VREDUCE &ref);
+
+    [[nodiscard]] struct INST_MFU_VREDUCE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 计算reduce，这个指令相当于bypass meshnet的reduce的短版本
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    [[nodiscard]] UNION_ADDR addr_src() const;
+    /**
+      UNION_ADDR addr_src 输入向量地址 (GLB or DDR)
+  */
+    void addr_src(const UNION_ADDR &value);
+    /**
+      UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+  */
+    [[nodiscard]] UNION_ADDR addr_dest() const;
+    /**
+      UNION_ADDR addr_dest 输出到 GLB 或者 DDR 的位置
+  */
+    void addr_dest(const UNION_ADDR &value);
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    [[nodiscard]] uint64_t init_value() const;
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    void init_value(const uint64_t &value);
+    /**
+      uint64_t length 向量输出长度（总长度是length*reduce_length）
+  */
+    [[nodiscard]] uint64_t length() const;
+    /**
+      uint64_t length 向量输出长度（总长度是length*reduce_length）
+  */
+    void length(const uint64_t &value);
+    /**
+      uint64_t reduce_length 每这么多个点输出一个点
+  */
+    [[nodiscard]] uint64_t reduce_length() const;
+    /**
+      uint64_t reduce_length 每这么多个点输出一个点
+  */
+    void reduce_length(const uint64_t &value);
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+  */
+    [[nodiscard]] MFU_REDUCE_OP op() const;
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator（含义见上方）
+  */
+    void op(const MFU_REDUCE_OP &value);
+    /**
+      uint64_t basement_src 是否是栈变量
+  */
+    [[nodiscard]] uint64_t basement_src() const;
+    /**
+      uint64_t basement_src 是否是栈变量
+  */
+    void basement_src(const uint64_t &value);
+    /**
+      uint64_t basement_dest 是否是栈变量
+  */
+    [[nodiscard]] uint64_t basement_dest() const;
+    /**
+      uint64_t basement_dest 是否是栈变量
+  */
+    void basement_dest(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_vreduce &c);
+
+/**
+    MFU.MN.BROADCAST.COMPUTE
+    @brief 配置MFU的DM模块，准备开始计算
+    - OPCODE opcode 配置MFU的DM模块，准备开始计算
+    - CCRCLR ccrclr_src1 None
+    - CCRCLR ccrclr_src2 None
+    - CCRSET ccrset None
+    - UNION_ADDR addr_src1 向量输入1地址
+    - UNION_ADDR addr_src2 向量输入2地址
+    - UNION_ADDR addr_dest 向量输出地址
+    - uint64_t len_src1 向量输入1长度
+    - uint64_t len_src2 向量输入2长度
+    - uint64_t len_dest
+输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+    - uint64_t basement_src1 None
+    - uint64_t basement_src2 None
+    - uint64_t basement_dest None
+**/
+class inst_mfu_mn_broadcast_compute : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 配置MFU的DM模块，准备开始计算 **/
+    CCRCLR ccrclr_src1_ = CCRCLR(0); /** None **/
+    CCRCLR ccrclr_src2_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    UNION_ADDR addr_src1_ = UNION_ADDR(0); /** 向量输入1地址 **/
+    UNION_ADDR addr_src2_ = UNION_ADDR(0); /** 向量输入2地址 **/
+    UNION_ADDR addr_dest_ = UNION_ADDR(0); /** 向量输出地址 **/
+    uint64_t len_src1_ = uint64_t(0); /** 向量输入1长度 **/
+    uint64_t len_src2_ = uint64_t(0); /** 向量输入2长度 **/
+    uint64_t len_dest_ = uint64_t(0); /**
+                                            输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+                                            **/
+    uint64_t basement_src1_ = uint64_t(0); /** None **/
+    uint64_t basement_src2_ = uint64_t(0); /** None **/
+    uint64_t basement_dest_ = uint64_t(0); /** None **/
+public:
+    inst_mfu_mn_broadcast_compute(
+        CCRCLR ccrclr_src1 = CCRCLR(0), CCRCLR ccrclr_src2 = CCRCLR(0),
+        CCRSET ccrset = CCRSET(0), UNION_ADDR addr_src1 = UNION_ADDR(0),
+        UNION_ADDR addr_src2 = UNION_ADDR(0),
+        UNION_ADDR addr_dest = UNION_ADDR(0), uint64_t len_src1 = uint64_t(0),
+        uint64_t len_src2 = uint64_t(0), uint64_t len_dest = uint64_t(0),
+        uint64_t basement_src1 = uint64_t(0),
+        uint64_t basement_src2 = uint64_t(0),
+        uint64_t basement_dest = uint64_t(0));
+
+    explicit inst_mfu_mn_broadcast_compute(
+        const INST_MFU_MN_BROADCAST_COMPUTE &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_BROADCAST_COMPUTE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 配置MFU的DM模块，准备开始计算
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr_src1 None
+  */
+    [[nodiscard]] CCRCLR ccrclr_src1() const;
+    /**
+      CCRCLR ccrclr_src1 None
+  */
+    void ccrclr_src1(const CCRCLR &value);
+    /**
+      CCRCLR ccrclr_src2 None
+  */
+    [[nodiscard]] CCRCLR ccrclr_src2() const;
+    /**
+      CCRCLR ccrclr_src2 None
+  */
+    void ccrclr_src2(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      UNION_ADDR addr_src1 向量输入1地址
+  */
+    [[nodiscard]] UNION_ADDR addr_src1() const;
+    /**
+      UNION_ADDR addr_src1 向量输入1地址
+  */
+    void addr_src1(const UNION_ADDR &value);
+    /**
+      UNION_ADDR addr_src2 向量输入2地址
+  */
+    [[nodiscard]] UNION_ADDR addr_src2() const;
+    /**
+      UNION_ADDR addr_src2 向量输入2地址
+  */
+    void addr_src2(const UNION_ADDR &value);
+    /**
+      UNION_ADDR addr_dest 向量输出地址
+  */
+    [[nodiscard]] UNION_ADDR addr_dest() const;
+    /**
+      UNION_ADDR addr_dest 向量输出地址
+  */
+    void addr_dest(const UNION_ADDR &value);
+    /**
+      uint64_t len_src1 向量输入1长度
+  */
+    [[nodiscard]] uint64_t len_src1() const;
+    /**
+      uint64_t len_src1 向量输入1长度
+  */
+    void len_src1(const uint64_t &value);
+    /**
+      uint64_t len_src2 向量输入2长度
+  */
+    [[nodiscard]] uint64_t len_src2() const;
+    /**
+      uint64_t len_src2 向量输入2长度
+  */
+    void len_src2(const uint64_t &value);
+    /**
+      uint64_t len_dest
+     输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+  */
+    [[nodiscard]] uint64_t len_dest() const;
+    /**
+      uint64_t len_dest
+     输出向量长度（超过了之后就会停止，和src1，src2的总长度成倍数，实现在左面广播）
+  */
+    void len_dest(const uint64_t &value);
+    /**
+      uint64_t basement_src1 None
+  */
+    [[nodiscard]] uint64_t basement_src1() const;
+    /**
+      uint64_t basement_src1 None
+  */
+    void basement_src1(const uint64_t &value);
+    /**
+      uint64_t basement_src2 None
+  */
+    [[nodiscard]] uint64_t basement_src2() const;
+    /**
+      uint64_t basement_src2 None
+  */
+    void basement_src2(const uint64_t &value);
+    /**
+      uint64_t basement_dest None
+  */
+    [[nodiscard]] uint64_t basement_dest() const;
+    /**
+      uint64_t basement_dest None
+  */
+    void basement_dest(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out,
+    const inst_mfu_mn_broadcast_compute &c);
+
+/**
+    MFU.MN.REDUCE
+    @brief 这条指令用于配置Fuse在Meshnet后面的Reduce
+    - OPCODE opcode 这条指令用于配置Fuse在Meshnet后面的Reduce
+    - uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+    - uint64_t recude_length 有多少个元素参与一次reduce
+    - uint64_t length reduce元素的次数
+    - MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator
+**/
+class inst_mfu_mn_reduce : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 这条指令用于配置Fuse在Meshnet后面的Reduce **/
+    uint64_t init_value_ = uint64_t(0); /** need_init 为 True 时有效，此时上面的 a1 为 init_value **/
+    uint64_t recude_length_ = uint64_t(0); /** 有多少个元素参与一次reduce **/
+    uint64_t length_ = uint64_t(0); /** reduce元素的次数 **/
+    MFU_REDUCE_OP op_ = MFU_REDUCE_OP(0); /** 参与的运算 Scalar Binary Operator **/
+public:
+    inst_mfu_mn_reduce(uint64_t init_value = uint64_t(0),
+        uint64_t recude_length = uint64_t(0),
+        uint64_t length = uint64_t(0),
+        MFU_REDUCE_OP op = MFU_REDUCE_OP(0));
+
+    explicit inst_mfu_mn_reduce(const INST_MFU_MN_REDUCE &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_REDUCE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 这条指令用于配置Fuse在Meshnet后面的Reduce
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 这条指令用于配置Fuse在Meshnet后面的Reduce
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    [[nodiscard]] uint64_t init_value() const;
+    /**
+      uint64_t init_value need_init 为 True 时有效，此时上面的 a1 为 init_value
+  */
+    void init_value(const uint64_t &value);
+    /**
+      uint64_t recude_length 有多少个元素参与一次reduce
+  */
+    [[nodiscard]] uint64_t recude_length() const;
+    /**
+      uint64_t recude_length 有多少个元素参与一次reduce
+  */
+    void recude_length(const uint64_t &value);
+    /**
+      uint64_t length reduce元素的次数
+  */
+    [[nodiscard]] uint64_t length() const;
+    /**
+      uint64_t length reduce元素的次数
+  */
+    void length(const uint64_t &value);
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator
+  */
+    [[nodiscard]] MFU_REDUCE_OP op() const;
+    /**
+      MFU_REDUCE_OP op 参与的运算 Scalar Binary Operator
+  */
+    void op(const MFU_REDUCE_OP &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mn_reduce &c);
+
+class inst_mfu_mn_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /**
+                                               配置互联网络。我们认为某个原件编号为0就是与网络断开连接并且gate掉。整个网络连接初始值都是0
+                                               **/
+    MFU_MN_PORTOUT out1_ = MFU_MN_PORTOUT(0); /** VECTOR_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out2_ = MFU_MN_PORTOUT(0); /** VECTOR_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out3_ = MFU_MN_PORTOUT(0); /** CONST1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out4_ = MFU_MN_PORTOUT(0); /** CONST1_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out5_ = MFU_MN_PORTOUT(0); /** CONST2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out6_ = MFU_MN_PORTOUT(0); /** CONST2_OUT_1连接的端口 **/
+    MFU_MN_PORTOUT out7_ = MFU_MN_PORTOUT(0); /** ADDSUB0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out8_ = MFU_MN_PORTOUT(0); /** ADDSUB1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out9_ = MFU_MN_PORTOUT(0); /** ADDSUB2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out10_ = MFU_MN_PORTOUT(0); /** ADDSUB3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out11_ = MFU_MN_PORTOUT(0); /** MUL0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out12_ = MFU_MN_PORTOUT(0); /** MUL1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out13_ = MFU_MN_PORTOUT(0); /** MUL2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out14_ = MFU_MN_PORTOUT(0); /** MUL3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out15_ = MFU_MN_PORTOUT(0); /** DIV_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out16_ = MFU_MN_PORTOUT(0); /** ROUND_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out17_ = MFU_MN_PORTOUT(0); /** SQRT_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out18_ = MFU_MN_PORTOUT(0); /** TRANGLE_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out19_ = MFU_MN_PORTOUT(0); /** LOG_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out20_ = MFU_MN_PORTOUT(0); /** UNARY_LOGIC_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out21_ = MFU_MN_PORTOUT(0); /** EXP_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out22_ = MFU_MN_PORTOUT(0); /** CMP0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out23_ = MFU_MN_PORTOUT(0); /** CMP1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out24_ = MFU_MN_PORTOUT(0); /** REG0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out25_ = MFU_MN_PORTOUT(0); /** SELECT0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out26_ = MFU_MN_PORTOUT(0); /** NOP0_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out27_ = MFU_MN_PORTOUT(0); /** NOP1_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out28_ = MFU_MN_PORTOUT(0); /** NOP2_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out29_ = MFU_MN_PORTOUT(0); /** NOP3_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out30_ = MFU_MN_PORTOUT(0); /** NOP4_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out31_ = MFU_MN_PORTOUT(0); /** NOP5_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out32_ = MFU_MN_PORTOUT(0); /** NOP6_OUT_0连接的端口 **/
+    MFU_MN_PORTOUT out33_ = MFU_MN_PORTOUT(0); /** NOP7_OUT_0连接的端口 **/
+public:
+    inst_mfu_mn_conf(MFU_MN_PORTOUT out1 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out2 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out3 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out4 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out5 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out6 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out7 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out8 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out9 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out10 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out11 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out12 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out13 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out14 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out15 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out16 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out17 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out18 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out19 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out20 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out21 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out22 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out23 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out24 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out25 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out26 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out27 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out28 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out29 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out30 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out31 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out32 = MFU_MN_PORTOUT(0),
+        MFU_MN_PORTOUT out33 = MFU_MN_PORTOUT(0));
+
+    explicit inst_mfu_mn_conf(const INST_MFU_MN_CONF &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode
+     配置互联网络。我们认为某个原件编号为0就是与网络断开连接并且gate掉。整个网络连接初始值都是0
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode
+     配置互联网络。我们认为某个原件编号为0就是与网络断开连接并且gate掉。整个网络连接初始值都是0
+  */
+    void opcode(const OPCODE &value);
+    /**
+      MFU_MN_PORTOUT out1 VECTOR_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out1() const;
+    /**
+      MFU_MN_PORTOUT out1 VECTOR_OUT_0连接的端口
+  */
+    void out1(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out2 VECTOR_OUT_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out2() const;
+    /**
+      MFU_MN_PORTOUT out2 VECTOR_OUT_1连接的端口
+  */
+    void out2(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out3 CONST1_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out3() const;
+    /**
+      MFU_MN_PORTOUT out3 CONST1_OUT_0连接的端口
+  */
+    void out3(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out4 CONST1_OUT_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out4() const;
+    /**
+      MFU_MN_PORTOUT out4 CONST1_OUT_1连接的端口
+  */
+    void out4(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out5 CONST2_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out5() const;
+    /**
+      MFU_MN_PORTOUT out5 CONST2_OUT_0连接的端口
+  */
+    void out5(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out6 CONST2_OUT_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out6() const;
+    /**
+      MFU_MN_PORTOUT out6 CONST2_OUT_1连接的端口
+  */
+    void out6(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out7 ADDSUB0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out7() const;
+    /**
+      MFU_MN_PORTOUT out7 ADDSUB0_OUT_0连接的端口
+  */
+    void out7(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out8 ADDSUB1_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out8() const;
+    /**
+      MFU_MN_PORTOUT out8 ADDSUB1_OUT_0连接的端口
+  */
+    void out8(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out9 ADDSUB2_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out9() const;
+    /**
+      MFU_MN_PORTOUT out9 ADDSUB2_OUT_0连接的端口
+  */
+    void out9(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out10 ADDSUB3_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out10() const;
+    /**
+      MFU_MN_PORTOUT out10 ADDSUB3_OUT_0连接的端口
+  */
+    void out10(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out11 MUL0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out11() const;
+    /**
+      MFU_MN_PORTOUT out11 MUL0_OUT_0连接的端口
+  */
+    void out11(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out12 MUL1_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out12() const;
+    /**
+      MFU_MN_PORTOUT out12 MUL1_OUT_0连接的端口
+  */
+    void out12(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out13 MUL2_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out13() const;
+    /**
+      MFU_MN_PORTOUT out13 MUL2_OUT_0连接的端口
+  */
+    void out13(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out14 MUL3_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out14() const;
+    /**
+      MFU_MN_PORTOUT out14 MUL3_OUT_0连接的端口
+  */
+    void out14(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out15 DIV_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out15() const;
+    /**
+      MFU_MN_PORTOUT out15 DIV_OUT_0连接的端口
+  */
+    void out15(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out16 ROUND_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out16() const;
+    /**
+      MFU_MN_PORTOUT out16 ROUND_OUT_0连接的端口
+  */
+    void out16(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out17 SQRT_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out17() const;
+    /**
+      MFU_MN_PORTOUT out17 SQRT_OUT_0连接的端口
+  */
+    void out17(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out18 TRANGLE_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out18() const;
+    /**
+      MFU_MN_PORTOUT out18 TRANGLE_OUT_0连接的端口
+  */
+    void out18(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out19 LOG_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out19() const;
+    /**
+      MFU_MN_PORTOUT out19 LOG_OUT_0连接的端口
+  */
+    void out19(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out20 UNARY_LOGIC_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out20() const;
+    /**
+      MFU_MN_PORTOUT out20 UNARY_LOGIC_OUT_0连接的端口
+  */
+    void out20(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out21 EXP_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out21() const;
+    /**
+      MFU_MN_PORTOUT out21 EXP_OUT_0连接的端口
+  */
+    void out21(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out22 CMP0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out22() const;
+    /**
+      MFU_MN_PORTOUT out22 CMP0_OUT_0连接的端口
+  */
+    void out22(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out23 CMP1_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out23() const;
+    /**
+      MFU_MN_PORTOUT out23 CMP1_OUT_0连接的端口
+  */
+    void out23(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out24 REG0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out24() const;
+    /**
+      MFU_MN_PORTOUT out24 REG0_OUT_0连接的端口
+  */
+    void out24(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out25 SELECT0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out25() const;
+    /**
+      MFU_MN_PORTOUT out25 SELECT0_OUT_0连接的端口
+  */
+    void out25(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out26 NOP0_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out26() const;
+    /**
+      MFU_MN_PORTOUT out26 NOP0_OUT_0连接的端口
+  */
+    void out26(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out27 NOP1_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out27() const;
+    /**
+      MFU_MN_PORTOUT out27 NOP1_OUT_0连接的端口
+  */
+    void out27(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out28 NOP2_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out28() const;
+    /**
+      MFU_MN_PORTOUT out28 NOP2_OUT_0连接的端口
+  */
+    void out28(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out29 NOP3_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out29() const;
+    /**
+      MFU_MN_PORTOUT out29 NOP3_OUT_0连接的端口
+  */
+    void out29(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out30 NOP4_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out30() const;
+    /**
+      MFU_MN_PORTOUT out26 NOP4_OUT_0连接的端口
+  */
+    void out30(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out31 NOP5_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out31() const;
+    /**
+      MFU_MN_PORTOUT out31 NOP5_OUT_0连接的端口
+  */
+    void out31(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out32 NOP6_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out32() const;
+    /**
+      MFU_MN_PORTOUT out32 NOP6_OUT_0连接的端口
+  */
+    void out32(const MFU_MN_PORTOUT &value);
+    /**
+      MFU_MN_PORTOUT out33 NOP7_OUT_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTOUT out33() const;
+    /**
+      MFU_MN_PORTOUT out33 NOP7_OUT_0连接的端口
+  */
+    void out33(const MFU_MN_PORTOUT &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mn_conf &c);
+
+/**
+    MFU.MNOP.CONF
+    @brief
+这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+    - OPCODE opcode
+这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+    - uint64_t mode 模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址
+    - uint64_t val 配置
+**/
+class inst_mfu_mnop_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /**
+                                   这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+                                   **/
+    uint64_t mode_ = uint64_t(0); /** 模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址 **/
+    uint64_t val_ = uint64_t(0); /** 配置 **/
+public:
+    inst_mfu_mnop_conf(uint64_t mode = uint64_t(0), uint64_t val = uint64_t(0));
+
+    explicit inst_mfu_mnop_conf(const INST_MFU_MNOP_CONF &ref);
+
+    [[nodiscard]] struct INST_MFU_MNOP_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode
+     这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode
+     这条指令用来配置原件的内部寄存器，比如group的操作的选通，或者是拟合运算的拟合表的配置
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t mode 模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址
+  */
+    [[nodiscard]] uint64_t mode() const;
+    /**
+      uint64_t mode 模式。
+0：配置的是各种原件的标志bit
+1：配置拟合模块0的参数地址
+2：配置拟合模块1的参数地址
+  */
+    void mode(const uint64_t &value);
+    /**
+      uint64_t val 配置
+  */
+    [[nodiscard]] uint64_t val() const;
+    /**
+      uint64_t val 配置
+  */
+    void val(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mnop_conf &c);
+
+/**
+    MFU.PDP.CONF
+    @brief 主要用于配置 PDP 模块计算中共用的一些全局配置
+    - OPCODE opcode 主要用于配置 PDP 模块计算中共用的一些全局配置
+    - uint64_t multiple_channels 是否在多个 channel
+上同时进行一样窗口和窗口移动规则。
+    - STRIDE_GLB stride_dest_glb None
+**/
+class inst_mfu_pdp_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 主要用于配置 PDP 模块计算中共用的一些全局配置 **/
+    uint64_t multiple_channels_ = uint64_t(0); /** 是否在多个 channel 上同时进行一样窗口和窗口移动规则。 **/
+    STRIDE_GLB stride_dest_glb_ = STRIDE_GLB(0); /** None **/
+public:
+    inst_mfu_pdp_conf(uint64_t multiple_channels = uint64_t(0),
+        STRIDE_GLB stride_dest_glb = STRIDE_GLB(0));
+
+    explicit inst_mfu_pdp_conf(const INST_MFU_PDP_CONF &ref);
+
+    [[nodiscard]] struct INST_MFU_PDP_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 主要用于配置 PDP 模块计算中共用的一些全局配置
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 主要用于配置 PDP 模块计算中共用的一些全局配置
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t multiple_channels 是否在多个 channel
+     上同时进行一样窗口和窗口移动规则。
+  */
+    [[nodiscard]] uint64_t multiple_channels() const;
+    /**
+      uint64_t multiple_channels 是否在多个 channel
+     上同时进行一样窗口和窗口移动规则。
+  */
+    void multiple_channels(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_dest_glb() const;
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    void stride_dest_glb(const STRIDE_GLB &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_pdp_conf &c);
+
+/**
+    MFU.PDP.SRC.CONF
+    @brief  主要用来配置待操作的 Tensor 的位置
+    - OPCODE opcode  主要用来配置待操作的 Tensor 的位置
+    - STRIDE_GLB stride_glb Tensor 的 shape
+**/
+class inst_mfu_pdp_src_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /**  主要用来配置待操作的 Tensor 的位置 **/
+    STRIDE_GLB stride_glb_ = STRIDE_GLB(0); /** Tensor 的 shape **/
+public:
+    inst_mfu_pdp_src_conf(STRIDE_GLB stride_glb = STRIDE_GLB(0));
+
+    explicit inst_mfu_pdp_src_conf(const INST_MFU_PDP_SRC_CONF &ref);
+
+    [[nodiscard]] struct INST_MFU_PDP_SRC_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode  主要用来配置待操作的 Tensor 的位置
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode  主要用来配置待操作的 Tensor 的位置
+  */
+    void opcode(const OPCODE &value);
+    /**
+      STRIDE_GLB stride_glb Tensor 的 shape
+  */
+    [[nodiscard]] STRIDE_GLB stride_glb() const;
+    /**
+      STRIDE_GLB stride_glb Tensor 的 shape
+  */
+    void stride_glb(const STRIDE_GLB &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_pdp_src_conf &c);
+
+/**
+    MFU.PDP.REDUCE
+    @brief 进行PDP运算
+    - OPCODE opcode 进行PDP运算
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_src 输入向量地址 (GLB or DDR)（slice起始地址）
+    - ADDR_GLB_8_WITH_BANK addr_dest 输出位置
+    - uint64_t window_w 2D 窗口的宽
+    - uint64_t window_h 2D 窗口的高
+    - uint64_t active_h PDP阵列硬件使能的高度（需要是window_h的整数倍）
+    - uint64_t shape_n None
+    - uint64_t shape_c None
+    - uint64_t shape_h None
+    - uint64_t shape_w None
+    - uint64_t count_w W 维度上做 N 次 ReduceWindow 操作
+    - uint64_t count_h H 维度上做 N 次 ReduceWindow操作
+    - uint64_t stride_w W 维度上每次取窗口的下标增加量
+    - uint64_t stride_h H 维度上每次取窗口的下标增加量
+    - uint64_t padding_top 在 2D Tensor 的顶部加的 Zero padding 行数
+    - uint64_t padding_bottom 在 2D Tensor 的底部加的 Zero padding 行数
+    - uint64_t padding_left 在 2D Tensor 的左边加的 Zero padding 行数
+    - uint64_t padding_right 在 2D Tensor 的右边加的 Zero padding 行数
+    - uint64_t pe_last_h 来表明最后一次计算需要使能多少个pdp单元
+    - MFU_PDP_OP computation 我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg 三种
+    - uint64_t quantized 是否是量化计算
+**/
+class inst_mfu_pdp_reduce : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 进行PDP运算 **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src_ = ADDR_GLB_8_WITH_BANK(
+        0); /** 输入向量地址 (GLB or DDR)（slice起始地址） **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** 输出位置 **/
+    uint64_t window_w_ = uint64_t(0); /** 2D 窗口的宽 **/
+    uint64_t window_h_ = uint64_t(0); /** 2D 窗口的高 **/
+    uint64_t active_h_ = uint64_t(0); /** PDP阵列硬件使能的高度（需要是window_h的整数倍） **/
+    uint64_t shape_n_ = uint64_t(0); /** None **/
+    uint64_t shape_c_ = uint64_t(0); /** None **/
+    uint64_t shape_h_ = uint64_t(0); /** None **/
+    uint64_t shape_w_ = uint64_t(0); /** None **/
+    uint64_t count_w_ = uint64_t(0); /** W 维度上做 N 次 ReduceWindow 操作 **/
+    uint64_t count_h_ = uint64_t(0); /** H 维度上做 N 次 ReduceWindow操作 **/
+    uint64_t stride_w_ = uint64_t(0); /** W 维度上每次取窗口的下标增加量 **/
+    uint64_t stride_h_ = uint64_t(0); /** H 维度上每次取窗口的下标增加量 **/
+    uint64_t padding_top_ = uint64_t(0); /** 在 2D Tensor 的顶部加的 Zero padding 行数 **/
+    uint64_t padding_bottom_ = uint64_t(0); /** 在 2D Tensor 的底部加的 Zero padding 行数 **/
+    uint64_t padding_left_ = uint64_t(0); /** 在 2D Tensor 的左边加的 Zero padding 行数 **/
+    uint64_t padding_right_ = uint64_t(0); /** 在 2D Tensor 的右边加的 Zero padding 行数 **/
+    uint64_t pe_last_h_ = uint64_t(0); /** 来表明最后一次计算需要使能多少个pdp单元 **/
+    MFU_PDP_OP computation_ = MFU_PDP_OP(0); /** 我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg 三种 **/
+    uint64_t quantized_ = uint64_t(0); /** 是否是量化计算 **/
+public:
+    inst_mfu_pdp_reduce(
+        CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_src = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t window_w = uint64_t(0), uint64_t window_h = uint64_t(0),
+        uint64_t active_h = uint64_t(0), uint64_t shape_n = uint64_t(0),
+        uint64_t shape_c = uint64_t(0), uint64_t shape_h = uint64_t(0),
+        uint64_t shape_w = uint64_t(0), uint64_t count_w = uint64_t(0),
+        uint64_t count_h = uint64_t(0), uint64_t stride_w = uint64_t(0),
+        uint64_t stride_h = uint64_t(0), uint64_t padding_top = uint64_t(0),
+        uint64_t padding_bottom = uint64_t(0),
+        uint64_t padding_left = uint64_t(0), uint64_t padding_right = uint64_t(0),
+        uint64_t pe_last_h = uint64_t(0), MFU_PDP_OP computation = MFU_PDP_OP(0),
+        uint64_t quantized = uint64_t(0));
+
+    explicit inst_mfu_pdp_reduce(const INST_MFU_PDP_REDUCE &ref);
+
+    [[nodiscard]] struct INST_MFU_PDP_REDUCE to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 进行PDP运算
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 进行PDP运算
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src 输入向量地址 (GLB or DDR)（slice起始地址）
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src 输入向量地址 (GLB or DDR)（slice起始地址）
+  */
+    void addr_src(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest 输出位置
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest 输出位置
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t window_w 2D 窗口的宽
+  */
+    [[nodiscard]] uint64_t window_w() const;
+    /**
+      uint64_t window_w 2D 窗口的宽
+  */
+    void window_w(const uint64_t &value);
+    /**
+      uint64_t window_h 2D 窗口的高
+  */
+    [[nodiscard]] uint64_t window_h() const;
+    /**
+      uint64_t window_h 2D 窗口的高
+  */
+    void window_h(const uint64_t &value);
+    /**
+      uint64_t active_h PDP阵列硬件使能的高度（需要是window_h的整数倍）
+  */
+    [[nodiscard]] uint64_t active_h() const;
+    /**
+      uint64_t active_h PDP阵列硬件使能的高度（需要是window_h的整数倍）
+  */
+    void active_h(const uint64_t &value);
+    /**
+      uint64_t shape_n None
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n None
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c None
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c None
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h None
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h None
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w None
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w None
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      uint64_t count_w W 维度上做 N 次 ReduceWindow 操作
+  */
+    [[nodiscard]] uint64_t count_w() const;
+    /**
+      uint64_t count_w W 维度上做 N 次 ReduceWindow 操作
+  */
+    void count_w(const uint64_t &value);
+    /**
+      uint64_t count_h H 维度上做 N 次 ReduceWindow操作
+  */
+    [[nodiscard]] uint64_t count_h() const;
+    /**
+      uint64_t count_h H 维度上做 N 次 ReduceWindow操作
+  */
+    void count_h(const uint64_t &value);
+    /**
+      uint64_t stride_w W 维度上每次取窗口的下标增加量
+  */
+    [[nodiscard]] uint64_t stride_w() const;
+    /**
+      uint64_t stride_w W 维度上每次取窗口的下标增加量
+  */
+    void stride_w(const uint64_t &value);
+    /**
+      uint64_t stride_h H 维度上每次取窗口的下标增加量
+  */
+    [[nodiscard]] uint64_t stride_h() const;
+    /**
+      uint64_t stride_h H 维度上每次取窗口的下标增加量
+  */
+    void stride_h(const uint64_t &value);
+    /**
+      uint64_t padding_top 在 2D Tensor 的顶部加的 Zero padding 行数
+  */
+    [[nodiscard]] uint64_t padding_top() const;
+    /**
+      uint64_t padding_top 在 2D Tensor 的顶部加的 Zero padding 行数
+  */
+    void padding_top(const uint64_t &value);
+    /**
+      uint64_t padding_bottom 在 2D Tensor 的底部加的 Zero padding 行数
+  */
+    [[nodiscard]] uint64_t padding_bottom() const;
+    /**
+      uint64_t padding_bottom 在 2D Tensor 的底部加的 Zero padding 行数
+  */
+    void padding_bottom(const uint64_t &value);
+    /**
+      uint64_t padding_left 在 2D Tensor 的左边加的 Zero padding 行数
+  */
+    [[nodiscard]] uint64_t padding_left() const;
+    /**
+      uint64_t padding_left 在 2D Tensor 的左边加的 Zero padding 行数
+  */
+    void padding_left(const uint64_t &value);
+    /**
+      uint64_t padding_right 在 2D Tensor 的右边加的 Zero padding 行数
+  */
+    [[nodiscard]] uint64_t padding_right() const;
+    /**
+      uint64_t padding_right 在 2D Tensor 的右边加的 Zero padding 行数
+  */
+    void padding_right(const uint64_t &value);
+    /**
+      uint64_t pe_last_h 来表明最后一次计算需要使能多少个pdp单元
+  */
+    [[nodiscard]] uint64_t pe_last_h() const;
+    /**
+      uint64_t pe_last_h 来表明最后一次计算需要使能多少个pdp单元
+  */
+    void pe_last_h(const uint64_t &value);
+    /**
+      MFU_PDP_OP computation 我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg 三种
+  */
+    [[nodiscard]] MFU_PDP_OP computation() const;
+    /**
+      MFU_PDP_OP computation 我们只支持 Map/Reduce 二元算子中的 Max/Min/Avg 三种
+  */
+    void computation(const MFU_PDP_OP &value);
+    /**
+      uint64_t quantized 是否是量化计算
+  */
+    [[nodiscard]] uint64_t quantized() const;
+    /**
+      uint64_t quantized 是否是量化计算
+  */
+    void quantized(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_pdp_reduce &c);
+
+/**
+    MFU.MN.BROADCAST.CONF
+    @brief None
+    - OPCODE opcode None
+    - uint64_t slice_src1 向量输入1 slice长度
+    - uint64_t slice_src2 向量输入2 slice长度
+    - uint64_t repeats_src1 向量输入1每个元素重复的次数（在右面广播）
+    - uint64_t repeats_src2 向量输入2每个元素重复的次数（在右面广播）
+    - uint64_t slice_repeats_src1 向量输入1 slice次数（实现在中间广播）
+    - uint64_t slice_repeats_src2 向量输入2 slice次数（实现在中间广播）
+    - STRIDE_GLB stride_src1_glb None
+    - uint64_t shape_src1_n None
+    - uint64_t shape_src1_c None
+    - uint64_t shape_src1_h None
+    - uint64_t shape_src1_w None
+    - STRIDE_GLB stride_src2_glb None
+    - uint64_t shape_src2_n None
+    - uint64_t shape_src2_c None
+    - uint64_t shape_src2_h None
+    - uint64_t shape_src2_w None
+    - uint64_t const1 常量1
+    - uint64_t const2 常量2
+    - uint64_t const3 常量3
+    - uint64_t const4 常量4
+**/
+class inst_mfu_mn_broadcast_conf : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    uint64_t slice_src1_ = uint64_t(0); /** 向量输入1 slice长度 **/
+    uint64_t slice_src2_ = uint64_t(0); /** 向量输入2 slice长度 **/
+    uint64_t repeats_src1_ = uint64_t(0); /** 向量输入1每个元素重复的次数（在右面广播） **/
+    uint64_t repeats_src2_ = uint64_t(0); /** 向量输入2每个元素重复的次数（在右面广播） **/
+    uint64_t slice_repeats_src1_ = uint64_t(0); /** 向量输入1 slice次数（实现在中间广播） **/
+    uint64_t slice_repeats_src2_ = uint64_t(0); /** 向量输入2 slice次数（实现在中间广播） **/
+    STRIDE_GLB stride_src1_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_src1_n_ = uint64_t(0); /** None **/
+    uint64_t shape_src1_c_ = uint64_t(0); /** None **/
+    uint64_t shape_src1_h_ = uint64_t(0); /** None **/
+    uint64_t shape_src1_w_ = uint64_t(0); /** None **/
+    STRIDE_GLB stride_src2_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_src2_n_ = uint64_t(0); /** None **/
+    uint64_t shape_src2_c_ = uint64_t(0); /** None **/
+    uint64_t shape_src2_h_ = uint64_t(0); /** None **/
+    uint64_t shape_src2_w_ = uint64_t(0); /** None **/
+    uint64_t const1_ = uint64_t(0); /** 常量1 **/
+    uint64_t const2_ = uint64_t(0); /** 常量2 **/
+    uint64_t const3_ = uint64_t(0); /** 常量3 **/
+    uint64_t const4_ = uint64_t(0); /** 常量4 **/
+public:
+    inst_mfu_mn_broadcast_conf(
+        uint64_t slice_src1 = uint64_t(0), uint64_t slice_src2 = uint64_t(0),
+        uint64_t repeats_src1 = uint64_t(0), uint64_t repeats_src2 = uint64_t(0),
+        uint64_t slice_repeats_src1 = uint64_t(0),
+        uint64_t slice_repeats_src2 = uint64_t(0),
+        STRIDE_GLB stride_src1_glb = STRIDE_GLB(0),
+        uint64_t shape_src1_n = uint64_t(0), uint64_t shape_src1_c = uint64_t(0),
+        uint64_t shape_src1_h = uint64_t(0), uint64_t shape_src1_w = uint64_t(0),
+        STRIDE_GLB stride_src2_glb = STRIDE_GLB(0),
+        uint64_t shape_src2_n = uint64_t(0), uint64_t shape_src2_c = uint64_t(0),
+        uint64_t shape_src2_h = uint64_t(0), uint64_t shape_src2_w = uint64_t(0),
+        uint64_t const1 = uint64_t(0), uint64_t const2 = uint64_t(0),
+        uint64_t const3 = uint64_t(0), uint64_t const4 = uint64_t(0));
+
+    explicit inst_mfu_mn_broadcast_conf(const INST_MFU_MN_BROADCAST_CONF &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_BROADCAST_CONF to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      uint64_t slice_src1 向量输入1 slice长度
+  */
+    [[nodiscard]] uint64_t slice_src1() const;
+    /**
+      uint64_t slice_src1 向量输入1 slice长度
+  */
+    void slice_src1(const uint64_t &value);
+    /**
+      uint64_t slice_src2 向量输入2 slice长度
+  */
+    [[nodiscard]] uint64_t slice_src2() const;
+    /**
+      uint64_t slice_src2 向量输入2 slice长度
+  */
+    void slice_src2(const uint64_t &value);
+    /**
+      uint64_t repeats_src1 向量输入1每个元素重复的次数（在右面广播）
+  */
+    [[nodiscard]] uint64_t repeats_src1() const;
+    /**
+      uint64_t repeats_src1 向量输入1每个元素重复的次数（在右面广播）
+  */
+    void repeats_src1(const uint64_t &value);
+    /**
+      uint64_t repeats_src2 向量输入2每个元素重复的次数（在右面广播）
+  */
+    [[nodiscard]] uint64_t repeats_src2() const;
+    /**
+      uint64_t repeats_src2 向量输入2每个元素重复的次数（在右面广播）
+  */
+    void repeats_src2(const uint64_t &value);
+    /**
+      uint64_t slice_repeats_src1 向量输入1 slice次数（实现在中间广播）
+  */
+    [[nodiscard]] uint64_t slice_repeats_src1() const;
+    /**
+      uint64_t slice_repeats_src1 向量输入1 slice次数（实现在中间广播）
+  */
+    void slice_repeats_src1(const uint64_t &value);
+    /**
+      uint64_t slice_repeats_src2 向量输入2 slice次数（实现在中间广播）
+  */
+    [[nodiscard]] uint64_t slice_repeats_src2() const;
+    /**
+      uint64_t slice_repeats_src2 向量输入2 slice次数（实现在中间广播）
+  */
+    void slice_repeats_src2(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_src1_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src1_glb() const;
+    /**
+      STRIDE_GLB stride_src1_glb None
+  */
+    void stride_src1_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_src1_n None
+  */
+    [[nodiscard]] uint64_t shape_src1_n() const;
+    /**
+      uint64_t shape_src1_n None
+  */
+    void shape_src1_n(const uint64_t &value);
+    /**
+      uint64_t shape_src1_c None
+  */
+    [[nodiscard]] uint64_t shape_src1_c() const;
+    /**
+      uint64_t shape_src1_c None
+  */
+    void shape_src1_c(const uint64_t &value);
+    /**
+      uint64_t shape_src1_h None
+  */
+    [[nodiscard]] uint64_t shape_src1_h() const;
+    /**
+      uint64_t shape_src1_h None
+  */
+    void shape_src1_h(const uint64_t &value);
+    /**
+      uint64_t shape_src1_w None
+  */
+    [[nodiscard]] uint64_t shape_src1_w() const;
+    /**
+      uint64_t shape_src1_w None
+  */
+    void shape_src1_w(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_src2_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src2_glb() const;
+    /**
+      STRIDE_GLB stride_src2_glb None
+  */
+    void stride_src2_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_src2_n None
+  */
+    [[nodiscard]] uint64_t shape_src2_n() const;
+    /**
+      uint64_t shape_src2_n None
+  */
+    void shape_src2_n(const uint64_t &value);
+    /**
+      uint64_t shape_src2_c None
+  */
+    [[nodiscard]] uint64_t shape_src2_c() const;
+    /**
+      uint64_t shape_src2_c None
+  */
+    void shape_src2_c(const uint64_t &value);
+    /**
+      uint64_t shape_src2_h None
+  */
+    [[nodiscard]] uint64_t shape_src2_h() const;
+    /**
+      uint64_t shape_src2_h None
+  */
+    void shape_src2_h(const uint64_t &value);
+    /**
+      uint64_t shape_src2_w None
+  */
+    [[nodiscard]] uint64_t shape_src2_w() const;
+    /**
+      uint64_t shape_src2_w None
+  */
+    void shape_src2_w(const uint64_t &value);
+    /**
+      uint64_t const1 常量1
+  */
+    [[nodiscard]] uint64_t const1() const;
+    /**
+      uint64_t const1 常量1
+  */
+    void const1(const uint64_t &value);
+    /**
+      uint64_t const2 常量2
+  */
+    [[nodiscard]] uint64_t const2() const;
+    /**
+      uint64_t const2 常量2
+  */
+    void const2(const uint64_t &value);
+    /**
+      uint64_t const3 常量3
+  */
+    [[nodiscard]] uint64_t const3() const;
+    /**
+      uint64_t const3 常量3
+  */
+    void const3(const uint64_t &value);
+    /**
+      uint64_t const4 常量4
+  */
+    [[nodiscard]] uint64_t const4() const;
+    /**
+      uint64_t const4 常量4
+  */
+    void const4(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out,
+    const inst_mfu_mn_broadcast_conf &c);
+
+/**
+    MFU.CROP
+    @brief None
+    - OPCODE opcode None
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_src None
+    - ADDR_GLB_8_WITH_BANK addr_dest None
+    - ADDR_GLB_8_WITH_BANK addr_bbox None
+    - uint64_t reserve None
+    - uint64_t shape_src_c None
+    - uint64_t shape_src_h None
+    - uint64_t shape_src_w None
+    - STRIDE_GLB stride_src_glb None
+    - STRIDE_GLB stride_dest_glb None
+    - uint64_t roi_amount None
+    - uint64_t dest_h None
+    - uint64_t dest_w None
+    - BF24 step_h None
+    - BF24 step_w None
+    - MFU_CROP_ALIGN align_method None
+    - MFU_CROP_RESIZE resize_method None
+**/
+class inst_mfu_crop : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_bbox_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    uint64_t reserve_ = uint64_t(0); /** None **/
+    uint64_t shape_src_c_ = uint64_t(0); /** None **/
+    uint64_t shape_src_h_ = uint64_t(0); /** None **/
+    uint64_t shape_src_w_ = uint64_t(0); /** None **/
+    STRIDE_GLB stride_src_glb_ = STRIDE_GLB(0); /** None **/
+    STRIDE_GLB stride_dest_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t roi_amount_ = uint64_t(0); /** None **/
+    uint64_t dest_h_ = uint64_t(0); /** None **/
+    uint64_t dest_w_ = uint64_t(0); /** None **/
+    BF24 step_h_ = BF24(0); /** None **/
+    BF24 step_w_ = BF24(0); /** None **/
+    MFU_CROP_ALIGN align_method_ = MFU_CROP_ALIGN(0); /** None **/
+    MFU_CROP_RESIZE resize_method_ = MFU_CROP_RESIZE(0); /** None **/
+public:
+    inst_mfu_crop(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_src = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_bbox = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t reserve = uint64_t(0),
+        uint64_t shape_src_c = uint64_t(0),
+        uint64_t shape_src_h = uint64_t(0),
+        uint64_t shape_src_w = uint64_t(0),
+        STRIDE_GLB stride_src_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_dest_glb = STRIDE_GLB(0),
+        uint64_t roi_amount = uint64_t(0),
+        uint64_t dest_h = uint64_t(0), uint64_t dest_w = uint64_t(0),
+        BF24 step_h = BF24(0), BF24 step_w = BF24(0),
+        MFU_CROP_ALIGN align_method = MFU_CROP_ALIGN(0),
+        MFU_CROP_RESIZE resize_method = MFU_CROP_RESIZE(0));
+
+    explicit inst_mfu_crop(const INST_MFU_CROP &ref);
+
+    [[nodiscard]] struct INST_MFU_CROP to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    void addr_src(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_bbox None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_bbox() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_bbox None
+  */
+    void addr_bbox(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t reserve None
+  */
+    [[nodiscard]] uint64_t reserve() const;
+    /**
+      uint64_t reserve None
+  */
+    void reserve(const uint64_t &value);
+    /**
+      uint64_t shape_src_c None
+  */
+    [[nodiscard]] uint64_t shape_src_c() const;
+    /**
+      uint64_t shape_src_c None
+  */
+    void shape_src_c(const uint64_t &value);
+    /**
+      uint64_t shape_src_h None
+  */
+    [[nodiscard]] uint64_t shape_src_h() const;
+    /**
+      uint64_t shape_src_h None
+  */
+    void shape_src_h(const uint64_t &value);
+    /**
+      uint64_t shape_src_w None
+  */
+    [[nodiscard]] uint64_t shape_src_w() const;
+    /**
+      uint64_t shape_src_w None
+  */
+    void shape_src_w(const uint64_t &value);
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src_glb() const;
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    void stride_src_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_dest_glb() const;
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    void stride_dest_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t roi_amount None
+  */
+    [[nodiscard]] uint64_t roi_amount() const;
+    /**
+      uint64_t roi_amount None
+  */
+    void roi_amount(const uint64_t &value);
+    /**
+      uint64_t dest_h None
+  */
+    [[nodiscard]] uint64_t dest_h() const;
+    /**
+      uint64_t dest_h None
+  */
+    void dest_h(const uint64_t &value);
+    /**
+      uint64_t dest_w None
+  */
+    [[nodiscard]] uint64_t dest_w() const;
+    /**
+      uint64_t dest_w None
+  */
+    void dest_w(const uint64_t &value);
+    /**
+      BF24 step_h None
+  */
+    [[nodiscard]] BF24 step_h() const;
+    /**
+      BF24 step_h None
+  */
+    void step_h(const BF24 &value);
+    /**
+      BF24 step_w None
+  */
+    [[nodiscard]] BF24 step_w() const;
+    /**
+      BF24 step_w None
+  */
+    void step_w(const BF24 &value);
+    /**
+      MFU_CROP_ALIGN align_method None
+  */
+    [[nodiscard]] MFU_CROP_ALIGN align_method() const;
+    /**
+      MFU_CROP_ALIGN align_method None
+  */
+    void align_method(const MFU_CROP_ALIGN &value);
+    /**
+      MFU_CROP_RESIZE resize_method None
+  */
+    [[nodiscard]] MFU_CROP_RESIZE resize_method() const;
+    /**
+      MFU_CROP_RESIZE resize_method None
+  */
+    void resize_method(const MFU_CROP_RESIZE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_crop &c);
+
+/**
+    MFU.MEMSET
+    @brief None
+    - OPCODE opcode None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_dest None
+    - uint64_t imm None
+    - uint64_t len None
+**/
+class inst_mfu_memset : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    uint64_t imm_ = uint64_t(0); /** None **/
+    uint64_t len_ = uint64_t(0); /** None **/
+public:
+    inst_mfu_memset(CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        uint64_t imm = uint64_t(0), uint64_t len = uint64_t(0));
+
+    explicit inst_mfu_memset(const INST_MFU_MEMSET &ref);
+
+    [[nodiscard]] struct INST_MFU_MEMSET to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      uint64_t imm None
+  */
+    [[nodiscard]] uint64_t imm() const;
+    /**
+      uint64_t imm None
+  */
+    void imm(const uint64_t &value);
+    /**
+      uint64_t len None
+  */
+    [[nodiscard]] uint64_t len() const;
+    /**
+      uint64_t len None
+  */
+    void len(const uint64_t &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_memset &c);
+
+/**
+    MFU.MEMCPY
+    @brief None
+    - OPCODE opcode None
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_src None
+    - ADDR_GLB_8_WITH_BANK addr_dest None
+    - STRIDE_GLB stride_src_glb None
+    - STRIDE_GLB stride_dest_glb None
+    - uint64_t shape_n None
+    - uint64_t shape_c None
+    - uint64_t shape_h None
+    - uint64_t shape_w None
+    - PRECISION precision_glb None
+**/
+class inst_mfu_memcpy : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    STRIDE_GLB stride_src_glb_ = STRIDE_GLB(0); /** None **/
+    STRIDE_GLB stride_dest_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_n_ = uint64_t(0); /** None **/
+    uint64_t shape_c_ = uint64_t(0); /** None **/
+    uint64_t shape_h_ = uint64_t(0); /** None **/
+    uint64_t shape_w_ = uint64_t(0); /** None **/
+    PRECISION precision_glb_ = PRECISION(0); /** None **/
+public:
+    inst_mfu_memcpy(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_src = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        STRIDE_GLB stride_src_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_dest_glb = STRIDE_GLB(0),
+        uint64_t shape_n = uint64_t(0),
+        uint64_t shape_c = uint64_t(0),
+        uint64_t shape_h = uint64_t(0),
+        uint64_t shape_w = uint64_t(0),
+        PRECISION precision_glb = PRECISION(0));
+
+    explicit inst_mfu_memcpy(const INST_MFU_MEMCPY &ref);
+
+    [[nodiscard]] struct INST_MFU_MEMCPY to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    void addr_src(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src_glb() const;
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    void stride_src_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_dest_glb() const;
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    void stride_dest_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_n None
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n None
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c None
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c None
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h None
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h None
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w None
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w None
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      PRECISION precision_glb None
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb None
+  */
+    void precision_glb(const PRECISION &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_memcpy &c);
+
+/**
+    MFU.TRANS
+    @brief None
+    - OPCODE opcode None
+    - CCRCLR ccrclr None
+    - CCRSET ccrset None
+    - ADDR_GLB_8_WITH_BANK addr_src None
+    - ADDR_GLB_8_WITH_BANK addr_dest None
+    - STRIDE_GLB stride_src_glb None
+    - STRIDE_GLB stride_dest_glb None
+    - uint64_t shape_n None
+    - uint64_t shape_c None
+    - uint64_t shape_h None
+    - uint64_t shape_w None
+    - PRECISION precision_glb None
+    - MFU_TRANS_PERMUTE permute None
+**/
+class inst_mfu_trans : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** None **/
+    CCRCLR ccrclr_ = CCRCLR(0); /** None **/
+    CCRSET ccrset_ = CCRSET(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_src_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    ADDR_GLB_8_WITH_BANK addr_dest_ = ADDR_GLB_8_WITH_BANK(0); /** None **/
+    STRIDE_GLB stride_src_glb_ = STRIDE_GLB(0); /** None **/
+    STRIDE_GLB stride_dest_glb_ = STRIDE_GLB(0); /** None **/
+    uint64_t shape_n_ = uint64_t(0); /** None **/
+    uint64_t shape_c_ = uint64_t(0); /** None **/
+    uint64_t shape_h_ = uint64_t(0); /** None **/
+    uint64_t shape_w_ = uint64_t(0); /** None **/
+    PRECISION precision_glb_ = PRECISION(0); /** None **/
+    MFU_TRANS_PERMUTE permute_ = MFU_TRANS_PERMUTE(0); /** None **/
+public:
+    inst_mfu_trans(CCRCLR ccrclr = CCRCLR(0), CCRSET ccrset = CCRSET(0),
+        ADDR_GLB_8_WITH_BANK addr_src = ADDR_GLB_8_WITH_BANK(0),
+        ADDR_GLB_8_WITH_BANK addr_dest = ADDR_GLB_8_WITH_BANK(0),
+        STRIDE_GLB stride_src_glb = STRIDE_GLB(0),
+        STRIDE_GLB stride_dest_glb = STRIDE_GLB(0),
+        uint64_t shape_n = uint64_t(0), uint64_t shape_c = uint64_t(0),
+        uint64_t shape_h = uint64_t(0), uint64_t shape_w = uint64_t(0),
+        PRECISION precision_glb = PRECISION(0),
+        MFU_TRANS_PERMUTE permute = MFU_TRANS_PERMUTE(0));
+
+    explicit inst_mfu_trans(const INST_MFU_TRANS &ref);
+
+    [[nodiscard]] struct INST_MFU_TRANS to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode None
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode None
+  */
+    void opcode(const OPCODE &value);
+    /**
+      CCRCLR ccrclr None
+  */
+    [[nodiscard]] CCRCLR ccrclr() const;
+    /**
+      CCRCLR ccrclr None
+  */
+    void ccrclr(const CCRCLR &value);
+    /**
+      CCRSET ccrset None
+  */
+    [[nodiscard]] CCRSET ccrset() const;
+    /**
+      CCRSET ccrset None
+  */
+    void ccrset(const CCRSET &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_src() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_src None
+  */
+    void addr_src(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    [[nodiscard]] ADDR_GLB_8_WITH_BANK addr_dest() const;
+    /**
+      ADDR_GLB_8_WITH_BANK addr_dest None
+  */
+    void addr_dest(const ADDR_GLB_8_WITH_BANK &value);
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_src_glb() const;
+    /**
+      STRIDE_GLB stride_src_glb None
+  */
+    void stride_src_glb(const STRIDE_GLB &value);
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    [[nodiscard]] STRIDE_GLB stride_dest_glb() const;
+    /**
+      STRIDE_GLB stride_dest_glb None
+  */
+    void stride_dest_glb(const STRIDE_GLB &value);
+    /**
+      uint64_t shape_n None
+  */
+    [[nodiscard]] uint64_t shape_n() const;
+    /**
+      uint64_t shape_n None
+  */
+    void shape_n(const uint64_t &value);
+    /**
+      uint64_t shape_c None
+  */
+    [[nodiscard]] uint64_t shape_c() const;
+    /**
+      uint64_t shape_c None
+  */
+    void shape_c(const uint64_t &value);
+    /**
+      uint64_t shape_h None
+  */
+    [[nodiscard]] uint64_t shape_h() const;
+    /**
+      uint64_t shape_h None
+  */
+    void shape_h(const uint64_t &value);
+    /**
+      uint64_t shape_w None
+  */
+    [[nodiscard]] uint64_t shape_w() const;
+    /**
+      uint64_t shape_w None
+  */
+    void shape_w(const uint64_t &value);
+    /**
+      PRECISION precision_glb None
+  */
+    [[nodiscard]] PRECISION precision_glb() const;
+    /**
+      PRECISION precision_glb None
+  */
+    void precision_glb(const PRECISION &value);
+    /**
+      MFU_TRANS_PERMUTE permute None
+  */
+    [[nodiscard]] MFU_TRANS_PERMUTE permute() const;
+    /**
+      MFU_TRANS_PERMUTE permute None
+  */
+    void permute(const MFU_TRANS_PERMUTE &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_trans &c);
+
+class inst_mfu_mn_conf2 : public gnne_instruction
+{
+    OPCODE opcode_ = OPCODE(0); /** 这条指令用来反向配置meshnet连接关系 **/
+    MFU_MN_PORTIN in1_ = MFU_MN_PORTIN(0); /** VECTOR_IN_0连接的端口 **/
+    MFU_MN_PORTIN in2_ = MFU_MN_PORTIN(0); /** ADDSUB0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in3_ = MFU_MN_PORTIN(0); /** ADDSUB0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in4_ = MFU_MN_PORTIN(0); /** ADDSUB1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in5_ = MFU_MN_PORTIN(0); /** ADDSUB1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in6_ = MFU_MN_PORTIN(0); /** ADDSUB2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in7_ = MFU_MN_PORTIN(0); /** ADDSUB2_IN_1连接的端口 **/
+    MFU_MN_PORTIN in8_ = MFU_MN_PORTIN(0); /** ADDSUB3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in9_ = MFU_MN_PORTIN(0); /** ADDSUB3_IN_1连接的端口 **/
+    MFU_MN_PORTIN in10_ = MFU_MN_PORTIN(0); /** MUL0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in11_ = MFU_MN_PORTIN(0); /** MUL0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in12_ = MFU_MN_PORTIN(0); /** MUL1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in13_ = MFU_MN_PORTIN(0); /** MUL1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in14_ = MFU_MN_PORTIN(0); /** MUL2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in15_ = MFU_MN_PORTIN(0); /** MUL2_IN_1连接的端口 **/
+    MFU_MN_PORTIN in16_ = MFU_MN_PORTIN(0); /** MUL3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in17_ = MFU_MN_PORTIN(0); /** MUL3_IN_1连接的端口 **/
+    MFU_MN_PORTIN in18_ = MFU_MN_PORTIN(0); /** DIV_IN_0连接的端口 **/
+    MFU_MN_PORTIN in19_ = MFU_MN_PORTIN(0); /** DIV_IN_1连接的端口 **/
+    MFU_MN_PORTIN in20_ = MFU_MN_PORTIN(0); /** ROUND_IN_0连接的端口 **/
+    MFU_MN_PORTIN in21_ = MFU_MN_PORTIN(0); /** SQRT_IN_0连接的端口 **/
+    MFU_MN_PORTIN in22_ = MFU_MN_PORTIN(0); /** TRANGLE_IN_0连接的端口 **/
+    MFU_MN_PORTIN in23_ = MFU_MN_PORTIN(0); /** LOG_IN_0连接的端口 **/
+    MFU_MN_PORTIN in24_ = MFU_MN_PORTIN(0); /** UNARY_LOGIC_IN_0连接的端口 **/
+    MFU_MN_PORTIN in25_ = MFU_MN_PORTIN(0); /** EXP_IN_0连接的端口 **/
+    MFU_MN_PORTIN in26_ = MFU_MN_PORTIN(0); /** CMP0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in27_ = MFU_MN_PORTIN(0); /** CMP0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in28_ = MFU_MN_PORTIN(0); /** CMP1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in29_ = MFU_MN_PORTIN(0); /** CMP1_IN_1连接的端口 **/
+    MFU_MN_PORTIN in30_ = MFU_MN_PORTIN(0); /** REG0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in31_ = MFU_MN_PORTIN(0); /** SELECT0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in32_ = MFU_MN_PORTIN(0); /** SELECT0_IN_1连接的端口 **/
+    MFU_MN_PORTIN in33_ = MFU_MN_PORTIN(0); /** SELECT0_IN_2连接的端口 **/
+    MFU_MN_PORTIN in34_ = MFU_MN_PORTIN(0); /** NOP0_IN_0连接的端口 **/
+    MFU_MN_PORTIN in35_ = MFU_MN_PORTIN(0); /** NOP1_IN_0连接的端口 **/
+    MFU_MN_PORTIN in36_ = MFU_MN_PORTIN(0); /** NOP2_IN_0连接的端口 **/
+    MFU_MN_PORTIN in37_ = MFU_MN_PORTIN(0); /** NOP3_IN_0连接的端口 **/
+    MFU_MN_PORTIN in38_ = MFU_MN_PORTIN(0); /** NOP4_IN_0连接的端口 **/
+    MFU_MN_PORTIN in39_ = MFU_MN_PORTIN(0); /** NOP5_IN_0连接的端口 **/
+    MFU_MN_PORTIN in40_ = MFU_MN_PORTIN(0); /** NOP6_IN_0连接的端口 **/
+    MFU_MN_PORTIN in41_ = MFU_MN_PORTIN(0); /** NOP7_IN_0连接的端口 **/
+    MFU_MN_PORTIN in42_ = MFU_MN_PORTIN(0); /** CLEAR0_IN_0连接的端口 **/
+
+public:
+    inst_mfu_mn_conf2(MFU_MN_PORTIN in1 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in2 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in3 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in4 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in5 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in6 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in7 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in8 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in9 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in10 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in11 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in12 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in13 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in14 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in15 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in16 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in17 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in18 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in19 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in20 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in21 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in22 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in23 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in24 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in25 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in26 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in27 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in28 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in29 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in30 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in31 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in32 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in33 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in34 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in35 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in36 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in37 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in38 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in39 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in40 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in41 = MFU_MN_PORTIN(0),
+        MFU_MN_PORTIN in42 = MFU_MN_PORTIN(0));
+
+    explicit inst_mfu_mn_conf2(const INST_MFU_MN_CONF2 &ref);
+
+    [[nodiscard]] struct INST_MFU_MN_CONF2 to_struct() const;
+
+    void serialize(binary_writer &writer) const override;
+
+    // getter and setters
+    /**
+      OPCODE opcode 这条指令用来反向配置meshnet连接关系
+  */
+    [[nodiscard]] OPCODE opcode() const override;
+    /**
+      OPCODE opcode 这条指令用来反向配置meshnet连接关系
+  */
+    void opcode(const OPCODE &value);
+    /**
+      MFU_MN_PORTIN in1 VECTOR_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in1() const;
+    /**
+      MFU_MN_PORTIN in1 VECTOR_IN_0连接的端口
+  */
+    void in1(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in2 ADDSUB0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in2() const;
+    /**
+      MFU_MN_PORTIN in2 ADDSUB0_IN_0连接的端口
+  */
+    void in2(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in3 ADDSUB0_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in3() const;
+    /**
+      MFU_MN_PORTIN in3 ADDSUB0_IN_1连接的端口
+  */
+    void in3(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in4 ADDSUB1_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in4() const;
+    /**
+      MFU_MN_PORTIN in4 ADDSUB1_IN_0连接的端口
+  */
+    void in4(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in5 ADDSUB1_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in5() const;
+    /**
+      MFU_MN_PORTIN in5 ADDSUB1_IN_1连接的端口
+  */
+    void in5(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in6 ADDSUB2_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in6() const;
+    /**
+      MFU_MN_PORTIN in6 ADDSUB2_IN_0连接的端口
+  */
+    void in6(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in7 ADDSUB2_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in7() const;
+    /**
+      MFU_MN_PORTIN in7 ADDSUB2_IN_1连接的端口
+  */
+    void in7(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in8 ADDSUB3_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in8() const;
+    /**
+      MFU_MN_PORTIN in8 ADDSUB3_IN_0连接的端口
+  */
+    void in8(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in9 ADDSUB3_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in9() const;
+    /**
+      MFU_MN_PORTIN in9 ADDSUB3_IN_1连接的端口
+  */
+    void in9(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in10 MUL0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in10() const;
+    /**
+      MFU_MN_PORTIN in10 MUL0_IN_0连接的端口
+  */
+    void in10(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in11 MUL0_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in11() const;
+    /**
+      MFU_MN_PORTIN in11 MUL0_IN_1连接的端口
+  */
+    void in11(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in12 MUL1_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in12() const;
+    /**
+      MFU_MN_PORTIN in12 MUL1_IN_0连接的端口
+  */
+    void in12(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in13 MUL1_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in13() const;
+    /**
+      MFU_MN_PORTIN in13 MUL1_IN_1连接的端口
+  */
+    void in13(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in14 MUL2_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in14() const;
+    /**
+      MFU_MN_PORTIN in14 MUL2_IN_0连接的端口
+  */
+    void in14(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in15 MUL2_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in15() const;
+    /**
+      MFU_MN_PORTIN in15 MUL2_IN_1连接的端口
+  */
+    void in15(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in16 MUL3_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in16() const;
+    /**
+      MFU_MN_PORTIN in16 MUL3_IN_0连接的端口
+  */
+    void in16(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in17 MUL3_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in17() const;
+    /**
+      MFU_MN_PORTIN in17 MUL3_IN_1连接的端口
+  */
+    void in17(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in18 DIV_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in18() const;
+    /**
+      MFU_MN_PORTIN in18 DIV_IN_0连接的端口
+  */
+    void in18(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in19 DIV_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in19() const;
+    /**
+      MFU_MN_PORTIN in19 DIV_IN_1连接的端口
+  */
+    void in19(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in20 ROUND_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in20() const;
+    /**
+      MFU_MN_PORTIN in20 ROUND_IN_0连接的端口
+  */
+    void in20(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in21 SQRT_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in21() const;
+    /**
+      MFU_MN_PORTIN in21 SQRT_IN_0连接的端口
+  */
+    void in21(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in22 TRANGLE_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in22() const;
+    /**
+      MFU_MN_PORTIN in22 TRANGLE_IN_0连接的端口
+  */
+    void in22(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in23 LOG_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in23() const;
+    /**
+      MFU_MN_PORTIN in23 LOG_IN_0连接的端口
+  */
+    void in23(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in24 UNARY_LOGIC_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in24() const;
+    /**
+      MFU_MN_PORTIN in24 UNARY_LOGIC_IN_0连接的端口
+  */
+    void in24(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in25 EXP_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in25() const;
+    /**
+      MFU_MN_PORTIN in25 EXP_IN_0连接的端口
+  */
+    void in25(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in26 CMP0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in26() const;
+    /**
+      MFU_MN_PORTIN in26 CMP0_IN_0连接的端口
+  */
+    void in26(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in27 CMP0_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in27() const;
+    /**
+      MFU_MN_PORTIN in27 CMP0_IN_1连接的端口
+  */
+    void in27(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in28 CMP1_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in28() const;
+    /**
+      MFU_MN_PORTIN in28 CMP1_IN_0连接的端口
+  */
+    void in28(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in29 CMP1_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in29() const;
+    /**
+      MFU_MN_PORTIN in29 CMP1_IN_1连接的端口
+  */
+    void in29(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in30 REG0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in30() const;
+    /**
+      MFU_MN_PORTIN in30 REG0_IN_0连接的端口
+  */
+    void in30(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in31 SELECT0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in31() const;
+    /**
+      MFU_MN_PORTIN in31 SELECT0_IN_0连接的端口
+  */
+    void in31(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in32 SELECT0_IN_1连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in32() const;
+    /**
+      MFU_MN_PORTIN in32 SELECT0_IN_1连接的端口
+  */
+    void in32(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in33 SELECT0_IN_2连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in33() const;
+    /**
+      MFU_MN_PORTIN in33 SELECT0_IN_2连接的端口
+  */
+    void in33(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in34 NOP0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in34() const;
+    /**
+      MFU_MN_PORTIN in34 NOP0_IN_0连接的端口
+  */
+    void in34(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in35 NOP1_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in35() const;
+    /**
+      MFU_MN_PORTIN in35 NOP1_IN_0连接的端口
+  */
+    void in35(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in36 NOP2_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in36() const;
+    /**
+      MFU_MN_PORTIN in36 NOP2_IN_0连接的端口
+  */
+    void in36(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in37 NOP3_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in37() const;
+    /**
+      MFU_MN_PORTIN in37 NOP3_IN_0连接的端口
+  */
+    void in37(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in38 NOP4_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in38() const;
+    /**
+      MFU_MN_PORTIN in38 NOP4_IN_0连接的端口
+  */
+    void in38(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in39 NOP5_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in39() const;
+    /**
+      MFU_MN_PORTIN in39 NOP5_IN_0连接的端口
+  */
+    void in39(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in40 NOP6_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in40() const;
+    /**
+      MFU_MN_PORTIN in40 NOP6_IN_0连接的端口
+  */
+    void in40(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in41 NOP7_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in41() const;
+    /**
+      MFU_MN_PORTIN in41 NOP7_IN_0连接的端口
+  */
+    void in41(const MFU_MN_PORTIN &value);
+    /**
+      MFU_MN_PORTIN in42 CLEAR0_IN_0连接的端口
+  */
+    [[nodiscard]] MFU_MN_PORTIN in42() const;
+    /**
+      MFU_MN_PORTIN in42 CLEAR0_IN_0连接的端口
+  */
+    void in42(const MFU_MN_PORTIN &value);
+
+    void to_string(std::ostream &out) const override;
+};
+
+std::ostream &operator<<(std::ostream &out, const inst_mfu_mn_conf2 &c);
+
+////////////////////////////////////
+
+class gnne_visitor
+{
+public:
+    virtual void visit(uint8_t *pc) = 0;
+    virtual std::unique_ptr<inst_nop> visit(std::unique_ptr<inst_nop> inst) = 0;
+    virtual std::unique_ptr<inst_li> visit(std::unique_ptr<inst_li> inst) = 0;
+    virtual std::unique_ptr<inst_intr> visit(std::unique_ptr<inst_intr> inst) = 0;
+    virtual std::unique_ptr<inst_end> visit(std::unique_ptr<inst_end> inst) = 0;
+    virtual std::unique_ptr<inst_fence>
+    visit(std::unique_ptr<inst_fence> inst) = 0;
+    virtual std::unique_ptr<inst_mmu_conf>
+    visit(std::unique_ptr<inst_mmu_conf> inst) = 0;
+    virtual std::unique_ptr<inst_fence_ccr>
+    visit(std::unique_ptr<inst_fence_ccr> inst) = 0;
+    virtual std::unique_ptr<inst_loadif_config>
+    visit(std::unique_ptr<inst_loadif_config> inst) = 0;
+    virtual std::unique_ptr<inst_loadif>
+    visit(std::unique_ptr<inst_loadif> inst) = 0;
+    virtual std::unique_ptr<inst_load> visit(std::unique_ptr<inst_load> inst) = 0;
+    virtual std::unique_ptr<inst_loadif_compress_conf>
+    visit(std::unique_ptr<inst_loadif_compress_conf> inst) = 0;
+    virtual std::unique_ptr<inst_load_compress_conf>
+    visit(std::unique_ptr<inst_load_compress_conf> inst) = 0;
+    virtual std::unique_ptr<inst_store>
+    visit(std::unique_ptr<inst_store> inst) = 0;
+    virtual std::unique_ptr<inst_store_t_config>
+    visit(std::unique_ptr<inst_store_t_config> inst) = 0;
+    virtual std::unique_ptr<inst_store_t>
+    visit(std::unique_ptr<inst_store_t> inst) = 0;
+    virtual std::unique_ptr<inst_store_t_compress_conf>
+    visit(std::unique_ptr<inst_store_t_compress_conf> inst) = 0;
+    virtual std::unique_ptr<inst_store_compress_conf>
+    visit(std::unique_ptr<inst_store_compress_conf> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_broadcast>
+    visit(std::unique_ptr<inst_tcu_dm_broadcast> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_conf_if>
+    visit(std::unique_ptr<inst_tcu_dm_conf_if> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_fetchif>
+    visit(std::unique_ptr<inst_tcu_dm_fetchif> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_conf_w>
+    visit(std::unique_ptr<inst_tcu_dm_conf_w> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_fetchw>
+    visit(std::unique_ptr<inst_tcu_dm_fetchw> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dm_conf_of>
+    visit(std::unique_ptr<inst_tcu_dm_conf_of> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_pu_conf>
+    visit(std::unique_ptr<inst_tcu_pu_conf> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_pu_conf_act>
+    visit(std::unique_ptr<inst_tcu_pu_conf_act> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_pu_compute>
+    visit(std::unique_ptr<inst_tcu_pu_compute> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dot_dm_if_conf>
+    visit(std::unique_ptr<inst_tcu_dot_dm_if_conf> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dot_dm_of_conf>
+    visit(std::unique_ptr<inst_tcu_dot_dm_of_conf> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dot_dm_fetch_src1>
+    visit(std::unique_ptr<inst_tcu_dot_dm_fetch_src1> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_dot_dm_fetch_src2>
+    visit(std::unique_ptr<inst_tcu_dot_dm_fetch_src2> inst) = 0;
+    virtual std::unique_ptr<inst_tcu_pu_compute_dummy>
+    visit(std::unique_ptr<inst_tcu_pu_compute_dummy> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_map_compute>
+    visit(std::unique_ptr<inst_mfu_mn_map_compute> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_vmap_compute>
+    visit(std::unique_ptr<inst_mfu_mn_vmap_compute> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_reduce>
+    visit(std::unique_ptr<inst_mfu_reduce> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_vreduce>
+    visit(std::unique_ptr<inst_mfu_vreduce> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_broadcast_compute>
+    visit(std::unique_ptr<inst_mfu_mn_broadcast_compute> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_reduce>
+    visit(std::unique_ptr<inst_mfu_mn_reduce> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_conf>
+    visit(std::unique_ptr<inst_mfu_mn_conf> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mnop_conf>
+    visit(std::unique_ptr<inst_mfu_mnop_conf> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_pdp_conf>
+    visit(std::unique_ptr<inst_mfu_pdp_conf> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_pdp_src_conf>
+    visit(std::unique_ptr<inst_mfu_pdp_src_conf> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_pdp_reduce>
+    visit(std::unique_ptr<inst_mfu_pdp_reduce> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_broadcast_conf>
+    visit(std::unique_ptr<inst_mfu_mn_broadcast_conf> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_crop>
+    visit(std::unique_ptr<inst_mfu_crop> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_memset>
+    visit(std::unique_ptr<inst_mfu_memset> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_memcpy>
+    visit(std::unique_ptr<inst_mfu_memcpy> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_trans>
+    visit(std::unique_ptr<inst_mfu_trans> inst) = 0;
+    virtual std::unique_ptr<inst_mfu_mn_conf2>
+    visit(std::unique_ptr<inst_mfu_mn_conf2> inst) = 0;
+};
+
+std::unique_ptr<gnne_instruction> decode(uint8_t *pc, uint8_t **next_pc,
+    gnne_visitor *visitor);
+
+template <class T, typename... Args>
+inline std::shared_ptr<gnne_instruction> make_instructions(Args &&... args)
+{
+    return static_cast<std::shared_ptr<gnne_instruction>>(
+        std::make_shared<T>(std::forward<Args>(args)...));
+}
+
+} // namespace nncase::runtime::k230::isa
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_tile_utils.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_tile_utils.h
new file mode 100644
index 0000000..780f86a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/gnne_tile_utils.h
@@ -0,0 +1,869 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+#include "nncase/runtime/runtime_tensor.h"
+#include <nncase/runtime/datatypes.h>
+
+namespace nncase
+{
+namespace runtime
+{
+    namespace k230
+    {
+        struct segment
+        {
+            int32_t start;
+            int32_t end;
+            int32_t length;
+            padding pad;
+
+            segment()
+            {
+                start = end = length = 0;
+                pad = { 0, 0 };
+            }
+
+            segment(int32_t start_, int32_t end_, int32_t length_)
+                : start(start_), end(end_), length(length_)
+            {
+                pad = { 0, 0 };
+            }
+
+            segment(int32_t start_, int32_t end_, int32_t length_, padding pad_)
+                : start(start_), end(end_), length(length_), pad(pad_) { }
+
+            bool operator==(const segment &other) const
+            {
+                return start == other.start && end == other.end && length == other.length;
+            }
+
+            bool operator!=(const segment &other) const
+            {
+                return !(*this == other);
+            }
+
+            segment operator+(const segment &other) const
+            {
+                auto min_start = std::min(start, other.start);
+                auto max_end = std::max(end, other.end);
+                return { min_start, max_end, max_end - min_start };
+            }
+
+            segment operator/(const int32_t &scale) const
+            {
+                return segment { start / scale, end / scale, length / scale, pad };
+            }
+
+            segment operator*(const int32_t &scale) const
+            {
+                return segment { start * scale, end * scale, length * scale, pad };
+            }
+
+            size_t hasher() const
+            {
+                return std::hash<int32_t>()(start) ^ std::hash<int32_t>()(end) ^ std::hash<int32_t>()(length);
+            }
+        };
+
+        struct tensor4d_segment
+        {
+            segment dim_0;
+            segment dim_1;
+            segment dim_2;
+            segment dim_3;
+            padding p_h;
+            padding p_w;
+
+            tensor4d_segment()
+            {
+                dim_0 = dim_1 = dim_2 = dim_3 = { 0, 0, 0 };
+                p_h = p_w = { 0, 0 };
+            }
+
+            tensor4d_segment(segment dim_0_, segment dim_1_, segment dim_2_, segment dim_3_)
+                : dim_0(dim_0_), dim_1(dim_1_), dim_2(dim_2_), dim_3(dim_3_)
+            {
+                p_h = p_w = { 0, 0 };
+            }
+
+            tensor4d_segment(segment dim_0_, segment dim_1_, segment dim_2_, segment dim_3_, padding p_h_, padding p_w_)
+                : dim_0(dim_0_), dim_1(dim_1_), dim_2(dim_2_), dim_3(dim_3_), p_h(p_h_), p_w(p_w_) { }
+
+            int32_t get_shape_size()
+            {
+                return dim_0.length * dim_1.length * dim_2.length * dim_3.length;
+            }
+
+            bool operator==(const tensor4d_segment &other) const
+            {
+                return dim_0 == other.dim_0
+                    && dim_1 == other.dim_1
+                    && dim_2 == other.dim_2
+                    && dim_3 == other.dim_3;
+            }
+
+            tensor4d_segment operator+(const tensor4d_segment &other) const
+            {
+                return { dim_0 + other.dim_0, dim_1 + other.dim_1, dim_2 + other.dim_2, dim_3 + other.dim_3 };
+            }
+
+            size_t hasher() const
+            {
+                return dim_0.hasher() ^ dim_1.hasher() ^ dim_2.hasher() ^ dim_3.hasher();
+            }
+
+            dims_t to_gnne_shape()
+            {
+                return dims_t { static_cast<unsigned long>(dim_0.length), static_cast<unsigned long>(dim_1.length), static_cast<unsigned long>(dim_2.length), static_cast<unsigned long>(dim_3.length) };
+            }
+        };
+
+        class segment_hash
+        {
+        public:
+            size_t operator()(const segment &key) const
+            {
+                return key.hasher();
+            }
+        };
+
+        class tensor4d_segment_hash
+        {
+        public:
+            size_t operator()(const tensor4d_segment &key) const
+            {
+                return key.hasher();
+            }
+        };
+
+        struct ai2d_sram_t
+        {
+            int32_t sram_len = 256;
+            int32_t sram_size = sram_len * sram_len;
+        };
+
+        enum class ai2d_format
+        {
+            YUV420_NV12 = 0,
+            YUV420_NV21 = 1,
+            YUV420_I420 = 2,
+            NCHW_FMT = 3,
+            RGB_packed = 4,
+            RAW16 = 5,
+        };
+
+        enum class ai2d_pad_mode
+        {
+            constant = 0,
+            copy = 1,
+            mirror = 2,
+        };
+
+        enum class ai2d_data_loc
+        {
+            glb = 0,
+            ddr = 1,
+        };
+
+        enum class ai2d_interp_method
+        {
+            tf_nearest = 0,
+            tf_bilinear = 1,
+            cv2_nearest = 2,
+            cv2_bilinear = 3,
+        };
+
+        enum class ai2d_interp_mode
+        {
+            none = 0,
+            align_corner = 1,
+            half_pixel = 2,
+        };
+
+        union FP32
+        {
+            unsigned int u;
+            float f;
+        };
+
+        struct ai2d_shift_param_t
+        {
+            bool shift_flag = false;
+            int32_t shift_val = 0;
+        };
+
+        struct ai2d_resize_param_t
+        {
+            bool resize_flag = false;
+            ai2d_interp_method interp_method = ai2d_interp_method::tf_bilinear;
+            ai2d_interp_mode interp_mode = ai2d_interp_mode::none;
+        };
+
+        struct ai2d_crop_param_t
+        {
+            bool crop_flag = false;
+            int32_t start_x = 0;
+            int32_t start_y = 0;
+            int32_t width = 0;
+            int32_t height = 0;
+        };
+
+        struct ai2d_pad_param_t
+        {
+            bool pad_flag = false;
+            paddings_t paddings;
+            ai2d_pad_mode pad_mode = ai2d_pad_mode::constant;
+            std::vector<int32_t> pad_val; // by channel
+        };
+
+        struct ai2d_affine_param_t
+        {
+            bool affine_flag = false;
+            ai2d_interp_method interp_method = ai2d_interp_method::cv2_bilinear;
+            uint32_t cord_round = 0;
+            uint32_t bound_ind = 0;
+            int32_t bound_val = 0;
+            uint32_t bound_smooth = 0;
+            std::vector<float> M;
+        };
+
+        struct ai2d_datatype_t
+        {
+            ai2d_format src_format;
+            ai2d_format dst_format;
+            typecode_t src_type;
+            typecode_t dst_type;
+            ai2d_data_loc src_loc = ai2d_data_loc::ddr;
+            ai2d_data_loc dst_loc = ai2d_data_loc::ddr;
+        };
+
+        struct ai2d_config
+        {
+            // 0x00
+            uint32_t src_ch0_ptr : 32;
+            uint32_t src_ch1_ptr : 32;
+            uint32_t src_ch2_ptr : 32;
+            uint32_t src_ch3_ptr : 32;
+            // 0x10
+            uint32_t dst_ch0_ptr : 32;
+            uint32_t dst_ch1_ptr : 32;
+            uint32_t dst_ch2_ptr : 32;
+            uint32_t dst_ch3_ptr : 32;
+            // 0x20
+            uint32_t src_ch0_width_layout : 16;
+            uint32_t src_ch1_width_layout : 16;
+            uint32_t src_ch2_width_layout : 16;
+            uint32_t src_ch3_width_layout : 16;
+            uint32_t dst_ch0_width_layout : 16;
+            uint32_t dst_ch1_width_layout : 16;
+            uint32_t dst_ch2_width_layout : 16;
+            uint32_t dst_ch3_width_layout : 16;
+            // 0x30
+            uint32_t M0 : 32;
+            uint32_t M1 : 32;
+            uint32_t M3 : 32;
+            uint32_t M4 : 32;
+            // 0x40
+            uint32_t reserved0 : 32;
+            uint32_t reserved1 : 32;
+            uint32_t channel : 3;
+            uint32_t dst_channel : 3;
+            uint32_t cord_round : 2;
+            uint32_t interpolation : 2;
+            uint32_t pad_mod : 2;
+            uint32_t shift : 8;
+            uint32_t bound_ind : 4;
+            uint32_t src_format : 4;
+            uint32_t dst_format : 4;
+            uint32_t bound_val : 16;
+            uint32_t bound_smooth : 1;
+            uint32_t reserved2 : 15;
+            // 0x50
+            uint32_t yuv2rgb_coef0 : 12;
+            uint32_t yuv2rgb_coef1 : 12;
+            uint32_t reserved3 : 8;
+            uint32_t yuv2rgb_coef2 : 12;
+            uint32_t yuv2rgb_coef3 : 12;
+            uint32_t reserved4 : 8;
+            uint32_t yuv2rgb_coef4 : 12;
+            uint32_t yuv2rgb_coef5 : 12;
+            uint32_t reserved5 : 8;
+            uint32_t yuv2rgb_coef6 : 12;
+            uint32_t yuv2rgb_coef7 : 12;
+            uint32_t reserved6 : 8;
+            // 0x60
+            uint32_t yuv2rgb_coef10 : 12;
+            uint32_t yuv2rgb_coef11 : 12;
+            uint32_t const_pad_ch0 : 8;
+            uint32_t const_pad_ch1 : 8;
+            uint32_t const_pad_ch2 : 8;
+            uint32_t const_pad_ch3 : 8;
+            uint32_t src_ind : 1;
+            uint32_t dst_ind : 1;
+            uint32_t cmd_id : 1;
+            uint32_t sign : 1;
+            uint32_t reserved7 : 4;
+            uint32_t yuv2rgb_coef8 : 12;
+            uint32_t yuv2rgb_coef9 : 12;
+            uint32_t reserved8 : 8;
+            uint32_t reserved9 : 32;
+            // 0x70
+            uint32_t pad_t : 16;
+            uint32_t pad_b : 16;
+            uint32_t pad_l : 16;
+            uint32_t pad_r : 16;
+            uint32_t src_width_shape : 16;
+            uint32_t src_height_shape : 16;
+            uint32_t dst_width_shape : 16;
+            uint32_t dst_height_shape : 14;
+            uint32_t intr_mask : 1;
+            uint32_t csc_en : 1;
+            // 0x80
+            uint32_t M2 : 32;
+            uint32_t M5 : 32;
+            uint32_t src_x : 16;
+            uint32_t src_y : 16;
+            uint32_t dst_x : 16;
+            uint32_t dst_y : 13;
+            uint32_t reserved10 : 2;
+            uint32_t ai2d_calc_enable : 1;
+
+            ai2d_config()
+            {
+                src_ch0_ptr = 0;
+                src_ch1_ptr = 0;
+                src_ch2_ptr = 0;
+                src_ch3_ptr = 0;
+                dst_ch0_ptr = 0;
+                dst_ch1_ptr = 0;
+                dst_ch2_ptr = 0;
+                dst_ch3_ptr = 0;
+
+                src_ch0_width_layout = 0;
+                src_ch1_width_layout = 0;
+                src_ch2_width_layout = 0;
+                src_ch3_width_layout = 0;
+                dst_ch0_width_layout = 0;
+                dst_ch1_width_layout = 0;
+                dst_ch2_width_layout = 0;
+                dst_ch3_width_layout = 0;
+
+                FP32 m;
+                m.f = 1024;
+                M0 = m.u;
+                M1 = 0;
+                M3 = 0;
+                M4 = m.u;
+
+                reserved0 = 0;
+                reserved1 = 0;
+                channel = 0;
+                dst_channel = 0;
+                cord_round = 0;
+                interpolation = 0;
+                pad_mod = 0;
+                shift = 0;
+                bound_ind = 0;
+                src_format = 0;
+                dst_format = 0;
+                bound_val = 0;
+                bound_smooth = 0;
+                reserved2 = 0;
+
+                yuv2rgb_coef0 = 256;
+                yuv2rgb_coef1 = 0;
+                reserved3 = 0;
+                yuv2rgb_coef2 = 292;
+                yuv2rgb_coef3 = (1 << 12) - 146;
+                reserved4 = 0;
+                yuv2rgb_coef4 = 256;
+                yuv2rgb_coef5 = (1 << 12) - 101;
+                reserved5 = 0;
+                yuv2rgb_coef6 = (1 << 12) - 149;
+                yuv2rgb_coef7 = 125;
+                reserved6 = 0;
+
+                yuv2rgb_coef10 = 0;
+                yuv2rgb_coef11 = (1 << 12) - 260;
+                const_pad_ch0 = 0;
+                const_pad_ch1 = 0;
+                const_pad_ch2 = 0;
+                const_pad_ch3 = 0;
+                src_ind = 0;
+                dst_ind = 0;
+                cmd_id = 0;
+                sign = 0;
+                reserved7 = 0;
+                yuv2rgb_coef8 = 256;
+                yuv2rgb_coef9 = 520;
+                reserved8 = 0;
+                reserved9 = 0;
+
+                pad_t = 0;
+                pad_b = 0;
+                pad_l = 0;
+                pad_r = 0;
+                src_width_shape = 0;
+                src_height_shape = 0;
+                dst_width_shape = 0;
+                dst_height_shape = 0;
+                intr_mask = 1;
+                csc_en = 0;
+
+                M2 = 0;
+                M5 = 0;
+                src_x = 0;
+                src_y = 0;
+                dst_x = 0;
+                dst_y = 0;
+                reserved10 = 0;
+                ai2d_calc_enable = 1;
+            }
+
+            uint32_t get_addr_value(uint32_t idx)
+            {
+                switch (idx)
+                {
+                case 0:
+                {
+                    return src_ch0_ptr;
+                }
+                case 1:
+                {
+                    return src_ch1_ptr;
+                }
+                case 2:
+                {
+                    return src_ch2_ptr;
+                }
+                case 3:
+                {
+                    return src_ch3_ptr;
+                }
+                case 4:
+                {
+                    return dst_ch0_ptr;
+                }
+                case 5:
+                {
+                    return dst_ch1_ptr;
+                }
+                case 6:
+                {
+                    return dst_ch2_ptr;
+                }
+                case 7:
+                {
+                    return dst_ch3_ptr;
+                }
+                case 8:
+                {
+                    return (src_ch1_width_layout << 16) + src_ch0_width_layout;
+                }
+                case 9:
+                {
+                    return (src_ch3_width_layout << 16) + src_ch2_width_layout;
+                }
+                case 10:
+                {
+                    return (dst_ch1_width_layout << 16) + dst_ch0_width_layout;
+                }
+                case 11:
+                {
+                    return (dst_ch3_width_layout << 16) + dst_ch2_width_layout;
+                }
+
+                case 12:
+                {
+                    return M0;
+                }
+                case 13:
+                {
+                    return M1;
+                }
+                case 14:
+                {
+                    return M3;
+                }
+                case 15:
+                {
+                    return M4;
+                }
+                case 16:
+                {
+                    return reserved0;
+                }
+                case 17:
+                {
+                    return reserved1;
+                }
+                case 18:
+                {
+                    return (dst_format << 28)
+                        | (src_format << 24)
+                        | (bound_ind << 20)
+                        | (shift << 12)
+                        | (pad_mod << 10)
+                        | (interpolation << 8)
+                        | (cord_round << 6)
+                        | (dst_channel << 3)
+                        | (channel);
+                }
+                case 19:
+                {
+                    return (reserved2 << 17)
+                        | (bound_smooth << 16)
+                        | (bound_val);
+                }
+                case 20:
+                {
+                    return (reserved3 << 24)
+                        | (yuv2rgb_coef1 << 12)
+                        | (yuv2rgb_coef0);
+                }
+                case 21:
+                {
+                    return (reserved4 << 24)
+                        | (yuv2rgb_coef3 << 12)
+                        | (yuv2rgb_coef2);
+                }
+                case 22:
+                {
+                    return (reserved5 << 24)
+                        | (yuv2rgb_coef5 << 12)
+                        | (yuv2rgb_coef4);
+                }
+                case 23:
+                {
+                    return (reserved6 << 24)
+                        | (yuv2rgb_coef7 << 12)
+                        | (yuv2rgb_coef6);
+                }
+                case 24:
+                {
+                    return (const_pad_ch0 << 24)
+                        | (yuv2rgb_coef11 << 12)
+                        | (yuv2rgb_coef10);
+                }
+                case 25:
+                {
+                    return (reserved7 << 28)
+                        | (sign << 27)
+                        | (cmd_id << 26)
+                        | (dst_ind << 25)
+                        | (src_ind << 24)
+                        | (const_pad_ch3 << 16)
+                        | (const_pad_ch2 << 8)
+                        | (const_pad_ch1);
+                }
+                case 26:
+                {
+                    return (reserved8 << 24)
+                        | (yuv2rgb_coef9 << 12)
+                        | (yuv2rgb_coef8);
+                }
+                case 27:
+                {
+                    return reserved9;
+                }
+                case 28:
+                {
+                    return (pad_b << 16) | pad_t;
+                }
+                case 29:
+                {
+                    return (pad_r << 16) | pad_l;
+                }
+                case 30:
+                {
+                    return (src_height_shape << 16) | src_width_shape;
+                }
+                case 31:
+                {
+                    return (csc_en << 31)
+                        | (intr_mask << 30)
+                        | (dst_height_shape << 16)
+                        | (dst_width_shape);
+                }
+                case 32:
+                {
+                    return M2;
+                }
+                case 33:
+                {
+                    return M5;
+                }
+                case 34:
+                {
+                    return (src_y << 16) | src_x;
+                }
+                case 35:
+                {
+                    return (ai2d_calc_enable << 31)
+                        | (reserved10 << 29)
+                        | (dst_y << 16)
+                        | (dst_x);
+                }
+                default:
+                    return 0;
+                }
+            }
+
+            std::string to_string(uint32_t idx)
+            {
+                switch (idx)
+                {
+                case 0:
+                {
+                    return "src_ch0_ptr: " + std::to_string(src_ch0_ptr);
+                }
+                case 1:
+                {
+                    return "src_ch1_ptr: " + std::to_string(src_ch1_ptr);
+                }
+                case 2:
+                {
+                    return "src_ch2_ptr: " + std::to_string(src_ch2_ptr);
+                }
+                case 3:
+                {
+                    return "src_ch3_ptr: " + std::to_string(src_ch3_ptr);
+                }
+                case 4:
+                {
+                    return "dst_ch0_ptr: " + std::to_string(dst_ch0_ptr);
+                }
+                case 5:
+                {
+                    return "dst_ch1_ptr: " + std::to_string(dst_ch1_ptr);
+                }
+                case 6:
+                {
+                    return "dst_ch2_ptr: " + std::to_string(dst_ch2_ptr);
+                }
+                case 7:
+                {
+                    return "dst_ch3_ptr: " + std::to_string(dst_ch3_ptr);
+                }
+                case 8:
+                {
+                    return "src_ch1_width_layout: " + std::to_string(src_ch1_width_layout)
+                        + "\n"
+                        + "src_ch0_width_layout: " + std::to_string(src_ch0_width_layout);
+                }
+                case 9:
+                {
+                    return "src_ch3_width_layout: " + std::to_string(src_ch3_width_layout)
+                        + "\n"
+                        + "src_ch2_width_layout: " + std::to_string(src_ch2_width_layout);
+                }
+                case 10:
+                {
+                    return "dst_ch1_width_layout: " + std::to_string(dst_ch1_width_layout)
+                        + "\n"
+                        + "dst_ch0_width_layout: " + std::to_string(dst_ch0_width_layout);
+                }
+                case 11:
+                {
+                    return "dst_ch3_width_layout: " + std::to_string(dst_ch3_width_layout)
+                        + "\n"
+                        + "dst_ch2_width_layout: " + std::to_string(dst_ch2_width_layout);
+                }
+
+                case 12:
+                {
+                    FP32 m;
+                    m.u = M0;
+                    return "M0: " + std::to_string(m.f);
+                }
+                case 13:
+                {
+                    FP32 m;
+                    m.u = M1;
+                    return "M1: " + std::to_string(m.f);
+                }
+                case 14:
+                {
+                    FP32 m;
+                    m.u = M3;
+                    return "M3: " + std::to_string(m.f);
+                }
+                case 15:
+                {
+                    FP32 m;
+                    m.u = M4;
+                    return "M4: " + std::to_string(m.f);
+                }
+                case 16:
+                {
+                    return "";
+                }
+                case 17:
+                {
+                    return "";
+                }
+                case 18:
+                {
+                    return "dst_format: " + std::to_string(dst_format) + "\n"
+                        + "src_format: " + std::to_string(src_format) + "\n"
+                        + "bound_ind: " + std::to_string(bound_ind) + "\n"
+                        + "shift: " + std::to_string(shift) + "\n"
+                        + "pad_mod: " + std::to_string(pad_mod) + "\n"
+                        + "interpolation: " + std::to_string(interpolation) + "\n"
+                        + "cord_round: " + std::to_string(cord_round) + "\n"
+                        + "dst_channel: " + std::to_string(dst_channel) + "\n"
+                        + "channel: " + std::to_string(channel);
+                }
+                case 19:
+                {
+                    return "bound_smooth: " + std::to_string(bound_smooth) + "\n"
+                        + "bound_val: " + std::to_string(bound_val);
+                }
+                case 20:
+                {
+                    return "yuv2rgb_coef1: " + std::to_string(yuv2rgb_coef1) + "\n"
+                        + "yuv2rgb_coef0: " + std::to_string(yuv2rgb_coef0);
+                }
+                case 21:
+                {
+                    return "yuv2rgb_coef3: " + std::to_string(yuv2rgb_coef3) + "\n"
+                        + "yuv2rgb_coef2: " + std::to_string(yuv2rgb_coef2);
+                }
+                case 22:
+                {
+                    return "yuv2rgb_coef5: " + std::to_string(yuv2rgb_coef5) + "\n"
+                        + "yuv2rgb_coef4: " + std::to_string(yuv2rgb_coef4);
+                }
+                case 23:
+                {
+                    return "yuv2rgb_coef7: " + std::to_string(yuv2rgb_coef7) + "\n"
+                        + "yuv2rgb_coef6: " + std::to_string(yuv2rgb_coef6);
+                }
+                case 24:
+                {
+                    return "const_pad_ch0: " + std::to_string(const_pad_ch0) + "\n"
+                        + "yuv2rgb_coef11: " + std::to_string(yuv2rgb_coef11) + "\n"
+                        + "yuv2rgb_coef10: " + std::to_string(yuv2rgb_coef10);
+                }
+                case 25:
+                {
+                    return "sign: " + std::to_string(sign) + "\n"
+                        + "cmd_id: " + std::to_string(cmd_id) + "\n"
+                        + "dst_ind: " + std::to_string(dst_ind) + "\n"
+                        + "src_ind: " + std::to_string(src_ind) + "\n"
+                        + "const_pad_ch3: " + std::to_string(const_pad_ch3) + "\n"
+                        + "const_pad_ch2: " + std::to_string(const_pad_ch2) + "\n"
+                        + "const_pad_ch1: " + std::to_string(const_pad_ch1);
+                }
+                case 26:
+                {
+                    return "yuv2rgb_coef9: " + std::to_string(yuv2rgb_coef9) + "\n"
+                        + "yuv2rgb_coef8: " + std::to_string(yuv2rgb_coef8);
+                }
+                case 27:
+                {
+                    return "";
+                }
+                case 28:
+                {
+                    return "pad_b: " + std::to_string(pad_b) + "\n"
+                        + "pad_t: " + std::to_string(pad_t);
+                }
+                case 29:
+                {
+                    return "pad_r: " + std::to_string(pad_r) + "\n"
+                        + "pad_l: " + std::to_string(pad_l);
+                }
+                case 30:
+                {
+                    return "src_height_shape: " + std::to_string(src_height_shape) + "\n"
+                        + "src_width_shape: " + std::to_string(src_width_shape);
+                }
+                case 31:
+                {
+                    return "csc_en: " + std::to_string(csc_en) + "\n"
+                        + "intr_mask: " + std::to_string(intr_mask) + "\n"
+                        + "dst_height_shape: " + std::to_string(dst_height_shape) + "\n"
+                        + "dst_width_shape: " + std::to_string(dst_width_shape);
+                }
+                case 32:
+                {
+                    FP32 m;
+                    m.u = M2;
+                    return "M2: " + std::to_string(m.f);
+                }
+                case 33:
+                {
+                    FP32 m;
+                    m.u = M5;
+                    return "M5: " + std::to_string(m.f);
+                }
+                case 34:
+                {
+                    return "src_y: " + std::to_string(src_y) + "\n"
+                        + "src_x: " + std::to_string(src_x);
+                }
+                case 35:
+                {
+                    return "ai2d_calc_enable: " + std::to_string(ai2d_calc_enable) + "\n"
+                        + "dst_y: " + std::to_string(dst_y) + "\n"
+                        + "dst_x: " + std::to_string(dst_x);
+                }
+                default:
+                    return "";
+                }
+            }
+
+            float u32_to_float(uint32_t u)
+            {
+                FP32 m;
+                m.u = u;
+                return m.f;
+            }
+
+            float origin_M(uint32_t u)
+            {
+                return u32_to_float(u) / 1024.f;
+            }
+        };
+
+        int32_t get_size_from_shape(dims_t shape);
+        int32_t get_bytes_from_type(typecode_t type);
+        std::vector<segment> get_segment_start_end_length(int32_t start, int32_t chunk_size, int32_t upper_bound);
+
+        class ai2d_utils
+        {
+        public:
+            void update_static_param(ai2d_config &config, dims_t &in_shape, dims_t &out_shape,
+                ai2d_datatype_t &ai2d_dtype, ai2d_crop_param_t &crop_param, ai2d_shift_param_t &shift_param, ai2d_pad_param_t &pad_param,
+                ai2d_resize_param_t &resize_param, ai2d_affine_param_t &affine_param);
+            void update_M_param(ai2d_config &config, tensor4d_segment &ifmap, tensor4d_segment &ofmap, ai2d_datatype_t &ai2d_dtype, ai2d_resize_param_t &resize_param, ai2d_affine_param_t &affine_param);
+            void update_dynamic_param(ai2d_config &config, int32_t src_x, int32_t src_y, ai2d_datatype_t &ai2d_dtype, ai2d_pad_param_t &pad_param, tensor4d_segment &ifmap_sram, tensor4d_segment &ofmap_sram, tensor4d_segment &ifmap, tensor4d_segment &ofmap, float offset_M2, float offset_M5, dims_t &input_shape, dims_t &output_shape, bool broadcast_in_channel);
+            void resize_sram_search(ai2d_config &config, tensor4d_segment &ofmap, tensor4d_segment &ifmap, std::vector<int32_t> &ret);
+            void affine_sram_search(ai2d_config &config, tensor4d_segment &ofmap, tensor4d_segment &ifmap, ai2d_pad_param_t &pad_param, std::vector<int32_t> &ret);
+            void inv_M(std::vector<float> &M_ori_scale, std::vector<float> &M_ori_bias, std::vector<float> &M_inv_scale, std::vector<float> &M_inv_bias);
+            std::vector<float> M_mul_add(std::vector<float> &M_scale, std::vector<float> &M_bias, std::vector<float> &v_i);
+            bool try_allocate_resize_sram(std::vector<float> &M_ori_scale, std::vector<float> &M_ori_bias, int32_t dst_max_h, int32_t dst_max_w, tensor4d_segment &ifmap, tensor4d_segment &ofmap, ai2d_format &src_format);
+            bool try_allocate_affine_sram(std::vector<float> &M_ori_scale, std::vector<float> &M_ori_bias, segment &output_h, segment &output_w);
+            void update_regs(ai2d_config &config, bool write_all, std::vector<std::vector<uint32_t>> &regs);
+
+        private:
+            ai2d_sram_t ai2d_sram;
+        };
+
+    }
+}
+}
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_module.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_module.h
new file mode 100644
index 0000000..7ec613d
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_module.h
@@ -0,0 +1,31 @@
+/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <nncase/runtime/runtime_module.h>
+#include <nncase/runtime/runtime_tensor.h>
+
+BEGIN_NS_NNCASE_RT_K230
+
+#define K230_SEC_TEXT ".text"
+#define K230_SEC_DSP_TEXT ".dsp.text"
+#define K230_DSP_BASEMENT 2
+
+NNCASE_INLINE_VAR constexpr module_kind_t k230_module_type = to_module_kind("k230");
+
+NNCASE_MODULES_K230_API result<std::unique_ptr<runtime_module>> create_k230_runtime_module();
+NNCASE_MODULES_K230_API result<std::vector<std::pair<std::string, runtime_module::custom_call_type>>> create_k230_custom_calls();
+
+END_NS_NNCASE_RT_K230
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_types.h b/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_types.h
new file mode 100644
index 0000000..4ea079f
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/k230/runtime_types.h
@@ -0,0 +1,302 @@
+﻿/* Copyright 2020 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <string>
+
+BEGIN_NS_NNCASE_RT_K230
+
+enum gnne_reg_id
+{
+    gnne_reg_gpr0 = 0,
+    gnne_reg_gpr1 = 1,
+    gnne_reg_host_mem_base_addr0 = 33,
+    gnne_reg_host_mem_base_addr1 = 34,
+    gnne_reg_host_mem_base_addr2 = 35,
+    gnne_reg_host_mem_base_addr3 = 36,
+};
+
+typedef struct dequantize_params
+{
+    int16_t scale;
+    int8_t shift;
+    uint8_t zero_point;
+} dequantize_params_t;
+
+typedef struct quantize_params
+{
+    bfloat16 scale;
+    bfloat16 zero_point;
+} quantize_params_t;
+
+enum class mfu_trans_permute
+{
+    nchw = 0x0, /* 0:重要*/
+    ncwh = 0x1, /* 1:重要*/
+    nhcw = 0x2, /* 2:重要*/
+    nhwc = 0x3, /* 3:重要*/
+    nwch = 0x4, /* 4:None*/
+    nwhc = 0x5, /* 5:None*/
+    cnhw = 0x6, /* 6:None*/
+    cnwh = 0x7, /* 7:None*/
+    chnw = 0x8, /* 8:None*/
+    chwn = 0x9, /* 9:None*/
+    cwnh = 0xa, /* 10:None*/
+    cwhn = 0xb, /* 11:None*/
+    hncw = 0xc, /* 12:None*/
+    hnwc = 0xd, /* 13:None*/
+    hcnw = 0xe, /* 14:None*/
+    hcwn = 0xf, /* 15:None*/
+    hwnc = 0x10, /* 16:None*/
+    hwcn = 0x11, /* 17:None*/
+    wnch = 0x12, /* 18:None*/
+    wnhc = 0x13, /* 19:None*/
+    wcnh = 0x14, /* 20:None*/
+    wchn = 0x15, /* 21:None*/
+    whnc = 0x16, /* 22:None*/
+    whcn = 0x17 /* 23:None*/
+};
+
+enum class mfu_pdp_op
+{
+    min = 0x1, /* 1:取最小值*/
+    max = 0x0, /* 0:取最大值*/
+    average = 0x2, /* 2:取平均值*/
+    sum = 0x3 /* 3:求和*/
+};
+
+enum class mfu_reduce_op
+{
+    max = 0x0, /* 0:两者取最大值*/
+    min = 0x1, /* 1:两者取最小值*/
+    add = 0x2, /* 2:两者求和*/
+    sub = 0x3, /* 3:左操作数减去右操作数*/
+    mul = 0x4 /* 4:两者求其点积*/
+};
+
+enum class mfu_reduce_dim
+{
+    w = 0x0, /* 0:None*/
+    hw = 0x1, /* 1:None*/
+    chw = 0x2, /* 2: None*/
+    nchw = 0x3, /* 3:None*/
+};
+
+enum class mfu_crop_resize
+{
+    biliner = 0x0, /* 0:双线性插值*/
+    nearest = 0x1 /* 1:最邻近插值*/
+};
+
+enum class mfu_crop_align
+{
+    none = 0x0, /* 0:tensorflow align_corner=false*/
+    corner = 0x1, /* 1:tensorflow align_corner=True*/
+    center = 0x2 /* 2:open cv，中心对齐*/
+};
+
+enum class mn_round_mode
+{
+    round = 0,
+    floor = 1,
+    ceil = 2
+};
+
+static std::string to_string(mn_round_mode v)
+{
+    switch (v)
+    {
+    case mn_round_mode::round:
+        return "round";
+    case mn_round_mode::floor:
+        return "floor";
+    case mn_round_mode::ceil:
+        return "ceil";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_triangle_mode
+{
+    sin = 0,
+    cos = 1
+};
+
+static std::string to_string(mn_triangle_mode v)
+{
+    switch (v)
+    {
+    case mn_triangle_mode::sin:
+        return "sin";
+    case mn_triangle_mode::cos:
+        return "cos";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_unary_logic_mode
+{
+    abs = 0,
+    sign = 1,
+    neg = 2
+};
+
+static std::string to_string(mn_unary_logic_mode v)
+{
+    switch (v)
+    {
+    case mn_unary_logic_mode::abs:
+        return "abs";
+    case mn_unary_logic_mode::sign:
+        return "sign";
+    case mn_unary_logic_mode::neg:
+        return "neg";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_cmp_mode
+{
+    min = 0,
+    max = 1,
+    gt = 2,
+    ge = 3,
+    lt = 4,
+    le = 5,
+    eq = 6
+};
+
+static std::string to_string(mn_cmp_mode v)
+{
+    switch (v)
+    {
+    case mn_cmp_mode::min:
+        return "min";
+    case mn_cmp_mode::max:
+        return "max";
+    case mn_cmp_mode::gt:
+        return "gt";
+    case mn_cmp_mode::ge:
+        return "ge";
+    case mn_cmp_mode::lt:
+        return "lt";
+    case mn_cmp_mode::le:
+        return "le";
+    case mn_cmp_mode::eq:
+        return "eq";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_sqrt_mode
+{
+    positive = 0, // 输入符号位直接认为是0，一定是正数
+    nan = 1, // 如果是输入符号位位负的，返回NaN
+    negative = 2 // 如果输入是正数，正常输出。否则输出负数
+};
+
+static std::string to_string(mn_sqrt_mode v)
+{
+    switch (v)
+    {
+    case mn_sqrt_mode::positive:
+        return "positive";
+    case mn_sqrt_mode::nan:
+        return "nan";
+    case mn_sqrt_mode::negative:
+        return "negative";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_log_mode
+{
+    positive = 0, // 输入符号位直接认为是0，一定是正数
+    nan = 1, // 如果是输入符号位位负的，返回NaN
+    negative = 2 //如果输入是正数，正常输出。否则输出负数
+};
+
+static std::string to_string(mn_log_mode v)
+{
+    switch (v)
+    {
+    case mn_log_mode::positive:
+        return "positive";
+    case mn_log_mode::nan:
+        return "nan";
+    case mn_log_mode::negative:
+        return "negative";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_binary_logic_islogic
+{
+    bitwise = 0,
+    logic = 1
+};
+
+static std::string to_string(mn_binary_logic_islogic v)
+{
+    switch (v)
+    {
+    case mn_binary_logic_islogic::bitwise:
+        return "bitwise";
+    case mn_binary_logic_islogic::logic:
+        return "logic";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+enum class mn_binary_logic_mode
+{
+    // add prefix to avoid collision with C++ keywords.
+    kand = 0,
+    kor = 1,
+    knot = 2,
+    kxor = 3
+};
+
+enum class sparsity
+{
+    dense = 0, /* 0:直接存储*/
+    sparse = 1 /* 1:对0进行压缩编码*/
+};
+
+static std::string to_string(mn_binary_logic_mode v, mn_binary_logic_islogic l = mn_binary_logic_islogic::bitwise)
+{
+    switch (v)
+    {
+    case mn_binary_logic_mode::kand:
+        return l == mn_binary_logic_islogic::bitwise ? "&" : "&&";
+    case mn_binary_logic_mode::kor:
+        return l == mn_binary_logic_islogic::bitwise ? "|" : "||";
+    case mn_binary_logic_mode::knot:
+        return l == mn_binary_logic_islogic::bitwise ? "~" : "!";
+    case mn_binary_logic_mode::kxor:
+        return l == mn_binary_logic_islogic::bitwise ? "^" : "^^";
+    default:
+        throw std::runtime_error("unimplemented");
+    }
+}
+
+END_NS_NNCASE_RT_K230
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/model.h b/third_party/nncase/riscv64/include/nncase/runtime/model.h
new file mode 100644
index 0000000..45c67c6
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/model.h
@@ -0,0 +1,101 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include <cassert>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+inline constexpr size_t MAX_SECTION_NAME_LENGTH = 16;
+inline constexpr size_t MAX_MODULE_KIND_LENGTH = 16;
+inline constexpr uint32_t MODEL_HAS_NO_ENTRY = -1;
+
+typedef std::array<char, MAX_MODULE_KIND_LENGTH> module_kind_t;
+
+template <std::size_t N, std::size_t... Is>
+constexpr module_kind_t to_module_kind(const char (&a)[N],
+                                       std::index_sequence<Is...>) {
+    return {{a[Is]...}};
+}
+
+template <std::size_t N>
+constexpr module_kind_t to_module_kind(const char (&a)[N]) {
+    return to_module_kind(a, std::make_index_sequence<N>());
+}
+
+struct model_header {
+    uint32_t identifier;
+    uint32_t version;
+    uint32_t flags;
+    uint32_t alignment;
+    uint32_t modules;
+    uint32_t entry_module;
+    uint32_t entry_function;
+    uint32_t reserved0;
+};
+
+struct function_header {
+    uint32_t parameters;
+    uint32_t sections;
+    uint64_t entrypoint;
+    uint64_t text_size;
+    uint64_t size;
+};
+
+struct module_header {
+    module_kind_t kind;
+    uint32_t version;
+    uint32_t sections;
+    uint32_t functions;
+    uint32_t reserved0;
+    uint64_t size;
+};
+
+struct section_header {
+    char name[MAX_SECTION_NAME_LENGTH];
+    uint32_t flags;
+    uint32_t reserved0;
+    uint64_t size;
+    uint64_t body_start;
+    uint64_t body_size;
+    uint64_t memory_size;
+};
+
+NNCASE_INLINE_VAR constexpr uint32_t SECTION_MERGED_INTO_RDATA = 1;
+
+struct shape_header {
+    uint32_t size;
+
+    shape_header() = delete;
+    shape_header(shape_header &) = delete;
+    shape_header &operator=(shape_header &) = delete;
+
+    const uint32_t *begin() const noexcept {
+        return reinterpret_cast<const uint32_t *>(
+            reinterpret_cast<uintptr_t>(this) + sizeof(shape_header));
+    }
+
+    const uint32_t *end() const noexcept { return begin() + size; }
+
+    uint32_t operator[](size_t index) const {
+        assert(index < size);
+        return begin()[index];
+    }
+};
+
+NNCASE_INLINE_VAR constexpr uint32_t MODEL_IDENTIFIER = 'KMDL';
+NNCASE_INLINE_VAR constexpr uint32_t MODEL_VERSION = 7;
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/nnil.h b/third_party/nncase/riscv64/include/nncase/runtime/nnil.h
new file mode 100644
index 0000000..66b79e9
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/nnil.h
@@ -0,0 +1,123 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include "span_reader.h"
+#include <array>
+#include <cassert>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef enum _nnil_opcode {
+    nnil_nop = 0x00,
+    nnil_dup = 0x01,
+    nnil_pop = 0x02,
+    nnil_lda_0 = 0x03,
+    nnil_ldc_r4_0 = 0x04,
+    nnil_ldc_r4_1 = 0x05,
+    nnil_ldc_r4 = 0x06,
+    nnil_abs = 0x20,
+    nnil_ceil = 0x21,
+    nnil_cos = 0x22,
+    nnil_exp = 0x23,
+    nnil_floor = 0x24,
+    nnil_log = 0x25,
+    nnil_neg = 0x26,
+    nnil_rsqrt = 0x27,
+    nnil_sin = 0x28,
+    nnil_sqrt = 0x29,
+    nnil_square = 0x2A,
+    nnil_tanh = 0x2B,
+    nnil_bitwise_not = 0x2C,
+    nnil_logical_not = 0x2D,
+    nnil_round = 0x2E,
+    nnil_acos = 0x2F,
+    nnil_asin = 0x30,
+    nnil_sign = 0x31,
+    nnil_add = 0x40,
+    nnil_sub = 0x41,
+    nnil_mul = 0x42,
+    nnil_div = 0x43,
+    nnil_min = 0x44,
+    nnil_max = 0x45,
+    nnil_pow = 0x46,
+    nnil_clamp = 0x80,
+    nnil_ret = 0xA0
+} nnil_opcode_t;
+
+typedef struct _nnil_ldc_r4 {
+    float r4;
+} nnil_ldc_r4_t;
+
+typedef struct _nnil_op {
+    nnil_opcode_t opcode;
+
+    union {
+        nnil_ldc_r4_t ldc_r4;
+    };
+} nnil_op_t;
+
+class nnil_reader {
+  public:
+    nnil_reader(span_reader &reader) : reader_(reader) {}
+
+    bool avail() const noexcept { return !reader_.empty(); }
+
+    nnil_op_t next() {
+        assert(avail());
+        nnil_op_t op;
+        op.opcode = (nnil_opcode_t)reader_.read<uint8_t>();
+
+        switch (op.opcode) {
+        case nnil_ldc_r4:
+            op.ldc_r4 = reader_.read_unaligned<nnil_ldc_r4_t>();
+            break;
+        default:
+            break;
+        }
+
+        return op;
+    }
+
+  private:
+    span_reader &reader_;
+};
+
+class nnil_evalstack {
+  public:
+    nnil_evalstack() noexcept : top(0) {}
+
+    void push(float value) {
+        assert(top < _stack.size());
+        _stack[top++] = value;
+    }
+
+    float pop() {
+        assert(top > 0);
+        return _stack[--top];
+    }
+
+    void dup() {
+        assert(top > 0);
+        _stack[top] = _stack[top - 1];
+        top++;
+    }
+
+  private:
+    std::array<float, 64> _stack;
+    size_t top;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/result.h b/third_party/nncase/riscv64/include/nncase/runtime/result.h
new file mode 100644
index 0000000..39fd0aa
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/result.h
@@ -0,0 +1,401 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <functional>
+#include <string_view>
+#include <system_error>
+#include <type_traits>
+
+namespace nncase {
+#define try_(x)                                                                \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok())                                                        \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+#define try_var(name, x)                                                       \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok())                                                         \
+            name = std::move(v.unwrap());                                      \
+        else                                                                   \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+#define try_var_err(name, x, e)                                                \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            e = nncase::err(std::move(v.unwrap_err()));                        \
+            return;                                                            \
+        }                                                                      \
+    }
+
+#define try_set(name, x)                                                       \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok())                                                         \
+            name = std::move(v.unwrap());                                      \
+        else                                                                   \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+[[noreturn]] inline void fail_fast(const char *message) {
+    fprintf(stderr, "terminate:%s\n", message);
+    // auto exit for pld
+    fprintf(stderr, "}");
+    std::terminate();
+}
+
+template <class T> class NNCASE_NODISCARD result;
+
+namespace detail {
+enum class result_type { ok, err };
+
+struct ok_t {};
+NNCASE_INLINE_VAR ok_t constexpr ok_v = {};
+
+template <class T> NNCASE_INLINE_VAR bool constexpr is_result_v = false;
+template <class T>
+NNCASE_INLINE_VAR bool constexpr is_result_v<result<T>> = true;
+
+template <class T, class U, class Func> class map_call_impl {
+    result<U> operator()(Func &&func, T &value) noexcept {
+        return ok(func(value));
+    }
+};
+
+template <class T, class Func> struct map_traits {
+    using U = invoke_result_t<Func, T>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+    using result_t = result<U>;
+
+    result<U> operator()(Func &&func, T &value) noexcept {
+        return map_call_impl<T, U, Func>()(std::forward<Func>(func), value);
+    }
+};
+
+template <class Func> struct map_traits<void, Func> {
+    using U = invoke_result_t<Func>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+    using result_t = result<U>;
+
+    result<U> operator()(Func &&func) noexcept {
+        return map_call_impl<void, U, Func>()(std::forward<Func>(func));
+    }
+};
+
+template <class T, class Func> struct map_err_traits {
+    using U = invoke_result_t<Func, std::error_condition>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+
+    result<U> operator()(Func &&func, std::error_condition &value) noexcept {
+        return err(func(value));
+    }
+};
+
+template <class T, class Func> struct map_err_traits;
+
+template <class T, class Func> struct and_then_traits {
+    using result_t = invoke_result_t<Func, T>;
+    using traits_t = typename result_t::traits;
+    using U = typename traits_t::ok_type;
+    static_assert(
+        is_result_v<result_t>,
+        "Cannot then a callback not returning result, use map instead");
+
+    result_t operator()(Func &&func, T &value) noexcept { return func(value); }
+};
+
+template <class Func> struct and_then_traits<void, Func> {
+    using result_t = invoke_result_t<Func>;
+    using traits_t = typename result_t::traits;
+    using U = typename traits_t::ok_type;
+    static_assert(
+        is_result_v<result_t>,
+        "Cannot then a callback not returning result, use map instead");
+
+    result_t operator()(Func &&func) noexcept { return func(); }
+};
+} // namespace detail
+
+template <class T> class NNCASE_NODISCARD result {
+  public:
+    static_assert(!detail::is_result_v<T>, "Cannot use nested result");
+
+    using value_type = T;
+
+    template <class... Args>
+    result(detail::ok_t, Args... args)
+        : type_(detail::result_type::ok), ok_(std::forward<Args>(args)...) {}
+
+    result(std::error_condition err) noexcept
+        : type_(detail::result_type::err), err_(std::move(err)) {}
+
+    result(const result &other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(other.ok_);
+        else
+            new (&err_) std::error_condition(other.err_);
+    }
+
+    result(result &&other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+    }
+
+    template <class U, class = std::enable_if_t<std::is_convertible_v<U, T>>>
+    result(result<U> &&other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+    }
+
+    ~result() { destroy(); }
+
+    result &operator=(const result &other) noexcept {
+        destroy();
+        type_ = other.type_;
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(other.ok_);
+        else
+            new (&err_) std::error_condition(other.err_);
+        return *this;
+    }
+
+    result &operator=(result &&other) noexcept {
+        destroy();
+        type_ = other.type_;
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+        return *this;
+    }
+
+    constexpr bool is_ok() const noexcept {
+        return type_ == detail::result_type::ok;
+    }
+
+    constexpr bool is_err() const noexcept {
+        return type_ == detail::result_type::err;
+    }
+
+    constexpr T &unwrap() &noexcept {
+        if (is_ok())
+            return ok_;
+        else
+            std::terminate();
+    }
+
+    constexpr T &&unwrap() &&noexcept {
+        if (is_ok())
+            return std::move(ok_);
+        else
+            std::terminate();
+    }
+
+    constexpr T &unwrap_or_throw() & {
+        if (is_ok())
+            return ok_;
+        else
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    constexpr T &&unwrap_or_throw() && {
+        if (is_ok())
+            return std::move(ok_);
+        else
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    constexpr std::error_condition &unwrap_err() noexcept {
+        if (is_ok())
+            std::terminate();
+        else
+            return err_;
+    }
+
+    constexpr T &expect(gsl::cstring_span message) &noexcept {
+        if (is_ok())
+            return ok_;
+        else {
+            fail_fast(message.data());
+        }
+    }
+
+    constexpr T &&expect(gsl::cstring_span message) &&noexcept {
+        if (is_ok())
+            return std::move(ok_);
+        else {
+            fail_fast(message.data());
+        }
+    }
+
+    template <class Func, class Traits = detail::map_traits<T, Func>>
+    constexpr typename Traits::result_t &&map(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func), std::move(ok_));
+        else
+            return std::move(*this);
+    }
+
+    template <class Func, class Traits = detail::map_err_traits<T, Func>>
+    constexpr typename Traits::result_t &&map_err(Func &&func) &&noexcept {
+        if (is_ok())
+            return std::move(*this);
+        else
+            return Traits()(std::forward<Func>(func), err_);
+    }
+
+    template <class Func, class Traits = detail::and_then_traits<T, Func>>
+    constexpr typename Traits::result_t &&and_then(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func), ok_);
+        else
+            return std::move(*this);
+    }
+
+  private:
+    void destroy() {
+        if (is_ok())
+            std::destroy_at(&ok_);
+        else
+            std::destroy_at(&err_);
+    }
+
+  private:
+    template <class U> friend class result;
+
+    detail::result_type type_;
+    union {
+        T ok_;
+        std::error_condition err_;
+    };
+};
+
+template <> class NNCASE_NODISCARD result<void> {
+  public:
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wnull-dereference"
+    result() noexcept : err_(0, *(std::error_category *)nullptr) {}
+#pragma GCC diagnostic pop
+
+    result(std::error_condition err) noexcept : err_(std::move(err)) {}
+
+    bool is_ok() const noexcept { return !is_err(); }
+    bool is_err() const noexcept { return (bool)err_; }
+
+    void unwrap() noexcept {
+        if (is_err())
+            std::terminate();
+    }
+
+    void unwrap_or_throw() {
+        if (is_err())
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    std::error_condition &unwrap_err() noexcept {
+        if (is_ok())
+            std::terminate();
+        else
+            return err_;
+    }
+
+    void expect(gsl::cstring_span message) noexcept {
+        if (is_err())
+            fail_fast(message.data());
+    }
+
+    template <class Func, class Traits = detail::map_traits<void, Func>>
+    typename Traits::result_t &&map(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func));
+        else
+            return std::move(*this);
+    }
+
+    template <class Func, class Traits = detail::map_err_traits<void, Func>>
+    typename Traits::result_t &&map_err(Func &&func) &&noexcept {
+        if (is_ok())
+            return std::move(*this);
+        else
+            return Traits()(std::forward<Func>(func), err_);
+    }
+
+    template <class Func, class Traits = detail::and_then_traits<void, Func>>
+    typename Traits::result_t &&and_then(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func));
+        else
+            return std::move(*this);
+    }
+
+  private:
+    std::error_condition err_;
+};
+
+inline result<void> ok() { return {}; }
+
+template <class T, class... Args> constexpr result<T> ok(Args &&...args) {
+    return {detail::ok_v, std::forward<Args>(args)...};
+}
+
+template <class T> constexpr result<std::decay_t<T>> ok(T &&value) {
+    return {detail::ok_v, std::forward<T>(value)};
+}
+
+inline std::error_condition err(std::error_condition value) noexcept {
+    return value;
+}
+
+template <class ErrCode, class = std::enable_if_t<
+                             std::is_error_condition_enum<ErrCode>::value>>
+std::error_condition err(ErrCode value) {
+    return err(std::error_condition(value));
+}
+
+namespace detail {
+template <class T, class Func> class map_call_impl<T, void, Func> {
+    result<void> operator()(Func &&func, T &value) noexcept {
+        func(value);
+        return ok();
+    }
+};
+
+template <class Func> class map_call_impl<void, void, Func> {
+    result<void> operator()(Func &&func) noexcept {
+        func();
+        return ok();
+    }
+};
+} // namespace detail
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_function.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_function.h
new file mode 100644
index 0000000..ba2515c
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_function.h
@@ -0,0 +1,72 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "model.h"
+#include "result.h"
+#include "runtime_section_context.h"
+#include <nncase/runtime/stream_reader.h>
+#include <nncase/type.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class interpreter;
+class runtime_module;
+struct runtime_module_init_context;
+
+struct NNCASE_API runtime_function_init_context
+    : public runtime_section_context {
+    virtual runtime_module_init_context &module_init_context() noexcept = 0;
+    virtual const function_header &header() noexcept = 0;
+};
+
+class NNCASE_API runtime_function {
+  public:
+    runtime_function(runtime_module &rt_module);
+    runtime_function(const runtime_function &) = delete;
+    virtual ~runtime_function() = default;
+    runtime_function &operator=(const runtime_function &) = delete;
+
+    result<void>
+    initialize(gsl::span<const gsl::byte> payload,
+               runtime_module_init_context &module_init_context) noexcept;
+    result<void>
+    initialize(stream_reader &reader,
+               runtime_module_init_context &module_init_context) noexcept;
+
+    runtime_module &module() const noexcept;
+
+    uint32_t parameters_size() const noexcept;
+    result<type> parameter_type(size_t index) const noexcept;
+    const type &return_type() const noexcept;
+
+    result<value_t> invoke(gsl::span<value_t> parameters,
+                           value_t return_value = nullptr) noexcept;
+
+  protected:
+    virtual result<void>
+    initialize_core(runtime_function_init_context &context) noexcept = 0;
+
+    virtual result<value_t> invoke_core(gsl::span<value_t> parameters,
+                                        value_t return_value) noexcept = 0;
+
+  private:
+    function_header header_;
+    runtime_module &rt_module_;
+    std::vector<type> parameter_types_;
+    type return_type_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_loader.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_loader.h
new file mode 100644
index 0000000..e5e5df4
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_loader.h
@@ -0,0 +1,42 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <memory>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/model.h>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/runtime_module.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef void (*rt_module_activator_t)(
+    result<std::unique_ptr<runtime_module>> &result);
+typedef void (*rt_module_collector_t)(
+    result<
+        std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+        &result);
+
+#define RUNTIME_MODULE_ACTIVATOR_NAME create_runtime_module
+#define RUNTIME_MODULE_COLLECTOR_NAME collect_custom_call
+
+struct runtime_registration {
+    module_kind_t id;
+    rt_module_activator_t activator;
+    rt_module_collector_t collector;
+};
+
+extern runtime_registration builtin_runtimes[];
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_module.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_module.h
new file mode 100644
index 0000000..194dd3b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_module.h
@@ -0,0 +1,81 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "model.h"
+#include "result.h"
+#include "runtime_function.h"
+#include "runtime_section_context.h"
+#include "span_reader.h"
+#include "stream_reader.h"
+#include <nncase/kernels/kernel_context.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class interpreter;
+
+struct NNCASE_API runtime_module_init_context : public runtime_section_context {
+    virtual interpreter &interp() noexcept = 0;
+    virtual const module_header &header() noexcept = 0;
+};
+
+class NNCASE_API runtime_module {
+  public:
+    static result<std::unique_ptr<runtime_module>>
+    create(const module_kind_t &kind);
+
+    using custom_call_type = result<value_t> (*)(
+        gsl::span<const gsl::byte>, const std::vector<value_t> &,
+        const kernels::kernel_context &);
+
+    static result<
+        std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+    collect(const module_kind_t &kind);
+
+    runtime_module() = default;
+    runtime_module(const runtime_module &) = delete;
+    virtual ~runtime_module() = default;
+    runtime_module &operator=(const runtime_module &) = delete;
+
+    result<void> initialize(gsl::span<const gsl::byte> payload,
+                            interpreter &interp) noexcept;
+    result<void> initialize(stream_reader &reader,
+                            interpreter &interp) noexcept;
+    const module_kind_t &kind() const noexcept;
+
+    interpreter &interp() const noexcept { return *interp_; }
+
+    result<runtime_function *> find_function_by_id(size_t index) noexcept;
+
+    result<size_t> find_id_by_function(runtime_function *function) noexcept;
+
+  protected:
+    virtual result<void>
+    initialize_before_functions(runtime_module_init_context &context) noexcept;
+    virtual result<void>
+    initialize_after_functions(runtime_module_init_context &context) noexcept;
+    virtual result<std::unique_ptr<runtime_function>>
+    create_function() noexcept = 0;
+
+    gsl::span<std::unique_ptr<runtime_function>> functions() noexcept {
+        return functions_;
+    }
+
+  private:
+    module_header header_;
+    std::vector<std::unique_ptr<runtime_function>> functions_;
+    interpreter *interp_ = nullptr;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_op_utility.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_op_utility.h
new file mode 100644
index 0000000..f06d9e7
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_op_utility.h
@@ -0,0 +1,238 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include "result.h"
+#include <numeric>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+inline size_t get_bytes(const datatype_t &type) { return type->size_bytes(); }
+
+template <class TShape> inline size_t compute_size(const TShape &shape) {
+    return std::accumulate(shape.begin(), shape.end(), 1,
+                           std::multiplies<size_t>());
+}
+
+template <class TShape>
+inline size_t get_bytes(const datatype_t &type, const TShape &shape) {
+    return compute_size(shape) * get_bytes(type);
+}
+
+template <class TShape>
+inline size_t compute_size(const TShape &shape, const TShape &strides) {
+    size_t max_stride = 1, max_shape = 1;
+    for (size_t i = 0; i < shape.size(); i++) {
+        if ((shape[i] == 1 ? 0 : strides[i]) >= max_stride) {
+            max_stride = strides[i];
+            max_shape = shape[i];
+        }
+    }
+    size_t size = max_stride * max_shape;
+    return size;
+}
+
+template <class TShape>
+inline size_t get_bytes(const datatype_t &type, const TShape &shape,
+                        const TShape &strides) {
+    return compute_size(shape, strides) * get_bytes(type);
+}
+
+namespace detail {
+template <class shape_type, class strides_type, class bs_ptr>
+inline std::size_t compute_strides(const shape_type &shape,
+                                   strides_type &strides,
+                                   [[maybe_unused]] bs_ptr bs) {
+    using strides_value_type = typename std::decay_t<strides_type>::value_type;
+    strides_value_type data_size = 1;
+    for (std::size_t i = shape.size(); i != 0; --i) {
+        strides[i - 1] = data_size;
+        data_size =
+            strides[i - 1] * static_cast<strides_value_type>(shape[i - 1]);
+    }
+    return static_cast<std::size_t>(data_size);
+}
+} // namespace detail
+
+template <class shape_type, class strides_type>
+inline std::size_t compute_strides(const shape_type &shape,
+                                   strides_type &strides) {
+    return detail::compute_strides(shape, strides, nullptr);
+}
+
+inline strides_t get_default_strides(gsl::span<const size_t> shape) {
+    strides_t strides(shape.size());
+    compute_strides(shape, strides);
+    return strides;
+}
+
+template <class TShape>
+TShape convert_shape_type(const TShape &shape, datatype_t src,
+                          datatype_t dest) {
+    const auto src_size = get_bytes(src);
+    const auto dest_size = get_bytes(dest);
+
+    TShape new_shape = shape;
+    if (!new_shape.empty()) {
+        auto &v = new_shape.back();
+        v = new_shape.back() * src_size / dest_size;
+    }
+
+    return new_shape;
+}
+
+template <class TShape>
+result<TShape> convert_strides_type(const TShape &strides, datatype_t src,
+                                    datatype_t dest) {
+    const auto src_size = get_bytes(src);
+    const auto dest_size = get_bytes(dest);
+
+    if (src_size == dest_size)
+        return ok(strides);
+
+    TShape new_strides = strides;
+    // 1. Except last dim
+    for (size_t i = 0; i < new_strides.size() - 1; i++) {
+        auto &v = new_strides[i];
+        if (v == 0)
+            v = 1;
+        v = v * src_size / dest_size;
+    }
+
+    // 2. Last dim
+    if (!new_strides.empty()) {
+        // 2.1. If last dim is not 0 or 1, unsupported
+        auto last_dim = new_strides.back();
+        if (last_dim != 0 || last_dim != 1)
+            return err(std::errc::not_supported);
+    }
+
+    return ok(new_strides);
+}
+
+template <int32_t Bits, class T> uint8_t count_leading_zeros(T value) {
+    uint8_t num_zeroes = 0;
+    for (int32_t i = Bits - 1; i >= 0; i--) {
+        if ((value & (1ULL << i)) == 0)
+            ++num_zeroes;
+        else
+            break;
+    }
+
+    return num_zeroes;
+}
+
+template <class T = uint64_t> inline T bit_mask(uint8_t shift) {
+    return (T(1) << shift) - 1;
+}
+
+template <class T, bool Banker = false> T carry_shift(T value, int32_t shift) {
+    if (shift > 0) {
+        if (Banker) {
+            T result;
+            // Sign |  Int (T - shift - 1 bits) | Frac (shift bits)
+            //  S      IIII                       FFF
+            auto integral = value >> shift;
+            auto fractional = value & bit_mask(shift);
+            auto sign = value < 0 ? -1 : 1;
+            auto half = size_t(1) << (shift - 1);
+
+            // frac < 0.5
+            if (fractional < half) {
+                return integral;
+            }
+            // frac > 0.5
+            else if (fractional > half) {
+                return integral + sign;
+            }
+            // frac == 0.5
+            else {
+                // odd
+                if (integral & 1)
+                    return integral + sign;
+                // even
+                else
+                    return integral;
+            }
+
+            return result;
+        } else {
+            value += T(1) << (shift - 1);
+            value >>= shift;
+        }
+    } else if (shift < 0) {
+        value = value << (-shift);
+    }
+
+    return value;
+}
+
+template <bool Banker = false>
+inline int32_t mul_and_carry_shift(int32_t value, int32_t mul, int32_t shift) {
+    return (int32_t)carry_shift<int64_t, Banker>((int64_t)value * mul, shift);
+}
+
+template <size_t Bits, bool Signed = true, class T = int64_t>
+inline bool within_range(T value) noexcept {
+    if constexpr (Signed) {
+        auto min = -(1LL << (Bits - 1));
+        auto max = (1LL << (Bits - 1)) - 1;
+        return value >= min && value <= max;
+    } else {
+        auto min = 0ULL;
+        auto max = (1ULL << Bits) - 1;
+        return value >= min && value <= max;
+    }
+}
+
+template <class T> inline T clamp(T value, T min, T max) {
+    return std::min(max, std::max(value, min));
+}
+
+template <uint8_t Bits> inline int32_t clamp(int32_t value) {
+    auto min = std::numeric_limits<int32_t>::lowest() >> (32 - Bits);
+    auto max = std::numeric_limits<int32_t>::max() >> (32 - Bits);
+    return clamp(value, min, max);
+}
+
+inline bool is_contiguous(gsl::span<const size_t> shape,
+                          gsl::span<const size_t> strides) {
+    size_t data_size = 1;
+    for (std::size_t i = shape.size(); i != 0; --i) {
+        if (strides[i - 1] != data_size) {
+            return false;
+        }
+        data_size *= shape[i - 1];
+    }
+    return true;
+}
+
+inline int
+get_last_not_contiguous_index(gsl::span<const size_t> strides,
+                              gsl::span<const size_t> default_strides) {
+    for (int i = strides.size() - 1; i >= 0; --i) {
+        if (strides[i] != default_strides[i]) {
+            return i + 1;
+        }
+    }
+    return -1;
+}
+
+template <size_t A, size_t B>
+constexpr auto is_not_equal =
+    std::integral_constant<bool, std::not_equal_to<size_t>{}(A, B)>{};
+
+struct DefaultCallable {};
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_section_context.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_section_context.h
new file mode 100644
index 0000000..0777257
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_section_context.h
@@ -0,0 +1,51 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "host_buffer.h"
+#include "model.h"
+#include "result.h"
+#include "span_reader.h"
+#include "stream_reader.h"
+#include <nncase/type.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+struct NNCASE_API runtime_section_context {
+    virtual bool is_section_pinned() const noexcept = 0;
+    virtual result<gsl::span<const gsl::byte>>
+    section(const char *name) noexcept = 0;
+    virtual result<stream_reader *>
+    seek_section(const char *name, section_header &header) noexcept = 0;
+
+    result<gsl::span<const gsl::byte>>
+    get_or_read_section(const char *name, host_buffer_t &storage,
+                        bool allocate_shared) noexcept;
+
+    template <class TCallable>
+    result<void> read_section(const char *name, TCallable &&callable) noexcept {
+        auto section_span_r = section(name);
+        if (section_span_r.is_ok()) {
+            span_reader sr(std::move(section_span_r).unwrap());
+            return callable(sr, sr.avail());
+        } else {
+            section_header header;
+            try_var(sr, seek_section(name, header));
+            return callable(*sr, (size_t)header.body_size);
+        }
+    }
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/runtime_tensor.h b/third_party/nncase/riscv64/include/nncase/runtime/runtime_tensor.h
new file mode 100644
index 0000000..8a480f0
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/runtime_tensor.h
@@ -0,0 +1,108 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include "host_buffer.h"
+#include "model.h"
+#include "result.h"
+#include <functional>
+#include <memory>
+#include <nncase/tensor.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+// V1 APIs
+
+class NNCASE_API runtime_tensor {
+  public:
+    runtime_tensor() noexcept;
+    explicit runtime_tensor(tensor impl) noexcept;
+
+    typecode_t datatype() const noexcept;
+    gsl::span<const size_t> shape() const noexcept;
+    gsl::span<const size_t> strides() const noexcept;
+    bool empty() const noexcept;
+    bool is_host() const noexcept;
+    bool is_contiguous() const noexcept;
+
+    bool can_copy_to_without_staging(const runtime_tensor &dest) const noexcept;
+    result<void> copy_to(runtime_tensor &dest) noexcept;
+    result<runtime_tensor> to_host() noexcept;
+
+    void reset() noexcept;
+
+    tensor impl() const noexcept { return impl_; }
+
+  private:
+    tensor impl_;
+};
+
+NNCASE_API bool operator==(const runtime_tensor &lhs,
+                           const runtime_tensor &rhs) noexcept;
+NNCASE_API bool operator!=(const runtime_tensor &lhs,
+                           const runtime_tensor &rhs) noexcept;
+
+namespace host_runtime_tensor {
+
+typedef enum memory_pool_ {
+    pool_shared_first,
+    pool_cpu_only,
+    pool_shared
+} memory_pool_t;
+
+typedef std::function<void(gsl::byte *)> data_deleter_t;
+
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape,
+       memory_pool_t pool = pool_cpu_only) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, gsl::span<gsl::byte> data, bool copy,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, gsl::span<gsl::byte> data,
+       data_deleter_t data_deleter, memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       memory_pool_t pool = pool_cpu_only) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       gsl::span<gsl::byte> data, bool copy,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       gsl::span<gsl::byte> data, data_deleter_t data_deleter,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+
+NNCASE_API result<memory_pool_t>
+memory_pool(const runtime_tensor &tensor) noexcept;
+NNCASE_API result<mapped_buffer> map(runtime_tensor &tensor,
+                                     map_access_t access) noexcept;
+NNCASE_API result<void> sync(runtime_tensor &tensor, sync_op_t op,
+                             bool force = false) noexcept;
+} // namespace host_runtime_tensor
+
+namespace hrt = host_runtime_tensor;
+
+namespace detail {
+NNCASE_API result<tensor>
+create(datatype_t datatype, dims_t shape,
+       hrt::memory_pool_t pool = hrt::pool_cpu_only) noexcept;
+}
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.h b/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.h
new file mode 100644
index 0000000..676a094
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.h
@@ -0,0 +1,30 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "runtime_tensor_impl.h"
+
+BEGIN_NS_NNCASE_RUNTIME
+
+namespace detail {
+class host_runtime_tensor_impl;
+}
+
+END_NS_NNCASE_RUNTIME
+
+#ifndef NNCASE_SHARED_RUNTIME_TENSOR_PLATFORM_HEADER
+#include "shared_runtime_tensor.platform.h"
+#else
+#include NNCASE_SHARED_RUNTIME_TENSOR_PLATFORM_HEADER
+#endif
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.platform.h b/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.platform.h
new file mode 100644
index 0000000..6cf6c81
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/shared_runtime_tensor.platform.h
@@ -0,0 +1,43 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "runtime_tensor_impl.h"
+
+BEGIN_NS_NNCASE_RUNTIME
+
+namespace detail {
+struct host_memory_block;
+
+struct NNCASE_API physical_memory_block {
+    uintptr_t physical_address;
+    bool owned;
+
+    physical_memory_block() noexcept;
+    ~physical_memory_block();
+    physical_memory_block(const physical_memory_block &) = delete;
+    physical_memory_block(physical_memory_block &&other) noexcept;
+    physical_memory_block &operator=(const physical_memory_block &) = delete;
+    physical_memory_block &operator=(physical_memory_block &&other) noexcept;
+
+    void free(NNCASE_UNUSED host_memory_block &block) noexcept;
+
+    static result<void> acknowledge(host_memory_block &block) noexcept;
+    static result<void> allocate(host_memory_block &block) noexcept;
+    static result<void> sync(host_memory_block &block,
+                             host_runtime_tensor::sync_op_t op) noexcept;
+};
+} // namespace detail
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/simple_types.h b/third_party/nncase/riscv64/include/nncase/runtime/simple_types.h
new file mode 100644
index 0000000..cebc780
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/simple_types.h
@@ -0,0 +1,192 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include "bfloat16.h"
+#include "half.h"
+#include "small_vector.hpp"
+#include <array>
+
+namespace nncase {
+typedef enum : uint8_t {
+#define DEFINE_TYPECODE(id, name, value) dt_##id = value,
+#include "typecodes.def"
+#undef DEFINE_TYPECODE
+} typecode_t;
+
+struct scalar {
+    typecode_t type;
+    std::aligned_storage_t<8> storage;
+
+    scalar() = default;
+
+    scalar(int8_t value) noexcept {
+        type = dt_int8;
+        as<int8_t>() = value;
+    }
+
+    scalar(int16_t value) noexcept {
+        type = dt_int16;
+        as<int16_t>() = value;
+    }
+
+    scalar(int32_t value) noexcept {
+        type = dt_int32;
+        as<int32_t>() = value;
+    }
+
+    scalar(uint8_t value) noexcept {
+        type = dt_uint8;
+        as<uint8_t>() = value;
+    }
+
+    scalar(uint16_t value) noexcept {
+        type = dt_uint16;
+        as<uint16_t>() = value;
+    }
+
+    scalar(uint32_t value) noexcept {
+        type = dt_uint32;
+        as<uint32_t>() = value;
+    }
+
+    scalar(bfloat16 value) noexcept {
+        type = dt_bfloat16;
+        as<bfloat16>() = value;
+    }
+
+    scalar(half value) noexcept {
+        type = dt_float16;
+        as<half>() = value;
+    }
+
+    scalar(float value) noexcept {
+        type = dt_float32;
+        as<float>() = value;
+    }
+
+    template <class T> T &as() noexcept {
+        return *reinterpret_cast<T *>(&storage);
+    }
+
+    template <class T> const T &as() const noexcept {
+        return *reinterpret_cast<const T *>(&storage);
+    }
+};
+
+inline constexpr size_t typecode_bytes(typecode_t typecode) {
+    switch (typecode) {
+    case dt_boolean:
+    case dt_uint8:
+    case dt_int8:
+        return 1;
+    case dt_uint16:
+    case dt_int16:
+    case dt_float16:
+    case dt_bfloat16:
+        return 2;
+    case dt_uint32:
+    case dt_int32:
+    case dt_float32:
+        return 4;
+    case dt_uint64:
+    case dt_int64:
+    case dt_float64:
+        return 8;
+    case dt_pointer:
+        return sizeof(intptr_t);
+    default:
+        return -1;
+    }
+}
+
+struct padding {
+    int32_t before;
+    int32_t after;
+    int32_t interior = 0;
+
+    int32_t sum() const noexcept { return before + after; }
+
+    static padding zero() noexcept { return {}; }
+};
+
+using uuid_t = std::array<uint8_t, 16>;
+using dims_t = itlib::small_vector<size_t, 8>;
+using axes_t = itlib::small_vector<int64_t, 8>;
+using strides_t = itlib::small_vector<size_t, 8>;
+using paddings_t = itlib::small_vector<padding, 4>;
+
+template <class... Ints>
+auto fixed_dims(Ints &&...values) -> std::array<size_t, sizeof...(Ints)> {
+    return {(size_t)values...};
+}
+
+template <class T> struct value_range {
+    T min;
+    T max;
+
+    static constexpr value_range<T> full() noexcept {
+        if (std::is_floating_point<T>::value ||
+            std::is_same<T, bfloat16>::value || std::is_same<T, half>::value)
+            return {-std::numeric_limits<T>::infinity(),
+                    std::numeric_limits<T>::infinity()};
+        else
+            return {std::numeric_limits<T>::lowest(),
+                    std::numeric_limits<T>::max()};
+    }
+
+    static constexpr value_range<T> nonnegative() noexcept {
+        return {0, std::numeric_limits<T>::max()};
+    }
+
+    constexpr T length() const noexcept { return max - min; }
+};
+
+typedef struct _quant_param {
+    int32_t zero_point;
+    float scale;
+
+    template <class T> constexpr value_range<float> range() const noexcept {
+        return {(std::numeric_limits<T>::lowest() - zero_point) * scale,
+                (std::numeric_limits<T>::max() - zero_point) * scale};
+    }
+} quant_param_t;
+
+inline bool operator==(const quant_param_t &lhs,
+                       const quant_param_t &rhs) noexcept {
+    return lhs.zero_point == rhs.zero_point && lhs.scale == rhs.scale;
+}
+
+inline bool almost_equal(const quant_param_t &lhs,
+                         const quant_param_t &rhs) noexcept {
+    return lhs.zero_point == rhs.zero_point &&
+           fabs(lhs.scale - rhs.scale) <= std::numeric_limits<float>::epsilon();
+}
+
+namespace runtime {
+typedef enum sync_op_ { sync_invalidate, sync_write_back } sync_op_t;
+
+typedef enum map_access_ {
+    map_none = 0,
+    map_read = 1,
+    map_write = 2,
+    map_read_write = 3
+} map_access_t;
+
+DEFINE_ENUM_BITMASK_OPERATORS(map_access_t)
+
+enum class host_sync_status_t { valid, need_invalidate, need_write_back };
+} // namespace runtime
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/small_vector.hpp b/third_party/nncase/riscv64/include/nncase/runtime/small_vector.hpp
new file mode 100644
index 0000000..1f541ed
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/small_vector.hpp
@@ -0,0 +1,1003 @@
+// itlib-small-vector v1.00
+//
+// std::vector-like class with a static buffer for initial capacity
+//
+// MIT License:
+// Copyright(c) 2016-2018 Chobolabs Inc.
+// Copyright(c) 2020 Borislav Stanimirov
+//
+// Permission is hereby granted, free of charge, to any person obtaining
+// a copy of this software and associated documentation files(the
+// "Software"), to deal in the Software without restriction, including
+// without limitation the rights to use, copy, modify, merge, publish,
+// distribute, sublicense, and / or sell copies of the Software, and to
+// permit persons to whom the Software is furnished to do so, subject to
+// the following conditions :
+//
+// The above copyright notice and this permission notice shall be
+// included in all copies or substantial portions of the Software.
+//
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+// NONINFRINGEMENT.IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
+// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+//
+//
+//                  VERSION HISTORY
+//
+//  1.00 (2020-10-14) Rebranded release from chobo-small-vector
+//
+//
+//                  DOCUMENTATION
+//
+// Simply include this file wherever you need.
+// It defines the class itlib::small_vector, which is a drop-in replacement of
+// std::vector, but with an initial capacity as a template argument.
+// It gives you the benefits of using std::vector, at the cost of having a
+// statically allocated buffer for the initial capacity, which gives you
+// cache-local data when the vector is small (smaller than the initial
+// capacity).
+//
+// When the size exceeds the capacity, the vector allocates memory via the
+// provided allocator, falling back to classic std::vector behavior.
+//
+// The second size_t template argument, RevertToStaticSize, is used when a
+// small_vector which has already switched to dynamically allocated size reduces
+// its size to a number smaller than that. In this case the vector's buffer
+// switches back to the staticallly allocated one
+//
+// A default value for the initial static capacity is provided so a replacement
+// in an existing code is possible with minimal changes to it.
+//
+// Example:
+//
+// itlib::small_vector<int, 4, 5> myvec; // a small_vector of size 0, initial
+// capacity 4, and revert size 4 (smaller than 5) myvec.resize(2); // vector is
+// {0,0} in static buffer myvec[1] = 11; // vector is {0,11} in static buffer
+// myvec.push_back(7); // vector is {0,11,7}  in static buffer
+// myvec.insert(myvec.begin() + 1, 3); // vector is {0,3,11,7} in static buffer
+// myvec.push_back(5); // vector is {0,3,11,7,5} in dynamically allocated memory
+// buffer myvec.erase(myvec.begin());  // vector is {3,11,7,5} back in static
+// buffer myvec.resize(5); // vector is {3,11,7,5,0} back in dynamically
+// allocated memory
+//
+//
+// Reference:
+//
+// itlib::small_vector is fully compatible with std::vector with
+// the following exceptions:
+// * when reducing the size with erase or resize the new size may fall below
+//   RevertToStaticSize (if it is not 0). In such a case the vector will
+//   revert to using its static buffer, invalidating all iterators (contrary
+//   to the standard)
+// * a method is added `revert_to_static()` which reverts to the static buffer
+//   if possible, but doesn't free the dynamically allocated one
+//
+// Other notes:
+//
+// * the default value for RevertToStaticSize is zero. This means that once a
+// dynamic
+//   buffer is allocated the data will never be put into the static one, even if
+//   the size allows it. Even if clear() is called. The only way to do so is to
+//   call shrink_to_fit() or revert_to_static()
+// * shrink_to_fit will free and reallocate if size != capacity and the data
+//   doesn't fit into the static buffer. It also will revert to the static
+//   buffer whenever possible regardless of the RevertToStaticSize value
+//
+//
+//                  Configuration
+//
+// The library has two configuration options. They can be set as #define-s
+// before including the header file, but it is recommended to change the code
+// of the library itself with the values you want, especially if you include
+// the library in many compilation units (as opposed to, say, a precompiled
+// header or a central header).
+//
+//                  Config out of range error handling
+//
+// An out of range error is a runtime error which is triggered when a method is
+// called with an iterator that doesn't belong to the vector's current range.
+// For example: vec.erase(vec.end() + 1);
+//
+// This is set by defining ITLIB_SMALL_VECTOR_ERROR_HANDLING to one of the
+// following values:
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE - no error handling. Crashes WILL
+//      ensue if the error is triggered.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW - std::out_of_range is thrown.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT - asserions are triggered.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW - combines assert and
+//      throw to catch errors more easily in debug mode
+//
+// To set this setting by editing the file change the line:
+// ```
+// #   define ITLIB_SMALL_VECTOR_ERROR_HANDLING
+// ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+// ```
+// to the default setting of your choice
+//
+//                  Config bounds checks:
+//
+// By default bounds checks are made in debug mode (via an asser) when accessing
+// elements (with `at` or `[]`). Iterators are not checked (yet...)
+//
+// To disable them, you can define ITLIB_SMALL_VECTOR_NO_DEBUG_BOUNDS_CHECK
+// before including the header.
+//
+//
+//                  TESTS
+//
+// You can find unit tests for small_vector in its official repo:
+// https://github.com/iboB/itlib/blob/master/test/
+//
+#pragma once
+
+#include <cstddef>
+#include <gsl/gsl-lite.hpp>
+#include <memory>
+#include <type_traits>
+
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE 0
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW 1
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT 2
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW 3
+
+#if !defined(ITLIB_SMALL_VECTOR_ERROR_HANDLING)
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING                                      \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+#endif
+
+#if ITLIB_SMALL_VECTOR_ERROR_HANDLING == ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond)
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+#include <stdexcept>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond)                             \
+    if (cond)                                                                  \
+    throw std::out_of_range("itlib::small_vector out of range")
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT
+#include <cassert>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond, rescue_return)              \
+    assert(!(cond) && "itlib::small_vector out of range")
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW
+#include <cassert>
+#include <stdexcept>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond, rescue_return)              \
+    do {                                                                       \
+        if (cond) {                                                            \
+            assert(false && "itlib::small_vector out of range");               \
+            throw std::out_of_range("itlib::small_vector out of range");       \
+        }                                                                      \
+    } while (false)
+#else
+#error "Unknown ITLIB_SMALL_VECTOR_ERRROR_HANDLING"
+#endif
+
+#if defined(ITLIB_SMALL_VECTOR_NO_DEBUG_BOUNDS_CHECK)
+#define I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i)
+#else
+#include <cassert>
+#define I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i) assert((i) < this->size())
+#endif
+
+namespace itlib {
+
+template <typename T, size_t StaticCapacity = 16, size_t RevertToStaticSize = 0,
+          class Alloc = std::allocator<T>>
+struct small_vector : Alloc {
+    static_assert(RevertToStaticSize <= StaticCapacity + 1,
+                  "itlib::small_vector: the revert-to-static size shouldn't "
+                  "exceed the static capacity by more than one");
+
+    using atraits = std::allocator_traits<Alloc>;
+
+  public:
+    using allocator_type = Alloc;
+    using value_type = typename atraits::value_type;
+    using size_type = typename atraits::size_type;
+    using difference_type = typename atraits::difference_type;
+    using reference = T &;
+    using const_reference = const T &;
+    using pointer = typename atraits::pointer;
+    using const_pointer = typename atraits::const_pointer;
+    using iterator = pointer;
+    using const_iterator = const_pointer;
+    using reverse_iterator = std::reverse_iterator<iterator>;
+    using const_reverse_iterator = std::reverse_iterator<const_iterator>;
+
+    static constexpr size_t static_capacity = StaticCapacity;
+    static constexpr intptr_t revert_to_static_size = RevertToStaticSize;
+
+    small_vector() : small_vector(Alloc()) {}
+
+    small_vector(const Alloc &alloc)
+        : Alloc(alloc),
+          m_capacity(StaticCapacity),
+          m_dynamic_capacity(0),
+          m_dynamic_data(nullptr) {
+        m_begin = m_end = static_begin_ptr();
+    }
+
+    explicit small_vector(size_t count, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        resize(count);
+    }
+
+    explicit small_vector(size_t count, const T &value,
+                          const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(count, value);
+    }
+
+    template <class InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    small_vector(InputIterator first, InputIterator last,
+                 const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(first, last);
+    }
+
+    small_vector(std::initializer_list<T> l, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(l);
+    }
+
+    template <class U>
+    small_vector(gsl::span<U> c, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(c.begin(), c.end());
+    }
+
+    small_vector(const small_vector &v)
+        : small_vector(v, atraits::select_on_container_copy_construction(
+                              v.get_allocator())) {}
+
+    small_vector(const small_vector &v, const Alloc &alloc)
+        : Alloc(alloc), m_dynamic_capacity(0), m_dynamic_data(nullptr) {
+        if (v.size() > StaticCapacity) {
+            m_dynamic_capacity = v.size();
+            m_begin = m_end = m_dynamic_data =
+                atraits::allocate(get_alloc(), m_dynamic_capacity);
+            m_capacity = v.size();
+        } else {
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        }
+
+        for (auto p = v.m_begin; p != v.m_end; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+    }
+
+    small_vector(small_vector &&v)
+        : Alloc(std::move(v.get_alloc())),
+          m_capacity(v.m_capacity),
+          m_dynamic_capacity(v.m_dynamic_capacity),
+          m_dynamic_data(v.m_dynamic_data) {
+        if (v.m_begin == v.static_begin_ptr()) {
+            m_begin = m_end = static_begin_ptr();
+            for (auto p = v.m_begin; p != v.m_end; ++p) {
+                atraits::construct(get_alloc(), m_end, std::move(*p));
+                ++m_end;
+            }
+
+            v.clear();
+        } else {
+            m_begin = v.m_begin;
+            m_end = v.m_end;
+        }
+
+        v.m_dynamic_capacity = 0;
+        v.m_dynamic_data = nullptr;
+        v.m_begin = v.m_end = v.static_begin_ptr();
+        v.m_capacity = StaticCapacity;
+    }
+
+    ~small_vector() {
+        clear();
+
+        if (m_dynamic_data) {
+            atraits::deallocate(get_alloc(), m_dynamic_data,
+                                m_dynamic_capacity);
+        }
+    }
+
+    small_vector &operator=(const small_vector &v) {
+        if (this == &v) {
+            // prevent self usurp
+            return *this;
+        }
+
+        clear();
+
+        m_begin = m_end = choose_data(v.size());
+
+        for (auto p = v.m_begin; p != v.m_end; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+
+        update_capacity();
+
+        return *this;
+    }
+
+    small_vector &operator=(small_vector &&v) {
+        clear();
+
+        get_alloc() = std::move(v.get_alloc());
+        m_capacity = v.m_capacity;
+        m_dynamic_capacity = v.m_dynamic_capacity;
+        m_dynamic_data = v.m_dynamic_data;
+
+        if (v.m_begin == v.static_begin_ptr()) {
+            m_begin = m_end = static_begin_ptr();
+            for (auto p = v.m_begin; p != v.m_end; ++p) {
+                atraits::construct(get_alloc(), m_end, std::move(*p));
+                ++m_end;
+            }
+
+            v.clear();
+        } else {
+            m_begin = v.m_begin;
+            m_end = v.m_end;
+        }
+
+        v.m_dynamic_capacity = 0;
+        v.m_dynamic_data = nullptr;
+        v.m_begin = v.m_end = v.static_begin_ptr();
+        v.m_capacity = StaticCapacity;
+
+        return *this;
+    }
+
+    void assign(size_type count, const T &value) {
+        clear();
+        assign_impl(count, value);
+    }
+
+    template <class InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    void assign(InputIterator first, InputIterator last) {
+        clear();
+        assign_impl(first, last);
+    }
+
+    void assign(std::initializer_list<T> ilist) {
+        clear();
+        assign_impl(ilist);
+    }
+
+    allocator_type get_allocator() const { return get_alloc(); }
+
+    const_reference at(size_type i) const {
+        I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i);
+        return *(m_begin + i);
+    }
+
+    reference at(size_type i) {
+        I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i);
+        return *(m_begin + i);
+    }
+
+    const_reference operator[](size_type i) const { return at(i); }
+
+    reference operator[](size_type i) { return at(i); }
+
+    const_reference front() const { return at(0); }
+
+    reference front() { return at(0); }
+
+    const_reference back() const { return *(m_end - 1); }
+
+    reference back() { return *(m_end - 1); }
+
+    const_pointer data() const noexcept { return m_begin; }
+
+    pointer data() noexcept { return m_begin; }
+
+    // iterators
+    iterator begin() noexcept { return m_begin; }
+
+    const_iterator begin() const noexcept { return m_begin; }
+
+    const_iterator cbegin() const noexcept { return m_begin; }
+
+    iterator end() noexcept { return m_end; }
+
+    const_iterator end() const noexcept { return m_end; }
+
+    const_iterator cend() const noexcept { return m_end; }
+
+    reverse_iterator rbegin() noexcept { return reverse_iterator(end()); }
+
+    const_reverse_iterator rbegin() const noexcept {
+        return const_reverse_iterator(end());
+    }
+
+    const_reverse_iterator crbegin() const noexcept {
+        return const_reverse_iterator(end());
+    }
+
+    reverse_iterator rend() noexcept { return reverse_iterator(begin()); }
+
+    const_reverse_iterator rend() const noexcept {
+        return const_reverse_iterator(begin());
+    }
+
+    const_reverse_iterator crend() const noexcept {
+        return const_reverse_iterator(begin());
+    }
+
+    // capacity
+    bool empty() const noexcept { return m_begin == m_end; }
+
+    size_t size() const noexcept { return m_end - m_begin; }
+
+    size_t max_size() const noexcept { return atraits::max_size(); }
+
+    void reserve(size_type new_cap) {
+        if (new_cap <= m_capacity)
+            return;
+
+        auto new_buf = choose_data(new_cap);
+
+        assert(new_buf !=
+               m_begin); // should've been handled by new_cap <= m_capacity
+        assert(
+            new_buf !=
+            static_begin_ptr()); // we should never reserve into static memory
+
+        const auto s = size();
+        if (s < RevertToStaticSize) {
+            // we've allocated enough memory for the dynamic buffer but don't
+            // move there until we have to
+            return;
+        }
+
+        // now we need to transfer the existing elements into the new buffer
+        for (size_type i = 0; i < s; ++i) {
+            atraits::construct(get_alloc(), new_buf + i,
+                               std::move(*(m_begin + i)));
+        }
+
+        // free old elements
+        for (size_type i = 0; i < s; ++i) {
+            atraits::destroy(get_alloc(), m_begin + i);
+        }
+
+        if (m_begin != static_begin_ptr()) {
+            // we've moved from dyn to dyn memory, so deallocate the old one
+            atraits::deallocate(get_alloc(), m_begin, m_capacity);
+        }
+
+        m_begin = new_buf;
+        m_end = new_buf + s;
+        m_capacity = m_dynamic_capacity;
+    }
+
+    size_t capacity() const noexcept { return m_capacity; }
+
+    void shrink_to_fit() {
+        const auto s = size();
+
+        if (s == m_capacity)
+            return;
+        if (m_begin == static_begin_ptr())
+            return;
+
+        auto old_end = m_end;
+
+        if (s < StaticCapacity) {
+            // revert to static capacity
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        } else {
+            // alloc new smaller buffer
+            m_begin = m_end = atraits::allocate(get_alloc(), s);
+            m_capacity = s;
+        }
+
+        for (auto p = m_dynamic_data; p != old_end; ++p) {
+            atraits::construct(get_alloc(), m_end, std::move(*p));
+            ++m_end;
+            atraits::destroy(get_alloc(), p);
+        }
+
+        atraits::deallocate(get_alloc(), m_dynamic_data, m_dynamic_capacity);
+        m_dynamic_data = nullptr;
+        m_dynamic_capacity = 0;
+    }
+
+    void revert_to_static() {
+        const auto s = size();
+        if (m_begin == static_begin_ptr())
+            return; // we're already there
+        if (s > StaticCapacity)
+            return; // nothing we can do
+
+        // revert to static capacity
+        auto old_end = m_end;
+        m_begin = m_end = static_begin_ptr();
+        m_capacity = StaticCapacity;
+        for (auto p = m_dynamic_data; p != old_end; ++p) {
+            atraits::construct(get_alloc(), m_end, std::move(*p));
+            ++m_end;
+            atraits::destroy(get_alloc(), p);
+        }
+    }
+
+    // modifiers
+    void clear() noexcept {
+        for (auto p = m_begin; p != m_end; ++p) {
+            atraits::destroy(get_alloc(), p);
+        }
+
+        if (RevertToStaticSize > 0) {
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        } else {
+            m_end = m_begin;
+        }
+    }
+
+    iterator insert(const_iterator position, const value_type &val) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, val);
+        return pos;
+    }
+
+    iterator insert(const_iterator position, value_type &&val) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, std::move(val));
+        return pos;
+    }
+
+    iterator insert(const_iterator position, size_type count,
+                    const value_type &val) {
+        auto pos = grow_at(position, count);
+        for (size_type i = 0; i < count; ++i) {
+            atraits::construct(get_alloc(), pos + i, val);
+        }
+        return pos;
+    }
+
+    template <typename InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    iterator insert(const_iterator position, InputIterator first,
+                    InputIterator last) {
+        auto pos = grow_at(position, last - first);
+        auto np = pos;
+        for (auto p = first; p != last; ++p, ++np) {
+            atraits::construct(get_alloc(), np, *p);
+        }
+        return pos;
+    }
+
+    iterator insert(const_iterator position, std::initializer_list<T> ilist) {
+        auto pos = grow_at(position, ilist.size());
+        size_type i = 0;
+        for (auto &elem : ilist) {
+            atraits::construct(get_alloc(), pos + i, elem);
+            ++i;
+        }
+        return pos;
+    }
+
+    template <typename... Args>
+    iterator emplace(const_iterator position, Args &&...args) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, std::forward<Args>(args)...);
+        return pos;
+    }
+
+    iterator erase(const_iterator position) { return shrink_at(position, 1); }
+
+    iterator erase(const_iterator first, const_iterator last) {
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(first > last);
+        return shrink_at(first, last - first);
+    }
+
+    void push_back(const_reference val) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, val);
+    }
+
+    void push_back(T &&val) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, std::move(val));
+    }
+
+    template <typename... Args> reference emplace_back(Args &&...args) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, std::forward<Args>(args)...);
+        return *pos;
+    }
+
+    void pop_back() { shrink_at(m_end - 1, 1); }
+
+    void resize(size_type n, const value_type &v) {
+        auto new_buf = choose_data(n);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            auto new_end = m_begin + n;
+
+            while (m_end > new_end) {
+                atraits::destroy(get_alloc(), --m_end);
+            }
+
+            while (new_end > m_end) {
+                atraits::construct(get_alloc(), m_end++, v);
+            }
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            const auto s = size();
+            const auto num_transfer = n < s ? n : s;
+
+            for (size_type i = 0; i < num_transfer; ++i) {
+                atraits::construct(get_alloc(), new_buf + i,
+                                   std::move(*(m_begin + i)));
+            }
+
+            // free obsoletes
+            for (size_type i = 0; i < s; ++i) {
+                atraits::destroy(get_alloc(), m_begin + i);
+            }
+
+            // construct new elements
+            for (size_type i = num_transfer; i < n; ++i) {
+                atraits::construct(get_alloc(), new_buf + i, v);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            if (new_buf == static_begin_ptr()) {
+                m_capacity = StaticCapacity;
+            } else {
+                m_capacity = m_dynamic_capacity;
+            }
+
+            m_begin = new_buf;
+            m_end = new_buf + n;
+        }
+    }
+
+    void resize(size_type n) {
+        auto new_buf = choose_data(n);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            auto new_end = m_begin + n;
+
+            while (m_end > new_end) {
+                atraits::destroy(get_alloc(), --m_end);
+            }
+
+            while (new_end > m_end) {
+                atraits::construct(get_alloc(), m_end++);
+            }
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            const auto s = size();
+            const auto num_transfer = n < s ? n : s;
+
+            for (size_type i = 0; i < num_transfer; ++i) {
+                atraits::construct(get_alloc(), new_buf + i,
+                                   std::move(*(m_begin + i)));
+            }
+
+            // free obsoletes
+            for (size_type i = 0; i < n; ++i) {
+                atraits::destroy(get_alloc(), m_begin + i);
+            }
+
+            // construct new elements
+            for (size_type i = num_transfer; i < s; ++i) {
+                atraits::construct(get_alloc(), new_buf + i);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            if (new_buf == static_begin_ptr()) {
+                m_capacity = StaticCapacity;
+            } else {
+                m_capacity = m_dynamic_capacity;
+            }
+
+            m_begin = new_buf;
+            m_end = new_buf + n;
+        }
+    }
+
+  private:
+    T *static_begin_ptr() {
+        return reinterpret_cast<pointer>(m_static_data + 0);
+    }
+
+    // increase the size by splicing the elements in such a way that
+    // a hole of uninitialized elements is left at position, with size num
+    // returns the (potentially new) address of the hole
+    T *grow_at(const T *cp, size_t num) {
+        auto position = const_cast<T *>(cp);
+
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(position < m_begin ||
+                                             position > m_end);
+
+        const auto s = size();
+        auto new_buf = choose_data(s + num);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            m_end = m_begin + s + num;
+
+            for (auto p = m_end - num - 1; p >= position; --p) {
+                atraits::construct(get_alloc(), p + num, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            return position;
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            position = new_buf + (position - m_begin);
+
+            auto p = m_begin;
+            auto np = new_buf;
+
+            for (; np != position; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+            }
+
+            np += num;
+            for (; p != m_end; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+            }
+
+            // destroy old
+            for (p = m_begin; p != m_end; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            m_capacity = m_dynamic_capacity;
+
+            m_begin = new_buf;
+            m_end = new_buf + s + num;
+
+            return position;
+        }
+    }
+
+    T *shrink_at(const T *cp, size_t num) {
+        auto position = const_cast<T *>(cp);
+
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(
+            position < m_begin || position > m_end || position + num > m_end);
+
+        const auto s = size();
+        if (s - num == 0) {
+            clear();
+            return m_end;
+        }
+
+        auto new_buf = choose_data(s - num);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            for (auto p = position, np = position + num; np != m_end;
+                 ++p, ++np) {
+                atraits::destroy(get_alloc(), p);
+                atraits::construct(get_alloc(), p, std::move(*np));
+            }
+
+            for (auto p = m_end - num; p != m_end; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            m_end -= num;
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            assert(new_buf ==
+                   static_begin_ptr()); // since we're shrinking that's the only
+                                        // way to have a new buffer
+
+            m_capacity = StaticCapacity;
+
+            auto p = m_begin, np = new_buf;
+            for (; p != position; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            for (; p != position + num; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            for (; np != new_buf + s - num; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            position = new_buf + (position - m_begin);
+            m_begin = new_buf;
+            m_end = np;
+        }
+
+        return ++position;
+    }
+
+    void assign_impl(size_type count, const T &value) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(count);
+        for (size_type i = 0; i < count; ++i) {
+            atraits::construct(get_alloc(), m_end, value);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    template <class InputIterator>
+    void assign_impl(InputIterator first, InputIterator last) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(last - first);
+        for (auto p = first; p != last; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    void assign_impl(std::initializer_list<T> ilist) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(ilist.size());
+        for (auto &elem : ilist) {
+            atraits::construct(get_alloc(), m_end, elem);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    void update_capacity() {
+        if (m_begin == static_begin_ptr()) {
+            m_capacity = StaticCapacity;
+        } else {
+            m_capacity = m_dynamic_capacity;
+        }
+    }
+
+    T *choose_data(size_t desired_capacity) {
+        if (m_begin == m_dynamic_data) {
+            // we're at the dyn buffer, so see if it needs resize or revert to
+            // static
+
+            if (desired_capacity > m_dynamic_capacity) {
+                while (m_dynamic_capacity < desired_capacity) {
+                    // grow by roughly 1.5
+                    m_dynamic_capacity *= 3;
+                    ++m_dynamic_capacity;
+                    m_dynamic_capacity /= 2;
+                }
+
+                m_dynamic_data =
+                    atraits::allocate(get_alloc(), m_dynamic_capacity);
+                return m_dynamic_data;
+            } else if (desired_capacity < RevertToStaticSize) {
+                // we're reverting to the static buffer
+                return static_begin_ptr();
+            } else {
+                // if the capacity and we don't revert to static, just do
+                // nothing
+                return m_dynamic_data;
+            }
+        } else {
+            assert(m_begin == static_begin_ptr()); // corrupt begin ptr?
+
+            if (desired_capacity > StaticCapacity) {
+                // we must move to dyn memory
+
+                // see if we have enough
+                if (desired_capacity > m_dynamic_capacity) {
+                    // we need to allocate more
+                    // we don't have anything to destroy, so we can also
+                    // deallocate the buffer
+                    if (m_dynamic_data) {
+                        atraits::deallocate(get_alloc(), m_dynamic_data,
+                                            m_dynamic_capacity);
+                    }
+
+                    m_dynamic_capacity = desired_capacity;
+                    m_dynamic_data =
+                        atraits::allocate(get_alloc(), m_dynamic_capacity);
+                }
+
+                return m_dynamic_data;
+            } else {
+                // we have enough capacity as it is
+                return static_begin_ptr();
+            }
+        }
+    }
+
+    allocator_type &get_alloc() { return static_cast<allocator_type &>(*this); }
+    const allocator_type &get_alloc() const {
+        return static_cast<const allocator_type &>(*this);
+    }
+
+    pointer m_begin;
+    pointer m_end;
+
+    size_t m_capacity;
+    typename std::aligned_storage<sizeof(T), std::alignment_of<T>::value>::type
+        m_static_data[StaticCapacity];
+
+    size_t m_dynamic_capacity;
+    pointer m_dynamic_data;
+};
+
+template <typename T, size_t StaticCapacity, size_t RevertToStaticSize,
+          class Alloc>
+bool operator==(
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &a,
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &b) {
+    if (a.size() != b.size()) {
+        return false;
+    }
+
+    for (size_t i = 0; i < a.size(); ++i) {
+        if (a[i] != b[i])
+            return false;
+    }
+
+    return true;
+}
+
+template <typename T, size_t StaticCapacity, size_t RevertToStaticSize,
+          class Alloc>
+bool operator!=(
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &a,
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &b) {
+    if (a.size() != b.size()) {
+        return true;
+    }
+
+    for (size_t i = 0; i < a.size(); ++i) {
+        if (a[i] != b[i])
+            return true;
+    }
+
+    return false;
+}
+
+} // namespace itlib
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/span_reader.h b/third_party/nncase/riscv64/include/nncase/runtime/span_reader.h
new file mode 100644
index 0000000..720bc48
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/span_reader.h
@@ -0,0 +1,145 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+#include <iterator>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/dbg.h>
+#include <string>
+#include <vector>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class span_reader {
+  public:
+    span_reader(gsl::span<const gsl::byte> span)
+        : begin_(span.begin()), end_(span.end()) {}
+
+    const gsl::byte *tell() const noexcept { return begin_; }
+    bool empty() const noexcept { return begin_ == end_; }
+    size_t avail() const noexcept { return end_ - begin_; }
+
+    void seek(const gsl::byte *pos) noexcept { begin_ = pos; }
+
+    template <class T> T read() {
+        auto value = *reinterpret_cast<const T *>(begin_);
+        advance(sizeof(T));
+        return value;
+    }
+
+    template <class T> T read_unaligned() {
+        alignas(T) uint8_t storage[sizeof(T)];
+        std::memcpy(storage, begin_, sizeof(T));
+        advance(sizeof(T));
+        return *reinterpret_cast<const T *>(storage);
+    }
+
+    template <class T> void read(T &value) {
+        value = *reinterpret_cast<const T *>(begin_);
+        advance(sizeof(T));
+    }
+
+    template <class T> void read_span(gsl::span<const T> &span, size_t size) {
+        span = {reinterpret_cast<const T *>(begin_), size};
+        advance(sizeof(T) * size);
+    }
+
+    template <class T = gsl::byte> gsl::span<const T> read_span(size_t size) {
+        gsl::span<const T> span(reinterpret_cast<const T *>(begin_), size);
+        advance(sizeof(T) * size);
+        return span;
+    }
+
+    std::string read_string() {
+        auto span = read_until((gsl::byte)0).as_span<const char>();
+        advance(1);
+        return {span.begin(), span.end()};
+    }
+
+    std::vector<std::string> read_string_array() {
+        std::vector<std::string> array;
+        while (true) {
+            if (peek<char>() == '\0') {
+                advance(1);
+                break;
+            }
+            array.emplace_back(read_string());
+        }
+        return array;
+    }
+
+    void read_avail(gsl::span<const gsl::byte> &span) {
+        span = {begin_, end_};
+        begin_ = end_;
+    }
+
+    gsl::span<const gsl::byte> read_until(gsl::byte value) {
+        auto it = std::find(begin_, end_, value);
+        return read_span((size_t)std::distance(begin_, it));
+    }
+
+    gsl::span<const gsl::byte> read_avail() {
+        gsl::span<const gsl::byte> span;
+        read_avail(span);
+        return span;
+    }
+
+    gsl::span<const gsl::byte> peek_avail() { return {begin_, end_}; }
+
+    template <class T> T peek_with_offset(size_t offset) {
+        auto value = *reinterpret_cast<const T *>(begin_ + offset);
+        return value;
+    }
+
+    template <class T> T peek() { return peek_with_offset<T>(0); }
+
+    template <class T> T peek_unaligned_with_offset(size_t offset) {
+        T value;
+        std::memcpy(&value, begin_ + offset, sizeof(T));
+        return value;
+    }
+
+    template <class T> T peek_unaligned() {
+        return peek_unaligned_with_offset<T>(0);
+    }
+
+    template <class T> const T *peek_ref() {
+        auto ptr = reinterpret_cast<const T *>(begin_);
+        return ptr;
+    }
+
+    template <class T> const T *get_ref() {
+        auto ptr = peek_ref<T>();
+        advance(sizeof(T));
+        return ptr;
+    }
+
+    template <class T> void get_ref(const T *&ptr) { ptr = get_ref<T>(); }
+
+    void skip(size_t count) { advance(count); }
+
+  private:
+    void advance(size_t count) {
+        begin_ += count;
+        dbg_check(begin_ <= end_);
+    }
+
+  private:
+    const gsl::byte *begin_;
+    const gsl::byte *end_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_profile.h b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_profile.h
new file mode 100644
index 0000000..013cbae
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_profile.h
@@ -0,0 +1,49 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "opcode.h"
+#include <iomanip>
+#include <iostream>
+#include <tuple>
+#include <vector>
+
+extern "C" {
+double get_ms_time();
+}
+
+class op_profile {
+  public:
+    op_profile(const std::string &op_name, uint8_t op_type)
+        : op_name_(op_name), op_type_(op_type) {
+        begin_ = get_ms_time();
+    }
+
+    ~op_profile() {
+        end_ = get_ms_time();
+        op_timing_.push_back(std::make_tuple(op_name_, op_type_, begin_, end_));
+    }
+
+    static void print();
+
+  public:
+    static std::vector<std::tuple<std::string, uint8_t, double, double>>
+        op_timing_;
+
+  private:
+    double begin_;
+    double end_;
+    std::string op_name_;
+    uint8_t op_type_;
+};
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_reader.h b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_reader.h
new file mode 100644
index 0000000..52670fb
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/op_reader.h
@@ -0,0 +1,1895 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../error.h"
+#include "../result.h"
+#include "../span_reader.h"
+#include "opcode.h"
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+template <opcode_t Op> struct op_reader;
+
+template <> struct op_reader<opcode_t::NOP> {
+    nop_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        nop_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR> {
+    br_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR_TRUE> {
+    br_true_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_true_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR_FALSE> {
+    br_false_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_false_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::RET> {
+    ret_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ret_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CALL> {
+    call_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        call_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::ECALL> {
+    ecall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ecall_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::EXTCALL> {
+    extcall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        extcall_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        op.is_prim_func = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CUSCALL> {
+    cuscall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cuscall_op_t op;
+        op.registered_name = reader.read_string();
+        op.fields_span = reader.read_span(reader.read_unaligned<uint32_t>());
+        op.args = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::THROW> {
+    throw_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        throw_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BREAK> {
+    break_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        break_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4> {
+    ldc_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_op_t op;
+        op.imm = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDNULL> {
+    ldnull_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldnull_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4_0> {
+    ldc_i4_0_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_0_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4_1> {
+    ldc_i4_1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_R4> {
+    ldc_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_r4_op_t op;
+        op.imm = reader.read_unaligned<float>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I1> {
+    ldind_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I2> {
+    ldind_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I4> {
+    ldind_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I> {
+    ldind_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U1> {
+    ldind_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U2> {
+    ldind_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U4> {
+    ldind_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U> {
+    ldind_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_BR2> {
+    ldind_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_R4> {
+    ldind_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I1> {
+    stind_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I2> {
+    stind_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I4> {
+    stind_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I> {
+    stind_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_BR2> {
+    stind_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_R4> {
+    stind_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LEA_GP> {
+    lea_gp_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        lea_gp_op_t op;
+        op.gpid = reader.read_unaligned<uint8_t>();
+        op.offset = reader.read_unaligned<int64_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I1> {
+    ldelem_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I2> {
+    ldelem_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I4> {
+    ldelem_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I> {
+    ldelem_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U1> {
+    ldelem_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U2> {
+    ldelem_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U4> {
+    ldelem_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U> {
+    ldelem_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_BR2> {
+    ldelem_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_R4> {
+    ldelem_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I1> {
+    stelem_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I2> {
+    stelem_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I4> {
+    stelem_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I> {
+    stelem_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_BR2> {
+    stelem_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_R4> {
+    stelem_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG> {
+    ldarg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_0> {
+    ldarg_0_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_0_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_1> {
+    ldarg_1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_2> {
+    ldarg_2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_3> {
+    ldarg_3_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_3_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_4> {
+    ldarg_4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_5> {
+    ldarg_5_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_5_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTUPLE_ELEM> {
+    ldtuple_elem_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtuple_elem_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTUPLE> {
+    ldtuple_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtuple_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDDATATYPE> {
+    lddatatype_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        lddatatype_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTENSOR> {
+    ldtensor_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtensor_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDLOCAL> {
+    ldlocal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldlocal_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STLOCAL> {
+    stlocal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stlocal_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDSCALAR> {
+    ldscalar_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldscalar_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DUP> {
+    dup_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        dup_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::POP> {
+    pop_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        pop_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::NEG> {
+    neg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        neg_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::ADD> {
+    add_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        add_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SUB> {
+    sub_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        sub_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::MUL> {
+    mul_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        mul_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DIV> {
+    div_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        div_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DIV_U> {
+    div_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        div_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::REM> {
+    rem_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        rem_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::REM_U> {
+    rem_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        rem_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::AND> {
+    and_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        and_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::OR> {
+    or_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        or_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::XOR> {
+    xor_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        xor_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::NOT> {
+    not_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        not_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHL> {
+    shl_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shl_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHR> {
+    shr_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shr_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHR_U> {
+    shr_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shr_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLT> {
+    clt_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        clt_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLT_U> {
+    clt_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        clt_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLE> {
+    cle_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cle_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLE_U> {
+    cle_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cle_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CEQ> {
+    ceq_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ceq_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGE> {
+    cge_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cge_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGE_U> {
+    cge_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cge_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGT> {
+    cgt_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cgt_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGT_U> {
+    cgt_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cgt_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CNE> {
+    cne_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cne_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I1> {
+    conv_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I2> {
+    conv_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I4> {
+    conv_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I> {
+    conv_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U1> {
+    conv_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U2> {
+    conv_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U4> {
+    conv_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U> {
+    conv_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_BR2> {
+    conv_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_R4> {
+    conv_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_r4_op_t op;
+        return op;
+    }
+};
+
+template <tensor_function_t Op> struct tensor_op_reader;
+
+template <> struct tensor_op_reader<tensor_function_t::batch_normalization> {
+    tensor_batch_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_batch_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::batch_to_space> {
+    tensor_batch_to_space_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_batch_to_space_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::binary> {
+    tensor_binary_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_binary_op_t op;
+        op.binary_op =
+            static_cast<binary_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::bitcast> {
+    tensor_bitcast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_bitcast_op_t op;
+        op.type = reader.read_unaligned<prim_type_t>();
+        op.new_type = reader.read_unaligned<prim_type_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::broadcast> {
+    tensor_broadcast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_broadcast_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::broadcast_shape> {
+    tensor_broadcast_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_broadcast_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::bucket_pad> {
+    tensor_bucket_pad_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_bucket_pad_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::cast> {
+    tensor_cast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_cast_op_t op;
+        op.new_type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        op.cast_mode =
+            static_cast<cast_mode_t>(reader.read_unaligned<uint32_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::celu> {
+    tensor_celu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_celu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::clamp> {
+    tensor_clamp_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_clamp_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::compare> {
+    tensor_compare_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_compare_op_t op;
+        op.compare_op =
+            static_cast<compare_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::concat> {
+    tensor_concat_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_concat_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::condition> {
+    tensor_condition_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_condition_op_t op;
+        op.can_fold_const_call = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::constant_of_shape> {
+    tensor_constant_of_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_constant_of_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d> {
+    tensor_conv2d_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_shape> {
+    tensor_conv2d_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_transpose> {
+    tensor_conv2d_transpose_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_transpose_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_transpose_shape> {
+    tensor_conv2d_transpose_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_transpose_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::cum_sum> {
+    tensor_cum_sum_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_cum_sum_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::dequantize> {
+    tensor_dequantize_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_dequantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::elu> {
+    tensor_elu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_elu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::erf> {
+    tensor_erf_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_erf_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::expand> {
+    tensor_expand_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_expand_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fake_dequantize> {
+    tensor_fake_dequantize_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fake_dequantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fake_quantize> {
+    tensor_fake_quantize_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fake_quantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fix_shape> {
+    tensor_fix_shape_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fix_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::flatten> {
+    tensor_flatten_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_flatten_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather> {
+    tensor_gather_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather_elements> {
+    tensor_gather_elements_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_elements_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather_nd> {
+    tensor_gather_nd_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_nd_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gelu> {
+    tensor_gelu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gelu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::get_item> {
+    tensor_get_item_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_get_item_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::get_paddings> {
+    tensor_get_paddings_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_get_paddings_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hard_sigmoid> {
+    tensor_hard_sigmoid_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hard_sigmoid_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hard_swish> {
+    tensor_hard_swish_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hard_swish_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hardmax> {
+    tensor_hardmax_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hardmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::index_of> {
+    tensor_index_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_index_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::instance_normalization> {
+    tensor_instance_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_instance_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::l2_normalization> {
+    tensor_l2_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_l2_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::layer_norm> {
+    tensor_layer_norm_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_layer_norm_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        op.epsilon = reader.read_unaligned<float>();
+        op.use_mean = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::leaky_relu> {
+    tensor_leaky_relu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_leaky_relu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::log_softmax> {
+    tensor_log_softmax_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_log_softmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lp_normalization> {
+    tensor_lp_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lp_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lrn> {
+    tensor_lrn_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lrn_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lstm> {
+    tensor_lstm_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lstm_op_t op;
+        op.direction =
+            static_cast<lstmdirection_t>(reader.read_unaligned<uint32_t>());
+        op.layout =
+            static_cast<lstmlayout_t>(reader.read_unaligned<uint32_t>());
+        op.activations = reader.read_string_array();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::mat_mul> {
+    tensor_mat_mul_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_mat_mul_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::mat_mul_shape> {
+    tensor_mat_mul_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_mat_mul_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::normal> {
+    tensor_normal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_normal_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::normal_like> {
+    tensor_normal_like_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_normal_like_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::one_hot> {
+    tensor_one_hot_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_one_hot_op_t op;
+        op.one_hot_mode =
+            static_cast<one_hot_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::pad> {
+    tensor_pad_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_pad_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::prelu> {
+    tensor_prelu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_prelu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::prod> {
+    tensor_prod_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_prod_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::quant_param_of> {
+    tensor_quant_param_of_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_quant_param_of_op_t op;
+        op.quant_mode =
+            static_cast<quant_mode_t>(reader.read_unaligned<uint32_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::quantize> {
+    tensor_quantize_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_quantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::range> {
+    tensor_range_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_range_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::range_of> {
+    tensor_range_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_range_of_op_t op;
+        op.is_range_of_weight = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::rank> {
+    tensor_rank_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_rank_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce> {
+    tensor_reduce_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_op_t op;
+        op.reduce_op =
+            static_cast<reduce_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce_arg> {
+    tensor_reduce_arg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_arg_op_t op;
+        op.reduce_arg_op =
+            static_cast<reduce_arg_op_t>(reader.read_unaligned<uint8_t>());
+        op.dest_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce_window2d> {
+    tensor_reduce_window2d_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_window2d_op_t op;
+        op.reduce_op =
+            static_cast<reduce_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::relu> {
+    tensor_relu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_relu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::relu6> {
+    tensor_relu6_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_relu6_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::require> {
+    tensor_require_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_require_op_t op;
+        op.message = reader.read_string();
+        op.can_fold_const_call = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reshape> {
+    tensor_reshape_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reshape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reshape_shape> {
+    tensor_reshape_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reshape_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::resize_image> {
+    tensor_resize_image_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_resize_image_op_t op;
+        op.resize_mode =
+            static_cast<image_resize_mode_t>(reader.read_unaligned<uint8_t>());
+        op.transformation_mode =
+            static_cast<image_resize_transformation_mode_t>(
+                reader.read_unaligned<uint32_t>());
+        op.nearest_mode = static_cast<image_resize_nearest_mode_t>(
+            reader.read_unaligned<uint32_t>());
+        op.is_tfresize = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reverse_sequence> {
+    tensor_reverse_sequence_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reverse_sequence_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::scatter_nd> {
+    tensor_scatter_nd_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_scatter_nd_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::select> {
+    tensor_select_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_select_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::selu> {
+    tensor_selu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_selu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::shape_of> {
+    tensor_shape_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_shape_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::sigmoid> {
+    tensor_sigmoid_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_sigmoid_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::size_of> {
+    tensor_size_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_size_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::slice> {
+    tensor_slice_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_slice_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softmax> {
+    tensor_softmax_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softplus> {
+    tensor_softplus_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softplus_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softsign> {
+    tensor_softsign_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softsign_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::space_to_batch> {
+    tensor_space_to_batch_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_space_to_batch_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::split> {
+    tensor_split_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_split_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::squeeze> {
+    tensor_squeeze_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_squeeze_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::squeeze_shape> {
+    tensor_squeeze_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_squeeze_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::stack> {
+    tensor_stack_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_stack_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::swish> {
+    tensor_swish_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_swish_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::tile> {
+    tensor_tile_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_tile_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::top_k> {
+    tensor_top_k_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_top_k_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::transpose> {
+    tensor_transpose_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_transpose_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::transpose_shape> {
+    tensor_transpose_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_transpose_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::trilu> {
+    tensor_trilu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_trilu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unary> {
+    tensor_unary_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unary_op_t op;
+        op.unary_op = static_cast<unary_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::uniform> {
+    tensor_uniform_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_uniform_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::uniform_like> {
+    tensor_uniform_like_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_uniform_like_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unsqueeze> {
+    tensor_unsqueeze_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unsqueeze_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unsqueeze_shape> {
+    tensor_unsqueeze_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unsqueeze_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::where> {
+    tensor_where_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_where_op_t op;
+        op.is_tf_where = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+class NNCASE_API tensor_op_visitor {
+  public:
+    result<void> visit(tensor_function_t tensor_funct,
+                       span_reader &reader) noexcept;
+
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_batch_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::batch_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_batch_to_space_op_t &op) noexcept {
+        return default_visit(tensor_function_t::batch_to_space, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_binary_op_t &op) noexcept {
+        return default_visit(tensor_function_t::binary, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_bitcast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::bitcast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_broadcast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::broadcast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_broadcast_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::broadcast_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_bucket_pad_op_t &op) noexcept {
+        return default_visit(tensor_function_t::bucket_pad, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_cast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::cast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_celu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::celu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_clamp_op_t &op) noexcept {
+        return default_visit(tensor_function_t::clamp, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_compare_op_t &op) noexcept {
+        return default_visit(tensor_function_t::compare, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_concat_op_t &op) noexcept {
+        return default_visit(tensor_function_t::concat, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_condition_op_t &op) noexcept {
+        return default_visit(tensor_function_t::condition, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_constant_of_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::constant_of_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_transpose_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_transpose, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_transpose_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_transpose_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_cum_sum_op_t &op) noexcept {
+        return default_visit(tensor_function_t::cum_sum, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_dequantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::dequantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_elu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::elu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_erf_op_t &op) noexcept {
+        return default_visit(tensor_function_t::erf, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_expand_op_t &op) noexcept {
+        return default_visit(tensor_function_t::expand, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fake_dequantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fake_dequantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fake_quantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fake_quantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fix_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fix_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_flatten_op_t &op) noexcept {
+        return default_visit(tensor_function_t::flatten, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_elements_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather_elements, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_nd_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather_nd, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gelu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gelu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_get_item_op_t &op) noexcept {
+        return default_visit(tensor_function_t::get_item, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_get_paddings_op_t &op) noexcept {
+        return default_visit(tensor_function_t::get_paddings, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hard_sigmoid_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hard_sigmoid, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hard_swish_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hard_swish, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hardmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hardmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_index_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::index_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_instance_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::instance_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_l2_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::l2_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_layer_norm_op_t &op) noexcept {
+        return default_visit(tensor_function_t::layer_norm, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_leaky_relu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::leaky_relu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_log_softmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::log_softmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lp_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lp_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lrn_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lrn, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lstm_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lstm, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_mat_mul_op_t &op) noexcept {
+        return default_visit(tensor_function_t::mat_mul, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_mat_mul_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::mat_mul_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_normal_op_t &op) noexcept {
+        return default_visit(tensor_function_t::normal, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_normal_like_op_t &op) noexcept {
+        return default_visit(tensor_function_t::normal_like, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_one_hot_op_t &op) noexcept {
+        return default_visit(tensor_function_t::one_hot, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_pad_op_t &op) noexcept {
+        return default_visit(tensor_function_t::pad, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_prelu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::prelu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_prod_op_t &op) noexcept {
+        return default_visit(tensor_function_t::prod, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_quant_param_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::quant_param_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_quantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::quantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_range_op_t &op) noexcept {
+        return default_visit(tensor_function_t::range, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_range_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::range_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_rank_op_t &op) noexcept {
+        return default_visit(tensor_function_t::rank, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_arg_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce_arg, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_window2d_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce_window2d, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_relu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::relu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_relu6_op_t &op) noexcept {
+        return default_visit(tensor_function_t::relu6, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_require_op_t &op) noexcept {
+        return default_visit(tensor_function_t::require, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reshape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reshape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reshape_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reshape_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_resize_image_op_t &op) noexcept {
+        return default_visit(tensor_function_t::resize_image, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reverse_sequence_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reverse_sequence, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_scatter_nd_op_t &op) noexcept {
+        return default_visit(tensor_function_t::scatter_nd, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_select_op_t &op) noexcept {
+        return default_visit(tensor_function_t::select, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_selu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::selu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_shape_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::shape_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_sigmoid_op_t &op) noexcept {
+        return default_visit(tensor_function_t::sigmoid, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_size_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::size_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_slice_op_t &op) noexcept {
+        return default_visit(tensor_function_t::slice, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softplus_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softplus, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softsign_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softsign, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_space_to_batch_op_t &op) noexcept {
+        return default_visit(tensor_function_t::space_to_batch, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_split_op_t &op) noexcept {
+        return default_visit(tensor_function_t::split, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_squeeze_op_t &op) noexcept {
+        return default_visit(tensor_function_t::squeeze, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_squeeze_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::squeeze_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_stack_op_t &op) noexcept {
+        return default_visit(tensor_function_t::stack, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_swish_op_t &op) noexcept {
+        return default_visit(tensor_function_t::swish, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_tile_op_t &op) noexcept {
+        return default_visit(tensor_function_t::tile, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_top_k_op_t &op) noexcept {
+        return default_visit(tensor_function_t::top_k, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_transpose_op_t &op) noexcept {
+        return default_visit(tensor_function_t::transpose, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_transpose_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::transpose_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_trilu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::trilu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unary_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unary, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_uniform_op_t &op) noexcept {
+        return default_visit(tensor_function_t::uniform, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_uniform_like_op_t &op) noexcept {
+        return default_visit(tensor_function_t::uniform_like, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unsqueeze_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unsqueeze, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unsqueeze_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unsqueeze_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_where_op_t &op) noexcept {
+        return default_visit(tensor_function_t::where, &op);
+    }
+
+  protected:
+    virtual result<void>
+    default_visit(NNCASE_UNUSED tensor_function_t tensor_funct,
+                  NNCASE_UNUSED const void *op) noexcept {
+        return err(std::errc::not_supported);
+    }
+};
+
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/stackvm/opcode.h b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/opcode.h
new file mode 100644
index 0000000..888ae24
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/opcode.h
@@ -0,0 +1,1249 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../datatypes.h"
+#include <vector>
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+// Enums
+
+enum class opcode_t : uint8_t {
+    NOP = 0,
+    LDNULL = 1,
+    LDC_I4 = 2,
+    LDC_I4_0 = 3,
+    LDC_I4_1 = 4,
+    LDC_R4 = 5,
+    LDIND_I1 = 6,
+    LDIND_I2 = 7,
+    LDIND_I4 = 8,
+    LDIND_I = 9,
+    LDIND_U1 = 10,
+    LDIND_U2 = 11,
+    LDIND_U4 = 12,
+    LDIND_U = 13,
+    LDIND_BR2 = 14,
+    LDIND_R4 = 15,
+    STIND_I1 = 16,
+    STIND_I2 = 17,
+    STIND_I4 = 18,
+    STIND_I = 19,
+    STIND_BR2 = 20,
+    STIND_R4 = 21,
+    LEA_GP = 22,
+    LDELEM_I1 = 23,
+    LDELEM_I2 = 24,
+    LDELEM_I4 = 25,
+    LDELEM_I = 26,
+    LDELEM_U1 = 27,
+    LDELEM_U2 = 28,
+    LDELEM_U4 = 29,
+    LDELEM_U = 30,
+    LDELEM_BR2 = 31,
+    LDELEM_R4 = 32,
+    STELEM_I1 = 33,
+    STELEM_I2 = 34,
+    STELEM_I4 = 35,
+    STELEM_I = 36,
+    STELEM_BR2 = 37,
+    STELEM_R4 = 38,
+    LDARG = 39,
+    LDARG_0 = 40,
+    LDARG_1 = 41,
+    LDARG_2 = 42,
+    LDARG_3 = 43,
+    LDARG_4 = 44,
+    LDARG_5 = 45,
+    DUP = 46,
+    POP = 47,
+    LDLOCAL = 48,
+    STLOCAL = 49,
+    LDTUPLE_ELEM = 50,
+    LDTUPLE = 51,
+    LDDATATYPE = 52,
+    LDTENSOR = 53,
+    LDSCALAR = 54,
+    NEG = 55,
+    ADD = 56,
+    SUB = 57,
+    MUL = 58,
+    DIV = 59,
+    DIV_U = 60,
+    REM = 61,
+    REM_U = 62,
+    AND = 63,
+    OR = 64,
+    XOR = 65,
+    NOT = 66,
+    SHL = 67,
+    SHR = 68,
+    SHR_U = 69,
+    CLT = 70,
+    CLT_U = 71,
+    CLE = 72,
+    CLE_U = 73,
+    CEQ = 74,
+    CGE = 75,
+    CGE_U = 76,
+    CGT = 77,
+    CGT_U = 78,
+    CNE = 79,
+    CONV_I1 = 80,
+    CONV_I2 = 81,
+    CONV_I4 = 82,
+    CONV_I = 83,
+    CONV_U1 = 84,
+    CONV_U2 = 85,
+    CONV_U4 = 86,
+    CONV_U = 87,
+    CONV_BR2 = 88,
+    CONV_R4 = 89,
+    BR = 90,
+    BR_TRUE = 91,
+    BR_FALSE = 92,
+    RET = 93,
+    CALL = 94,
+    ECALL = 95,
+    EXTCALL = 96,
+    CUSCALL = 97,
+    THROW = 98,
+    BREAK = 99,
+    TENSOR = 100,
+};
+
+enum class tensor_function_t : uint16_t {
+    batch_normalization = 0,
+    batch_to_space = 1,
+    celu = 8,
+    conv2d = 14,
+    conv2d_transpose = 16,
+    elu = 20,
+    erf = 21,
+    gelu = 30,
+    hardmax = 33,
+    hard_sigmoid = 34,
+    hard_swish = 35,
+    instance_normalization = 37,
+    l2_normalization = 38,
+    layer_norm = 39,
+    leaky_relu = 40,
+    log_softmax = 41,
+    lp_normalization = 42,
+    lrn = 43,
+    one_hot = 49,
+    pad = 50,
+    prelu = 51,
+    reduce_window2d = 60,
+    relu = 61,
+    relu6 = 62,
+    selu = 70,
+    sigmoid = 72,
+    softmax = 75,
+    softplus = 76,
+    softsign = 77,
+    space_to_batch = 78,
+    swish = 83,
+    binary = 2,
+    clamp = 9,
+    compare = 10,
+    condition = 12,
+    cum_sum = 18,
+    dequantize = 19,
+    fake_dequantize = 23,
+    fake_quantize = 24,
+    mat_mul = 45,
+    quantize = 53,
+    quant_param_of = 54,
+    range_of = 56,
+    reduce = 58,
+    reduce_arg = 59,
+    require = 63,
+    select = 69,
+    unary = 89,
+    bitcast = 3,
+    broadcast = 4,
+    bucket_pad = 6,
+    cast = 7,
+    concat = 11,
+    constant_of_shape = 13,
+    expand = 22,
+    fix_shape = 25,
+    flatten = 26,
+    gather = 27,
+    gather_elements = 28,
+    gather_nd = 29,
+    get_item = 31,
+    index_of = 36,
+    prod = 52,
+    range = 55,
+    rank = 57,
+    reshape = 64,
+    reverse_sequence = 67,
+    scatter_nd = 68,
+    shape_of = 71,
+    size_of = 73,
+    slice = 74,
+    split = 79,
+    squeeze = 80,
+    stack = 82,
+    tile = 84,
+    top_k = 85,
+    transpose = 86,
+    trilu = 88,
+    unsqueeze = 92,
+    where = 94,
+    broadcast_shape = 5,
+    conv2d_shape = 15,
+    conv2d_transpose_shape = 17,
+    get_paddings = 32,
+    mat_mul_shape = 46,
+    reshape_shape = 65,
+    squeeze_shape = 81,
+    transpose_shape = 87,
+    unsqueeze_shape = 93,
+    lstm = 44,
+    normal = 47,
+    normal_like = 48,
+    uniform = 90,
+    uniform_like = 91,
+    resize_image = 66,
+};
+
+enum class binary_op_t : uint8_t {
+    add = 0,
+    sub = 1,
+    mul = 2,
+    div = 3,
+    mod = 4,
+    min = 5,
+    max = 6,
+    pow = 7,
+    bitwise_and = 8,
+    bitwise_or = 9,
+    bitwise_xor = 10,
+    logical_and = 11,
+    logical_or = 12,
+    logical_xor = 13,
+    left_shift = 14,
+    right_shift = 15,
+};
+
+enum class cast_mode_t : int32_t {
+    kdefault = 0,
+    exact = 1,
+    check_overflow = 2,
+    reinterpret = 3,
+};
+
+enum class compare_op_t : uint8_t {
+    equal = 0,
+    not_equal = 1,
+    lower_than = 2,
+    lower_or_equal = 3,
+    greater_than = 4,
+    greater_or_equal = 5,
+};
+
+enum class pad_mode_t : uint8_t {
+    constant = 0,
+    reflect = 1,
+    symmetric = 2,
+    edge = 3,
+};
+
+enum class lstmdirection_t : int32_t {
+    forward = 0,
+    reverse = 1,
+    bidirectional = 2,
+};
+
+enum class lstmlayout_t : int32_t {
+    zero = 0,
+    one = 1,
+};
+
+enum class one_hot_mode_t : uint8_t {
+    normal = 0,
+    process_neg = 1,
+};
+
+enum class quant_mode_t : int32_t {
+    unsigned_mode = 0,
+    signed_symmetric_mode = 1,
+    signed_asymmetric_mode = 2,
+};
+
+enum class reduce_op_t : uint8_t {
+    mean = 0,
+    min = 1,
+    max = 2,
+    sum = 3,
+    prod = 4,
+};
+
+enum class reduce_arg_op_t : uint8_t {
+    arg_min = 0,
+    arg_max = 1,
+};
+
+enum class image_resize_mode_t : uint8_t {
+    bilinear = 0,
+    nearest_neighbor = 1,
+};
+
+enum class image_resize_transformation_mode_t : int32_t {
+    half_pixel = 0,
+    pytorch_half_pixel = 1,
+    align_corners = 2,
+    asymmetric = 3,
+    tfcrop_and_resize = 4,
+};
+
+enum class image_resize_nearest_mode_t : int32_t {
+    round_prefer_floor = 0,
+    round_prefer_ceil = 1,
+    floor = 2,
+    ceil = 3,
+};
+
+enum class unary_op_t : uint8_t {
+    abs = 0,
+    acos = 1,
+    acosh = 2,
+    asin = 3,
+    asinh = 4,
+    ceil = 5,
+    cos = 6,
+    cosh = 7,
+    exp = 8,
+    floor = 9,
+    log = 10,
+    neg = 11,
+    round = 12,
+    rsqrt = 13,
+    sin = 14,
+    sinh = 15,
+    sign = 16,
+    sqrt = 17,
+    square = 18,
+    tanh = 19,
+    bitwise_not = 20,
+    logical_not = 21,
+};
+
+// Instructions
+
+struct nop_op_t {};
+
+struct br_op_t {
+    int32_t target;
+};
+
+struct br_true_op_t {
+    int32_t target;
+};
+
+struct br_false_op_t {
+    int32_t target;
+};
+
+struct ret_op_t {};
+
+struct call_op_t {
+    uint16_t args;
+    int32_t target;
+};
+
+struct ecall_op_t {
+    uint16_t args;
+};
+
+struct extcall_op_t {
+    uint16_t args;
+    bool is_prim_func;
+};
+
+struct cuscall_op_t {
+    std::string registered_name;
+    gsl::span<const gsl::byte> fields_span;
+    uint16_t args;
+};
+
+struct throw_op_t {};
+
+struct break_op_t {};
+
+struct ldc_i4_op_t {
+    int32_t imm;
+};
+
+struct ldnull_op_t {};
+
+struct ldc_i4_0_op_t {};
+
+struct ldc_i4_1_op_t {};
+
+struct ldc_r4_op_t {
+    float imm;
+};
+
+struct ldind_i1_op_t {};
+
+struct ldind_i2_op_t {};
+
+struct ldind_i4_op_t {};
+
+struct ldind_i_op_t {};
+
+struct ldind_u1_op_t {};
+
+struct ldind_u2_op_t {};
+
+struct ldind_u4_op_t {};
+
+struct ldind_u_op_t {};
+
+struct ldind_br2_op_t {};
+
+struct ldind_r4_op_t {};
+
+struct stind_i1_op_t {};
+
+struct stind_i2_op_t {};
+
+struct stind_i4_op_t {};
+
+struct stind_i_op_t {};
+
+struct stind_br2_op_t {};
+
+struct stind_r4_op_t {};
+
+struct lea_gp_op_t {
+    uint8_t gpid;
+    int64_t offset;
+};
+
+struct ldelem_i1_op_t {};
+
+struct ldelem_i2_op_t {};
+
+struct ldelem_i4_op_t {};
+
+struct ldelem_i_op_t {};
+
+struct ldelem_u1_op_t {};
+
+struct ldelem_u2_op_t {};
+
+struct ldelem_u4_op_t {};
+
+struct ldelem_u_op_t {};
+
+struct ldelem_br2_op_t {};
+
+struct ldelem_r4_op_t {};
+
+struct stelem_i1_op_t {};
+
+struct stelem_i2_op_t {};
+
+struct stelem_i4_op_t {};
+
+struct stelem_i_op_t {};
+
+struct stelem_br2_op_t {};
+
+struct stelem_r4_op_t {};
+
+struct ldarg_op_t {
+    uint16_t index;
+};
+
+struct ldarg_0_op_t {};
+
+struct ldarg_1_op_t {};
+
+struct ldarg_2_op_t {};
+
+struct ldarg_3_op_t {};
+
+struct ldarg_4_op_t {};
+
+struct ldarg_5_op_t {};
+
+struct ldtuple_elem_op_t {};
+
+struct ldtuple_op_t {};
+
+struct lddatatype_op_t {};
+
+struct ldtensor_op_t {};
+
+struct ldlocal_op_t {
+    uint16_t index;
+};
+
+struct stlocal_op_t {
+    uint16_t index;
+};
+
+struct ldscalar_op_t {};
+
+struct dup_op_t {};
+
+struct pop_op_t {};
+
+struct neg_op_t {};
+
+struct add_op_t {};
+
+struct sub_op_t {};
+
+struct mul_op_t {};
+
+struct div_op_t {};
+
+struct div_u_op_t {};
+
+struct rem_op_t {};
+
+struct rem_u_op_t {};
+
+struct and_op_t {};
+
+struct or_op_t {};
+
+struct xor_op_t {};
+
+struct not_op_t {};
+
+struct shl_op_t {};
+
+struct shr_op_t {};
+
+struct shr_u_op_t {};
+
+struct clt_op_t {};
+
+struct clt_u_op_t {};
+
+struct cle_op_t {};
+
+struct cle_u_op_t {};
+
+struct ceq_op_t {};
+
+struct cge_op_t {};
+
+struct cge_u_op_t {};
+
+struct cgt_op_t {};
+
+struct cgt_u_op_t {};
+
+struct cne_op_t {};
+
+struct conv_i1_op_t {};
+
+struct conv_i2_op_t {};
+
+struct conv_i4_op_t {};
+
+struct conv_i_op_t {};
+
+struct conv_u1_op_t {};
+
+struct conv_u2_op_t {};
+
+struct conv_u4_op_t {};
+
+struct conv_u_op_t {};
+
+struct conv_br2_op_t {};
+
+struct conv_r4_op_t {};
+
+// Tensor instructions
+
+struct tensor_batch_normalization_op_t {};
+
+struct tensor_batch_to_space_op_t {};
+
+struct tensor_binary_op_t {
+    binary_op_t binary_op;
+};
+
+struct tensor_bitcast_op_t {
+    prim_type_t type;
+    prim_type_t new_type;
+};
+
+struct tensor_broadcast_op_t {};
+
+struct tensor_broadcast_shape_op_t {};
+
+struct tensor_bucket_pad_op_t {};
+
+struct tensor_cast_op_t {
+    typecode_t new_type;
+    cast_mode_t cast_mode;
+};
+
+struct tensor_celu_op_t {};
+
+struct tensor_clamp_op_t {};
+
+struct tensor_compare_op_t {
+    compare_op_t compare_op;
+};
+
+struct tensor_concat_op_t {
+    int32_t axis;
+};
+
+struct tensor_condition_op_t {
+    bool can_fold_const_call;
+};
+
+struct tensor_constant_of_shape_op_t {};
+
+struct tensor_conv2d_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_conv2d_shape_op_t {};
+
+struct tensor_conv2d_transpose_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_conv2d_transpose_shape_op_t {};
+
+struct tensor_cum_sum_op_t {};
+
+struct tensor_dequantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_elu_op_t {};
+
+struct tensor_erf_op_t {};
+
+struct tensor_expand_op_t {};
+
+struct tensor_fake_dequantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_fake_quantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_fix_shape_op_t {};
+
+struct tensor_flatten_op_t {};
+
+struct tensor_gather_op_t {
+    int32_t axis;
+};
+
+struct tensor_gather_elements_op_t {};
+
+struct tensor_gather_nd_op_t {};
+
+struct tensor_gelu_op_t {};
+
+struct tensor_get_item_op_t {};
+
+struct tensor_get_paddings_op_t {};
+
+struct tensor_hard_sigmoid_op_t {};
+
+struct tensor_hard_swish_op_t {};
+
+struct tensor_hardmax_op_t {};
+
+struct tensor_index_of_op_t {};
+
+struct tensor_instance_normalization_op_t {};
+
+struct tensor_l2_normalization_op_t {};
+
+struct tensor_layer_norm_op_t {
+    int32_t axis;
+    float epsilon;
+    bool use_mean;
+};
+
+struct tensor_leaky_relu_op_t {};
+
+struct tensor_log_softmax_op_t {};
+
+struct tensor_lp_normalization_op_t {};
+
+struct tensor_lrn_op_t {};
+
+struct tensor_lstm_op_t {
+    lstmdirection_t direction;
+    lstmlayout_t layout;
+    std::vector<std::string> activations;
+};
+
+struct tensor_mat_mul_op_t {};
+
+struct tensor_mat_mul_shape_op_t {};
+
+struct tensor_normal_op_t {
+    typecode_t type;
+};
+
+struct tensor_normal_like_op_t {
+    typecode_t type;
+};
+
+struct tensor_one_hot_op_t {
+    one_hot_mode_t one_hot_mode;
+};
+
+struct tensor_pad_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_prelu_op_t {};
+
+struct tensor_prod_op_t {};
+
+struct tensor_quant_param_of_op_t {
+    quant_mode_t quant_mode;
+};
+
+struct tensor_quantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_range_op_t {};
+
+struct tensor_range_of_op_t {
+    bool is_range_of_weight;
+};
+
+struct tensor_rank_op_t {};
+
+struct tensor_reduce_op_t {
+    reduce_op_t reduce_op;
+};
+
+struct tensor_reduce_arg_op_t {
+    reduce_arg_op_t reduce_arg_op;
+    typecode_t dest_type;
+};
+
+struct tensor_reduce_window2d_op_t {
+    reduce_op_t reduce_op;
+};
+
+struct tensor_relu_op_t {};
+
+struct tensor_relu6_op_t {};
+
+struct tensor_require_op_t {
+    std::string message;
+    bool can_fold_const_call;
+};
+
+struct tensor_reshape_op_t {};
+
+struct tensor_reshape_shape_op_t {};
+
+struct tensor_resize_image_op_t {
+    image_resize_mode_t resize_mode;
+    image_resize_transformation_mode_t transformation_mode;
+    image_resize_nearest_mode_t nearest_mode;
+    bool is_tfresize;
+};
+
+struct tensor_reverse_sequence_op_t {};
+
+struct tensor_scatter_nd_op_t {};
+
+struct tensor_select_op_t {};
+
+struct tensor_selu_op_t {};
+
+struct tensor_shape_of_op_t {};
+
+struct tensor_sigmoid_op_t {};
+
+struct tensor_size_of_op_t {};
+
+struct tensor_slice_op_t {};
+
+struct tensor_softmax_op_t {};
+
+struct tensor_softplus_op_t {};
+
+struct tensor_softsign_op_t {};
+
+struct tensor_space_to_batch_op_t {};
+
+struct tensor_split_op_t {};
+
+struct tensor_squeeze_op_t {};
+
+struct tensor_squeeze_shape_op_t {};
+
+struct tensor_stack_op_t {};
+
+struct tensor_swish_op_t {};
+
+struct tensor_tile_op_t {};
+
+struct tensor_top_k_op_t {};
+
+struct tensor_transpose_op_t {};
+
+struct tensor_transpose_shape_op_t {};
+
+struct tensor_trilu_op_t {};
+
+struct tensor_unary_op_t {
+    unary_op_t unary_op;
+};
+
+struct tensor_uniform_op_t {
+    typecode_t type;
+};
+
+struct tensor_uniform_like_op_t {
+    typecode_t type;
+};
+
+struct tensor_unsqueeze_op_t {};
+
+struct tensor_unsqueeze_shape_op_t {};
+
+struct tensor_where_op_t {
+    bool is_tf_where;
+};
+
+inline std::string to_string(tensor_function_t tensor_funct) {
+    switch (tensor_funct) {
+    case tensor_function_t::batch_normalization:
+        return "batch_normalization";
+    case tensor_function_t::batch_to_space:
+        return "batch_to_space";
+    case tensor_function_t::celu:
+        return "celu";
+    case tensor_function_t::conv2d:
+        return "conv2d";
+    case tensor_function_t::conv2d_transpose:
+        return "conv2d_transpose";
+    case tensor_function_t::elu:
+        return "elu";
+    case tensor_function_t::erf:
+        return "erf";
+    case tensor_function_t::gelu:
+        return "gelu";
+    case tensor_function_t::hardmax:
+        return "hardmax";
+    case tensor_function_t::hard_sigmoid:
+        return "hard_sigmoid";
+    case tensor_function_t::hard_swish:
+        return "hard_swish";
+    case tensor_function_t::instance_normalization:
+        return "instance_normalization";
+    case tensor_function_t::l2_normalization:
+        return "l2_normalization";
+    case tensor_function_t::layer_norm:
+        return "layer_norm";
+    case tensor_function_t::leaky_relu:
+        return "leaky_relu";
+    case tensor_function_t::log_softmax:
+        return "log_softmax";
+    case tensor_function_t::lp_normalization:
+        return "lp_normalization";
+    case tensor_function_t::lrn:
+        return "lrn";
+    case tensor_function_t::one_hot:
+        return "one_hot";
+    case tensor_function_t::pad:
+        return "pad";
+    case tensor_function_t::prelu:
+        return "prelu";
+    case tensor_function_t::reduce_window2d:
+        return "reduce_window2d";
+    case tensor_function_t::relu:
+        return "relu";
+    case tensor_function_t::relu6:
+        return "relu6";
+    case tensor_function_t::selu:
+        return "selu";
+    case tensor_function_t::sigmoid:
+        return "sigmoid";
+    case tensor_function_t::softmax:
+        return "softmax";
+    case tensor_function_t::softplus:
+        return "softplus";
+    case tensor_function_t::softsign:
+        return "softsign";
+    case tensor_function_t::space_to_batch:
+        return "space_to_batch";
+    case tensor_function_t::swish:
+        return "swish";
+    case tensor_function_t::binary:
+        return "binary";
+    case tensor_function_t::clamp:
+        return "clamp";
+    case tensor_function_t::compare:
+        return "compare";
+    case tensor_function_t::condition:
+        return "condition";
+    case tensor_function_t::cum_sum:
+        return "cum_sum";
+    case tensor_function_t::dequantize:
+        return "dequantize";
+    case tensor_function_t::fake_dequantize:
+        return "fake_dequantize";
+    case tensor_function_t::fake_quantize:
+        return "fake_quantize";
+    case tensor_function_t::mat_mul:
+        return "mat_mul";
+    case tensor_function_t::quantize:
+        return "quantize";
+    case tensor_function_t::quant_param_of:
+        return "quant_param_of";
+    case tensor_function_t::range_of:
+        return "range_of";
+    case tensor_function_t::reduce:
+        return "reduce";
+    case tensor_function_t::reduce_arg:
+        return "reduce_arg";
+    case tensor_function_t::require:
+        return "require";
+    case tensor_function_t::select:
+        return "select";
+    case tensor_function_t::unary:
+        return "unary";
+    case tensor_function_t::bitcast:
+        return "bitcast";
+    case tensor_function_t::broadcast:
+        return "broadcast";
+    case tensor_function_t::bucket_pad:
+        return "bucket_pad";
+    case tensor_function_t::cast:
+        return "cast";
+    case tensor_function_t::concat:
+        return "concat";
+    case tensor_function_t::constant_of_shape:
+        return "constant_of_shape";
+    case tensor_function_t::expand:
+        return "expand";
+    case tensor_function_t::fix_shape:
+        return "fix_shape";
+    case tensor_function_t::flatten:
+        return "flatten";
+    case tensor_function_t::gather:
+        return "gather";
+    case tensor_function_t::gather_elements:
+        return "gather_elements";
+    case tensor_function_t::gather_nd:
+        return "gather_nd";
+    case tensor_function_t::get_item:
+        return "get_item";
+    case tensor_function_t::index_of:
+        return "index_of";
+    case tensor_function_t::prod:
+        return "prod";
+    case tensor_function_t::range:
+        return "range";
+    case tensor_function_t::rank:
+        return "rank";
+    case tensor_function_t::reshape:
+        return "reshape";
+    case tensor_function_t::reverse_sequence:
+        return "reverse_sequence";
+    case tensor_function_t::scatter_nd:
+        return "scatter_nd";
+    case tensor_function_t::shape_of:
+        return "shape_of";
+    case tensor_function_t::size_of:
+        return "size_of";
+    case tensor_function_t::slice:
+        return "slice";
+    case tensor_function_t::split:
+        return "split";
+    case tensor_function_t::squeeze:
+        return "squeeze";
+    case tensor_function_t::stack:
+        return "stack";
+    case tensor_function_t::tile:
+        return "tile";
+    case tensor_function_t::top_k:
+        return "top_k";
+    case tensor_function_t::transpose:
+        return "transpose";
+    case tensor_function_t::trilu:
+        return "trilu";
+    case tensor_function_t::unsqueeze:
+        return "unsqueeze";
+    case tensor_function_t::where:
+        return "where";
+    case tensor_function_t::broadcast_shape:
+        return "broadcast_shape";
+    case tensor_function_t::conv2d_shape:
+        return "conv2d_shape";
+    case tensor_function_t::conv2d_transpose_shape:
+        return "conv2d_transpose_shape";
+    case tensor_function_t::get_paddings:
+        return "get_paddings";
+    case tensor_function_t::mat_mul_shape:
+        return "mat_mul_shape";
+    case tensor_function_t::reshape_shape:
+        return "reshape_shape";
+    case tensor_function_t::squeeze_shape:
+        return "squeeze_shape";
+    case tensor_function_t::transpose_shape:
+        return "transpose_shape";
+    case tensor_function_t::unsqueeze_shape:
+        return "unsqueeze_shape";
+    case tensor_function_t::lstm:
+        return "lstm";
+    case tensor_function_t::normal:
+        return "normal";
+    case tensor_function_t::normal_like:
+        return "normal_like";
+    case tensor_function_t::uniform:
+        return "uniform";
+    case tensor_function_t::uniform_like:
+        return "uniform_like";
+    case tensor_function_t::resize_image:
+        return "resize_image";
+    }
+    return "unknown tensor_function_t";
+}
+
+inline std::string to_string(opcode_t code) {
+    switch (code) {
+    case opcode_t::NOP:
+        return "NOP";
+    case opcode_t::LDNULL:
+        return "LDNULL";
+    case opcode_t::LDC_I4:
+        return "LDC_I4";
+    case opcode_t::LDC_I4_0:
+        return "LDC_I4_0";
+    case opcode_t::LDC_I4_1:
+        return "LDC_I4_1";
+    case opcode_t::LDC_R4:
+        return "LDC_R4";
+    case opcode_t::LDIND_I1:
+        return "LDIND_I1";
+    case opcode_t::LDIND_I2:
+        return "LDIND_I2";
+    case opcode_t::LDIND_I4:
+        return "LDIND_I4";
+    case opcode_t::LDIND_I:
+        return "LDIND_I";
+    case opcode_t::LDIND_U1:
+        return "LDIND_U1";
+    case opcode_t::LDIND_U2:
+        return "LDIND_U2";
+    case opcode_t::LDIND_U4:
+        return "LDIND_U4";
+    case opcode_t::LDIND_U:
+        return "LDIND_U";
+    case opcode_t::LDIND_BR2:
+        return "LDIND_BR2";
+    case opcode_t::LDIND_R4:
+        return "LDIND_R4";
+    case opcode_t::STIND_I1:
+        return "STIND_I1";
+    case opcode_t::STIND_I2:
+        return "STIND_I2";
+    case opcode_t::STIND_I4:
+        return "STIND_I4";
+    case opcode_t::STIND_I:
+        return "STIND_I";
+    case opcode_t::STIND_BR2:
+        return "STIND_BR2";
+    case opcode_t::STIND_R4:
+        return "STIND_R4";
+    case opcode_t::LEA_GP:
+        return "LEA_GP";
+    case opcode_t::LDELEM_I1:
+        return "LDELEM_I1";
+    case opcode_t::LDELEM_I2:
+        return "LDELEM_I2";
+    case opcode_t::LDELEM_I4:
+        return "LDELEM_I4";
+    case opcode_t::LDELEM_I:
+        return "LDELEM_I";
+    case opcode_t::LDELEM_U1:
+        return "LDELEM_U1";
+    case opcode_t::LDELEM_U2:
+        return "LDELEM_U2";
+    case opcode_t::LDELEM_U4:
+        return "LDELEM_U4";
+    case opcode_t::LDELEM_U:
+        return "LDELEM_U";
+    case opcode_t::LDELEM_BR2:
+        return "LDELEM_BR2";
+    case opcode_t::LDELEM_R4:
+        return "LDELEM_R4";
+    case opcode_t::STELEM_I1:
+        return "STELEM_I1";
+    case opcode_t::STELEM_I2:
+        return "STELEM_I2";
+    case opcode_t::STELEM_I4:
+        return "STELEM_I4";
+    case opcode_t::STELEM_I:
+        return "STELEM_I";
+    case opcode_t::STELEM_BR2:
+        return "STELEM_BR2";
+    case opcode_t::STELEM_R4:
+        return "STELEM_R4";
+    case opcode_t::LDARG:
+        return "LDARG";
+    case opcode_t::LDARG_0:
+        return "LDARG_0";
+    case opcode_t::LDARG_1:
+        return "LDARG_1";
+    case opcode_t::LDARG_2:
+        return "LDARG_2";
+    case opcode_t::LDARG_3:
+        return "LDARG_3";
+    case opcode_t::LDARG_4:
+        return "LDARG_4";
+    case opcode_t::LDARG_5:
+        return "LDARG_5";
+    case opcode_t::DUP:
+        return "DUP";
+    case opcode_t::POP:
+        return "POP";
+    case opcode_t::LDLOCAL:
+        return "LDLOCAL";
+    case opcode_t::STLOCAL:
+        return "STLOCAL";
+    case opcode_t::LDTUPLE_ELEM:
+        return "LDTUPLE_ELEM";
+    case opcode_t::LDTUPLE:
+        return "LDTUPLE";
+    case opcode_t::LDDATATYPE:
+        return "LDDATATYPE";
+    case opcode_t::LDTENSOR:
+        return "LDTENSOR";
+    case opcode_t::LDSCALAR:
+        return "LDSCALAR";
+    case opcode_t::NEG:
+        return "NEG";
+    case opcode_t::ADD:
+        return "ADD";
+    case opcode_t::SUB:
+        return "SUB";
+    case opcode_t::MUL:
+        return "MUL";
+    case opcode_t::DIV:
+        return "DIV";
+    case opcode_t::DIV_U:
+        return "DIV_U";
+    case opcode_t::REM:
+        return "REM";
+    case opcode_t::REM_U:
+        return "REM_U";
+    case opcode_t::AND:
+        return "AND";
+    case opcode_t::OR:
+        return "OR";
+    case opcode_t::XOR:
+        return "XOR";
+    case opcode_t::NOT:
+        return "NOT";
+    case opcode_t::SHL:
+        return "SHL";
+    case opcode_t::SHR:
+        return "SHR";
+    case opcode_t::SHR_U:
+        return "SHR_U";
+    case opcode_t::CLT:
+        return "CLT";
+    case opcode_t::CLT_U:
+        return "CLT_U";
+    case opcode_t::CLE:
+        return "CLE";
+    case opcode_t::CLE_U:
+        return "CLE_U";
+    case opcode_t::CEQ:
+        return "CEQ";
+    case opcode_t::CGE:
+        return "CGE";
+    case opcode_t::CGE_U:
+        return "CGE_U";
+    case opcode_t::CGT:
+        return "CGT";
+    case opcode_t::CGT_U:
+        return "CGT_U";
+    case opcode_t::CNE:
+        return "CNE";
+    case opcode_t::CONV_I1:
+        return "CONV_I1";
+    case opcode_t::CONV_I2:
+        return "CONV_I2";
+    case opcode_t::CONV_I4:
+        return "CONV_I4";
+    case opcode_t::CONV_I:
+        return "CONV_I";
+    case opcode_t::CONV_U1:
+        return "CONV_U1";
+    case opcode_t::CONV_U2:
+        return "CONV_U2";
+    case opcode_t::CONV_U4:
+        return "CONV_U4";
+    case opcode_t::CONV_U:
+        return "CONV_U";
+    case opcode_t::CONV_BR2:
+        return "CONV_BR2";
+    case opcode_t::CONV_R4:
+        return "CONV_R4";
+    case opcode_t::BR:
+        return "BR";
+    case opcode_t::BR_TRUE:
+        return "BR_TRUE";
+    case opcode_t::BR_FALSE:
+        return "BR_FALSE";
+    case opcode_t::RET:
+        return "RET";
+    case opcode_t::CALL:
+        return "CALL";
+    case opcode_t::ECALL:
+        return "ECALL";
+    case opcode_t::EXTCALL:
+        return "EXTCALL";
+    case opcode_t::CUSCALL:
+        return "CUSCALL";
+    case opcode_t::THROW:
+        return "THROW";
+    case opcode_t::BREAK:
+        return "BREAK";
+    case opcode_t::TENSOR:
+        return "TENSOR";
+    }
+    return "unknown opcode_t";
+}
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/stackvm/runtime_module.h b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/runtime_module.h
new file mode 100644
index 0000000..a714cdd
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/stackvm/runtime_module.h
@@ -0,0 +1,31 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../runtime_module.h"
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+NNCASE_INLINE_VAR constexpr module_kind_t stackvm_module_kind =
+    to_module_kind("stackvm");
+NNCASE_INLINE_VAR constexpr uint32_t stackvm_module_version = 1;
+
+NNCASE_API result<std::unique_ptr<runtime_module>>
+create_stackvm_runtime_module();
+
+NNCASE_API result<
+    std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+create_stackvm_custom_calls();
+
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/stream_reader.h b/third_party/nncase/riscv64/include/nncase/runtime/stream_reader.h
new file mode 100644
index 0000000..59999ac
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/stream_reader.h
@@ -0,0 +1,75 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+#include <istream>
+#include <iterator>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/dbg.h>
+#include <string>
+#include <vector>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class stream_reader {
+  public:
+    stream_reader(std::istream &stream) : stream_(stream) {}
+
+    std::streampos tell() const noexcept { return stream_.tellg(); }
+    bool empty() const noexcept { return !stream_.eof(); }
+
+    void seek(std::streampos pos) noexcept { stream_.seekg(pos); }
+
+    template <class T> T read() {
+        T value;
+        read(value);
+        return value;
+    }
+
+    template <class T> T read_unaligned() { return read<T>(); }
+
+    template <class T> T peek() {
+        T value;
+        auto pos = tell();
+        read(value);
+        seek(pos);
+        return value;
+    }
+
+    template <class T> T peek_unaligned() { return peek<T>(); }
+
+    template <class T> void read(T &value) {
+        stream_.read(reinterpret_cast<char *>(&value), sizeof(value));
+    }
+
+    template <class T> void read_span(gsl::span<T> span) {
+        size_t sub_data_size = 8388608;
+        for (size_t pos = 0; pos < span.size_bytes();) {
+            if (pos + sub_data_size >= span.size_bytes())
+                sub_data_size = span.size_bytes() - pos;
+            stream_.read(reinterpret_cast<char *>(span.data()) + pos,
+                         sub_data_size);
+            pos += sub_data_size;
+        }
+    }
+
+    void skip(size_t count) { stream_.seekg(count, std::ios::cur); }
+
+  private:
+    std::istream &stream_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/tensor_util.h b/third_party/nncase/riscv64/include/nncase/runtime/tensor_util.h
new file mode 100644
index 0000000..c39fcb3
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/tensor_util.h
@@ -0,0 +1,29 @@
+#pragma once
+#include <cmath>
+#include <iostream>
+#include <nncase/runtime/simple_types.h>
+#include <string>
+
+namespace nncase::runtime {
+inline float dot(const float *v1, const float *v2, size_t size) {
+    float ret = 0.f;
+    for (size_t i = 0; i < size; i++) {
+        ret += v1[i] * v2[i];
+    }
+
+    return ret;
+}
+
+inline float cosine(const float *v1, const float *v2, size_t size) {
+    return dot(v1, v2, size) /
+           ((sqrt(dot(v1, v1, size)) * sqrt(dot(v2, v2, size))));
+}
+
+inline void dump_shape(gsl::span<const size_t> shape) {
+    std::cout << "shape:";
+    for (size_t i = 0; i < shape.size(); i++) {
+        std::cout << shape[i] << " ";
+    }
+    std::cout << "\n";
+}
+} // namespace nncase::runtime
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/type_serializer.h b/third_party/nncase/riscv64/include/nncase/runtime/type_serializer.h
new file mode 100644
index 0000000..dab234b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/type_serializer.h
@@ -0,0 +1,38 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/span_reader.h>
+#include <nncase/runtime/stream_reader.h>
+#include <nncase/type.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef enum : uint8_t {
+    type_sig_invalid,
+    type_sig_any,
+    type_sig_tensor,
+    type_sig_tuple,
+    type_sig_callable,
+    type_sig_end = 0xFF
+} type_signature_token_t;
+
+result<type> deserialize_type(span_reader &sr) noexcept;
+result<datatype_t> deserialize_datatype(span_reader &sr) noexcept;
+
+result<type> deserialize_type(stream_reader &sr) noexcept;
+result<datatype_t> deserialize_datatype(stream_reader &sr) noexcept;
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/typecodes.def b/third_party/nncase/riscv64/include/nncase/runtime/typecodes.def
new file mode 100644
index 0000000..1ddeb1e
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/typecodes.def
@@ -0,0 +1,16 @@
+DEFINE_TYPECODE(boolean,    bool,   0x00)
+DEFINE_TYPECODE(utf8char,   u8char, 0x01)
+DEFINE_TYPECODE(int8,       i8,     0x02)
+DEFINE_TYPECODE(int16,      i16,    0x03)
+DEFINE_TYPECODE(int32,      i32,    0x04)
+DEFINE_TYPECODE(int64,      i64,    0x05)
+DEFINE_TYPECODE(uint8,      u8,     0x06)
+DEFINE_TYPECODE(uint16,     u16,    0x07)
+DEFINE_TYPECODE(uint32,     u32,    0x08)
+DEFINE_TYPECODE(uint64,     u64,    0x09)
+DEFINE_TYPECODE(float16,    f16,    0x0A)
+DEFINE_TYPECODE(float32,    f32,    0x0B)
+DEFINE_TYPECODE(float64,    f64,    0x0C)
+DEFINE_TYPECODE(bfloat16,   bf16,   0x0D)
+DEFINE_TYPECODE(pointer,    *,      0xF0)
+DEFINE_TYPECODE(valuetype,  val,    0xF1)
diff --git a/third_party/nncase/riscv64/include/nncase/runtime/util.h b/third_party/nncase/riscv64/include/nncase/runtime/util.h
new file mode 100644
index 0000000..9f56876
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/runtime/util.h
@@ -0,0 +1,596 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../tensor.h"
+#include "allocator.h"
+#include "buffer.h"
+#include "error.h"
+#include "host_buffer.h"
+#include "runtime_tensor.h"
+#include "simple_types.h"
+#include <nncase/api.h>
+#include <nncase/runtime/runtime_op_utility.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+// cast macro
+#define IN_CAST(_ty, _name) reinterpret_cast<const _ty *>(_name)
+#define OUT_CAST(_ty, _name) reinterpret_cast<_ty *>(_name)
+#define SCALAR_CAST(_ty, _name) *reinterpret_cast<const _ty *>(_name)
+#define IN_BYTE_CAST(_var) IN_CAST(gsl::byte, _var)
+#define OUT_BYTE_CAST(_var) OUT_CAST(gsl::byte, _var)
+
+// compare type
+// for typecode, datatype_t, tensor(tensor->dtype())
+inline result<bool> cmp_dt_impl(datatype_t lhs, datatype_t rhs) {
+    try_var(l, to_typecode(lhs));
+    try_var(r, to_typecode(rhs));
+    return ok(l == r);
+}
+
+inline bool cmp_dt(tensor lhs, tensor rhs) {
+    auto result = cmp_dt_impl(lhs->dtype(), rhs->dtype());
+    return result.is_ok() && result.unwrap();
+}
+
+inline bool cmp_dt(datatype_t lhs, datatype_t rhs) {
+    auto result = cmp_dt_impl(lhs, rhs);
+    return result.is_ok() && result.unwrap();
+}
+
+template <typename T> inline bool cmp_type(datatype_t dt) {
+    return cmp_dt(datatype_t::from_type<T>(), dt);
+}
+
+template <typename T> inline result<bool> type_only_check(tensor input) {
+    return cmp_dt_impl(input->dtype(), datatype_t::from_type<T>());
+}
+
+inline result<bool> float_only_check(tensor input) {
+    return cmp_dt_impl(input->dtype(), datatype_t::float32);
+}
+
+// tuple helper
+template <typename F>
+inline result<void> tuple_for_each_with_i(tuple inputs, F &&f) {
+    for (size_t i = 0; i < inputs->fields().size(); ++i) {
+        try_(f(inputs->fields()[i], i));
+    }
+    return ok();
+}
+
+// todo:not process nest tuple
+template <typename T, bool IsResult, typename F>
+inline result<std::vector<T>> get_from_tuple_with_result(tuple inputs, F &&f) {
+    std::vector<T> data(inputs->fields().size());
+    for (size_t i = 0; i < inputs->fields().size(); ++i) {
+        try_var(input, inputs->fields()[i].as<tensor>());
+        if constexpr (IsResult) {
+            try_var(in, f(input));
+            data[i] = in;
+        } else {
+            data[i] = f(input);
+        }
+    }
+    return ok(data);
+}
+
+template <typename T, typename F>
+inline result<std::vector<T>> get_from_tuple(tuple inputs, F &&f) {
+    return get_from_tuple_with_result<T, false>(inputs, f);
+}
+
+inline result<std::vector<dims_t>> get_shapes(tuple inputs) {
+    return get_from_tuple<dims_t>(inputs,
+                                  [](auto &input) { return input->shape(); });
+}
+
+inline result<std::vector<dims_t>> get_strides(tuple inputs) {
+    return get_from_tuple<dims_t>(inputs,
+                                  [](auto &input) { return input->strides(); });
+}
+
+// get input and output
+inline result<void> alloc_output(value_t &output, datatype_t dtype,
+                                 gsl::span<const size_t> out_shape) {
+    // TODO: copy back output
+    if (output.empty()) {
+        try_var(typecode, to_typecode(dtype));
+        try_var(out_tensor, hrt::create(typecode, dims_t(out_shape)));
+        output = out_tensor.impl();
+    } else {
+        try_var(
+            out_tensor,
+            output.as<tensor>()) if (out_tensor->shape() !=
+                                     out_shape) return err(nncase_errc::
+                                                               shape_mismatch);
+    }
+    return ok();
+}
+
+inline result<void> check_tuple_shape(value_t &outputs,
+                                      const std::vector<dims_t> &out_shapes) {
+    try_var(output_tuple, outputs.as<tuple>());
+    try_(tuple_for_each_with_i(
+        output_tuple, [&](auto &output, auto i) -> result<void> {
+            try_var(out_tensor, output.template as<tensor>());
+            if (out_tensor->shape() != gsl::span(out_shapes[i])) {
+                return err(nncase_errc::shape_mismatch);
+            } else {
+                return ok();
+            }
+        }));
+    return ok();
+}
+
+inline result<void> alloc_tuple_output(value_t &outputs,
+                                       const std::vector<datatype_t> dtypes,
+                                       const std::vector<dims_t> &out_shapes) {
+    if (outputs.empty()) {
+        auto size = out_shapes.size();
+        std::vector<value_t> fields(size);
+        for (size_t i = 0; i < size; ++i) {
+            auto output = value_t();
+            try_(alloc_output(output, dtypes[i], out_shapes[i]));
+            fields[i] = output;
+        }
+        outputs = tuple(std::in_place, std::move(fields));
+    } else {
+        try_(check_tuple_shape(outputs, out_shapes));
+    }
+    return ok();
+}
+
+inline result<void> alloc_output(value_t &outputs, datatype_t dtype,
+                                 const std::vector<dims_t> &out_shapes) {
+    if (outputs.empty()) {
+        auto size = out_shapes.size();
+        std::vector<value_t> fields(size);
+        for (size_t i = 0; i < size; ++i) {
+            auto output = value_t();
+            try_(alloc_output(output, dtype, out_shapes[i]));
+            fields[i] = output;
+        }
+        outputs = tuple(std::in_place, std::move(fields));
+    } else {
+        try_(check_tuple_shape(outputs, out_shapes));
+    }
+    return ok();
+}
+
+inline result<host_buffer_slice> get_host_buffer(tensor tensor) {
+    try_var(tensor_host, tensor->to_host());
+    try_var(tensor_buffer, tensor_host->buffer().as_host());
+    return ok(tensor_buffer);
+}
+
+inline result<gsl::span<gsl::byte>> get_output_span(tensor output) {
+    try_var(output_buffer, get_host_buffer(output));
+    try_var(output_map, output_buffer.map(map_write));
+    return ok(output_map.buffer());
+}
+
+inline result<gsl::byte *> get_output_data(tensor output) {
+    try_var(output_buffer, get_output_span(output));
+    return ok(output_buffer.data());
+}
+
+inline result<std::vector<gsl::byte *>> get_output_data(tuple outputs) {
+    return get_from_tuple_with_result<gsl::byte *, true>(
+        outputs, [](tensor &input) { return get_output_data(input); });
+}
+
+inline result<gsl::span<gsl::byte>> get_input_span(tensor input) {
+    try_var(input_buffer, get_host_buffer(input));
+    try_var(input_map, input_buffer.map(map_read));
+    return ok(input_map.buffer());
+}
+
+inline result<gsl::byte *> get_input_data(tensor input) {
+    try_var(input_buffer, get_input_span(input));
+    return ok(input_buffer.data());
+}
+
+inline result<std::vector<gsl::byte *>> get_input_data(tuple inputs) {
+    return get_from_tuple_with_result<gsl::byte *, true>(
+        inputs, [](tensor &input) { return get_input_data(input); });
+}
+
+inline result<std::vector<gsl::byte *>> get_readonly_span(tuple inputs) {
+    return get_input_data(inputs);
+}
+
+inline result<gsl::byte *> get_readonly_span(tensor input) {
+    return get_input_data(input);
+}
+
+// some macro about get value for tensor_ops.cpp
+// implicit define tensor/tuple for try_input[xxx] and try_output[xxx]
+// e.g. try_input(in_mem, input) ->
+// 1. in_mem: const gsl::byte*
+// 2. input_tensor: tensor
+#define try_alloc_output(_out_tensor, _dt, _shape, _is_tuple)                  \
+    try_(alloc_output(_out_tensor, _dt, _shape));
+
+#define try_input_impl(_var_name, _value_name, _value_kind)                    \
+    try_var(_value_name##_##_value_kind, _value_name.as<_value_kind>());       \
+    try_var(_var_name, get_input_data(_value_name##_##_value_kind))
+
+#define try_input(_var_name, _value_name)                                      \
+    try_input_impl(_var_name, _value_name, tensor)
+#define try_tuple_input(_var_name, _value_name)                                \
+    try_input_impl(_var_name, _value_name, tuple)
+
+#define try_input_with_value_type(_var_name, _value_name, _ty)                 \
+    try_input(__##_var_name, _value_name);                                     \
+    auto *_var_name = IN_CAST(_ty, __##_var_name);
+
+#define try_tuple_field0(_input0_name, _tuple_name)                            \
+    try_var(_input0_name, _tuple_name->fields()[0].as<tensor>());
+
+#define try_input_with_ty(_var_name, _value_name, _ty)                         \
+    try_input(__##_var_name, _value_name);                                     \
+    try_(type_only_check<_ty>(_value_name##_tensor));                          \
+    auto _var_name = reinterpret_cast<const _ty *>(__##_var_name)
+
+#define try_integer_input(_var_name, _value_name)                              \
+    try_input_with_ty(_var_name, _value_name, int64_t)
+
+#define try_f32_input(_var_name, _value_name)                                  \
+    try_input_with_ty(_var_name, _value_name, float)
+#define try_f32_output(_var_name, _value_name, _out_shape)                     \
+    try_output(__##_var_name, _value_name, dt_float32, _out_shape);            \
+    auto _var_name = reinterpret_cast<float *>(__##_var_name)
+
+// todo:when _value_kind is tuple, _value_name_tensor is a bad name
+#define try_output_impl(_var_name, _value_name, _dt, _out_shape, _value_kind,  \
+                        _is_tuple)                                             \
+    try_alloc_output(_value_name, _dt, _out_shape, _is_tuple);                 \
+    try_var(_value_name##_##_value_kind, _value_name.as<_value_kind>());       \
+    try_var(_var_name, get_output_data(_value_name##_##_value_kind))
+
+#define try_output(_var_name, _value_name, _dt, _out_shape)                    \
+    try_output_impl(_var_name, _value_name, _dt, _out_shape, tensor, false)
+
+#define try_output_like_input(_var_name, _value_name, _tensor)                 \
+    try_output(_var_name, _value_name, (_tensor)->dtype(), (_tensor)->shape())
+
+#define try_tuple_output(_var_name, _value_name, _dt, _out_shapes)             \
+    try_output_impl(_var_name, _value_name, _dt, _out_shapes, tuple, true)
+
+#define try_value_as(_var_name, _value_name, f_name)                           \
+    try_var(_var_name, value_as_##f_name(_value_name))
+#define try_strides(_var_name, _value_name)                                    \
+    try_value_as(_var_name, _value_name, strides)
+#define try_dims(_var_name, _value_name)                                       \
+    try_value_as(_var_name, _value_name, dims)
+#define try_positive_axes(_var_name, _value_name, _rank)                       \
+    try_var(_var_name, value_as_positive_axes(_value_name, _rank))
+
+#define try_axes(_var_name, _value_name)                                       \
+    try_var(_var_name, value_as_axes(_value_name))
+#define try_paddings(_var_name, _value_name)                                   \
+    try_value_as(_var_name, _value_name, paddings)
+#define try_value_as_t(_var_name, _value_name, _ty, f_name)                    \
+    try_var(_var_name, value_as_##f_name<_ty>(_value_name))
+#define try_to_scalar(_var_name, _value_name, _ty)                             \
+    try_var(_var_name, value_to_scalar<_ty>(_value_name))
+
+#define try_float_scalar(_var_name, _value_name)                               \
+    try_to_scalar(_var_name, _value_name, float)
+
+#define try_to_integer(_var_name, _value_name)                                 \
+    try_to_scalar(_var_name, _value_name, int64_t)
+
+#define try_positive_axis_with_rank(_var_name, _value_name, _rank)             \
+    try_to_scalar(__##_var_name, _value_name, int64_t);                        \
+    auto _var_name = positive_index(__##_var_name, _rank)
+
+#define try_positive_axis(_var_name, _value_name, _input_tensor)               \
+    try_positive_axis_with_rank(_var_name, _value_name,                        \
+                                _input_tensor->shape().size())
+
+#define try_typecode(_var_name, _tensor_name)                                  \
+    try_var(_var_name, to_typecode(_tensor_name->dtype()))
+
+#define try_ref(op, ...) try_(reference::op(__VA_ARGS__))
+
+// implicit set var name
+#define try_out_mem(_value_name, _dt, _out_shape)                              \
+    try_output(_value_name##_mem, _value_name, _dt, _out_shape)
+#define try_f32_out_mem(_value_name, _out_shape)                               \
+    try_f32_output(_value_name##_mem, _value_name, _out_shape)
+
+#define try_in_mem(_value_name) try_input(_value_name##_mem, _value_name)
+#define try_f32_in_mem(_value_name)                                            \
+    try_f32_input(_value_name##_mem, _value_name)
+
+#define try_float_scalar_v(_value_name) try_to_scalar_v(_value_name, float)
+
+#define try_to_scalar_v(_value_name, _ty)                                      \
+    try_to_scalar(_value_name##_value, _value_name, _ty)
+
+#define try_integer_v(_value_name)                                             \
+    try_to_integer(_value_name##_value, _value_name)
+
+#define try_dims_v(_value_name) try_dims(_value_name##_value, _value_name)
+
+// other cast macro
+#define to_tensor(_tensor_name, _value)                                        \
+    try_var(_tensor_name, _value.as<tensor>());
+
+#define to_tensor_t(_value) to_tensor(_value##_tensor, _value)
+
+#define KERNEL_FINISH return ok(output)
+#define TUPLE_FINISH return ok(output_tuple)
+
+// get data from value
+template <typename TI, typename TO>
+itlib::small_vector<TO, 8> to_vec(const gsl::byte *input, size_t size) {
+    auto in_ptr = reinterpret_cast<const TI *>(input);
+    auto vec = itlib::small_vector<TO, 8>(size);
+    for (size_t i = 0; i < size; ++i) {
+        vec[i] = (TO)in_ptr[i];
+    }
+    return vec;
+}
+
+#define RETURN_RESULT_SELECT(RETURN_RESULT_IMPL)                               \
+    RETURN_RESULT_IMPL(bool);                                                  \
+    RETURN_RESULT_IMPL(int8_t);                                                \
+    RETURN_RESULT_IMPL(uint8_t);                                               \
+    RETURN_RESULT_IMPL(int32_t);                                               \
+    RETURN_RESULT_IMPL(uint32_t);                                              \
+    RETURN_RESULT_IMPL(int64_t);                                               \
+    RETURN_RESULT_IMPL(uint64_t);                                              \
+    RETURN_RESULT_IMPL(float);                                                 \
+    RETURN_RESULT_IMPL(double);
+
+template <typename T>
+inline result<T> value_to_scalar([[maybe_unused]] value_t value) {
+    try_input(input, value);
+    // todo: maybe this is a bad way?
+#define RETURN_RESULT(_in_type)                                                \
+    if (cmp_type<_in_type>(value_tensor->dtype())) {                           \
+        return ok((T)(*reinterpret_cast<const _in_type *>(input)));            \
+    }
+    RETURN_RESULT_SELECT(RETURN_RESULT);
+    return err(nncase_errc::datatype_mismatch);
+#undef RETURN_RESULT
+}
+
+template <typename T>
+inline result<itlib::small_vector<T, 8>> value_as_Ts(value_t value) {
+    try_input(input, value);
+    assert(value_tensor->shape().size() <= 1);
+    auto size =
+        value_tensor->shape().size() == 0 ? 1 : value_tensor->shape()[0];
+#define RETURN_RESULT(_in_type)                                                \
+    if (cmp_type<_in_type>(value_tensor->dtype())) {                           \
+        return ok(to_vec<_in_type, T>(input, size));                           \
+    }
+
+    static_assert(std::is_same_v<T, int32_t> || std::is_same_v<T, uint32_t> ||
+                      std::is_same_v<T, int64_t> ||
+                      std::is_same_v<T, int64_t> || std::is_same_v<T, size_t>,
+                  "not suppported type");
+    RETURN_RESULT(int32_t);
+    RETURN_RESULT(uint32_t);
+    RETURN_RESULT(int64_t);
+    RETURN_RESULT(uint64_t);
+#undef RETURN_RESULT
+    return err(nncase_errc::datatype_mismatch);
+}
+
+inline result<dims_t> value_as_dims(value_t value) {
+    return value_as_Ts<dims_t::value_type>(value);
+}
+
+inline result<axes_t> value_as_axes(value_t value) {
+    return value_as_Ts<axes_t::value_type>(value);
+}
+
+inline size_t positive_index(int index, size_t rank) {
+    return index < 0 ? index + rank : index;
+}
+
+// todo:refactor, same as axes but should positive
+inline result<dims_t> value_as_positive_axes(value_t value, size_t rank) {
+    try_input(input, value);
+    assert(value_tensor->shape().size() == 1);
+    auto size = value_tensor->shape()[0];
+    auto axis = dims_t(size);
+    for (size_t i = 0; i < size; ++i) {
+        if (cmp_type<int32_t>(value_tensor->dtype())) {
+            axis[i] = (dims_t::value_type)positive_index(
+                IN_CAST(int32_t, input)[i], rank);
+        } else if (cmp_type<int64_t>(value_tensor->dtype())) {
+            axis[i] = (dims_t::value_type)positive_index(
+                IN_CAST(int64_t, input)[i], rank);
+        } else {
+            return err(nncase_errc::datatype_mismatch);
+        }
+    }
+    return ok(axis);
+}
+
+inline result<strides_t> value_as_strides(value_t value) {
+    return value_as_Ts<strides_t::value_type>(value);
+}
+
+inline size_t compute_size(tensor t) {
+    return compute_size(t->shape(), t->strides());
+}
+
+inline result<paddings_t> value_as_paddings([[maybe_unused]] value_t value) {
+    try_input(input, value);
+    auto size = compute_size(value_tensor);
+    auto dims = size / 2;
+    auto pads = paddings_t(dims);
+    auto dt = value_tensor->dtype();
+    for (size_t i = 0; i < dims; ++i) {
+        if (cmp_type<int32_t>(dt)) {
+            pads[i].before = *(IN_CAST(int32_t, input) + 2 * i);
+            pads[i].after = *(IN_CAST(int32_t, input) + 2 * i + 1);
+            pads[i].interior = 0;
+        } else if (cmp_type<int64_t>(dt)) {
+            pads[i].before = *(IN_CAST(int64_t, input) + 2 * i);
+            pads[i].after = *(IN_CAST(int64_t, input) + 2 * i + 1);
+            pads[i].interior = 0;
+        } else {
+            return err(nncase_errc::datatype_mismatch);
+        }
+    }
+    return ok(pads);
+}
+
+// kernel util
+inline bool is_contiguous(tensor tensor) {
+    return is_contiguous(tensor->shape(), tensor->strides());
+}
+
+#define not_impl_no_contiguous(tensor)                                         \
+    if (!is_contiguous(tensor)) {                                              \
+        return err(nncase_errc::shape_mismatch);                               \
+    }
+
+#define TYPE_SELECT(_typecode, _impl)                                          \
+    switch (_typecode) {                                                       \
+    case dt_float32:                                                           \
+        _impl(float);                                                          \
+    case dt_float16:                                                           \
+        _impl(half);                                                           \
+    case dt_bfloat16:                                                          \
+        _impl(bfloat16);                                                       \
+    case dt_int8:                                                              \
+        _impl(int8_t);                                                         \
+    case dt_int16:                                                             \
+        _impl(int16_t);                                                        \
+    case dt_int32:                                                             \
+        _impl(int32_t);                                                        \
+    case dt_int64:                                                             \
+        _impl(int64_t);                                                        \
+    case dt_uint8:                                                             \
+        _impl(uint8_t);                                                        \
+    case dt_uint16:                                                            \
+        _impl(uint16_t);                                                       \
+    case dt_uint32:                                                            \
+        _impl(uint32_t);                                                       \
+    case dt_uint64:                                                            \
+        _impl(uint64_t);                                                       \
+    case dt_float64:                                                           \
+        _impl(double);                                                         \
+    case dt_boolean:                                                           \
+        _impl(bool);                                                           \
+    default:                                                                   \
+        return err(std::errc::not_supported);                                  \
+    }
+
+// kernel dispatch for single input
+#define CONTIGUOUS_KERNEL(_op, _in_tensor, ...)                                \
+    if (is_contiguous(_in_tensor)) {                                           \
+        try_(optimized::_op(__VA_ARGS__))                                      \
+    } else {                                                                   \
+        try_(reference::_op(__VA_ARGS__))                                      \
+    }
+
+// used for op only do reshape
+inline tensor tensor_reshape(tensor in_tensor,
+                             gsl::span<const size_t> new_shape) {
+    auto strides = get_default_strides(new_shape);
+    return tensor(std::in_place, in_tensor->dtype(), new_shape, strides,
+                  in_tensor->buffer());
+}
+
+inline bool is_scalar(tensor t) noexcept { return t->shape().empty(); }
+inline bool is_scalar(gsl::span<const size_t> t) noexcept { return t.empty(); }
+
+template <typename F>
+inline result<void> integer_cast(datatype_t type, const gsl::byte *input,
+                                 F &&f) {
+    if (cmp_type<int32_t>(type)) {
+        try_(f(IN_CAST(int32_t, input)));
+    } else if (cmp_type<int64_t>(type)) {
+        try_(f(IN_CAST(int64_t, input)));
+    } else {
+        return err(nncase_errc::datatype_mismatch);
+    }
+    return ok();
+}
+
+// used for slice args
+inline std::tuple<axes_t, axes_t, axes_t>
+slice_fill(gsl::span<const size_t> in_shape, axes_t &begins_value,
+           axes_t &ends_value, axes_t &strides_value, axes_t axes_value) {
+    auto ndim = in_shape.size();
+    axes_t begin_values(ndim, 0);
+    axes_t end_values(in_shape.begin(), in_shape.end());
+    axes_t strides_values(ndim, 1);
+    for (size_t i = 0; i < ndim; ++i) {
+        const auto it = std::find_if(axes_value.begin(), axes_value.end(),
+                                     [i, ndim](const auto axis) {
+                                         return positive_index(axis, ndim) == i;
+                                     });
+        if (it != axes_value.end()) {
+            auto idx = std::distance(axes_value.begin(), it);
+            auto max = static_cast<int>(in_shape[i]);
+            auto min = (-1) * max - 1;
+
+            // check starts
+            begin_values[i] = begins_value[idx] < min   ? min
+                              : begins_value[idx] > max ? max
+                                                        : begins_value[idx];
+
+            // check stops
+            end_values[i] = ends_value[idx] < min   ? min
+                            : ends_value[idx] > max ? max
+                                                    : ends_value[idx];
+
+            // check steps
+            if (!strides_value.empty()) {
+                assert(strides_value[idx] != 0);
+                strides_values[i] = strides_value[idx];
+            }
+
+            // fixup begin_values
+            if ((strides_values[i] > 0 && end_values[i] > begin_values[i]) ||
+                (strides_values[i] < 0 && end_values[i] < begin_values[i])) {
+                begin_values[i] =
+                    begin_values[i] == min ? min + 1 : begin_values[i];
+                begin_values[i] =
+                    begin_values[i] == max ? max - 1 : begin_values[i];
+            }
+            if (begin_values[i] < 0)
+                begin_values[i] += max;
+            if (end_values[i] < 0)
+                end_values[i] += max;
+        }
+    }
+    return std::tuple(begin_values, end_values, strides_values);
+}
+
+inline dims_t to_4d(dims_t in_a_shape) {
+    auto size = 4 - in_a_shape.size();
+    for (size_t i = 0; i < size; ++i) {
+        in_a_shape.insert(in_a_shape.begin(), 1);
+    }
+    return in_a_shape;
+}
+
+inline void shrink_memory_pool() {
+    buffer_allocator::host().shrink_memory_pool();
+}
+
+END_NS_NNCASE_RUNTIME
\ No newline at end of file
diff --git a/third_party/nncase/riscv64/include/nncase/shape.h b/third_party/nncase/riscv64/include/nncase/shape.h
new file mode 100644
index 0000000..f835a0a
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/shape.h
@@ -0,0 +1,168 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <algorithm>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/simple_types.h>
+#include <nncase/runtime/small_vector.hpp>
+#include <optional>
+
+namespace nncase {
+struct unknown_dim_t {};
+
+inline constexpr unknown_dim_t unknown_dim;
+
+enum dim_kind_t { dim_unknown = 0, dim_fixed = 1 };
+
+using dim_value_t = int64_t;
+
+/** @brief Dimension */
+struct dim_t {
+    /** @brief Initialize an unknown dim */
+    constexpr dim_t(unknown_dim_t = unknown_dim) noexcept
+        : kind(dim_unknown), value(0) {}
+
+    /** @brief Initialize an fixed dim */
+    constexpr dim_t(dim_value_t value) noexcept
+        : kind(dim_fixed), value(value) {}
+
+    /** @brief Is this a fixed dim */
+    bool is_fixed() const noexcept { return kind == dim_fixed; }
+    /** @brief Is this an unknown dim */
+    bool is_unknown() const noexcept { return kind == dim_unknown; }
+
+    dim_value_t fixed_value() const {
+        assert(is_fixed());
+        return value;
+    }
+
+    dim_kind_t kind;
+    dim_value_t value;
+};
+
+struct scalar_shape_t {};
+
+inline constexpr scalar_shape_t scalar_shape;
+
+struct unranked_shape_t {};
+
+inline constexpr unranked_shape_t unranked_shape;
+
+struct invalid_shape_t {};
+
+inline constexpr invalid_shape_t invalid_shape;
+
+/** @brief Shape type */
+class NNCASE_API shape_t {
+    enum shape_kind_t {
+        shape_kind_fixed,
+        shape_kind_has_unknown_dim,
+        shape_kind_unranked,
+        shape_kind_invalid
+    };
+
+  public:
+    using value_type = dim_t;
+
+    /** @brief Initialize a scalar shape */
+    shape_t(scalar_shape_t) noexcept : kind_(shape_kind_fixed) {}
+
+    /** @brief Initialize an unranked shape */
+    shape_t(unranked_shape_t) noexcept : kind_(shape_kind_unranked) {}
+
+    /** @brief Initialize an invalid shape */
+    shape_t(invalid_shape_t) noexcept : kind_(shape_kind_invalid) {}
+
+    /** @brief Initialize a ranked shape */
+    template <class R>
+    shape_t(R dims) : kind_(kind_of(dims)), dims_(dims.begin(), dims.end()) {}
+
+    /** @brief Initialize a fixed shape */
+    shape_t(std::initializer_list<dim_value_t> dims) : kind_(shape_kind_fixed) {
+        dims_.reserve(dims.size());
+        std::transform(dims.begin(), dims.end(), std::back_inserter(dims_),
+                       [](dim_value_t dim) -> dim_t { return dim; });
+    }
+
+    /** @brief Get kind */
+    shape_kind_t kind() const noexcept { return kind_; }
+
+    /** @brief Is this a fixed shape */
+    bool is_fixed() const noexcept { return kind() == shape_kind_fixed; }
+    /** @brief Is this a scalar */
+    bool is_scalar() const noexcept {
+        return kind() == shape_kind_fixed && dims_.empty();
+    }
+    /** @brief Is this an ranked shape */
+    bool is_ranked() const noexcept { return is_fixed() || has_unknown_dim(); }
+    /** @brief Is this an unranked shape */
+    bool is_unranked() const noexcept { return kind() == shape_kind_unranked; }
+    /** @brief Has at least one unknown dimension */
+    bool has_unknown_dim() const noexcept {
+        return kind() == shape_kind_has_unknown_dim;
+    }
+    /** @brief Is this an invalid shape */
+    bool is_invalid() const noexcept { return kind() == shape_kind_invalid; }
+
+    /** @brief Get dimensions */
+    gsl::span<const dim_t> dims() const noexcept { return dims_; }
+
+    /** @brief Get rank */
+    std::optional<size_t> rank() const noexcept {
+        return is_ranked() ? std::make_optional(dims_.size()) : std::nullopt;
+    }
+
+    auto begin() const noexcept { return dims_.cbegin(); }
+    auto end() const noexcept { return dims_.cend(); }
+
+    const dim_t &front() const { return dims_.front(); }
+    const dim_t &back() const { return dims_.back(); }
+
+    /** @brief Get dimension */
+    const dim_t &dim(size_t index) const { return dims_.at(index); }
+    const dim_t &operator[](size_t index) const { return dim(index); }
+
+    /** @brief Set dimension */
+    void dim(size_t index, dim_t value);
+
+    /** @brief Place a new dim at back */
+    void push_back(dim_t value);
+    const dim_t &emplace_back(dim_t value);
+    /** @brief Place a new dim */
+    const dim_t *emplace(const dim_t *position, dim_t value);
+
+    /** @brief Remove the dim at back */
+    void pop_back();
+
+    /** @brief As fixed dims */
+    result<dims_t> as_fixed() const noexcept;
+
+  private:
+    template <class R> static shape_kind_t kind_of(R &&range) noexcept {
+        return std::any_of(range.begin(), range.end(),
+                           [](const dim_t &dim) { return dim.is_unknown(); })
+                   ? shape_kind_has_unknown_dim
+                   : shape_kind_fixed;
+    }
+
+    void update_kind(shape_kind_t before_kind,
+                     dim_kind_t new_dim_kind) noexcept;
+
+  private:
+    shape_kind_t kind_;
+    itlib::small_vector<dim_t, 8> dims_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/tensor.h b/third_party/nncase/riscv64/include/nncase/tensor.h
new file mode 100644
index 0000000..6ecc44b
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/tensor.h
@@ -0,0 +1,64 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object.h"
+#include "shape.h"
+#include "value.h"
+#include <nncase/runtime/buffer.h>
+#include <nncase/runtime/datatypes.h>
+
+namespace nncase {
+class tensor_node;
+using tensor = object_t<tensor_node>;
+
+class NNCASE_API tensor_node : public value_node {
+    DEFINE_OBJECT_KIND(value_node, object_tensor);
+
+  public:
+    tensor_node(datatype_t dtype, dims_t shape, strides_t strides,
+                runtime::buffer_slice buffer);
+
+    /** @brief Gets element type. */
+    const datatype_t &dtype() const noexcept { return dtype_; }
+
+    /** @brief Gets shape. */
+    gsl::span<const size_t> shape() const noexcept { return shape_; }
+
+    /** @brief Gets strides. */
+    gsl::span<const size_t> strides() const noexcept { return strides_; }
+
+    /** @brief Gets length. */
+    size_t length() const noexcept { return length_; }
+
+    /** @brief Gets buffer. */
+    const runtime::buffer_slice &buffer() const noexcept { return buffer_; }
+
+    /** @brief Gets whether buffer is contiguous. */
+    bool is_contiguous() const noexcept;
+
+    result<void> copy_from(tensor src) noexcept;
+    result<void> copy_to(tensor dest) const noexcept;
+    result<tensor> to_host() noexcept;
+
+    result<void> copy_to(value_t dest) const noexcept override;
+
+  private:
+    datatype_t dtype_;
+    dims_t shape_;
+    strides_t strides_;
+    size_t length_;
+    runtime::buffer_slice buffer_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/type.h b/third_party/nncase/riscv64/include/nncase/type.h
new file mode 100644
index 0000000..7382328
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/type.h
@@ -0,0 +1,167 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "shape.h"
+#include <nncase/runtime/datatypes.h>
+
+namespace nncase {
+/** @brief Type node */
+class NNCASE_API type_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_type);
+
+  protected:
+    type_node() = default;
+};
+
+/** @brief Type */
+using type = object_t<type_node>;
+
+class any_type_node;
+
+/** @brief Any type */
+class any_type : public object_t<any_type_node> {
+  public:
+    using object_t::object_t;
+
+    static any_type value;
+};
+
+/** @brief Any type node */
+class NNCASE_API any_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_any_type);
+
+  public:
+};
+
+class invalid_type_node;
+
+/** @brief Invalid type */
+class invalid_type : public object_t<invalid_type_node> {
+  public:
+    using object_t::object_t;
+
+    static invalid_type value;
+};
+
+/** @brief Invalid type node */
+class NNCASE_API invalid_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_invalid_type);
+
+  public:
+    invalid_type_node() noexcept {}
+    invalid_type_node(std::string reason) noexcept
+        : reason_(std::move(reason)) {}
+
+    /** @brief Get reason */
+    const std::string &reason() const noexcept { return reason_; }
+    /** @brief Get mutable reason */
+    std::string &reason() noexcept { return reason_; }
+    /** @brief Set reason */
+    void reason(std::string value) noexcept { reason_ = std::move(value); }
+
+  private:
+    std::string reason_;
+};
+
+/** @brief Tensor type node */
+class NNCASE_API tensor_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_tensor_type);
+
+  public:
+    tensor_type_node(datatype_t dtype, shape_t shape) noexcept
+        : dtype_(std::move(dtype)), shape_(std::move(shape)) {}
+
+    /** @brief Is this a scalar type */
+    bool is_scalar() const noexcept { return shape_.is_scalar(); }
+    /** @brief Is this a tensor type */
+    bool is_tensor() const noexcept { return !shape_.is_scalar(); }
+
+    /** @brief Get element datatype */
+    datatype_t dtype() const noexcept { return dtype_; }
+    /** @brief Set element datatype */
+    void dtype(datatype_t value) noexcept { dtype_ = value; }
+
+    /** @brief Get shape */
+    const shape_t &shape() const noexcept { return shape_; }
+    /** @brief Get mutable shape */
+    shape_t &shape() noexcept { return shape_; }
+    /** @brief Set shape */
+    void shape(shape_t value) noexcept { shape_ = std::move(value); }
+
+  private:
+    datatype_t dtype_;
+    shape_t shape_;
+};
+
+/** @brief Tensor type */
+using tensor_type = object_t<tensor_type_node>;
+
+/** @brief Tuple type node */
+class NNCASE_API tuple_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_tuple_type);
+
+  public:
+    tuple_type_node(itlib::small_vector<type> fields) noexcept
+        : fields_(std::move(fields)) {}
+
+    /** @brief Get fields */
+    gsl::span<const type> fields() const noexcept { return fields_; }
+    /** @brief Get mutable fields */
+    itlib::small_vector<type> &shape() noexcept { return fields_; }
+    /** @brief Set fields */
+    void shape(itlib::small_vector<type> value) noexcept {
+        fields_ = std::move(value);
+    }
+
+  private:
+    itlib::small_vector<type> fields_;
+};
+
+/** @brief Tuple type */
+using tuple_type = object_t<tuple_type_node>;
+
+/** @brief Callable type node */
+class NNCASE_API callable_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_callable_type);
+
+  public:
+    callable_type_node(itlib::small_vector<type> parameters,
+                       type return_type) noexcept
+        : parameters_(std::move(parameters)), return_type_(return_type) {}
+
+    /** @brief Get parameters */
+    gsl::span<const type> parameters() const noexcept { return parameters_; }
+    /** @brief Get parameters */
+    itlib::small_vector<type> &parameters() noexcept { return parameters_; }
+    /** @brief Set parameters */
+    void parameters(itlib::small_vector<type> value) noexcept {
+        parameters_ = std::move(value);
+    }
+
+    /** @brief Get return type */
+    const type &return_type() const noexcept { return return_type_; }
+    /** @brief Get mutable return type */
+    type &return_type() noexcept { return return_type_; }
+    /** @brief Set return type */
+    void return_type(type value) noexcept { return_type_ = std::move(value); }
+
+  private:
+    itlib::small_vector<type> parameters_;
+    type return_type_;
+};
+
+/** @brief Callable type */
+using callable_type = object_t<callable_type_node>;
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/value.h b/third_party/nncase/riscv64/include/nncase/value.h
new file mode 100644
index 0000000..1389d08
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/value.h
@@ -0,0 +1,52 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object.h"
+#include <vector>
+
+namespace nncase {
+
+class value_node;
+
+/** @brief Value */
+using value_t = object_t<value_node>;
+
+class NNCASE_API value_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_value);
+
+  public:
+    virtual result<void> copy_to(value_t dest) const noexcept = 0;
+};
+
+class NNCASE_API tuple_node : public value_node {
+    DEFINE_OBJECT_KIND(value_node, object_tuple);
+
+  public:
+    tuple_node() noexcept = default;
+    tuple_node(std::vector<value_t> fields) noexcept
+        : fields_(std::move(fields)) {}
+
+    gsl::span<const value_t> fields() const noexcept { return fields_; }
+    gsl::span<value_t> fields() noexcept { return fields_; }
+
+    result<void> copy_to(value_t dest) const noexcept override;
+
+  private:
+    std::vector<value_t> fields_;
+};
+
+/** @brief Tuple */
+using tuple = object_t<tuple_node>;
+} // namespace nncase
diff --git a/third_party/nncase/riscv64/include/nncase/version.h b/third_party/nncase/riscv64/include/nncase/version.h
new file mode 100644
index 0000000..000a31d
--- /dev/null
+++ b/third_party/nncase/riscv64/include/nncase/version.h
@@ -0,0 +1,17 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#define NNCASE_VERSION "2.0.0"
+#define NNCASE_VERSION_SUFFIX "-"
diff --git a/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets-release.cmake b/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets-release.cmake
new file mode 100644
index 0000000..1fa65e2
--- /dev/null
+++ b/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets-release.cmake
@@ -0,0 +1,29 @@
+#----------------------------------------------------------------
+# Generated CMake target import file for configuration "Release".
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Import target "functional_k230" for configuration "Release"
+set_property(TARGET functional_k230 APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
+set_target_properties(functional_k230 PROPERTIES
+  IMPORTED_LINK_INTERFACE_LANGUAGES_RELEASE "C;CXX"
+  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib/libfunctional_k230.a"
+  )
+
+list(APPEND _cmake_import_check_targets functional_k230 )
+list(APPEND _cmake_import_check_files_for_functional_k230 "${_IMPORT_PREFIX}/lib/libfunctional_k230.a" )
+
+# Import target "nncase_rt_modules_k230" for configuration "Release"
+set_property(TARGET nncase_rt_modules_k230 APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
+set_target_properties(nncase_rt_modules_k230 PROPERTIES
+  IMPORTED_LINK_INTERFACE_LANGUAGES_RELEASE "C;CXX"
+  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib/libnncase.rt_modules.k230.a"
+  )
+
+list(APPEND _cmake_import_check_targets nncase_rt_modules_k230 )
+list(APPEND _cmake_import_check_files_for_nncase_rt_modules_k230 "${_IMPORT_PREFIX}/lib/libnncase.rt_modules.k230.a" )
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
diff --git a/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets.cmake b/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets.cmake
new file mode 100644
index 0000000..bd3c184
--- /dev/null
+++ b/third_party/nncase/riscv64/lib/cmake/nncase_rt_modules_k230/nncase_rt_modules_k230Targets.cmake
@@ -0,0 +1,130 @@
+# Generated by CMake
+
+if("${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}" LESS 2.8)
+   message(FATAL_ERROR "CMake >= 2.8.0 required")
+endif()
+if(CMAKE_VERSION VERSION_LESS "2.8.3")
+   message(FATAL_ERROR "CMake >= 2.8.3 required")
+endif()
+cmake_policy(PUSH)
+cmake_policy(VERSION 2.8.3...3.26)
+#----------------------------------------------------------------
+# Generated CMake target import file.
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Protect against multiple inclusion, which would fail when already imported targets are added once more.
+set(_cmake_targets_defined "")
+set(_cmake_targets_not_defined "")
+set(_cmake_expected_targets "")
+foreach(_cmake_expected_target IN ITEMS runtime_k230 functional_ai2d functional_k230 nncase_rt_modules_k230)
+  list(APPEND _cmake_expected_targets "${_cmake_expected_target}")
+  if(TARGET "${_cmake_expected_target}")
+    list(APPEND _cmake_targets_defined "${_cmake_expected_target}")
+  else()
+    list(APPEND _cmake_targets_not_defined "${_cmake_expected_target}")
+  endif()
+endforeach()
+unset(_cmake_expected_target)
+if(_cmake_targets_defined STREQUAL _cmake_expected_targets)
+  unset(_cmake_targets_defined)
+  unset(_cmake_targets_not_defined)
+  unset(_cmake_expected_targets)
+  unset(CMAKE_IMPORT_FILE_VERSION)
+  cmake_policy(POP)
+  return()
+endif()
+if(NOT _cmake_targets_defined STREQUAL "")
+  string(REPLACE ";" ", " _cmake_targets_defined_text "${_cmake_targets_defined}")
+  string(REPLACE ";" ", " _cmake_targets_not_defined_text "${_cmake_targets_not_defined}")
+  message(FATAL_ERROR "Some (but not all) targets in this export set were already defined.\nTargets Defined: ${_cmake_targets_defined_text}\nTargets not yet defined: ${_cmake_targets_not_defined_text}\n")
+endif()
+unset(_cmake_targets_defined)
+unset(_cmake_targets_not_defined)
+unset(_cmake_expected_targets)
+
+
+# Compute the installation prefix relative to this file.
+get_filename_component(_IMPORT_PREFIX "${CMAKE_CURRENT_LIST_FILE}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+if(_IMPORT_PREFIX STREQUAL "/")
+  set(_IMPORT_PREFIX "")
+endif()
+
+# Create imported target runtime_k230
+add_library(runtime_k230 INTERFACE IMPORTED)
+
+set_target_properties(runtime_k230 PROPERTIES
+  INTERFACE_LINK_DIRECTORIES "/mnt/k230_linux_sdk/buildroot-overlay/package/libmmz"
+  INTERFACE_LINK_LIBRARIES "nncaseruntime"
+)
+
+# Create imported target functional_ai2d
+add_library(functional_ai2d INTERFACE IMPORTED)
+
+set_target_properties(functional_ai2d PROPERTIES
+  INTERFACE_LINK_LIBRARIES "\$<LINK_ONLY:runtime_k230>"
+)
+
+# Create imported target functional_k230
+add_library(functional_k230 STATIC IMPORTED)
+
+set_target_properties(functional_k230 PROPERTIES
+  INTERFACE_COMPILE_DEFINITIONS "NNCASE_MODULES_K230_DLL;NNCASE_functional"
+  INTERFACE_LINK_LIBRARIES "nncasebase;\$<LINK_ONLY:nncaseruntime>;\$<LINK_ONLY:runtime_k230>"
+)
+
+# Create imported target nncase_rt_modules_k230
+add_library(nncase_rt_modules_k230 STATIC IMPORTED)
+
+set_target_properties(nncase_rt_modules_k230 PROPERTIES
+  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
+  INTERFACE_LINK_LIBRARIES "\$<LINK_ONLY:runtime_k230>;\$<LINK_ONLY:functional_k230>;\$<LINK_ONLY:functional_ai2d>"
+)
+
+if(CMAKE_VERSION VERSION_LESS 3.0.0)
+  message(FATAL_ERROR "This file relies on consumers using CMake 3.0.0 or greater.")
+endif()
+
+# Load information for each installed configuration.
+file(GLOB _cmake_config_files "${CMAKE_CURRENT_LIST_DIR}/nncase_rt_modules_k230Targets-*.cmake")
+foreach(_cmake_config_file IN LISTS _cmake_config_files)
+  include("${_cmake_config_file}")
+endforeach()
+unset(_cmake_config_file)
+unset(_cmake_config_files)
+
+# Cleanup temporary variables.
+set(_IMPORT_PREFIX)
+
+# Loop over all imported files and verify that they actually exist
+foreach(_cmake_target IN LISTS _cmake_import_check_targets)
+  foreach(_cmake_file IN LISTS "_cmake_import_check_files_for_${_cmake_target}")
+    if(NOT EXISTS "${_cmake_file}")
+      message(FATAL_ERROR "The imported target \"${_cmake_target}\" references the file
+   \"${_cmake_file}\"
+but this file does not exist.  Possible reasons include:
+* The file was deleted, renamed, or moved to another location.
+* An install or uninstall procedure did not complete successfully.
+* The installation package was faulty and contained
+   \"${CMAKE_CURRENT_LIST_FILE}\"
+but not all the files it references.
+")
+    endif()
+  endforeach()
+  unset(_cmake_file)
+  unset("_cmake_import_check_files_for_${_cmake_target}")
+endforeach()
+unset(_cmake_target)
+unset(_cmake_import_check_targets)
+
+# This file does not depend on other imported targets which have
+# been exported from the same project but in a separate export set.
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
+cmake_policy(POP)
diff --git a/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeConfig.cmake b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeConfig.cmake
new file mode 100644
index 0000000..3490341
--- /dev/null
+++ b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeConfig.cmake
@@ -0,0 +1,4 @@
+include(${CMAKE_CURRENT_LIST_DIR}/nncaseruntimeTargets.cmake)
+
+set(nncaseruntime_INCLUDE_DIRS ${CMAKE_CURRENT_LIST_DIR}/../../../include)
+set(nncaseruntime_LIBS ${CMAKE_CURRENT_LIST_DIR}/../../libNncase.Runtime.Native.a)
diff --git a/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets-release.cmake b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets-release.cmake
new file mode 100644
index 0000000..7f098a9
--- /dev/null
+++ b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets-release.cmake
@@ -0,0 +1,19 @@
+#----------------------------------------------------------------
+# Generated CMake target import file for configuration "Release".
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Import target "nncaseruntime" for configuration "Release"
+set_property(TARGET nncaseruntime APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
+set_target_properties(nncaseruntime PROPERTIES
+  IMPORTED_LINK_INTERFACE_LANGUAGES_RELEASE "CXX"
+  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib/libNncase.Runtime.Native.a"
+  )
+
+list(APPEND _cmake_import_check_targets nncaseruntime )
+list(APPEND _cmake_import_check_files_for_nncaseruntime "${_IMPORT_PREFIX}/lib/libNncase.Runtime.Native.a" )
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
diff --git a/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets.cmake b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets.cmake
new file mode 100644
index 0000000..ccf9d6f
--- /dev/null
+++ b/third_party/nncase/riscv64/lib/cmake/nncaseruntime/nncaseruntimeTargets.cmake
@@ -0,0 +1,136 @@
+# Generated by CMake
+
+if("${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}" LESS 2.8)
+   message(FATAL_ERROR "CMake >= 2.8.0 required")
+endif()
+if(CMAKE_VERSION VERSION_LESS "2.8.3")
+   message(FATAL_ERROR "CMake >= 2.8.3 required")
+endif()
+cmake_policy(PUSH)
+cmake_policy(VERSION 2.8.3...3.26)
+#----------------------------------------------------------------
+# Generated CMake target import file.
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Protect against multiple inclusion, which would fail when already imported targets are added once more.
+set(_cmake_targets_defined "")
+set(_cmake_targets_not_defined "")
+set(_cmake_expected_targets "")
+foreach(_cmake_expected_target IN ITEMS runtime nncaseruntime runtime_stackvm kernels nncasebase)
+  list(APPEND _cmake_expected_targets "${_cmake_expected_target}")
+  if(TARGET "${_cmake_expected_target}")
+    list(APPEND _cmake_targets_defined "${_cmake_expected_target}")
+  else()
+    list(APPEND _cmake_targets_not_defined "${_cmake_expected_target}")
+  endif()
+endforeach()
+unset(_cmake_expected_target)
+if(_cmake_targets_defined STREQUAL _cmake_expected_targets)
+  unset(_cmake_targets_defined)
+  unset(_cmake_targets_not_defined)
+  unset(_cmake_expected_targets)
+  unset(CMAKE_IMPORT_FILE_VERSION)
+  cmake_policy(POP)
+  return()
+endif()
+if(NOT _cmake_targets_defined STREQUAL "")
+  string(REPLACE ";" ", " _cmake_targets_defined_text "${_cmake_targets_defined}")
+  string(REPLACE ";" ", " _cmake_targets_not_defined_text "${_cmake_targets_not_defined}")
+  message(FATAL_ERROR "Some (but not all) targets in this export set were already defined.\nTargets Defined: ${_cmake_targets_defined_text}\nTargets not yet defined: ${_cmake_targets_not_defined_text}\n")
+endif()
+unset(_cmake_targets_defined)
+unset(_cmake_targets_not_defined)
+unset(_cmake_expected_targets)
+
+
+# Compute the installation prefix relative to this file.
+get_filename_component(_IMPORT_PREFIX "${CMAKE_CURRENT_LIST_FILE}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+if(_IMPORT_PREFIX STREQUAL "/")
+  set(_IMPORT_PREFIX "")
+endif()
+
+# Create imported target runtime
+add_library(runtime INTERFACE IMPORTED)
+
+set_target_properties(runtime PROPERTIES
+  INTERFACE_LINK_LIBRARIES "gsl::gsl-lite;\$<LINK_ONLY:kernels>"
+)
+
+# Create imported target nncaseruntime
+add_library(nncaseruntime STATIC IMPORTED)
+
+set_target_properties(nncaseruntime PROPERTIES
+  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
+  INTERFACE_LINK_LIBRARIES "\$<LINK_ONLY:nncasebase>;\$<LINK_ONLY:kernels>;\$<LINK_ONLY:runtime>;\$<LINK_ONLY:runtime_stackvm>;gsl::gsl-lite"
+)
+
+# Create imported target runtime_stackvm
+add_library(runtime_stackvm INTERFACE IMPORTED)
+
+set_target_properties(runtime_stackvm PROPERTIES
+  INTERFACE_LINK_LIBRARIES "runtime;\$<LINK_ONLY:kernels>"
+)
+
+# Create imported target kernels
+add_library(kernels INTERFACE IMPORTED)
+
+set_target_properties(kernels PROPERTIES
+  INTERFACE_LINK_LIBRARIES "gsl::gsl-lite"
+)
+
+# Create imported target nncasebase
+add_library(nncasebase INTERFACE IMPORTED)
+
+set_target_properties(nncasebase PROPERTIES
+  INTERFACE_COMPILE_DEFINITIONS "NNCASE_DLL"
+  INTERFACE_LINK_LIBRARIES "gsl::gsl-lite"
+)
+
+if(CMAKE_VERSION VERSION_LESS 3.0.0)
+  message(FATAL_ERROR "This file relies on consumers using CMake 3.0.0 or greater.")
+endif()
+
+# Load information for each installed configuration.
+file(GLOB _cmake_config_files "${CMAKE_CURRENT_LIST_DIR}/nncaseruntimeTargets-*.cmake")
+foreach(_cmake_config_file IN LISTS _cmake_config_files)
+  include("${_cmake_config_file}")
+endforeach()
+unset(_cmake_config_file)
+unset(_cmake_config_files)
+
+# Cleanup temporary variables.
+set(_IMPORT_PREFIX)
+
+# Loop over all imported files and verify that they actually exist
+foreach(_cmake_target IN LISTS _cmake_import_check_targets)
+  foreach(_cmake_file IN LISTS "_cmake_import_check_files_for_${_cmake_target}")
+    if(NOT EXISTS "${_cmake_file}")
+      message(FATAL_ERROR "The imported target \"${_cmake_target}\" references the file
+   \"${_cmake_file}\"
+but this file does not exist.  Possible reasons include:
+* The file was deleted, renamed, or moved to another location.
+* An install or uninstall procedure did not complete successfully.
+* The installation package was faulty and contained
+   \"${CMAKE_CURRENT_LIST_FILE}\"
+but not all the files it references.
+")
+    endif()
+  endforeach()
+  unset(_cmake_file)
+  unset("_cmake_import_check_files_for_${_cmake_target}")
+endforeach()
+unset(_cmake_target)
+unset(_cmake_import_check_targets)
+
+# This file does not depend on other imported targets which have
+# been exported from the same project but in a separate export set.
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
+cmake_policy(POP)
diff --git a/third_party/nncase/riscv64/lib/libNncase.Runtime.Native.a b/third_party/nncase/riscv64/lib/libNncase.Runtime.Native.a
new file mode 100644
index 0000000..2e8e396
Binary files /dev/null and b/third_party/nncase/riscv64/lib/libNncase.Runtime.Native.a differ
diff --git a/third_party/nncase/riscv64/lib/libfunctional_k230.a b/third_party/nncase/riscv64/lib/libfunctional_k230.a
new file mode 100644
index 0000000..63cd2d6
Binary files /dev/null and b/third_party/nncase/riscv64/lib/libfunctional_k230.a differ
diff --git a/third_party/nncase/riscv64/lib/libnncase.rt_modules.k230.a b/third_party/nncase/riscv64/lib/libnncase.rt_modules.k230.a
new file mode 100644
index 0000000..10fa446
Binary files /dev/null and b/third_party/nncase/riscv64/lib/libnncase.rt_modules.k230.a differ
diff --git a/third_party/nncase/x86_64/bin/chibicc b/third_party/nncase/x86_64/bin/chibicc
new file mode 100644
index 0000000..d5d89eb
Binary files /dev/null and b/third_party/nncase/x86_64/bin/chibicc differ
diff --git a/third_party/nncase/x86_64/bin/k230_cmodel_cli b/third_party/nncase/x86_64/bin/k230_cmodel_cli
new file mode 100644
index 0000000..1093fb7
Binary files /dev/null and b/third_party/nncase/x86_64/bin/k230_cmodel_cli differ
diff --git a/third_party/nncase/x86_64/bin/nncase.simulator.k230.sc b/third_party/nncase/x86_64/bin/nncase.simulator.k230.sc
new file mode 100644
index 0000000..13c1e68
Binary files /dev/null and b/third_party/nncase/x86_64/bin/nncase.simulator.k230.sc differ
diff --git a/third_party/nncase/x86_64/get.sh b/third_party/nncase/x86_64/get.sh
new file mode 100644
index 0000000..ff34f8a
--- /dev/null
+++ b/third_party/nncase/x86_64/get.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+
+rm -rf bin lib include python
+
+cp -r /home/zhangyang/workspace/k230_conan2_test/nncase_native_runtime/* .
diff --git a/third_party/nncase/x86_64/include/nncase/api.h b/third_party/nncase/x86_64/include/nncase/api.h
new file mode 100644
index 0000000..1f457d1
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/api.h
@@ -0,0 +1,111 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/simple_types.h>
+
+namespace nncase {
+class object_node;
+class tensor_node;
+class tuple_node;
+class value_node;
+class type_node;
+class datatype_node;
+
+namespace runtime {
+class buffer_allocator;
+class buffer_node;
+class host_buffer_node;
+class interpreter;
+class runtime_function;
+} // namespace runtime
+} // namespace nncase
+
+extern "C" {
+struct nncase_buffer_slice {
+    nncase::runtime::buffer_node *buffer;
+    uint32_t start;
+    uint32_t size_bytes;
+};
+
+NNCASE_API int nncase_object_add_ref(nncase::object_node *node);
+NNCASE_API int nncase_object_release(nncase::object_node *node);
+
+NNCASE_API int nncase_interp_create(nncase::runtime::interpreter **interp);
+NNCASE_API int nncase_interp_free(nncase::runtime::interpreter *interp);
+NNCASE_API int nncase_interp_load_model(nncase::runtime::interpreter *interp,
+                                        void *model_buffer, uint32_t model_size,
+                                        bool copy_buffer);
+NNCASE_API int nncase_interp_set_dump_root(nncase::runtime::interpreter *interp,
+                                           const char *path);
+NNCASE_API int
+nncase_interp_get_entry_func(nncase::runtime::interpreter *interp,
+                             nncase::runtime::runtime_function **func);
+
+NNCASE_API int
+nncase_func_get_params_size(nncase::runtime::runtime_function *func,
+                            uint32_t *size);
+NNCASE_API int nncase_func_invoke(nncase::runtime::runtime_function *func,
+                                  nncase::value_node **params,
+                                  uint32_t params_size,
+                                  nncase::value_node **result);
+
+NNCASE_API int
+nncase_buffer_allocator_get_host(nncase::runtime::buffer_allocator **alloc);
+NNCASE_API int
+nncase_buffer_allocator_alloc(nncase::runtime::buffer_allocator *alloc,
+                              uint32_t bytes, void *options,
+                              nncase::runtime::buffer_node **buffer);
+NNCASE_API int
+nncase_buffer_as_host(nncase::runtime::buffer_node *buffer,
+                      nncase::runtime::host_buffer_node **host_buffer);
+
+NNCASE_API int
+nncase_host_buffer_map(nncase::runtime::host_buffer_node *host_buffer,
+                       nncase::runtime::map_access_t access, void **data,
+                       uint32_t *bytes);
+NNCASE_API int
+nncase_host_buffer_unmap(nncase::runtime::host_buffer_node *host_buffer);
+
+NNCASE_API int nncase_dtype_create_prime(nncase::typecode_t typecode,
+                                         nncase::datatype_node **dtype);
+
+NNCASE_API int nncase_dtype_get_typecode(nncase::datatype_node *dtype);
+
+NNCASE_API int nncase_value_is_tensor(nncase::value_node *value,
+                                      bool *is_tensor);
+
+NNCASE_API int nncase_tensor_create(nncase::datatype_node *dtype,
+                                    const uint32_t *dims, uint32_t dims_length,
+                                    const uint32_t *strides,
+                                    uint32_t strides_length,
+                                    nncase_buffer_slice *buffer,
+                                    nncase::tensor_node **tensor);
+NNCASE_API int nncase_tensor_get_dtype(nncase::tensor_node *tensor,
+                                       nncase::datatype_node **dtype);
+NNCASE_API int nncase_tensor_get_buffer(nncase::tensor_node *tensor,
+                                        nncase_buffer_slice *buffer);
+NNCASE_API int nncase_tensor_get_dims(nncase::tensor_node *tensor,
+                                      uint32_t *dims, uint32_t *dims_length);
+NNCASE_API int nncase_tensor_get_strides(nncase::tensor_node *tensor,
+                                         uint32_t *dims, uint32_t *dims_length);
+
+NNCASE_API int nncase_tuple_create(nncase::value_node **fields,
+                                   uint32_t fields_length,
+                                   nncase::tuple_node **tuple);
+NNCASE_API int nncase_tuple_get_fields(nncase::tuple_node *tuple,
+                                       nncase::value_node **fields,
+                                       uint32_t *fields_length);
+}
diff --git a/third_party/nncase/x86_64/include/nncase/compiler.h b/third_party/nncase/x86_64/include/nncase/compiler.h
new file mode 100644
index 0000000..1ef12f9
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/compiler.h
@@ -0,0 +1,697 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <iostream>
+#include <map>
+#include <nlohmann/json.hpp>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/simple_types.h>
+#include <nncase/value.h>
+#include <string>
+#include <unordered_map>
+using nlohmann::json;
+
+extern "C" {
+typedef void *clr_object_handle_t;
+typedef void *nncase_stream_handle_t;
+
+typedef enum {
+    nncase_array_rtvalue = 0,
+    nncase_array_var = 1
+} nncase_array_element_kind_t;
+
+typedef enum {
+    nncase_mqm_no_quant = 0,
+    nncase_mqm_use_ptq = 1,
+    nncase_mqm_use_qat = 2
+} nncase_model_quant_mode_t;
+
+typedef enum {
+    nncase_qm_unsigned = 0,
+    nncase_qm_signed_symmetric = 1,
+    nncase_qm_signed_asymmetric = 2
+} nncase_quant_mode_t;
+
+typedef enum {
+    nncase_qt_uint8 = 0,
+    nncase_qt_int8 = 1,
+    nncase_qt_int16 = 2
+} nncase_quant_type_t;
+
+typedef enum {
+    nncase_calib_noclip = 0,
+    nncase_calib_kld = 1
+} nncase_calib_method_t;
+
+typedef enum {
+    nncase_no_finetune_weights = 0,
+    nncase_finetune_weights_squant = 1,
+    nncase_finetune_weights_adaround = 2
+} nncase_finetune_weights_method_t;
+
+typedef enum {
+    nncase_dump_flags_none = 0,
+    nncase_dump_flags_import_ops = 1 << 1,
+    nncase_dump_flags_pass_ir = 1 << 2,
+    nncase_dump_flags_egraph_cost = 1 << 3,
+    nncase_dump_flags_rewrite = 1 << 4,
+    nncase_dump_flags_calibration = 1 << 5,
+    nncase_dump_flags_evaluator = 1 << 6,
+    nncase_dump_flags_compile = 1 << 7,
+    nncase_dump_flags_tiling = 1 << 8,
+    nncase_dump_flags_schedule = 1 << 9,
+    nncase_dump_flags_codegen = 1 << 10
+} nncase_dump_flags_t;
+
+typedef enum {
+    nncase_it_uint8 = 0,
+    nncase_it_int8 = 1,
+    nncase_it_float32 = 2
+} nncase_input_type_t;
+
+typedef struct {
+    void (*add_ref)(nncase_stream_handle_t handle);
+    void (*release)(nncase_stream_handle_t handle);
+    bool (*can_read)(nncase_stream_handle_t handle);
+    bool (*can_seek)(nncase_stream_handle_t handle);
+    bool (*can_write)(nncase_stream_handle_t handle);
+    void (*flush)(nncase_stream_handle_t handle);
+    int64_t (*get_length)(nncase_stream_handle_t handle);
+    int64_t (*set_length)(nncase_stream_handle_t handle, uint64_t value);
+    int64_t (*get_position)(nncase_stream_handle_t handle);
+    size_t (*read)(nncase_stream_handle_t handle, uint8_t *buffer,
+                   size_t length);
+    int64_t (*seek)(nncase_stream_handle_t handle, int origin, int64_t offset);
+    void (*write)(nncase_stream_handle_t handle, const uint8_t *buffer,
+                  size_t length);
+} nncase_stream_mt_t;
+
+typedef struct {
+    clr_object_handle_t (*array_create)(nncase_array_element_kind_t kind,
+                                        const clr_object_handle_t *elements,
+                                        size_t count);
+    clr_object_handle_t (*array_get_item)(clr_object_handle_t array,
+                                          size_t index);
+    size_t (*array_get_length)(clr_object_handle_t array);
+    clr_object_handle_t (*calibration_dataset_provider_create)(
+        clr_object_handle_t dataset, size_t samplesCount,
+        clr_object_handle_t fn_params);
+    void (*handle_dispose)(clr_object_handle_t handle);
+    void (*handle_free)(clr_object_handle_t handle);
+    clr_object_handle_t (*compile_options_create)();
+    void (*compile_options_set_input_file)(clr_object_handle_t compile_options,
+                                           const char *input_file,
+                                           size_t input_file_length);
+    void (*compile_options_set_input_format)(
+        clr_object_handle_t compile_options, const char *input_format,
+        size_t input_format_length);
+    void (*compile_options_set_dump_dir)(clr_object_handle_t compile_options,
+                                         const char *dump_dir,
+                                         size_t dump_dir_length);
+    nncase_dump_flags_t (*compile_options_get_dump_flags)(
+        clr_object_handle_t compile_options);
+    void (*compile_options_set_dump_flags)(clr_object_handle_t compile_options,
+                                           nncase_dump_flags_t dump_flags);
+    void (*compile_options_set_quantize_options)(
+        clr_object_handle_t compile_options,
+        clr_object_handle_t quantize_options);
+    void (*compile_options_set_preprocess)(clr_object_handle_t compile_options,
+                                           bool preprocess);
+    void (*compile_options_set_input_layout)(
+        clr_object_handle_t compile_options, const char *input_layout,
+        size_t input_layout_length);
+    void (*compile_options_set_output_layout)(
+        clr_object_handle_t compile_options, const char *output_layout,
+        size_t output_layout_length);
+    void (*compile_options_set_input_type)(clr_object_handle_t compile_options,
+                                           nncase_input_type_t input_type);
+    void (*compile_options_set_input_shape)(clr_object_handle_t compile_options,
+                                            const char *input_shape,
+                                            size_t input_shape_length);
+    void (*compile_options_set_input_range)(clr_object_handle_t compile_options,
+                                            const char *input_range,
+                                            size_t input_range_length);
+    void (*compile_options_set_swapRB)(clr_object_handle_t compile_options,
+                                       bool swapRB);
+    void (*compile_options_set_letterbox_value)(
+        clr_object_handle_t compile_options, float letterbox_value);
+    void (*compile_options_set_mean)(clr_object_handle_t compile_options,
+                                     const char *mean, size_t mean_length);
+    void (*compile_options_set_std)(clr_object_handle_t compile_options,
+                                    const char *std, size_t std_length);
+    void (*compile_options_set_shape_bucket_options)(
+        clr_object_handle_t compile_options,
+        clr_object_handle_t shape_bucket_options);
+    clr_object_handle_t (*compile_session_create)(
+        clr_object_handle_t target, clr_object_handle_t compile_options);
+    clr_object_handle_t (*compile_session_get_compiler)(
+        clr_object_handle_t compile_session);
+    void (*compiler_initialize)();
+    clr_object_handle_t (*compiler_import_tflite_module)(
+        clr_object_handle_t compiler, clr_object_handle_t stream);
+    clr_object_handle_t (*compiler_import_onnx_module)(
+        clr_object_handle_t compiler, clr_object_handle_t stream);
+    clr_object_handle_t (*compiler_import_ncnn_module)(
+        clr_object_handle_t compiler, clr_object_handle_t param_stream,
+        clr_object_handle_t bin_stream);
+    void (*compiler_compile)(clr_object_handle_t compiler);
+    void (*compiler_gencode)(clr_object_handle_t compiler,
+                             clr_object_handle_t stream);
+    clr_object_handle_t (*datatype_from_typecode)(nncase::typecode_t typecode);
+    clr_object_handle_t (*expr_evaluate)(clr_object_handle_t expr,
+                                         clr_object_handle_t parameters,
+                                         clr_object_handle_t inputs);
+    clr_object_handle_t (*function_get_body)(clr_object_handle_t function);
+    clr_object_handle_t (*function_get_parameters)(
+        clr_object_handle_t function);
+    clr_object_handle_t (*ir_module_get_entry)(clr_object_handle_t module);
+    void (*luanch_debugger)();
+    clr_object_handle_t (*quantize_options_create)();
+    clr_object_handle_t (*shape_bucket_options_create)();
+    void (*quantize_options_set_calibration_dataset)(
+        clr_object_handle_t quantize_options, clr_object_handle_t dataset);
+    void (*quantize_options_set_calibration_method)(
+        clr_object_handle_t quantize_options, nncase_calib_method_t method);
+    void (*quantize_options_set_model_quant_mode)(
+        clr_object_handle_t quantize_options,
+        nncase_model_quant_mode_t model_quant_mode);
+    void (*quantize_options_set_quant_type)(
+        clr_object_handle_t quantize_options, nncase_quant_type_t quant_type);
+    void (*quantize_options_set_w_quant_type)(
+        clr_object_handle_t quantize_options, nncase_quant_type_t w_quant_type);
+    void (*quantize_options_set_finetune_weights_method)(
+        clr_object_handle_t quantize_options,
+        nncase_finetune_weights_method_t method);
+    void (*quantize_options_set_use_mix_quant)(
+        clr_object_handle_t quantize_options, bool use_mix_quant);
+    void (*quantize_options_set_quant_scheme)(
+        clr_object_handle_t quantize_options, const char *quant_scheme,
+        size_t quant_scheme_length);
+    void (*quantize_options_set_quant_scheme_strict_mode)(
+        clr_object_handle_t quantize_options, bool quant_scheme_strict_mode);
+    void (*quantize_options_set_export_quant_scheme)(
+        clr_object_handle_t quantize_options, bool export_quant_scheme);
+    void (*quantize_options_set_export_weight_range_by_channel)(
+        clr_object_handle_t quantize_options,
+        bool export_weight_range_by_channel);
+    void (*quantize_options_set_dump_quant_error)(
+        clr_object_handle_t quantize_options, bool dump_quant_error);
+    void (*quantize_options_set_dump_quant_error_symmetric_for_signed)(
+        clr_object_handle_t quantize_options,
+        bool dump_quant_error_symmetric_for_signed);
+    void (*shape_bucket_options_set_enable)(
+        clr_object_handle_t shape_bucket_options, bool enable);
+    void (*shape_bucket_options_set_range_info)(
+        clr_object_handle_t shape_bucket_options, const char *range_info,
+        size_t range_info_size);
+    void (*shape_bucket_options_set_segments_count)(
+        clr_object_handle_t shape_bucket_options, int segments_count);
+    void (*shape_bucket_options_set_fix_var_map)(
+        clr_object_handle_t shape_bucket_options, const char *fix_var_map,
+        size_t fix_var_map_size);
+
+    clr_object_handle_t (*rtvalue_from_handle)(nncase::value_node *value);
+    nncase::value_node *(*rtvalue_get_handle)(clr_object_handle_t rtvalue);
+    clr_object_handle_t (*stream_create)(const nncase_stream_mt_t *mt,
+                                         void *handle);
+    clr_object_handle_t (*target_create)(const char *target_name,
+                                         size_t target_name_length);
+    bool (*target_exists)(const char *target_name, size_t target_name_length);
+} nncase_api_mt_t;
+
+NNCASE_API nncase_api_mt_t *nncase_clr_api();
+NNCASE_API int nncase_clr_initialize(const char *root_assembly_path);
+NNCASE_API int nncase_clr_uninitialize();
+}
+
+DEFINE_ENUM_BITMASK_OPERATORS(nncase_dump_flags_t)
+
+namespace nncase::clr {
+class clr_object_ptr {
+  public:
+    constexpr clr_object_ptr(std::nullptr_t = nullptr) noexcept
+        : handle_(nullptr) {}
+    constexpr clr_object_ptr(clr_object_handle_t handle) noexcept
+        : handle_(handle) {}
+    constexpr clr_object_ptr(clr_object_ptr &&other) noexcept
+        : handle_(other.handle_) {
+        other.handle_ = nullptr;
+    }
+
+    ~clr_object_ptr() { release(); }
+
+    clr_object_ptr(const clr_object_ptr &) = delete;
+    clr_object_ptr &operator=(const clr_object_ptr &) = delete;
+
+    clr_object_ptr &operator=(clr_object_ptr &&other) noexcept {
+        release();
+        handle_ = other.handle_;
+        other.handle_ = nullptr;
+        return *this;
+    }
+
+    clr_object_handle_t get() const noexcept { return handle_; }
+
+    clr_object_handle_t detach() noexcept {
+        auto handle = handle_;
+        handle_ = nullptr;
+        return handle;
+    }
+
+    clr_object_handle_t *release_and_addressof() noexcept {
+        release();
+        return &handle_;
+    }
+
+  private:
+    void release() {
+        if (auto handle = handle_) {
+            handle_ = nullptr;
+            nncase_clr_api()->handle_free(handle);
+        }
+    }
+
+  private:
+    clr_object_handle_t handle_;
+};
+
+#define CHECK_CLR(x) x
+
+class clr_object_base {
+  public:
+    constexpr clr_object_base(std::nullptr_t = nullptr) noexcept
+        : obj_(nullptr) {}
+
+    clr_object_base(std::in_place_t, clr_object_ptr ptr) noexcept
+        : obj_(std::move(ptr)) {}
+
+    clr_object_base(clr_object_base &&) = default;
+    clr_object_base &operator=(clr_object_base &&) = default;
+
+    clr_object_handle_t get() const noexcept { return obj_.get(); }
+    clr_object_handle_t *release_and_addressof() noexcept {
+        return obj_.release_and_addressof();
+    }
+
+    template <class T, std::enable_if_t<std::is_base_of_v<clr_object_base, T>>>
+    T &cast() noexcept {
+        return static_cast<T &>(*this);
+    }
+
+  protected:
+    clr_object_ptr obj_;
+};
+
+class array : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    array(nncase_array_element_kind_t kind, const clr_object_handle_t *elements,
+          size_t length) {
+        obj_ = nncase_clr_api()->array_create(kind, elements, length);
+    }
+
+    template <class T = clr_object_base> T at(size_t index) {
+        return {std::in_place,
+                nncase_clr_api()->array_get_item(obj_.get(), index)};
+    }
+
+    size_t length() { return nncase_clr_api()->array_get_length(obj_.get()); }
+
+    template <class T = clr_object_base> std::vector<T> to_vector() {
+        std::vector<T> vector(length());
+        for (size_t i = 0; i < vector.size(); i++) {
+            vector[i] = at<T>(i);
+        }
+        return vector;
+    }
+};
+
+class calibration_dataset_provider : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    calibration_dataset_provider(array dataset, size_t samples_count,
+                                 array fn_params) {
+        obj_ = nncase_clr_api()->calibration_dataset_provider_create(
+            dataset.get(), samples_count, fn_params.get());
+    }
+};
+
+class quantize_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    quantize_options() { obj_ = nncase_clr_api()->quantize_options_create(); }
+
+    calibration_dataset_provider calibration_dataset() { return nullptr; }
+    void calibration_dataset(const calibration_dataset_provider &value) {
+        nncase_clr_api()->quantize_options_set_calibration_dataset(obj_.get(),
+                                                                   value.get());
+    }
+
+    nncase_model_quant_mode_t model_quant_mode() { return nncase_mqm_no_quant; }
+    void model_quant_mode(nncase_model_quant_mode_t value) {
+        nncase_clr_api()->quantize_options_set_model_quant_mode(obj_.get(),
+                                                                value);
+    }
+
+    nncase_calib_method_t calibrate_method() { return nncase_calib_noclip; }
+    void calibrate_method(nncase_calib_method_t value) {
+        nncase_clr_api()->quantize_options_set_calibration_method(obj_.get(),
+                                                                  value);
+    }
+
+    nncase_quant_type_t quant_type() { return nncase_qt_uint8; }
+    void quant_type(nncase_quant_type_t value) {
+        nncase_clr_api()->quantize_options_set_quant_type(obj_.get(), value);
+    }
+
+    nncase_quant_type_t w_quant_type() { return nncase_qt_uint8; }
+    void w_quant_type(nncase_quant_type_t value) {
+        nncase_clr_api()->quantize_options_set_w_quant_type(obj_.get(), value);
+    }
+
+    nncase_finetune_weights_method_t finetune_weights_method() {
+        return nncase_no_finetune_weights;
+    }
+    void finetune_weights_method(nncase_finetune_weights_method_t value) {
+        nncase_clr_api()->quantize_options_set_finetune_weights_method(
+            obj_.get(), value);
+    }
+
+    bool use_mix_quant() { return false; }
+    void use_mix_quant(bool value) {
+        nncase_clr_api()->quantize_options_set_use_mix_quant(obj_.get(), value);
+    }
+
+    std::string quant_scheme() { return ""; }
+    void quant_scheme(std::string_view value) {
+        nncase_clr_api()->quantize_options_set_quant_scheme(
+            obj_.get(), value.data(), value.length());
+    }
+
+    bool quant_scheme_strict_mode() { return false; }
+    void quant_scheme_strict_mode(bool value) {
+        nncase_clr_api()->quantize_options_set_quant_scheme_strict_mode(
+            obj_.get(), value);
+    }
+
+    bool export_quant_scheme() { return false; }
+    void export_quant_scheme(bool value) {
+        nncase_clr_api()->quantize_options_set_export_quant_scheme(obj_.get(),
+                                                                   value);
+    }
+
+    bool export_weight_range_by_channel() { return false; }
+    void export_weight_range_by_channel(bool value) {
+        nncase_clr_api()->quantize_options_set_export_weight_range_by_channel(
+            obj_.get(), value);
+    }
+
+    bool dump_quant_error() { return false; }
+    void dump_quant_error(bool value) {
+        nncase_clr_api()->quantize_options_set_dump_quant_error(obj_.get(),
+                                                                value);
+    }
+
+    bool dump_quant_error_symmetric_for_signed() { return false; }
+    void dump_quant_error_symmetric_for_signed(bool value) {
+        nncase_clr_api()
+            ->quantize_options_set_dump_quant_error_symmetric_for_signed(
+                obj_.get(), value);
+    }
+};
+
+class shape_bucket_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    shape_bucket_options() {
+        obj_ = nncase_clr_api()->shape_bucket_options_create();
+    }
+
+    bool enable() { return false; }
+    void enable(bool value) {
+        nncase_clr_api()->shape_bucket_options_set_enable(obj_.get(), value);
+    }
+
+    std::map<std::string, std::tuple<int, int>> range_info() { return {}; }
+    void range_info(std::map<std::string, std::tuple<int, int>> value) {
+        json j = value;
+        std::string s = j.dump();
+        nncase_clr_api()->shape_bucket_options_set_range_info(
+            obj_.get(), s.c_str(), s.length());
+    }
+
+    int segments_count() { return 2; }
+    void segments_count(int value) {
+        nncase_clr_api()->shape_bucket_options_set_segments_count(obj_.get(),
+                                                                  value);
+    }
+
+    std::map<std::string, int> fix_var_map() { return {}; }
+    void fix_var_map(std::map<std::string, int> value) {
+        json j = value;
+        std::string s = j.dump();
+        nncase_clr_api()->shape_bucket_options_set_fix_var_map(
+            obj_.get(), s.c_str(), s.length());
+    }
+};
+
+class cstream : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    cstream(const nncase_stream_mt_t *mt, void *handle) {
+        obj_ = nncase_clr_api()->stream_create(mt, handle);
+    }
+
+    ~cstream() { nncase_clr_api()->handle_dispose(obj_.get()); }
+};
+
+class compile_options : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    compile_options() { obj_ = nncase_clr_api()->compile_options_create(); }
+
+    std::string input_format() { return "cpu"; }
+    void input_format(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_format(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string dump_dir() { return "cpu"; }
+    void dump_dir(std::string_view value) {
+        nncase_clr_api()->compile_options_set_dump_dir(obj_.get(), value.data(),
+                                                       value.length());
+    }
+
+    nncase_dump_flags_t dump_flags() {
+        return nncase_clr_api()->compile_options_get_dump_flags(obj_.get());
+    }
+    void dump_flags(nncase_dump_flags_t value) {
+        nncase_clr_api()->compile_options_set_dump_flags(obj_.get(), value);
+    }
+
+    clr::quantize_options quantize_options() { return nullptr; }
+    void quantize_options(const clr::quantize_options &value) {
+        nncase_clr_api()->compile_options_set_quantize_options(obj_.get(),
+                                                               value.get());
+    }
+
+    bool preprocess() { return true; }
+    void preprocess(bool value) {
+        nncase_clr_api()->compile_options_set_preprocess(obj_.get(), value);
+    }
+
+    std::string input_layout() { return ""; }
+    void input_layout(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_layout(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string output_layout() { return ""; }
+    void output_layout(std::string_view value) {
+        nncase_clr_api()->compile_options_set_output_layout(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string input_file() { return ""; }
+    void input_file(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_file(
+            obj_.get(), value.data(), value.length());
+    }
+
+    nncase_input_type_t input_type() { return nncase_it_float32; }
+    void input_type(nncase_input_type_t value) {
+        nncase_clr_api()->compile_options_set_input_type(obj_.get(), value);
+    }
+
+    std::string input_shape() { return ""; }
+    void input_shape(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_shape(
+            obj_.get(), value.data(), value.length());
+    }
+
+    std::string input_range() { return ""; }
+    void input_range(std::string_view value) {
+        nncase_clr_api()->compile_options_set_input_range(
+            obj_.get(), value.data(), value.length());
+    }
+
+    bool swapRB() { return false; }
+    void swapRB(bool value) {
+        nncase_clr_api()->compile_options_set_swapRB(obj_.get(), value);
+    }
+
+    float letterbox_value() { return 0.f; }
+    void letterbox_value(float value) {
+        nncase_clr_api()->compile_options_set_letterbox_value(obj_.get(),
+                                                              value);
+    }
+
+    std::string mean() { return ""; }
+    void mean(std::string_view value) {
+        nncase_clr_api()->compile_options_set_mean(obj_.get(), value.data(),
+                                                   value.length());
+    }
+
+    std::string std() { return ""; }
+    void std(std::string_view value) {
+        nncase_clr_api()->compile_options_set_std(obj_.get(), value.data(),
+                                                  value.length());
+    }
+
+    clr::shape_bucket_options shape_bucket_options() { return nullptr; }
+    void shape_bucket_options(const clr::shape_bucket_options &value) {
+        nncase_clr_api()->compile_options_set_shape_bucket_options(obj_.get(),
+                                                                   value.get());
+    }
+};
+
+class target : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    static bool exists(std::string_view name) {
+        return nncase_clr_api()->target_exists(name.data(), name.length());
+    }
+
+    target(std::string_view name) {
+        obj_ = nncase_clr_api()->target_create(name.data(), name.length());
+    }
+};
+
+class rtvalue : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    rtvalue(nncase::value_t value) {
+        obj_ = nncase_clr_api()->rtvalue_from_handle(value.get());
+    }
+
+    value_t to_value() const {
+        auto ptr = nncase_clr_api()->rtvalue_get_handle(obj_.get());
+        return ptr;
+    }
+};
+
+class expr : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    rtvalue evaluate(const array &params, const array &inputs) {
+        return {std::in_place, nncase_clr_api()->expr_evaluate(
+                                   get(), params.get(), inputs.get())};
+    }
+};
+
+class var : public expr {
+  public:
+    using expr::expr;
+};
+
+class base_function : public expr {
+  public:
+    using expr::expr;
+};
+
+class function : public base_function {
+  public:
+    using base_function::base_function;
+
+    expr body() {
+        return {std::in_place, nncase_clr_api()->function_get_body(get())};
+    }
+
+    array parameters() {
+        return {std::in_place,
+                nncase_clr_api()->function_get_parameters(get())};
+    }
+};
+
+class ir_module : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    function entry() {
+        return {std::in_place, nncase_clr_api()->ir_module_get_entry(get())};
+    }
+};
+
+class compiler : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    ir_module import_tflite_module(cstream &stream) {
+        return {std::in_place, nncase_clr_api()->compiler_import_tflite_module(
+                                   get(), stream.get())};
+    }
+
+    ir_module import_onnx_module(cstream &stream) {
+        return {std::in_place, nncase_clr_api()->compiler_import_onnx_module(
+                                   get(), stream.get())};
+    }
+
+    ir_module import_ncnn_module(cstream &param_stream, cstream &bin_stream) {
+        return {std::in_place,
+                nncase_clr_api()->compiler_import_ncnn_module(
+                    get(), param_stream.get(), bin_stream.get())};
+    }
+
+    void compile() { nncase_clr_api()->compiler_compile(obj_.get()); }
+    void gencode(cstream &stream) {
+        nncase_clr_api()->compiler_gencode(obj_.get(), stream.get());
+    }
+};
+
+class compile_session : public clr_object_base {
+  public:
+    using clr_object_base::clr_object_base;
+
+    compile_session(const target &target, const compile_options &options) {
+        obj_ = nncase_clr_api()->compile_session_create(target.get(),
+                                                        options.get());
+    }
+
+    clr::compiler compiler() {
+        return {std::in_place,
+                nncase_clr_api()->compile_session_get_compiler(obj_.get())};
+    }
+};
+} // namespace nncase::clr
diff --git a/third_party/nncase/x86_64/include/nncase/compiler_defs.h b/third_party/nncase/x86_64/include/nncase/compiler_defs.h
new file mode 100644
index 0000000..ea44203
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/compiler_defs.h
@@ -0,0 +1,107 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <gsl/gsl-lite.hpp>
+#include <type_traits>
+
+#if defined(_MSC_VER)
+#ifdef NNCASE_DLL
+#define NNCASE_API __declspec(dllexport)
+#elif defined(NNCASE_SHARED_LIBS)
+#define NNCASE_API __declspec(dllimport)
+#else
+#define NNCASE_API
+#endif
+#else
+#define NNCASE_API __attribute__((visibility("default")))
+#endif
+
+#if defined(_MSC_VER)
+#define NNCASE_UNREACHABLE() __assume(0)
+#else
+#define NNCASE_UNREACHABLE() __builtin_unreachable()
+#endif
+
+#if gsl_CPP17_OR_GREATER
+#define NNCASE_INLINE_VAR inline
+#define NNCASE_UNUSED [[maybe_unused]]
+namespace nncase {
+template <class Callable, class... Args>
+using invoke_result_t = std::invoke_result_t<Callable, Args...>;
+}
+#else
+#define NNCASE_INLINE_VAR
+#if defined(_MSC_VER)
+#define NNCASE_UNUSED
+#else
+#define NNCASE_UNUSED __attribute__((unused))
+#endif
+namespace nncase {
+template <class Callable, class... Args>
+using invoke_result_t = std::result_of_t<Callable(Args...)>;
+}
+#endif
+
+#define NNCASE_LITTLE_ENDIAN 1
+
+#define NNCASE_HAVE_STD_BYTE gsl_CPP17_OR_GREATER
+#define NNCASE_NODISCARD gsl_NODISCARD
+#define NNCASE_NORETURN gsl_NORETURN
+
+#define BEGIN_NS_NNCASE_RUNTIME                                                \
+    namespace nncase {                                                         \
+    namespace runtime {
+#define END_NS_NNCASE_RUNTIME                                                  \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_RT_MODULE(MODULE)                                      \
+    namespace nncase {                                                         \
+    namespace runtime {                                                        \
+    namespace MODULE {
+
+#define END_NS_NNCASE_RT_MODULE                                                \
+    }                                                                          \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_KERNELS                                                \
+    namespace nncase {                                                         \
+    namespace kernels {
+
+#define END_NS_NNCASE_KERNELS                                                  \
+    }                                                                          \
+    }
+
+#define BEGIN_NS_NNCASE_KERNELS_MODULE(MODULE)                                 \
+    namespace nncase {                                                         \
+    namespace kernels {                                                        \
+    namespace MODULE {
+
+#define END_NS_NNCASE_KERNELS_MODULE                                           \
+    }                                                                          \
+    }                                                                          \
+    }
+
+#ifndef DEFINE_ENUM_BITMASK_OPERATORS
+#define DEFINE_ENUM_BITMASK_OPERATORS(ENUMTYPE)                                \
+    gsl_DEFINE_ENUM_BITMASK_OPERATORS(ENUMTYPE)
+#endif
+
+namespace nncase {
+struct default_init_t {};
+
+NNCASE_INLINE_VAR constexpr default_init_t default_init{};
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/functional/ops.h b/third_party/nncase/x86_64/include/nncase/functional/ops.h
new file mode 100644
index 0000000..f9e3454
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/functional/ops.h
@@ -0,0 +1,307 @@
+/**
+ * @file ops.h
+ * @date 2021-09-27
+ *
+ * @copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+#pragma once
+#include <nncase/runtime/runtime_tensor.h>
+
+#ifndef NNCASE_FUNCTIONAL_IMPL_PLATFORM_HEADER
+#include <nncase/functional/ops.platform.h>
+#else
+#include NNCASE_FUNCTIONAL_IMPL_PLATFORM_HEADER
+#endif
+
+namespace nncase::F {
+
+/**
+ * @brief unary_square
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+square(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_square);
+}
+/**
+ * @brief unary_sqrt
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sqrt(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_sqrt);
+}
+/**
+ * @brief unary_log
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+log(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_log);
+}
+/**
+ * @brief unary_exp
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+exp(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_exp);
+}
+/**
+ * @brief unary_sin
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sin(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_sin);
+}
+/**
+ * @brief unary_cos
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+cos(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_cos);
+}
+/**
+ * @brief unary_round
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+round(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_round);
+}
+/**
+ * @brief unary_floor
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+floor(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_floor);
+}
+/**
+ * @brief unary_ceil
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+ceil(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_ceil);
+}
+/**
+ * @brief unary_abs
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+abs(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_abs);
+}
+/**
+ * @brief unary_neg
+ *
+ * @param input runtime_tensor
+ * @param dtype output tensor datatype
+ * @return result<runtime::runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+neg(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::unary(input, dtype, unary_neg);
+}
+
+/**
+ * @brief binary add
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+add(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_add);
+}
+/**
+ * @brief binary sub
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+sub(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_sub);
+}
+/**
+ * @brief binary mul
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+mul(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_mul);
+}
+/**
+ * @brief binary div
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+div(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_div);
+}
+/**
+ * @brief binary min
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+min(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_min);
+}
+/**
+ * @brief binary max
+ *        temporary not support
+ * @param input_a runtime_tensor
+ * @param input_b runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+max(runtime::runtime_tensor &input_a, runtime::runtime_tensor &input_b,
+    datatype_t dtype) noexcept {
+    return impl::binary(input_a, input_b, dtype, binary_max);
+}
+
+/**
+ * @brief quantize float or bfloat tensor to uint8 or int8
+ *
+ * @param input runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+quantize(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::quantize(input, dtype);
+}
+/**
+ * @brief dequantize uint8 or int8 tensor to float or bfloat
+ *
+ * @param input runtime_tensor
+ * @param dtype datatype, output tensor datatype
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+dequantize(runtime::runtime_tensor &input, datatype_t dtype) noexcept {
+    return impl::dequantize(input, dtype);
+}
+
+/**
+ * @brief give bboxs, crop new tensor from current tensor.
+ *
+ * @param input
+ * @param bbox runtime tensor, shape should be [1,1,roi_amounts,4], layout
+ * should be [y0, x0, y1, x1]
+ * @param out_h output tensor height
+ * @param out_w output tensor width
+ * @param resize_mode resize mode
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+crop(runtime::runtime_tensor &input, runtime::runtime_tensor &bbox,
+     size_t out_h, size_t out_w, image_resize_mode_t resize_mode,
+     bool align_corners, bool half_pixel_centers) noexcept {
+    return impl::crop(input, bbox, out_h, out_w, resize_mode, align_corners,
+                      half_pixel_centers);
+}
+
+/**
+ * @brief resize tensor to new height or width
+ *
+ * @param input
+ * @param out_h
+ * @param out_w
+ * @param resize_mode
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+resize(runtime::runtime_tensor &input, size_t out_h, size_t out_w,
+       image_resize_mode_t resize_mode, bool align_corners,
+       bool half_pixel_centers) noexcept {
+    return impl::resize(input, out_h, out_w, resize_mode, align_corners,
+                        half_pixel_centers);
+}
+
+/**
+ * @brief padding value on the input tensor
+ *        temporary not support
+ * @param input
+ * @param padding vector for padding param, from last to frist. eg. vector [
+ * {2,3}, {1,3} ] mean pad {2,3} in last dim, pad {1,3} in last second dim
+ * @param pad_mode
+ * @param fill_v const fill value
+ * @return result<runtime_tensor>
+ */
+NNCASE_API inline result<runtime::runtime_tensor>
+pad(runtime::runtime_tensor &input, runtime_paddings_t &paddings,
+    pad_mode_t pad_mode, float fill_v) noexcept {
+    return impl::pad(input, paddings, pad_mode, fill_v);
+}
+
+} // namespace nncase::F
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/functional/ops.platform.h b/third_party/nncase/x86_64/include/nncase/functional/ops.platform.h
new file mode 100644
index 0000000..5990248
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/functional/ops.platform.h
@@ -0,0 +1,52 @@
+/**
+ * @file ops.platform.h
+ * @copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+#pragma once
+#include <nncase/runtime/runtime_tensor.h>
+
+namespace nncase::F::impl {
+
+result<runtime::runtime_tensor> unary(runtime::runtime_tensor &input,
+                                      datatype_t dtype,
+                                      unary_op_t op_type) noexcept;
+
+result<runtime::runtime_tensor> binary(runtime::runtime_tensor &input_a,
+                                       runtime::runtime_tensor &input_b,
+                                       datatype_t dtype,
+                                       binary_op_t op_type) noexcept;
+
+result<runtime::runtime_tensor> quantize(runtime::runtime_tensor &input,
+                                         datatype_t dtype) noexcept;
+
+result<runtime::runtime_tensor> dequantize(runtime::runtime_tensor &input,
+                                           datatype_t dtype) noexcept;
+
+result<runtime::runtime_tensor>
+crop(runtime::runtime_tensor &input, runtime::runtime_tensor &bbox,
+     size_t out_h, size_t out_w, image_resize_mode_t resize_mode,
+     bool align_corners, bool half_pixel_centers) noexcept;
+
+result<runtime::runtime_tensor> resize(runtime::runtime_tensor &input,
+                                       size_t out_h, size_t out_w,
+                                       image_resize_mode_t resize_mode,
+                                       bool align_corners,
+                                       bool half_pixel_centers) noexcept;
+
+result<runtime::runtime_tensor> pad(runtime::runtime_tensor &input,
+                                    runtime_paddings_t &paddings,
+                                    pad_mode_t pad_mode, float fill_v) noexcept;
+} // namespace nncase::F::impl
diff --git a/third_party/nncase/x86_64/include/nncase/io_utils.h b/third_party/nncase/x86_64/include/nncase/io_utils.h
new file mode 100644
index 0000000..bfd474f
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/io_utils.h
@@ -0,0 +1,36 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <filesystem>
+#include <fstream>
+#include <vector>
+
+namespace nncase {
+inline std::vector<uint8_t> read_stream(std::istream &stream) {
+    stream.seekg(0, std::ios::end);
+    size_t length = stream.tellg();
+    stream.seekg(0, std::ios::beg);
+    std::vector<uint8_t> data(length);
+    stream.read(reinterpret_cast<char *>(data.data()), length);
+    return data;
+}
+
+inline std::vector<uint8_t> read_file(const std::filesystem::path &filename) {
+    std::ifstream infile(filename.string(), std::ios::binary | std::ios::in);
+    if (!infile.good())
+        throw std::runtime_error("Cannot open file: " + filename.string());
+    return read_stream(infile);
+}
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/apply.h b/third_party/nncase/x86_64/include/nncase/kernels/apply.h
new file mode 100644
index 0000000..1df7158
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/apply.h
@@ -0,0 +1,153 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#ifdef _WIN32
+#include <malloc.h> // alloca
+#else
+#include <alloca.h> // alloca
+#endif
+
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/result.h>
+
+#define BEGIN_NS_NNCASE_KERNELS_STACKVM                                        \
+    namespace nncase {                                                         \
+    namespace kernels {                                                        \
+    namespace stackvm {
+namespace reference {
+
+#define END_NS_NNCASE_KERNELS_STACKVM                                          \
+    }                                                                          \
+    }                                                                          \
+    }
+} // namespace reference
+
+BEGIN_NS_NNCASE_KERNELS_STACKVM
+
+namespace detail {
+#define APPLY_IMPL_FOR(i) for (index[i] = 0; index[i] < shape[i]; index[i]++)
+
+template <class Callable>
+result<void> apply_1(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[1];
+    APPLY_IMPL_FOR(0)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_2(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[2];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_3(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[3];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_4(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[4];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    APPLY_IMPL_FOR(3)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_5(gsl::span<const size_t> shape,
+                     Callable &&callable) noexcept {
+    size_t index[5];
+    APPLY_IMPL_FOR(0)
+    APPLY_IMPL_FOR(1)
+    APPLY_IMPL_FOR(2)
+    APPLY_IMPL_FOR(3)
+    APPLY_IMPL_FOR(4)
+    try_(callable(gsl::span(index)));
+    return ok();
+}
+
+template <class Callable>
+result<void> apply_generic(gsl::span<const size_t> shape,
+                           Callable &&callable) noexcept {
+    auto index_buffer = (size_t *)
+#ifdef _WIN32
+        _alloca
+#else
+        __builtin_alloca
+#endif
+        (sizeof(size_t) * shape.size());
+
+    gsl::span<size_t> index(index_buffer, shape.size());
+    std::fill(index.begin(), index.end(), 0);
+    auto last_dim_idx = (int32_t)shape.size() - 1;
+    while (true) {
+        int dim = last_dim_idx;
+        while (index[dim] == shape[dim]) {
+            if (dim == 0) {
+                return ok();
+            }
+
+            index[dim] = 0;
+            index[--dim]++;
+        }
+
+        try_(callable(index));
+        index[last_dim_idx]++;
+    }
+    return ok();
+}
+} // namespace detail
+
+template <class Callable>
+result<void> apply(gsl::span<const size_t> shape,
+                   Callable &&callable) noexcept {
+    switch (shape.size()) {
+    case 0:
+        return callable(shape);
+    case 1:
+        return detail::apply_1(shape, std::forward<Callable>(callable));
+    case 2:
+        return detail::apply_2(shape, std::forward<Callable>(callable));
+    case 3:
+        return detail::apply_3(shape, std::forward<Callable>(callable));
+    case 4:
+        return detail::apply_4(shape, std::forward<Callable>(callable));
+    case 5:
+        return detail::apply_5(shape, std::forward<Callable>(callable));
+    default:
+        break;
+    }
+
+    return detail::apply_generic(shape, std::forward<Callable>(callable));
+}
+
+END_NS_NNCASE_KERNELS_STACKVM
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/kernel_context.h b/third_party/nncase/x86_64/include/nncase/kernels/kernel_context.h
new file mode 100644
index 0000000..695473a
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/kernel_context.h
@@ -0,0 +1,28 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/runtime/dump_manager.h>
+#include <nncase/runtime/result.h>
+
+BEGIN_NS_NNCASE_KERNELS
+
+struct NNCASE_API kernel_context {
+    uint32_t num_threads;
+    std::shared_ptr<runtime::dump_manager> dump_manager;
+};
+
+NNCASE_API kernel_context &default_kernel_context();
+
+END_NS_NNCASE_KERNELS
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/kernel_utils.h b/third_party/nncase/x86_64/include/nncase/kernels/kernel_utils.h
new file mode 100644
index 0000000..f787f59
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/kernel_utils.h
@@ -0,0 +1,266 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <algorithm>
+#include <cassert>
+#include <cmath>
+#include <cstddef>
+#include <nncase/kernels/stackvm/resize_image.h>
+#include <nncase/runtime/datatypes.h>
+#include <numeric>
+
+#ifdef __GNUC__
+#define CXX_RESTRICT __restrict__
+#elif _MSC_VER
+#define CXX_RESTRICT __restrict
+#else
+#define CXX_RESTRICT
+#endif
+
+#define TYPE_IMPL_SELECT(type, IMPL)                                           \
+    switch (runtime::get_bytes(type)) {                                        \
+        IMPL(1, uint8_t);                                                      \
+        IMPL(2, uint16_t);                                                     \
+        IMPL(4, uint32_t);                                                     \
+        IMPL(8, uint64_t);                                                     \
+    default:                                                                   \
+        return err(std::errc::not_supported);                                  \
+    }
+
+BEGIN_NS_NNCASE_KERNELS
+
+template <class offset_type, class S, class It>
+inline offset_type element_offset(const S &strides, It first,
+                                  It last) noexcept {
+    using difference_type = typename std::iterator_traits<It>::difference_type;
+    auto size = static_cast<difference_type>((std::min)(
+        static_cast<size_t>(std::distance(first, last)), strides.size()));
+    return std::inner_product(last - size, last, strides.cend() - size,
+                              offset_type(0));
+}
+
+inline size_t offset(gsl::span<const size_t> strides,
+                     gsl::span<const size_t> index) {
+    // scalar
+    if (strides.size() == 0 || index.size() == 0) {
+        return 0;
+    }
+    assert(strides.size() == index.size());
+    return kernels::element_offset<size_t>(strides, index.begin(), index.end());
+}
+
+template <class TShape>
+TShape reshape_linear_index(const TShape &new_shape, size_t index) {
+    TShape new_index(new_shape.size());
+    size_t i = new_shape.size() - 1;
+    for (auto it = new_shape.rbegin(); it != new_shape.rend(); ++it) {
+        new_index[i--] = index % *it;
+        index /= *it;
+    }
+
+    return new_index;
+}
+
+template <class TShape>
+size_t linear_index(const TShape &shape, const TShape &index) {
+    assert(index.size() == shape.size());
+    size_t new_index = index[0];
+    for (size_t i = 1; i < shape.size(); i++)
+        new_index = new_index * shape[i] + index[i];
+    return new_index;
+}
+
+namespace detail {
+inline size_t get_windowed_output_size(size_t size, int32_t filter,
+                                       int32_t stride, int32_t dilation,
+                                       const padding &padding) {
+    auto effective_filter_size = (filter - 1) * dilation + 1;
+    return (size_t)((int32_t)size + padding.before + padding.after -
+                    effective_filter_size + stride) /
+           stride;
+}
+
+inline dims_t get_binary_output_shape(gsl::span<const size_t> input_a_shape,
+                                      gsl::span<const size_t> input_b_shape) {
+    dims_t out_shape;
+
+    const auto dest_dims =
+        (int32_t)std::max(input_a_shape.size(), input_b_shape.size());
+    const auto in_a_ext = dest_dims - (int32_t)input_a_shape.size();
+    const auto in_b_ext = dest_dims - (int32_t)input_b_shape.size();
+
+    for (int32_t i = 0; i < dest_dims; i++) {
+        const auto in_a_dim = i - (int32_t)in_a_ext;
+        const auto in_b_dim = i - (int32_t)in_b_ext;
+
+        const auto in_a = in_a_dim < 0 ? 1 : input_a_shape[in_a_dim];
+        const auto in_b = in_b_dim < 0 ? 1 : input_b_shape[in_b_dim];
+        if (in_a == in_b)
+            out_shape.push_back(in_a);
+        else if (in_a == 1)
+            out_shape.push_back(in_b);
+        else if (in_b == 1)
+            out_shape.push_back(in_a);
+        else
+            assert(!"inputs are not compatible to broadcast");
+    }
+
+    return out_shape;
+}
+
+template <class T> inline T clamp(T value, T min, T max) {
+    return std::max(std::min(value, max), min);
+}
+
+template <class T>
+inline T apply_activation(T value, value_range<T> activation) {
+    return clamp(value, activation.min, activation.max);
+}
+
+inline dims_t get_reduced_offset(gsl::span<const size_t> in_offset,
+                                 gsl::span<const size_t> reduced_shape) {
+    dims_t off(reduced_shape.size());
+    const auto dims_ext = in_offset.size() - reduced_shape.size();
+    for (size_t i = 0; i < reduced_shape.size(); i++) {
+        if (in_offset[i + dims_ext] >= reduced_shape[i])
+            off[i] = 0;
+        else
+            off[i] = in_offset[i + dims_ext];
+    }
+
+    return off;
+}
+
+inline dims_t get_reduced_shape(gsl::span<const size_t> in_shape,
+                                gsl::span<const size_t> axis, bool keep_dims) {
+    dims_t shape;
+    shape.reserve(in_shape.size() - (keep_dims ? 0 : axis.size()));
+    for (size_t i = 0; i < in_shape.size(); i++) {
+        if (std::find(axis.begin(), axis.end(), i) == axis.end()) {
+            shape.push_back(in_shape[i]);
+        } else {
+            if (keep_dims)
+                shape.push_back(1);
+        }
+    }
+    return shape;
+}
+
+template <class TShape>
+size_t get_reduce_block_size(const TShape &in_shape, const TShape &axis) {
+    size_t size = 1;
+    for (size_t i = 0; i < in_shape.size(); i++) {
+        if (std::find(axis.begin(), axis.end(), i) != axis.end()) {
+            size *= in_shape[i];
+        }
+    }
+
+    return size;
+}
+
+inline dims_t get_reduced_offset(gsl::span<const size_t> in_offset,
+                                 gsl::span<const size_t> axis, bool keep_dims) {
+    if (in_offset.size() == 0) {
+        return in_offset;
+    }
+    dims_t off;
+    off.reserve(in_offset.size() - (keep_dims ? 0 : axis.size()));
+    for (size_t i = 0; i < in_offset.size(); i++) {
+        if (std::find(axis.begin(), axis.end(), i) == axis.end()) {
+            off.push_back(in_offset[i]);
+        } else {
+            if (keep_dims)
+                off.push_back(0);
+        }
+    }
+
+    return off;
+}
+
+template <class T, class TRange> struct default_ptr_getter {
+    T *operator()(const TRange &range) const noexcept { return range; }
+};
+
+template <int32_t Bits> int32_t to_signed(uint32_t value) {
+    auto mask = uint32_t(1) << (Bits - 1);
+    if (Bits != 32 && (value & mask) != 0) {
+        auto sign = 0xFFFFFFFF << Bits;
+        return (int)(value | sign);
+    }
+
+    return (int32_t)value;
+}
+
+template <int32_t Bits> int64_t to_signed(uint64_t value) {
+    auto mask = uint64_t(1) << (Bits - 1);
+    if ((value & mask) != 0) {
+        auto sign = 0xFFFFFFFFFFFFFFFF << Bits;
+        return (int64_t)(value | sign);
+    }
+
+    return (int64_t)value;
+}
+
+template <class T>
+constexpr T quantize(float value, const quant_param_t &param) noexcept {
+    return (T)clamp((int32_t)lrintf(value / param.scale + param.zero_point),
+                    (int32_t)std::numeric_limits<T>::lowest(),
+                    (int32_t)std::numeric_limits<T>::max());
+}
+
+inline std::pair<float, float>
+get_resize_scales(gsl::span<const size_t> in_shape, int32_t out_h,
+                  int32_t out_w, bool align_corners) {
+    auto height_scale = (float)in_shape[2] / out_h;
+    auto width_scale = (float)in_shape[3] / out_w;
+    if (align_corners && out_h > 1)
+        height_scale = (float)(in_shape[2] - 1) / (out_h - 1);
+    if (align_corners && out_w > 1)
+        width_scale = (float)(in_shape[3] - 1) / (out_w - 1);
+    return {height_scale, width_scale};
+}
+
+inline void set_resize_bilinear(size_t value, float scale,
+                                bool half_pixel_centers, size_t shape_size,
+                                float &scaled_value, int32_t &v0, int32_t &v1) {
+    if (half_pixel_centers) {
+        scaled_value = (value + 0.5f) * scale - 0.5f;
+    } else {
+        scaled_value = value * scale;
+    }
+    float scaled_value_floor = std::floor(scaled_value);
+    v0 = std::max(static_cast<int32_t>(scaled_value_floor), 0);
+    v1 = std::min(static_cast<int32_t>(std::ceil(scaled_value)),
+                  static_cast<int32_t>(shape_size - 1));
+}
+
+template <class T>
+inline size_t get_nearest_neighbor(T input_value, size_t shape_size,
+                                   float scale, bool align_corners,
+                                   bool half_pixel_centers) {
+    const auto offset = half_pixel_centers ? 0.5f : 0.0f;
+    const auto after_scale = (static_cast<float>(input_value) + offset) * scale;
+    const auto align_corners_val =
+        align_corners ? roundf(after_scale) : std::floor(after_scale);
+    int32_t output_value = std::min(static_cast<int32_t>(align_corners_val),
+                                    static_cast<int32_t>(shape_size - 1));
+    if (half_pixel_centers) {
+        output_value = std::max(0, output_value);
+    }
+    return output_value;
+}
+
+} // namespace detail
+END_NS_NNCASE_KERNELS
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/riscv/neutral_kernels.h b/third_party/nncase/x86_64/include/nncase/kernels/riscv/neutral_kernels.h
new file mode 100644
index 0000000..dddaa57
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/riscv/neutral_kernels.h
@@ -0,0 +1,79 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../kernel_utils.h"
+#include <cmath>
+#include <runtime/runtime_op_utility.h>
+#include <xtl/xspan.hpp>
+
+namespace nncase {
+namespace kernels {
+namespace neutral {
+template <class TQ>
+void riscv_dequantize(const TQ *CXX_RESTRICT input, float *CXX_RESTRICT output,
+                      size_t count, const quant_param_t &param) {
+    float scale = 1.f / param.scale;
+    float zero = -param.zero_point * scale;
+
+    for (size_t i = 0; i < count / 2; i++) {
+        // handwritten pipeline for in order CPU
+        auto in1_q = input[i * 2];
+        auto in2_q = input[i * 2 + 1];
+        auto in1 = (float)in1_q;
+        auto in2 = (float)in2_q;
+        auto out1 = in1 * scale + zero;
+        auto out2 = in2 * scale + zero;
+
+        output[i * 2] = out1;
+        output[i * 2 + 1] = out2;
+    }
+
+    if (count % 2)
+        output[count - 1] = input[count - 1] * scale + zero;
+}
+
+template <class TQ>
+void riscv_quantize(const float *CXX_RESTRICT input, TQ *CXX_RESTRICT output,
+                    size_t count, const quant_param_t &param) {
+    float scale = param.scale;
+    float zero = param.zero_point;
+
+    for (size_t i = 0; i < count / 2; i++) {
+        auto in1 = input[i * 2];
+        auto in2 = input[i * 2 + 1];
+        in1 = in1 * scale + zero;
+        in2 = in2 * scale + zero;
+        int32_t out1, out2;
+        asm volatile("fcvt.w.s %0, %1, rne" : "=r"(out1) : "f"(in1));
+        asm volatile("fcvt.w.s %0, %1, rne" : "=r"(out2) : "f"(in2));
+
+        output[i * 2] =
+            std::clamp(out1, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+        output[i * 2 + 1] =
+            std::clamp(out2, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+    }
+
+    if (count % 2) {
+        auto in = (int32_t)roundf(input[count - 1] * scale + zero);
+        output[count - 1] =
+            std::clamp(in, (int32_t)std::numeric_limits<TQ>::lowest(),
+                       (int32_t)std::numeric_limits<TQ>::max());
+    }
+}
+} // namespace neutral
+} // namespace kernels
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/stackvm/resize_image.h b/third_party/nncase/x86_64/include/nncase/kernels/stackvm/resize_image.h
new file mode 100644
index 0000000..820a05f
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/stackvm/resize_image.h
@@ -0,0 +1,94 @@
+/* Copyright 2019-2023 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+#include <nncase/runtime/stackvm/opcode.h>
+
+using namespace nncase::runtime::stackvm;
+
+using get_coordinate_func_t = float (*)(float, float, float, float, float,
+                                        float);
+using get_nearest_pixel_func_t = int64_t (*)(float);
+
+get_coordinate_func_t get_coordinate_from_resized(
+    image_resize_transformation_mode_t coordinate_transform_mode);
+
+get_nearest_pixel_func_t
+get_nearest_pixel_from_origin(image_resize_nearest_mode_t nearest_mode);
+
+inline get_coordinate_func_t get_coordinate_from_resized(
+    image_resize_transformation_mode_t coordinate_transform_mode) {
+    switch (coordinate_transform_mode) {
+    case image_resize_transformation_mode_t::asymmetric:
+        return [](float x_resized, float x_scale, float, float, float, float) {
+            return x_resized * x_scale;
+        };
+    case image_resize_transformation_mode_t::pytorch_half_pixel:
+        return [](float x_resized, float x_scale, float length_resized, float,
+                  float, float) {
+            return length_resized > 1 ? (x_resized + 0.5f) * x_scale - 0.5f
+                                      : 0.0f;
+        };
+    case image_resize_transformation_mode_t::align_corners:
+        return [](float x_resized, float, float length_resized,
+                  float length_original, float, float) {
+            return length_resized == 1 ? 0
+                                       : x_resized * (length_original - 1) /
+                                             (length_resized - 1);
+        };
+    case image_resize_transformation_mode_t::tfcrop_and_resize:
+        return [](float x_resized, float, float length_resized,
+                  float length_original, float roi_start, float roi_end) {
+            auto orig =
+                length_resized > 1
+                    ? roi_start * (length_original - 1) +
+                          (x_resized * (roi_end - roi_start) *
+                           (length_original - 1)) /
+                              (length_resized - 1)
+                    : 0.5 * (roi_start + roi_end) * (length_original - 1);
+            return static_cast<float>(orig);
+        };
+    default: // "image_resize_transformation_mode_t::half_pixel"
+        return [](float x_resized, float x_scale, float, float, float, float) {
+            return ((x_resized + 0.5f) * x_scale) - 0.5f;
+        };
+    }
+}
+
+inline get_nearest_pixel_func_t
+get_nearest_pixel_from_origin(image_resize_nearest_mode_t nearest_mode) {
+    switch (nearest_mode) {
+    case image_resize_nearest_mode_t::round_prefer_ceil:
+        return [](float x_original) {
+            return static_cast<int64_t>(roundf(x_original));
+        };
+    case image_resize_nearest_mode_t::floor:
+        return [](float x_original) {
+            return static_cast<int64_t>(std::floor(x_original));
+        };
+    case image_resize_nearest_mode_t::ceil:
+        return [](float x_original) {
+            return static_cast<int64_t>(std::ceil(x_original));
+        };
+    default: // default is round_prefer_floor
+        return [](float x_original) {
+            // for half way cases prefer floor
+            if (x_original == static_cast<int64_t>(x_original) + 0.5f) {
+                return static_cast<int64_t>(std::floor(x_original));
+            }
+            return static_cast<int64_t>(roundf(x_original));
+        };
+    }
+}
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/kernels/stackvm/tensor_ops.h b/third_party/nncase/x86_64/include/nncase/kernels/stackvm/tensor_ops.h
new file mode 100644
index 0000000..84cae4e
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/kernels/stackvm/tensor_ops.h
@@ -0,0 +1,474 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/kernels/kernel_context.h>
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/stackvm/opcode.h>
+#include <nncase/tensor.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_KERNELS_MODULE(stackvm)
+
+NNCASE_API result<value_t>
+batch_normalization(value_t input, value_t scale, value_t bias,
+                    value_t input_mean, value_t input_var, value_t epsilon,
+                    value_t momentum, value_t output = nullptr,
+                    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+batch_to_space(value_t input, value_t block_shape, value_t crops,
+               value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+binary(runtime::stackvm::binary_op_t binary_op, value_t lhs, value_t rhs,
+       value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+bitcast(prim_type_t type, prim_type_t new_type, value_t input,
+        value_t new_shape, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+broadcast(value_t input, value_t shape, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+broadcast_shape(value_t inputs, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+bucket_pad(value_t input, value_t shape, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+cast(typecode_t new_type, runtime::stackvm::cast_mode_t cast_mode,
+     value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+celu(value_t input, value_t alpha, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+clamp(value_t input, value_t min, value_t max, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+compare(runtime::stackvm::compare_op_t compare_op, value_t lhs, value_t rhs,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+concat(int32_t axis, value_t input, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+condition(bool can_fold_const_call, value_t predicate, value_t value,
+          value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+constant_of_shape(value_t shape, value_t value, value_t output = nullptr,
+                  kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d(runtime::stackvm::pad_mode_t pad_mode, value_t input, value_t weights,
+       value_t bias, value_t stride, value_t padding, value_t dilation,
+       value_t groups, value_t fused_clamp, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_shape(value_t input, value_t weights, value_t padding, value_t stride,
+             value_t dilation, value_t groups, value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_transpose(runtime::stackvm::pad_mode_t pad_mode, value_t input,
+                 value_t weights, value_t bias, value_t output_shape,
+                 value_t stride, value_t padding, value_t output_padding,
+                 value_t dilation, value_t groups, value_t fused_clamp,
+                 value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+conv2d_transpose_shape(value_t input, value_t weights, value_t stride,
+                       value_t dilation, value_t padding,
+                       value_t output_padding, value_t groups,
+                       value_t output = nullptr,
+                       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+cum_sum(value_t input, value_t axis, value_t exclusive, value_t reverse,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+dequantize(typecode_t target_type, value_t input, value_t dequant_param,
+           value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+elu(value_t input, value_t alpha, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+erf(value_t input, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+expand(value_t input, value_t shape, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fake_dequantize(typecode_t target_type, value_t input, value_t dequant_param,
+                value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fake_quantize(typecode_t target_type, value_t input, value_t quant_param,
+              value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+fix_shape(value_t input, value_t shape, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+flatten(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather(int32_t axis, value_t input, value_t index, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather_elements(value_t input, value_t axis, value_t indices,
+                value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gather_nd(value_t input, value_t batch_dims, value_t index,
+          value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+gelu(value_t input, value_t alpha, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+get_item(value_t input, value_t index, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+get_paddings(value_t input_shape, value_t weights_shape, value_t strides,
+             value_t dilations, value_t same, value_t lower,
+             value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hard_sigmoid(value_t input, value_t alpha, value_t beta,
+             value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hard_swish(value_t input, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+hardmax(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+index_of(value_t input, value_t value, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+instance_normalization(value_t input, value_t scale, value_t bias,
+                       value_t epsilon, value_t output = nullptr,
+                       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+l2_normalization(value_t input, value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+layer_norm(int32_t axis, float epsilon, bool use_mean, value_t input,
+           value_t scale, value_t bias, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+leaky_relu(value_t input, value_t alpha, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+log_softmax(value_t input, value_t axis, value_t output = nullptr,
+            kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lp_normalization(value_t input, value_t axis, value_t p,
+                 value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lrn(value_t input, value_t alpha, value_t beta, value_t bias, value_t size,
+    value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+lstm(runtime::stackvm::lstmdirection_t direction,
+     runtime::stackvm::lstmlayout_t layout,
+     std::vector<std::string> activations, value_t x, value_t w, value_t r,
+     value_t b, value_t sequence_lens, value_t initial_h, value_t initial_c,
+     value_t p, value_t activation_alpha, value_t activation_beta, value_t clip,
+     value_t hidden_size, value_t input_forget, value_t output_size,
+     value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+mat_mul(value_t lhs, value_t rhs, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+mat_mul_shape(value_t lhs, value_t rhs, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+normal(typecode_t type, value_t mean, value_t scale, value_t seed,
+       value_t shape, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+normal_like(typecode_t type, value_t input, value_t mean, value_t scale,
+            value_t seed, value_t output = nullptr,
+            kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+one_hot(runtime::stackvm::one_hot_mode_t one_hot_mode, value_t indices,
+        value_t depth, value_t values, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+pad(runtime::stackvm::pad_mode_t pad_mode, value_t input, value_t pads,
+    value_t value, value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+prelu(value_t input, value_t slope, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+prod(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+quant_param_of(runtime::stackvm::quant_mode_t quant_mode, value_t range,
+               value_t bits, value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+quantize(typecode_t target_type, value_t input, value_t quant_param,
+         value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+range(value_t begin, value_t end, value_t step, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+range_of(bool is_range_of_weight, value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+rank(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce(runtime::stackvm::reduce_op_t reduce_op, value_t input, value_t axis,
+       value_t init_value, value_t keep_dims, value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce_arg(runtime::stackvm::reduce_arg_op_t reduce_arg_op,
+           typecode_t dest_type, value_t input, value_t axis, value_t keep_dims,
+           value_t select_last_index, value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reduce_window2d(runtime::stackvm::reduce_op_t reduce_op, value_t input,
+                value_t init_value, value_t filter, value_t stride,
+                value_t padding, value_t dilation, value_t ceil_mode,
+                value_t count_include_pad, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+relu(value_t input, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+relu6(value_t input, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+require(std::string message, bool can_fold_const_call, value_t predicate,
+        value_t value, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reshape(value_t input, value_t shape, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reshape_shape(value_t input_shape, value_t shape, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t> resize_image(
+    runtime::stackvm::image_resize_mode_t resize_mode,
+    runtime::stackvm::image_resize_transformation_mode_t transformation_mode,
+    runtime::stackvm::image_resize_nearest_mode_t nearest_mode,
+    bool is_tfresize, value_t input, value_t roi, value_t new_size,
+    value_t cubic_coeff_a, value_t exclude_outside, value_t extrapolation_value,
+    value_t output = nullptr,
+    kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+reverse_sequence(value_t input, value_t seq_lens, value_t batch_axis,
+                 value_t time_axis, value_t output = nullptr,
+                 kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+scatter_nd(value_t input, value_t indices, value_t updates,
+           value_t output = nullptr,
+           kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+select(value_t predicate, value_t true_value, value_t false_value,
+       value_t output = nullptr,
+       kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+selu(value_t input, value_t alpha, value_t gamma, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+shape_of(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+sigmoid(value_t input, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+size_of(value_t input, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+slice(value_t input, value_t begins, value_t ends, value_t axes,
+      value_t strides, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softmax(value_t input, value_t axis, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softplus(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+softsign(value_t input, value_t output = nullptr,
+         kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+space_to_batch(value_t input, value_t block_shape, value_t paddings,
+               value_t output = nullptr,
+               kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+split(value_t input, value_t axis, value_t sections, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+squeeze(value_t input, value_t dim, value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+squeeze_shape(value_t input_shape, value_t dim, value_t output = nullptr,
+              kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+stack(value_t inputs, value_t axis, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+swish(value_t input, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+tile(value_t input, value_t repeats, value_t output = nullptr,
+     kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+top_k(value_t x, value_t k, value_t axis, value_t largest, value_t sorted,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+transpose(value_t input, value_t perm, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+transpose_shape(value_t input_shape, value_t perm, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+trilu(value_t input, value_t k, value_t upper, value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unary(runtime::stackvm::unary_op_t unary_op, value_t input,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+uniform(typecode_t type, value_t high, value_t low, value_t seed, value_t shape,
+        value_t output = nullptr,
+        kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+uniform_like(typecode_t type, value_t input, value_t high, value_t low,
+             value_t seed, value_t output = nullptr,
+             kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unsqueeze(value_t input, value_t dim, value_t output = nullptr,
+          kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+unsqueeze_shape(value_t input_shape, value_t dim, value_t output = nullptr,
+                kernel_context &context = default_kernel_context());
+
+NNCASE_API result<value_t>
+where(bool is_tf_where, value_t cond, value_t x, value_t y,
+      value_t output = nullptr,
+      kernel_context &context = default_kernel_context());
+
+END_NS_NNCASE_KERNELS_MODULE
diff --git a/third_party/nncase/x86_64/include/nncase/object.h b/third_party/nncase/x86_64/include/nncase/object.h
new file mode 100644
index 0000000..87a7ea4
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/object.h
@@ -0,0 +1,206 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object_kind.h"
+#include <atomic>
+#include <memory>
+#include <nncase/api.h>
+#include <nncase/runtime/result.h>
+#include <optional>
+#include <type_traits>
+#include <utility>
+
+namespace nncase {
+#define DEFINE_OBJECT_KIND(base_t, kind_)                                      \
+  public:                                                                      \
+    static constexpr object_kind kind() noexcept { return kind_; }             \
+    const object_kind &runtime_kind() const noexcept override {                \
+        return kind_;                                                          \
+    }                                                                          \
+                                                                               \
+  protected:                                                                   \
+    bool is_a(const object_kind &kind) const noexcept override {               \
+        return kind == kind_ || base_t::is_a(kind);                            \
+    }
+
+class NNCASE_API object_node {
+  public:
+    object_node() noexcept;
+    object_node(const object_node &) = delete;
+    object_node &operator=(const object_node &) = delete;
+    virtual ~object_node() = default;
+
+    /** @brief Get the kind of the object */
+    virtual const object_kind &runtime_kind() const noexcept = 0;
+
+  protected:
+    template <class T> friend class object_t;
+
+    /** @brief Is the object an instance of specific kind */
+    virtual bool is_a(const object_kind &kind) const noexcept;
+
+    /** @brief Is the object equal to another instance */
+    virtual bool equals(const object_node &other) const noexcept;
+
+  private:
+    uint32_t add_ref() const noexcept {
+        return ref_count_.fetch_add(1, std::memory_order_relaxed);
+    }
+
+    uint32_t release() const noexcept {
+        assert(ref_count_);
+        auto count = ref_count_.fetch_sub(1, std::memory_order_acq_rel);
+        if (count == 1) {
+            delete this;
+        }
+        return count;
+    }
+
+    template <class T> friend class object_t;
+    friend int ::nncase_object_add_ref(nncase::object_node *node);
+    friend int ::nncase_object_release(nncase::object_node *node);
+
+  private:
+    mutable std::atomic<uint32_t> ref_count_;
+};
+
+template <class T> class object_t {
+  public:
+    using node_type = T;
+
+    /** @brief Construct an empty object */
+    constexpr object_t(std::nullptr_t = nullptr) noexcept : object_(nullptr) {}
+    ~object_t() { release(); }
+
+    object_t(T *node) noexcept : object_(node) { add_ref(); }
+    object_t(std::in_place_t, T *node) noexcept : object_(node) {}
+
+    object_t(object_t &&other) noexcept : object_(other.object_) {
+        other.object_ = nullptr;
+    }
+
+    object_t(const object_t &other) noexcept : object_(other.object_) {
+        add_ref();
+    }
+
+    template <class U,
+              class = std::enable_if_t<std::is_convertible_v<U *, T *>>>
+    object_t(object_t<U> &&other) noexcept : object_(other.object_) {
+        other.object_ = nullptr;
+    }
+
+    template <class U,
+              class = std::enable_if_t<std::is_convertible_v<U *, T *>>>
+    object_t(const object_t<U> &other) noexcept : object_(other.object_) {
+        add_ref();
+    }
+
+    template <class... TArgs>
+    object_t(std::in_place_t, TArgs &&...args)
+        : object_(new T(std::forward<TArgs>(args)...)) {}
+
+    /** @brief Get the managed pointer to the object */
+    T *get() const noexcept { return object_; }
+    T *operator->() const noexcept { return get(); }
+
+    bool empty() const noexcept { return !object_; }
+
+    object_t value_or(object_t &&other) const noexcept {
+        if (!empty())
+            return *this;
+        return std::move(other);
+    }
+
+    /** @brief Is the object an instance of specific type */
+    bool is_a(const object_kind &kind) const noexcept {
+        return object_ && static_cast<object_node *>(object_)->is_a(kind);
+    }
+
+    /** @brief Is the object an instance of specific type */
+    template <class U> bool is_a() const noexcept {
+        return is_a(U::node_type::kind());
+    }
+
+    template <class U> result<U> as() const noexcept {
+        if (is_a<U>()) {
+            return ok(U(static_cast<typename U::node_type *>(object_)));
+        } else {
+            return err(std::errc::invalid_argument);
+        }
+    }
+
+    /** @brief Is the object equal to another instance */
+    template <class U> bool equals(const U &other) const noexcept {
+        if (get() == other.get())
+            return true;
+        else if (!empty() && !other.empty())
+            return object_->equals(*other.get());
+        return false;
+    }
+
+    object_t &operator=(object_t &&other) noexcept {
+        if (this != &other) {
+            release();
+            object_ = other.object_;
+            other.object_ = nullptr;
+        }
+        return *this;
+    }
+
+    object_t &operator=(const object_t &other) noexcept {
+        if (this != &other) {
+            release();
+            object_ = other.object_;
+            add_ref();
+        }
+        return *this;
+    }
+
+    T *detach() noexcept {
+        auto obj = object_;
+        object_ = nullptr;
+        return obj;
+    }
+
+    T **release_and_addressof() noexcept {
+        release();
+        return &object_;
+    }
+
+    void dangerous_add_ref() noexcept { return add_ref(); }
+
+  private:
+    void add_ref() noexcept {
+        if (object_) {
+            object_->add_ref();
+        }
+    }
+
+    void release() noexcept {
+        auto obj = object_;
+        if (obj) {
+            obj->release();
+            object_ = nullptr;
+        }
+    }
+
+  private:
+    template <class U> friend class object_t;
+
+    T *object_;
+};
+
+using object = object_t<object_node>;
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/object_kind.def b/third_party/nncase/x86_64/include/nncase/object_kind.def
new file mode 100644
index 0000000..7979ea3
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/object_kind.def
@@ -0,0 +1,17 @@
+DEFINE_OBJECT_KIND(datatype,         DataType,       1)
+DEFINE_OBJECT_KIND(prim_type,        PrimType,       2)
+DEFINE_OBJECT_KIND(pointer_type,     PointerType,    3)
+DEFINE_OBJECT_KIND(value_type,       ValueType,      4)
+DEFINE_OBJECT_KIND(type,             Type,           5)
+DEFINE_OBJECT_KIND(any_type,         AnyType,        6)
+DEFINE_OBJECT_KIND(invalid_type,     InvalidType,    7)
+DEFINE_OBJECT_KIND(tensor_type,      TensorType,     8)
+DEFINE_OBJECT_KIND(tuple_type,       TupleType,      9)
+DEFINE_OBJECT_KIND(callable_type,    CallableType,   10)
+DEFINE_OBJECT_KIND(buffer,           Buffer,         11)
+DEFINE_OBJECT_KIND(host_buffer,      HostBuffer,     12)
+DEFINE_OBJECT_KIND(device_buffer,    DeviceBuffer,   13)
+DEFINE_OBJECT_KIND(remote_buffer,    RemoteBuffer,   14)
+DEFINE_OBJECT_KIND(value,            Value,          15)
+DEFINE_OBJECT_KIND(tensor,			 Tensor,         16)
+DEFINE_OBJECT_KIND(tuple,            Tuple,          17)
diff --git a/third_party/nncase/x86_64/include/nncase/object_kind.h b/third_party/nncase/x86_64/include/nncase/object_kind.h
new file mode 100644
index 0000000..9b28b30
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/object_kind.h
@@ -0,0 +1,47 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <stdexcept>
+#include <string_view>
+#include <type_traits>
+
+namespace nncase {
+struct object_kind {
+    uint32_t id;
+    std::string_view name;
+};
+
+constexpr inline bool operator==(const object_kind &lhs,
+                                 const object_kind &rhs) noexcept {
+    return lhs.id == rhs.id;
+}
+
+#define DEFINE_OBJECT_KIND(id, name, value)                                    \
+    inline constexpr object_kind object_##id{value, #name};
+
+#include "object_kind.def"
+
+#undef DEFINE_OBJECT_KIND
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::object_kind> {
+    [[nodiscard]] size_t
+    operator()(const nncase::object_kind &opcode) const noexcept {
+        return std::hash<uint32_t>()(opcode.id);
+    }
+};
+} // namespace std
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/allocator.h b/third_party/nncase/x86_64/include/nncase/runtime/allocator.h
new file mode 100644
index 0000000..b81353a
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/allocator.h
@@ -0,0 +1,49 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "buffer.h"
+#include <memory>
+#include <nncase/compiler_defs.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+struct buffer_allocate_options {
+    size_t flags;
+};
+
+inline constexpr size_t HOST_BUFFER_ALLOCATE_CPU_ONLY = 1;
+inline constexpr size_t HOST_BUFFER_ALLOCATE_SHARED = 2;
+
+struct buffer_attach_options {
+    size_t flags;
+    uintptr_t physical_address;
+    std::function<void(gsl::byte *)> deleter;
+};
+
+inline constexpr size_t HOST_BUFFER_ATTACH_SHARED = 1;
+
+class NNCASE_API buffer_allocator {
+  public:
+    virtual result<buffer_t>
+    allocate(size_t bytes, const buffer_allocate_options &options) = 0;
+
+    virtual result<buffer_t> attach(gsl::span<gsl::byte> data,
+                                    const buffer_attach_options &options) = 0;
+
+    static buffer_allocator &host();
+    virtual void shrink_memory_pool() = 0;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/bfloat16.h b/third_party/nncase/x86_64/include/nncase/runtime/bfloat16.h
new file mode 100644
index 0000000..b97a4e7
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/bfloat16.h
@@ -0,0 +1,317 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <cmath>
+#include <cstdint>
+#include <float.h>
+#include <functional>
+#include <limits>
+
+namespace nncase {
+struct from_raw_t {
+    explicit from_raw_t() = default;
+};
+
+NNCASE_INLINE_VAR constexpr from_raw_t from_raw{};
+
+struct bfloat16 {
+  private:
+    union fp32 {
+        uint32_t u32;
+        float f32;
+
+        uint16_t u16() const noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<const uint16_t *>(&u32)[index];
+        }
+
+        uint16_t &u16() noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<uint16_t *>(&u32)[index];
+        }
+    };
+
+    // A value that represents "zero".
+    static constexpr uint16_t ZERO_VALUE = 0;
+
+    // A value that represents "not a number".
+    static constexpr uint16_t NAN_VALUE = 0x7FC0;
+
+  public:
+    bfloat16() noexcept = default;
+
+    explicit bfloat16(float v) noexcept : value_(round_to_bfloat16(v).value_) {}
+
+    template <class T,
+              class = std::enable_if_t<std::is_integral<T>::value ||
+                                       std::is_floating_point<T>::value>>
+    explicit bfloat16(const T &val) noexcept
+        : bfloat16(static_cast<float>(val)) {}
+
+    bfloat16(int &&val) noexcept : bfloat16(static_cast<float>(val)) {}
+
+    constexpr bfloat16(from_raw_t, uint16_t value) noexcept : value_(value) {}
+
+    operator float() const noexcept {
+        fp32 result;
+        result.u32 = 0;
+        result.u16() = value_;
+        return result.f32;
+    }
+
+    const uint16_t &raw() const noexcept { return value_; }
+    uint16_t &raw() noexcept { return value_; }
+
+    static constexpr bfloat16 from_raw(uint16_t v) noexcept {
+        return bfloat16(nncase::from_raw, v);
+    }
+
+    static bfloat16 truncate_to_bfloat16(const float v) noexcept {
+        bfloat16 output;
+
+        if (!std::isnan(v)) {
+            fp32 f;
+            f.f32 = v;
+            output.value_ = f.u16();
+        } else {
+            output.value_ = NAN_VALUE;
+        }
+
+        return output;
+    }
+
+    // Converts a float point to bfloat16, with round-nearest-to-even as
+    // rounding method.
+    static bfloat16 round_to_bfloat16(float v) {
+        uint32_t input;
+        fp32 f;
+        f.f32 = v;
+        input = f.u32;
+        bfloat16 output;
+
+        if (!std::isnan(v)) {
+            // Least significant bit of resulting bfloat.
+            uint32_t lsb = (input >> 16) & 1;
+            uint32_t rounding_bias = 0x7fff + lsb;
+            input += rounding_bias;
+            output.value_ = static_cast<uint16_t>(input >> 16);
+        } else {
+            // If the value is a NaN, squash it to a qNaN with msb of fraction
+            // set, this makes sure after truncation we don't end up with an
+            // inf.
+            //
+            // qNaN magic: All exponent bits set + most significant bit of
+            // fraction set.
+            output.value_ = NAN_VALUE;
+        }
+
+        return output;
+    }
+
+    static constexpr bfloat16 epsilon() noexcept {
+        // 0x1.0p-7
+        return from_raw(0x3c00);
+    }
+
+    static constexpr bfloat16 highest() noexcept {
+        // 0x1.FEp127
+        return from_raw(0x7F7F);
+    }
+
+    static constexpr bfloat16 min() noexcept {
+        // 0x1p-126
+        return from_raw(0x0080);
+    }
+
+    static constexpr bfloat16 lowest() noexcept {
+        // -0x1.FEp127
+        return from_raw(0xFF7F);
+    }
+
+    static constexpr bfloat16 nan() noexcept { return from_raw(0x7fc0); }
+
+    static constexpr bfloat16 quiet_NaN() noexcept { return from_raw(0x7fc0); }
+
+    static constexpr bfloat16 signaling_NaN() noexcept {
+        return from_raw(0x7f81);
+    }
+
+    static constexpr bfloat16 infinity() noexcept { return from_raw(0x7f80); }
+
+    constexpr bool zero() const noexcept {
+        return (value_ & 0x7FFF) == ZERO_VALUE;
+    }
+
+    void operator=(const float &v) noexcept {
+        value_ = (round_to_bfloat16(v).value_);
+    }
+
+  private:
+    uint16_t value_;
+};
+
+#define DEFINE_BF16_BINARY_BF16RET(x)                                          \
+    inline bfloat16 operator x(bfloat16 a, bfloat16 b) noexcept {              \
+        return bfloat16::round_to_bfloat16(float(a) x float(b));               \
+    }
+
+#define DEFINE_BF16_BINARY_BOOLRET(x)                                          \
+    inline bool operator x(bfloat16 a, bfloat16 b) noexcept {                  \
+        return float(a) x float(b);                                            \
+    }
+
+DEFINE_BF16_BINARY_BF16RET(+)
+DEFINE_BF16_BINARY_BF16RET(-)
+DEFINE_BF16_BINARY_BF16RET(*)
+DEFINE_BF16_BINARY_BF16RET(/)
+DEFINE_BF16_BINARY_BOOLRET(<)
+DEFINE_BF16_BINARY_BOOLRET(<=)
+DEFINE_BF16_BINARY_BOOLRET(>=)
+DEFINE_BF16_BINARY_BOOLRET(>)
+
+#define DEFINE_BF16_BINARY_SELF_MOD(x, op)                                     \
+    inline bfloat16 &operator x(bfloat16 &a, bfloat16 b) noexcept {            \
+        a = a op b;                                                            \
+        return a;                                                              \
+    }
+
+DEFINE_BF16_BINARY_SELF_MOD(+=, +)
+DEFINE_BF16_BINARY_SELF_MOD(-=, -)
+DEFINE_BF16_BINARY_SELF_MOD(*=, *)
+DEFINE_BF16_BINARY_SELF_MOD(/=, /)
+
+inline bfloat16 operator-(bfloat16 a) noexcept {
+    return bfloat16::round_to_bfloat16(-float(a));
+}
+
+inline bool operator==(const bfloat16 &lhs, const bfloat16 &rhs) noexcept {
+    return lhs.raw() == rhs.raw();
+}
+
+inline bool operator!=(const bfloat16 &lhs, const bfloat16 &rhs) noexcept {
+    return lhs.raw() != rhs.raw();
+}
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::bfloat16> {
+    size_t operator()(const nncase::bfloat16 &v) const {
+        return hash<float>()(static_cast<float>(v));
+    }
+};
+
+template <> struct numeric_limits<nncase::bfloat16> {
+    static constexpr float_denorm_style has_denorm = denorm_present;
+    static constexpr bool has_infinity = true;
+    static constexpr bool has_quiet_NaN = true;
+    static constexpr bool has_signaling_NaN = true;
+    static constexpr bool is_bounded = true;
+    static constexpr bool is_iec559 = true;
+    static constexpr bool is_signed = true;
+    static constexpr bool is_specialized = true;
+    static constexpr float_round_style round_style = round_to_nearest;
+    static constexpr int radix = FLT_RADIX;
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16(min)() noexcept {
+        return nncase::bfloat16::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16(max)() noexcept {
+        return nncase::bfloat16::highest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 lowest() noexcept {
+        return nncase::bfloat16::lowest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 epsilon() noexcept {
+        return nncase::bfloat16::epsilon();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 round_error() noexcept {
+        // 0.5
+        return nncase::bfloat16::from_raw(0x3f00);
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 denorm_min() noexcept {
+        return nncase::bfloat16::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 infinity() noexcept {
+        return nncase::bfloat16::infinity();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 quiet_NaN() noexcept {
+        return nncase::bfloat16::quiet_NaN();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::bfloat16 signaling_NaN() noexcept {
+        return nncase::bfloat16::signaling_NaN();
+    }
+
+    static constexpr int digits = 8;
+    static constexpr int max_exponent = FLT_MAX_EXP;
+    static constexpr int min_exponent = FLT_MIN_EXP;
+};
+
+using nncase::bfloat16;
+inline bool isinf(const bfloat16 &a) { return std::isinf(float(a)); }
+inline bool isnan(const bfloat16 &a) { return std::isnan(float(a)); }
+inline bool isfinite(const bfloat16 &a) { return std::isfinite(float(a)); }
+inline bfloat16 abs(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(fabsf(float(a)));
+}
+inline bfloat16 exp(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(expf(float(a)));
+}
+inline bfloat16 log(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(logf(float(a)));
+}
+inline bfloat16 log10(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(log10f(float(a)));
+}
+inline bfloat16 sqrt(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(sqrtf(float(a)));
+}
+inline bfloat16 pow(const bfloat16 &a, const bfloat16 &b) {
+    return bfloat16::round_to_bfloat16(powf(float(a), float(b)));
+}
+inline bfloat16 sin(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(sinf(float(a)));
+}
+inline bfloat16 cos(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(cosf(float(a)));
+}
+inline bfloat16 tan(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(tanf(float(a)));
+}
+inline bfloat16 tanh(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(tanhf(float(a)));
+}
+inline bfloat16 floor(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(floorf(float(a)));
+}
+inline bfloat16 ceil(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(ceilf(float(a)));
+}
+inline bfloat16 round(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(roundf(float(a)));
+}
+inline bfloat16 nearbyint(const bfloat16 &a) {
+    return bfloat16::round_to_bfloat16(nearbyintf(float(a)));
+}
+inline long lrint(const bfloat16 &a) { return lrintf(float(a)); }
+} // namespace std
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/binary_writer.h b/third_party/nncase/x86_64/include/nncase/runtime/binary_writer.h
new file mode 100644
index 0000000..b3fb73a
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/binary_writer.h
@@ -0,0 +1,74 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <iostream>
+#include <span>
+
+namespace nncase {
+class binary_writer {
+  public:
+    binary_writer(std::ostream &stream)
+        : stream_(stream), relative_offset_(0) {}
+
+    template <class T> void write(T &&value) {
+        stream_.write(reinterpret_cast<const char *>(&value), sizeof(value));
+        relative_offset_ += sizeof(value);
+    }
+
+    template <class T> void write_array(std::span<T const> value) {
+        stream_.write(reinterpret_cast<const char *>(value.data()),
+                      value.size_bytes());
+        relative_offset_ += value.size_bytes();
+    }
+
+    std::streampos position() const {
+        assert(stream_);
+        return stream_.tellp();
+    }
+
+    void position(std::streampos pos) {
+        auto old_pos = position();
+        stream_.seekp(pos);
+        assert(stream_);
+        relative_offset_ += pos - old_pos;
+    }
+
+    void skip(size_t len) {
+        char zero = 0;
+        for (size_t i = 0; i < len; i++)
+            stream_.write(&zero, 1);
+        relative_offset_ += len;
+    }
+
+    std::streamoff align_position(size_t alignment) {
+        auto pos = position();
+        auto rem = pos % alignment;
+        if (rem != 0) {
+            auto off = std::streamoff(alignment - rem);
+            skip(off);
+            return off;
+        }
+
+        return 0;
+    }
+
+    int64_t relative_offset() const noexcept { return relative_offset_; }
+
+  private:
+    std::ostream &stream_;
+    int64_t relative_offset_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/bitio.h b/third_party/nncase/x86_64/include/nncase/runtime/bitio.h
new file mode 100644
index 0000000..4803121
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/bitio.h
@@ -0,0 +1,146 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include <algorithm>
+#include <cassert>
+#include <cstdint>
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+
+namespace nncase::runtime {
+class bitreader {
+  public:
+    bitreader(gsl::span<const uint8_t> data)
+        : data_(data), buffer_(0), avail_(0) {}
+
+    void read(uint8_t *dest, size_t bits) {
+        while (bits) {
+            auto to_read = std::min(bits, size_t(8));
+            *dest++ = read_bits_le8(to_read);
+            bits -= to_read;
+        }
+    }
+
+    template <class T, size_t Bits> T read() {
+        T ret{};
+        read(reinterpret_cast<uint8_t *>(&ret), Bits);
+        return ret;
+    }
+
+  private:
+    uint8_t read_bits_le8(size_t bits) {
+        assert(bits <= 8);
+
+        fill_buffer_le8(bits);
+        uint8_t ret = buffer_ & ((size_t(1) << bits) - 1);
+        buffer_ >>= bits;
+        avail_ -= bits;
+        return ret;
+    }
+
+    void fill_buffer_le8(size_t bits) {
+        if (avail_ < bits) {
+            auto max_read_bytes =
+                std::min(data_.size() * 8, sizeof(buffer_) * 8 - avail_) / 8;
+            assert(max_read_bytes != 0);
+
+            uint64_t tmp = 0;
+            std::memcpy(&tmp, data_.data(), max_read_bytes);
+            data_ = data_.subspan(max_read_bytes);
+            buffer_ = buffer_ | (tmp << avail_);
+            avail_ += max_read_bytes * 8;
+        }
+    }
+
+  private:
+    gsl::span<const uint8_t> data_;
+    uint64_t buffer_;
+    size_t avail_;
+};
+
+class bitwriter {
+  public:
+    bitwriter(gsl::span<uint8_t> data, size_t bitoffset = 0)
+        : data_(data), buffer_(0), avail_(sizeof(buffer_) * 8) {
+        if (bitoffset) {
+            data_ = data_.subspan(bitoffset / 8);
+            bitoffset %= 8;
+            buffer_ = data_.front() & ((size_t(1) << bitoffset) - 1);
+            avail_ -= bitoffset;
+        }
+    }
+
+    ~bitwriter() { flush(); }
+
+    void write(const uint8_t *src, size_t bits) {
+        while (bits) {
+            auto to_write = std::min(bits, size_t(8));
+            write_bits_le8(*src++, to_write);
+            bits -= to_write;
+        }
+    }
+
+    template <size_t Bits, class T> void write(T value) {
+        write(reinterpret_cast<const uint8_t *>(&value), Bits);
+    }
+
+    void flush() {
+        auto write_bytes = (buffer_written_bits() + 7) / 8;
+        if (write_bytes) {
+            assert(data_.size() >= write_bytes);
+
+            std::memcpy(data_.data(), &buffer_, write_bytes);
+            data_ = data_.subspan(write_bytes);
+            buffer_ = 0;
+            avail_ = sizeof(buffer_) * 8;
+        }
+    }
+
+  private:
+    void write_bits_le8(uint8_t value, size_t bits) {
+        assert(bits <= 8);
+
+        reserve_buffer_8();
+        size_t new_value = value & ((size_t(1) << bits) - 1);
+        buffer_ = buffer_ | (new_value << buffer_written_bits());
+        avail_ -= bits;
+    }
+
+    void reserve_buffer_8() {
+        if (avail_ < 8) {
+            auto write_bytes = buffer_written_bits() / 8;
+            assert(data_.size() >= write_bytes);
+
+            std::memcpy(data_.data(), &buffer_, write_bytes);
+            data_ = data_.subspan(write_bytes);
+            if (write_bytes == sizeof(buffer_))
+                buffer_ = 0;
+            else
+                buffer_ >>= write_bytes * 8;
+            avail_ += write_bytes * 8;
+        }
+    }
+
+    size_t buffer_written_bits() const noexcept {
+        return sizeof(buffer_) * 8 - avail_;
+    }
+
+  private:
+    gsl::span<uint8_t> data_;
+    uint64_t buffer_;
+    size_t avail_;
+};
+} // namespace nncase::runtime
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/buffer.h b/third_party/nncase/x86_64/include/nncase/runtime/buffer.h
new file mode 100644
index 0000000..763dcf6
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/buffer.h
@@ -0,0 +1,81 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "result.h"
+#include <memory>
+#include <nncase/object.h>
+#include <nncase/runtime/datatypes.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class buffer_node;
+class buffer_allocator;
+class host_buffer_slice;
+
+using buffer_t = object_t<buffer_node>;
+
+class NNCASE_API buffer_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_buffer);
+
+  public:
+    buffer_node(size_t size_bytes, buffer_allocator &allocator);
+
+    size_t size_bytes() const noexcept { return size_bytes_; }
+    buffer_allocator &allocator() const noexcept { return allocator_; }
+
+    virtual result<void>
+    copy_to(buffer_t dest, size_t src_start, size_t dest_start,
+            datatype_t datatype, gsl::span<const size_t> shape,
+            gsl::span<const size_t> strides,
+            gsl::span<const size_t> dest_strides) noexcept = 0;
+
+  private:
+    size_t size_bytes_;
+    buffer_allocator &allocator_;
+};
+
+class NNCASE_API buffer_slice {
+  public:
+    buffer_slice() noexcept = default;
+    buffer_slice(buffer_t buffer) noexcept
+        : buffer_(std::move(buffer)),
+          start_(0),
+          length_(buffer_->size_bytes()) {}
+
+    buffer_slice(buffer_t buffer, size_t start, size_t length) noexcept
+        : buffer_(std::move(buffer)), start_(start), length_(length) {}
+
+    const buffer_t &buffer() const noexcept { return buffer_; }
+
+    size_t start() const noexcept { return start_; }
+    size_t size_bytes() const noexcept { return length_; }
+
+    buffer_allocator &allocator() const noexcept {
+        return buffer_->allocator();
+    }
+
+    result<host_buffer_slice> as_host() const noexcept;
+    result<void> copy_to(const buffer_slice &dest, datatype_t datatype,
+                         gsl::span<const size_t> shape,
+                         gsl::span<const size_t> src_strides,
+                         gsl::span<const size_t> dest_strides) const noexcept;
+
+  private:
+    buffer_t buffer_;
+    size_t start_;
+    size_t length_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/char_array_buffer.h b/third_party/nncase/x86_64/include/nncase/runtime/char_array_buffer.h
new file mode 100644
index 0000000..8dde31b
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/char_array_buffer.h
@@ -0,0 +1,97 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cassert>
+#include <gsl/gsl-lite.hpp>
+#include <iostream>
+
+namespace nncase {
+class char_array_buffer : public std::streambuf {
+  public:
+    char_array_buffer(gsl::span<const char> data)
+        : begin_(data.begin()), end_(data.end()), current_(data.data()) {}
+
+  private:
+    int_type underflow() override {
+        if (current_ == end_)
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*current_);
+    }
+
+    int_type uflow() override {
+        if (current_ == end_)
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*current_++);
+    }
+
+    int_type pbackfail(int_type ch) override {
+        if (current_ == begin_ ||
+            (ch != traits_type::eof() && ch != current_[-1]))
+            return traits_type::eof();
+
+        return traits_type::to_int_type(*--current_);
+    }
+
+    std::streamsize showmanyc() override {
+        assert(std::less_equal<const char *>()(current_, end_));
+        return end_ - current_;
+    }
+
+    std::streampos
+    seekoff(std::streamoff off, std::ios_base::seekdir way,
+            [[maybe_unused]] std::ios_base::openmode which) override {
+        if (way == std::ios_base::beg) {
+            current_ = begin_ + off;
+        } else if (way == std::ios_base::cur) {
+            current_ += off;
+        } else if (way == std::ios_base::end) {
+            current_ = end_ + off;
+        }
+
+        if (current_ < begin_ || current_ > end_)
+            return -1;
+
+        return current_ - begin_;
+    }
+
+    std::streampos
+    seekpos(std::streampos sp,
+            [[maybe_unused]] std::ios_base::openmode which) override {
+        current_ = begin_ + sp;
+
+        if (current_ < begin_ || current_ > end_)
+            return -1;
+
+        return current_ - begin_;
+    }
+
+    std::streamsize xsgetn(char_type *s, std::streamsize count) override {
+        std::streamsize available =
+            static_cast<std::streamsize>(end_ - current_);
+        std::streamsize n = (count > available) ? available : count;
+        if (n > 0) {
+            traits_type::copy(s, current_, static_cast<size_t>(n));
+            current_ += n;
+        }
+        return n;
+    }
+
+    const char *const begin_;
+    const char *const end_;
+    const char *current_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/datatypes.h b/third_party/nncase/x86_64/include/nncase/runtime/datatypes.h
new file mode 100644
index 0000000..f0ff9ad
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/datatypes.h
@@ -0,0 +1,146 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../object.h"
+#include "simple_types.h"
+
+namespace nncase {
+class NNCASE_API datatype_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_datatype)
+  public:
+    /** @brief Get size in bytes. */
+    virtual size_t size_bytes() const noexcept = 0;
+
+    /** @brief Get type code. */
+    virtual typecode_t typecode() const noexcept = 0;
+};
+
+class prim_type_node;
+using prim_type_t = object_t<prim_type_node>;
+
+class NNCASE_API datatype_t : public object_t<datatype_node> {
+  public:
+    using object_t::object_t;
+
+    static prim_type_t boolean;
+    static prim_type_t uint8;
+    static prim_type_t uint16;
+    static prim_type_t uint32;
+    static prim_type_t uint64;
+    static prim_type_t int8;
+    static prim_type_t int16;
+    static prim_type_t int32;
+    static prim_type_t int64;
+    static prim_type_t float16;
+    static prim_type_t float32;
+    static prim_type_t float64;
+    static prim_type_t bfloat16;
+
+    datatype_t(typecode_t typecode);
+
+    static result<prim_type_t> from_typecode(typecode_t typecode);
+
+    template <class T> static datatype_t from_type();
+};
+
+class NNCASE_API prim_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_prim_type)
+  public:
+    explicit prim_type_node(typecode_t typecode) noexcept
+        : typecode_(typecode) {}
+
+    size_t size_bytes() const noexcept override {
+        return typecode_bytes(typecode_);
+    }
+
+    typecode_t typecode() const noexcept override { return typecode_; }
+
+  private:
+    typecode_t typecode_;
+};
+
+class NNCASE_API pointer_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_pointer_type)
+  public:
+    explicit pointer_type_node(datatype_t elemtype) noexcept
+        : elemtype_(elemtype) {}
+
+    size_t size_bytes() const noexcept override {
+        return typecode_bytes(dt_pointer);
+    }
+
+    typecode_t typecode() const noexcept override { return dt_pointer; }
+    const datatype_t &elemtype() const noexcept { return elemtype_; }
+
+  private:
+    datatype_t elemtype_;
+};
+
+using pointer_type_t = object_t<pointer_type_node>;
+
+class NNCASE_API value_type_node : public datatype_node {
+    DEFINE_OBJECT_KIND(datatype_node, object_value_type)
+  public:
+    value_type_node(uuid_t uuid, size_t size_bytes) noexcept
+        : uuid_(uuid), size_bytes_(size_bytes) {}
+
+    size_t size_bytes() const noexcept override { return size_bytes_; }
+    typecode_t typecode() const noexcept override { return dt_valuetype; }
+    const uuid_t &uuid() const noexcept { return uuid_; }
+
+  private:
+    uuid_t uuid_;
+    size_t size_bytes_;
+};
+
+using value_type_t = object_t<value_type_node>;
+
+namespace detail {
+template <class T> struct datatype_of {};
+
+#define DEFINE_DATATYPE_OF(type, name)                                         \
+    template <> struct datatype_of<type> {                                     \
+        datatype_t operator()() const noexcept { return datatype_t::name; }    \
+    };
+
+DEFINE_DATATYPE_OF(bool, boolean)
+DEFINE_DATATYPE_OF(uint8_t, uint8)
+DEFINE_DATATYPE_OF(uint16_t, uint16)
+DEFINE_DATATYPE_OF(uint32_t, uint32)
+#ifdef __APPLE__
+DEFINE_DATATYPE_OF(size_t, uint64)
+#endif
+DEFINE_DATATYPE_OF(uint64_t, uint64)
+DEFINE_DATATYPE_OF(int8_t, int8)
+DEFINE_DATATYPE_OF(int16_t, int16)
+DEFINE_DATATYPE_OF(int32_t, int32)
+DEFINE_DATATYPE_OF(int64_t, int64)
+DEFINE_DATATYPE_OF(half, float16)
+DEFINE_DATATYPE_OF(float, float32)
+DEFINE_DATATYPE_OF(double, float64)
+DEFINE_DATATYPE_OF(bfloat16, bfloat16)
+
+#undef DEFINE_DATATYPE_OF
+} // namespace detail
+
+template <class T> datatype_t datatype_t::from_type() {
+    return detail::datatype_of<T>()();
+}
+
+inline result<typecode_t> to_typecode(const datatype_t &dtype) {
+    try_var(prim_type, dtype.as<prim_type_t>());
+    return ok(prim_type->typecode());
+}
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/dbg.h b/third_party/nncase/x86_64/include/nncase/runtime/dbg.h
new file mode 100644
index 0000000..81d6aa9
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/dbg.h
@@ -0,0 +1,952 @@
+/*****************************************************************************
+
+                                dbg(...) macro
+
+License (MIT):
+
+  Copyright (c) 2019 David Peter <mail@david-peter.de>
+
+  Permission is hereby granted, free of charge, to any person obtaining a copy
+  of this software and associated documentation files (the "Software"), to
+  deal in the Software without restriction, including without limitation the
+  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
+  sell copies of the Software, and to permit persons to whom the Software is
+  furnished to do so, subject to the following conditions:
+
+  The above copyright notice and this permission notice shall be included in
+  all copies or substantial portions of the Software.
+
+  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+  THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+  SOFTWARE.
+
+*****************************************************************************/
+
+#ifndef DBG_MACRO_DBG_H
+#define DBG_MACRO_DBG_H
+
+#if defined(__unix__) || (defined(__APPLE__) && defined(__MACH__))
+#define DBG_MACRO_UNIX
+#elif defined(_MSC_VER)
+#define DBG_MACRO_WINDOWS
+#endif
+
+#include "result.h"
+#include <algorithm>
+#include <chrono>
+#include <ctime>
+#include <iomanip>
+#include <ios>
+#include <iostream>
+#include <memory>
+#include <sstream>
+#include <string>
+#include <tuple>
+#include <type_traits>
+#include <vector>
+
+#ifdef DBG_MACRO_UNIX
+#include <unistd.h>
+#endif
+
+#if __cplusplus >= 201703L
+#define DBG_MACRO_CXX_STANDARD 17
+#elif __cplusplus >= 201402L
+#define DBG_MACRO_CXX_STANDARD 14
+#else
+#define DBG_MACRO_CXX_STANDARD 11
+#endif
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+#include <optional>
+#include <variant>
+#endif
+
+namespace dbg {
+
+#ifdef DBG_MACRO_UNIX
+inline bool isColorizedOutputEnabled() { return isatty(fileno(stderr)); }
+#else
+inline bool isColorizedOutputEnabled() { return true; }
+#endif
+
+struct time {};
+
+namespace pretty_function {
+
+// Compiler-agnostic version of __PRETTY_FUNCTION__ and constants to
+// extract the template argument in `type_name_impl`
+
+#if defined(__clang__)
+#define DBG_MACRO_PRETTY_FUNCTION __PRETTY_FUNCTION__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char *dbg::type_name_impl() [T = ") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof("]") - 1;
+#elif defined(__GNUC__) && !defined(__clang__)
+#define DBG_MACRO_PRETTY_FUNCTION __PRETTY_FUNCTION__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char* dbg::type_name_impl() [with T = ") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof("]") - 1;
+#elif defined(_MSC_VER)
+#define DBG_MACRO_PRETTY_FUNCTION __FUNCSIG__
+static constexpr size_t PREFIX_LENGTH =
+    sizeof("const char *__cdecl dbg::type_name_impl<") - 1;
+static constexpr size_t SUFFIX_LENGTH = sizeof(">(void)") - 1;
+#else
+#error "This compiler is currently not supported by dbg_macro."
+#endif
+
+} // namespace pretty_function
+
+// Formatting helpers
+
+template <typename T> struct print_formatted {
+    static_assert(std::is_integral<T>::value,
+                  "Only integral types are supported.");
+
+    print_formatted(T value, int numeric_base)
+        : inner(value), base(numeric_base) {}
+
+    operator T() const { return inner; }
+
+    const char *prefix() const {
+        switch (base) {
+        case 8:
+            return "0o";
+        case 16:
+            return "0x";
+        case 2:
+            return "0b";
+        default:
+            return "";
+        }
+    }
+
+    T inner;
+    int base;
+};
+
+template <typename T> print_formatted<T> hex(T value) {
+    return print_formatted<T>{value, 16};
+}
+
+template <typename T> print_formatted<T> oct(T value) {
+    return print_formatted<T>{value, 8};
+}
+
+template <typename T> print_formatted<T> bin(T value) {
+    return print_formatted<T>{value, 2};
+}
+
+// Implementation of 'type_name<T>()'
+
+template <typename T> const char *type_name_impl() {
+    return DBG_MACRO_PRETTY_FUNCTION;
+}
+
+template <typename T> struct type_tag {};
+
+template <int &...ExplicitArgumentBarrier, typename T>
+std::string get_type_name(type_tag<T>) {
+    namespace pf = pretty_function;
+
+    std::string type = type_name_impl<T>();
+    return type.substr(pf::PREFIX_LENGTH,
+                       type.size() - pf::PREFIX_LENGTH - pf::SUFFIX_LENGTH);
+}
+
+template <typename T> std::string type_name() {
+    if (std::is_volatile<T>::value) {
+        if (std::is_pointer<T>::value) {
+            return type_name<typename std::remove_volatile<T>::type>() +
+                   " volatile";
+        } else {
+            return "volatile " +
+                   type_name<typename std::remove_volatile<T>::type>();
+        }
+    }
+    if (std::is_const<T>::value) {
+        if (std::is_pointer<T>::value) {
+            return type_name<typename std::remove_const<T>::type>() + " const";
+        } else {
+            return "const " + type_name<typename std::remove_const<T>::type>();
+        }
+    }
+    if (std::is_pointer<T>::value) {
+        return type_name<typename std::remove_pointer<T>::type>() + "*";
+    }
+    if (std::is_lvalue_reference<T>::value) {
+        return type_name<typename std::remove_reference<T>::type>() + "&";
+    }
+    if (std::is_rvalue_reference<T>::value) {
+        return type_name<typename std::remove_reference<T>::type>() + "&&";
+    }
+    return get_type_name(type_tag<T>{});
+}
+
+inline std::string get_type_name(type_tag<short>) { return "short"; }
+
+inline std::string get_type_name(type_tag<unsigned short>) {
+    return "unsigned short";
+}
+
+inline std::string get_type_name(type_tag<long>) { return "long"; }
+
+inline std::string get_type_name(type_tag<unsigned long>) {
+    return "unsigned long";
+}
+
+inline std::string get_type_name(type_tag<std::string>) {
+    return "std::string";
+}
+
+template <typename T>
+std::string get_type_name(type_tag<std::vector<T, std::allocator<T>>>) {
+    return "std::vector<" + type_name<T>() + ">";
+}
+
+template <typename T1, typename T2>
+std::string get_type_name(type_tag<std::pair<T1, T2>>) {
+    return "std::pair<" + type_name<T1>() + ", " + type_name<T2>() + ">";
+}
+
+template <typename... T> std::string type_list_to_string() {
+    std::string result;
+    auto unused = {(result += type_name<T>() + ", ", 0)..., 0};
+    static_cast<void>(unused);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+    if constexpr (sizeof...(T) > 0) {
+#else
+    if (sizeof...(T) > 0) {
+#endif
+        result.pop_back();
+        result.pop_back();
+    }
+    return result;
+} // namespace dbg
+
+template <typename... T> std::string get_type_name(type_tag<std::tuple<T...>>) {
+    return "std::tuple<" + type_list_to_string<T...>() + ">";
+}
+
+template <typename T>
+inline std::string get_type_name(type_tag<print_formatted<T>>) {
+    return type_name<T>();
+}
+
+// Implementation of 'is_detected' to specialize for container-like types
+
+namespace detail_detector {
+
+struct nonesuch {
+    nonesuch() = delete;
+    ~nonesuch() = delete;
+    nonesuch(nonesuch const &) = delete;
+    void operator=(nonesuch const &) = delete;
+};
+
+template <typename...> using void_t = void;
+
+template <class Default, class AlwaysVoid, template <class...> class Op,
+          class... Args>
+struct detector {
+    using value_t = std::false_type;
+    using type = Default;
+};
+
+template <class Default, template <class...> class Op, class... Args>
+struct detector<Default, void_t<Op<Args...>>, Op, Args...> {
+    using value_t = std::true_type;
+    using type = Op<Args...>;
+};
+
+} // namespace detail_detector
+
+template <template <class...> class Op, class... Args>
+using is_detected =
+    typename detail_detector::detector<detail_detector::nonesuch, void, Op,
+                                       Args...>::value_t;
+
+namespace detail {
+
+namespace {
+using std::begin;
+using std::end;
+#if DBG_MACRO_CXX_STANDARD < 17
+template <typename T> constexpr auto size(const T &c) -> decltype(c.size()) {
+    return c.size();
+}
+template <typename T, std::size_t N>
+constexpr std::size_t size(const T (&)[N]) {
+    return N;
+}
+#else
+using std::size;
+#endif
+} // namespace
+
+template <typename T>
+using detect_begin_t = decltype(detail::begin(std::declval<T>()));
+
+template <typename T>
+using detect_end_t = decltype(detail::end(std::declval<T>()));
+
+template <typename T>
+using detect_size_t = decltype(detail::size(std::declval<T>()));
+
+template <typename T> struct is_container {
+    static constexpr bool value =
+        is_detected<detect_begin_t, T>::value &&
+        is_detected<detect_end_t, T>::value &&
+        is_detected<detect_size_t, T>::value &&
+        !std::is_same<std::string,
+                      typename std::remove_cv<typename std::remove_reference<
+                          T>::type>::type>::value;
+};
+
+template <typename T>
+using ostream_operator_t =
+    decltype(std::declval<std::ostream &>() << std::declval<T>());
+
+template <typename T>
+struct has_ostream_operator : is_detected<ostream_operator_t, T> {};
+
+} // namespace detail
+
+// Helper to dbg(…)-print types
+template <typename T> struct print_type {};
+
+template <typename T> print_type<T> type() { return print_type<T>{}; }
+
+// Forward declarations of "pretty_print"
+
+template <typename T>
+inline void pretty_print(std::ostream &stream, const T &value, std::true_type);
+
+template <typename T>
+inline void pretty_print(std::ostream &, const T &, std::false_type);
+
+template <typename T>
+inline typename std::enable_if<!detail::is_container<const T &>::value &&
+                                   !std::is_enum<T>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const T &value);
+
+inline bool pretty_print(std::ostream &stream, const bool &value);
+
+inline bool pretty_print(std::ostream &stream, const char &value);
+
+template <typename P>
+inline bool pretty_print(std::ostream &stream, P *const &value);
+
+template <typename T, typename Deleter>
+inline bool pretty_print(std::ostream &stream,
+                         std::unique_ptr<T, Deleter> &value);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, std::shared_ptr<T> &value);
+
+template <size_t N>
+inline bool pretty_print(std::ostream &stream, const char (&value)[N]);
+
+template <>
+inline bool pretty_print(std::ostream &stream, const char *const &value);
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream, const std::tuple<Ts...> &value);
+
+template <>
+inline bool pretty_print(std::ostream &stream, const std::tuple<> &);
+
+template <> inline bool pretty_print(std::ostream &stream, const time &);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_formatted<T> &value);
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_type<T> &);
+
+template <typename Enum>
+inline typename std::enable_if<std::is_enum<Enum>::value, bool>::type
+pretty_print(std::ostream &stream, Enum const &value);
+
+inline bool pretty_print(std::ostream &stream, const std::string &value);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+inline bool pretty_print(std::ostream &stream, const std::string_view &value);
+
+#endif
+
+template <typename T1, typename T2>
+inline bool pretty_print(std::ostream &stream, const std::pair<T1, T2> &value);
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const std::optional<T> &value);
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream,
+                         const std::variant<Ts...> &value);
+
+#endif
+
+template <typename Container>
+inline typename std::enable_if<detail::is_container<const Container &>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const Container &value);
+
+// Specializations of "pretty_print"
+
+template <typename T>
+inline void pretty_print(std::ostream &stream, const T &value, std::true_type) {
+    stream << value;
+}
+
+template <typename T>
+inline void pretty_print(std::ostream &, const T &, std::false_type) {
+    static_assert(detail::has_ostream_operator<const T &>::value,
+                  "Type does not support the << ostream operator");
+}
+
+template <typename T>
+inline typename std::enable_if<!detail::is_container<const T &>::value &&
+                                   !std::is_enum<T>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const T &value) {
+    pretty_print(stream, value,
+                 typename detail::has_ostream_operator<const T &>::type{});
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const bool &value) {
+    stream << std::boolalpha << value;
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const char &value) {
+    const bool printable = value >= 0x20 && value <= 0x7E;
+
+    if (printable) {
+        stream << "'" << value << "'";
+    } else {
+        stream << "'\\x" << std::setw(2) << std::setfill('0') << std::hex
+               << std::uppercase << (0xFF & value) << "'";
+    }
+    return true;
+}
+
+template <typename P>
+inline bool pretty_print(std::ostream &stream, P *const &value) {
+    if (value == nullptr) {
+        stream << "nullptr";
+    } else {
+        stream << value;
+    }
+    return true;
+}
+
+template <typename T, typename Deleter>
+inline bool pretty_print(std::ostream &stream,
+                         std::unique_ptr<T, Deleter> &value) {
+    pretty_print(stream, value.get());
+    return true;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, std::shared_ptr<T> &value) {
+    pretty_print(stream, value.get());
+    stream << " (use_count = " << value.use_count() << ")";
+
+    return true;
+}
+
+template <size_t N>
+inline bool pretty_print(std::ostream &stream, const char (&value)[N]) {
+    stream << value;
+    return false;
+}
+
+template <>
+inline bool pretty_print(std::ostream &stream, const char *const &value) {
+    stream << '"' << value << '"';
+    return true;
+}
+
+template <size_t Idx> struct pretty_print_tuple {
+    template <typename... Ts>
+    static void print(std::ostream &stream, const std::tuple<Ts...> &tuple) {
+        pretty_print_tuple<Idx - 1>::print(stream, tuple);
+        stream << ", ";
+        pretty_print(stream, std::get<Idx>(tuple));
+    }
+};
+
+template <> struct pretty_print_tuple<0> {
+    template <typename... Ts>
+    static void print(std::ostream &stream, const std::tuple<Ts...> &tuple) {
+        pretty_print(stream, std::get<0>(tuple));
+    }
+};
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream, const std::tuple<Ts...> &value) {
+    stream << "{";
+    pretty_print_tuple<sizeof...(Ts) - 1>::print(stream, value);
+    stream << "}";
+
+    return true;
+}
+
+template <>
+inline bool pretty_print(std::ostream &stream, const std::tuple<> &) {
+    stream << "{}";
+
+    return true;
+}
+
+template <> inline bool pretty_print(std::ostream &stream, const time &) {
+    using namespace std::chrono;
+
+    const auto now = system_clock::now();
+    const auto us =
+        duration_cast<microseconds>(now.time_since_epoch()).count() % 1000000;
+    const auto hms = system_clock::to_time_t(now);
+    const std::tm *tm = std::localtime(&hms);
+    stream << "current time = " << std::put_time(tm, "%H:%M:%S") << '.'
+           << std::setw(6) << std::setfill('0') << us;
+
+    return false;
+}
+
+// Converts decimal integer to binary string
+template <typename T> std::string decimalToBinary(T n) {
+    const size_t length = 8 * sizeof(T);
+    std::string toRet;
+    toRet.resize(length);
+
+    for (size_t i = 0; i < length; ++i) {
+        const auto bit_at_index_i = static_cast<char>((n >> i) & 1);
+        toRet[length - 1 - i] = bit_at_index_i + '0';
+    }
+
+    return toRet;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream,
+                         const print_formatted<T> &value) {
+    if (value.inner < 0) {
+        stream << "-";
+    }
+    stream << value.prefix();
+
+    // Print using setbase
+    if (value.base != 2) {
+        stream << std::setw(sizeof(T)) << std::setfill('0')
+               << std::setbase(value.base) << std::uppercase;
+
+        if (value.inner >= 0) {
+            // The '+' sign makes sure that a uint_8 is printed as a number
+            stream << +value.inner;
+        } else {
+            using unsigned_type = typename std::make_unsigned<T>::type;
+            stream << +(static_cast<unsigned_type>(-(value.inner + 1)) + 1);
+        }
+    } else {
+        // Print for binary
+        if (value.inner >= 0) {
+            stream << decimalToBinary(value.inner);
+        } else {
+            using unsigned_type = typename std::make_unsigned<T>::type;
+            stream << decimalToBinary<unsigned_type>(
+                static_cast<unsigned_type>(-(value.inner + 1)) + 1);
+        }
+    }
+
+    return true;
+}
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const print_type<T> &) {
+    stream << type_name<T>();
+
+    stream << " [sizeof: " << sizeof(T) << " byte, ";
+
+    stream << "trivial: ";
+    if (std::is_trivial<T>::value) {
+        stream << "yes";
+    } else {
+        stream << "no";
+    }
+
+    stream << ", standard layout: ";
+    if (std::is_standard_layout<T>::value) {
+        stream << "yes";
+    } else {
+        stream << "no";
+    }
+    stream << "]";
+
+    return false;
+}
+
+template <typename Enum>
+inline typename std::enable_if<std::is_enum<Enum>::value, bool>::type
+pretty_print(std::ostream &stream, Enum const &value) {
+    using UnderlyingType = typename std::underlying_type<Enum>::type;
+    stream << static_cast<UnderlyingType>(value);
+
+    return true;
+}
+
+inline bool pretty_print(std::ostream &stream, const std::string &value) {
+    stream << '"' << value << '"';
+    return true;
+}
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+inline bool pretty_print(std::ostream &stream, const std::string_view &value) {
+    stream << '"' << std::string(value) << '"';
+    return true;
+}
+
+#endif
+
+template <typename T1, typename T2>
+inline bool pretty_print(std::ostream &stream, const std::pair<T1, T2> &value) {
+    stream << "{";
+    pretty_print(stream, value.first);
+    stream << ", ";
+    pretty_print(stream, value.second);
+    stream << "}";
+    return true;
+}
+
+#if DBG_MACRO_CXX_STANDARD >= 17
+
+template <typename T>
+inline bool pretty_print(std::ostream &stream, const std::optional<T> &value) {
+    if (value) {
+        stream << '{';
+        pretty_print(stream, *value);
+        stream << '}';
+    } else {
+        stream << "nullopt";
+    }
+
+    return true;
+}
+
+template <typename... Ts>
+inline bool pretty_print(std::ostream &stream,
+                         const std::variant<Ts...> &value) {
+    stream << "{";
+    std::visit([&stream](auto &&arg) { pretty_print(stream, arg); }, value);
+    stream << "}";
+
+    return true;
+}
+
+#endif
+
+template <typename Container>
+inline typename std::enable_if<detail::is_container<const Container &>::value,
+                               bool>::type
+pretty_print(std::ostream &stream, const Container &value) {
+    stream << "{";
+    const size_t size = detail::size(value);
+    const size_t n = std::min(size_t{10}, size);
+    size_t i = 0;
+    using std::begin;
+    using std::end;
+    for (auto it = begin(value); it != end(value) && i < n; ++it, ++i) {
+        pretty_print(stream, *it);
+        if (i != n - 1) {
+            stream << ", ";
+        }
+    }
+
+    if (size > n) {
+        stream << ", ...";
+        stream << " size:" << size;
+    }
+
+    stream << "}";
+    return true;
+}
+
+template <typename T, typename... U> struct last {
+    using type = typename last<U...>::type;
+};
+
+template <typename T> struct last<T> { using type = T; };
+
+template <typename... T> using last_t = typename last<T...>::type;
+
+class DebugOutput {
+  public:
+    // Helper alias to avoid obscure type `const char* const*` in signature.
+    using expr_t = const char *;
+
+    DebugOutput(const char *filepath, int line, const char *function_name)
+        : m_use_colorized_output(isColorizedOutputEnabled()) {
+        std::string path = filepath;
+        const std::size_t path_length = path.length();
+        if (path_length > MAX_PATH_LENGTH) {
+            path = ".." +
+                   path.substr(path_length - MAX_PATH_LENGTH, MAX_PATH_LENGTH);
+        }
+        std::stringstream ss;
+        ss << ansi(ANSI_DEBUG) << "[" << path << ":" << line << " ("
+           << function_name << ")] " << ansi(ANSI_RESET);
+        m_location = ss.str();
+    }
+
+    template <typename... T>
+    auto print(std::initializer_list<expr_t> exprs,
+               std::initializer_list<std::string> types, T &&...values)
+        -> last_t<T...> {
+        if (exprs.size() != sizeof...(values)) {
+            std::cerr << m_location << ansi(ANSI_WARN)
+                      << "The number of arguments mismatch, please check "
+                         "unprotected comma"
+                      << ansi(ANSI_RESET) << std::endl;
+        }
+        return print_impl(exprs.begin(), types.begin(),
+                          std::forward<T>(values)...);
+    }
+
+    template <typename T> void print_err(T &&message) {
+        std::cerr << m_location << ansi(ANSI_WARN) << message
+                  << ansi(ANSI_RESET) << std::endl;
+    }
+
+    template <typename T>
+    T &&checked_print(std::initializer_list<expr_t> exprs,
+                      std::initializer_list<std::string> types, T &&value) {
+        if (!value) {
+            if (exprs.size() != 1) {
+                std::cerr << m_location << ansi(ANSI_WARN)
+                          << "The number of arguments mismatch, please check "
+                             "unprotected comma"
+                          << ansi(ANSI_RESET) << std::endl;
+            }
+            return print_impl(exprs.begin(), types.begin(),
+                              std::forward<T>(value));
+        } else {
+            return std::forward<T>(value);
+        }
+    }
+
+  private:
+    template <typename T>
+    T &&print_impl(const expr_t *expr, const std::string *type, T &&value) {
+        const T &ref = value;
+        std::stringstream stream_value;
+        const bool print_expr_and_type = pretty_print(stream_value, ref);
+
+        std::stringstream output;
+        output << m_location;
+        if (print_expr_and_type) {
+            output << ansi(ANSI_EXPRESSION) << *expr << ansi(ANSI_RESET)
+                   << " = ";
+        }
+        output << ansi(ANSI_VALUE) << stream_value.str() << ansi(ANSI_RESET);
+        if (print_expr_and_type) {
+            output << " (" << ansi(ANSI_TYPE) << *type << ansi(ANSI_RESET)
+                   << ")";
+        }
+        output << std::endl;
+        std::cerr << output.str();
+
+        return std::forward<T>(value);
+    }
+
+    template <typename T, typename... U>
+    auto print_impl(const expr_t *exprs, const std::string *types, T &&value,
+                    U &&...rest) -> last_t<T, U...> {
+        print_impl(exprs, types, std::forward<T>(value));
+        return print_impl(exprs + 1, types + 1, std::forward<U>(rest)...);
+    }
+
+    const char *ansi(const char *code) const {
+        if (m_use_colorized_output) {
+            return code;
+        } else {
+            return ANSI_EMPTY;
+        }
+    }
+
+    const bool m_use_colorized_output;
+
+    std::string m_location;
+
+    static constexpr std::size_t MAX_PATH_LENGTH = 20;
+
+    static constexpr const char *const ANSI_EMPTY = "";
+    static constexpr const char *const ANSI_DEBUG = "\x1b[02m";
+    static constexpr const char *const ANSI_WARN = "\x1b[33m";
+    static constexpr const char *const ANSI_EXPRESSION = "\x1b[36m";
+    static constexpr const char *const ANSI_VALUE = "\x1b[01m";
+    static constexpr const char *const ANSI_TYPE = "\x1b[32m";
+    static constexpr const char *const ANSI_RESET = "\x1b[0m";
+};
+
+// Identity function to suppress "-Wunused-value" warnings in DBG_MACRO_DISABLE
+// mode
+template <typename T> T &&identity(T &&t) { return std::forward<T>(t); }
+
+template <typename T, typename... U>
+auto identity(T &&, U &&...u) -> last_t<U...> {
+    return identity(std::forward<U>(u)...);
+}
+
+} // namespace dbg
+
+#ifndef DBG_MACRO_DISABLE
+
+// Force expanding argument with commas for MSVC, ref:
+// https://stackoverflow.com/questions/35210637/macro-expansion-argument-with-commas
+// Note that "args" should be a tuple with parentheses, such as "(e1, e2, ...)".
+#define DBG_IDENTITY(x) x
+#define DBG_CALL(fn, args) DBG_IDENTITY(fn args)
+
+#define DBG_CAT_IMPL(_1, _2) _1##_2
+#define DBG_CAT(_1, _2) DBG_CAT_IMPL(_1, _2)
+
+#define DBG_16TH_IMPL(_1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13,  \
+                      _14, _15, _16, ...)                                      \
+    _16
+#define DBG_16TH(args) DBG_CALL(DBG_16TH_IMPL, args)
+#define DBG_NARG(...)                                                          \
+    DBG_16TH(                                                                  \
+        (__VA_ARGS__, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0))
+
+// DBG_VARIADIC_CALL(fn, data, e1, e2, ...) => fn_N(data, (e1, e2, ...))
+#define DBG_VARIADIC_CALL(fn, data, ...)                                       \
+    DBG_CAT(fn##_, DBG_NARG(__VA_ARGS__))                                      \
+    (data, (__VA_ARGS__))
+
+// (e1, e2, e3, ...) => e1
+#define DBG_HEAD_IMPL(_1, ...) _1
+#define DBG_HEAD(args) DBG_CALL(DBG_HEAD_IMPL, args)
+
+// (e1, e2, e3, ...) => (e2, e3, ...)
+#define DBG_TAIL_IMPL(_1, ...) (__VA_ARGS__)
+#define DBG_TAIL(args) DBG_CALL(DBG_TAIL_IMPL, args)
+
+#define DBG_MAP_1(fn, args) DBG_CALL(fn, args)
+#define DBG_MAP_2(fn, args) fn(DBG_HEAD(args)), DBG_MAP_1(fn, DBG_TAIL(args))
+#define DBG_MAP_3(fn, args) fn(DBG_HEAD(args)), DBG_MAP_2(fn, DBG_TAIL(args))
+#define DBG_MAP_4(fn, args) fn(DBG_HEAD(args)), DBG_MAP_3(fn, DBG_TAIL(args))
+#define DBG_MAP_5(fn, args) fn(DBG_HEAD(args)), DBG_MAP_4(fn, DBG_TAIL(args))
+#define DBG_MAP_6(fn, args) fn(DBG_HEAD(args)), DBG_MAP_5(fn, DBG_TAIL(args))
+#define DBG_MAP_7(fn, args) fn(DBG_HEAD(args)), DBG_MAP_6(fn, DBG_TAIL(args))
+#define DBG_MAP_8(fn, args) fn(DBG_HEAD(args)), DBG_MAP_7(fn, DBG_TAIL(args))
+#define DBG_MAP_9(fn, args) fn(DBG_HEAD(args)), DBG_MAP_8(fn, DBG_TAIL(args))
+#define DBG_MAP_10(fn, args) fn(DBG_HEAD(args)), DBG_MAP_9(fn, DBG_TAIL(args))
+#define DBG_MAP_11(fn, args) fn(DBG_HEAD(args)), DBG_MAP_10(fn, DBG_TAIL(args))
+#define DBG_MAP_12(fn, args) fn(DBG_HEAD(args)), DBG_MAP_11(fn, DBG_TAIL(args))
+#define DBG_MAP_13(fn, args) fn(DBG_HEAD(args)), DBG_MAP_12(fn, DBG_TAIL(args))
+#define DBG_MAP_14(fn, args) fn(DBG_HEAD(args)), DBG_MAP_13(fn, DBG_TAIL(args))
+#define DBG_MAP_15(fn, args) fn(DBG_HEAD(args)), DBG_MAP_14(fn, DBG_TAIL(args))
+#define DBG_MAP_16(fn, args) fn(DBG_HEAD(args)), DBG_MAP_15(fn, DBG_TAIL(args))
+
+// DBG_MAP(fn, e1, e2, e3, ...) => fn(e1), fn(e2), fn(e3), ...
+#define DBG_MAP(fn, ...) DBG_VARIADIC_CALL(DBG_MAP, fn, __VA_ARGS__)
+
+#define DBG_STRINGIFY_IMPL(x) #x
+#define DBG_STRINGIFY(x) DBG_STRINGIFY_IMPL(x)
+
+#define DBG_TYPE_NAME(x) dbg::type_name<decltype(x)>()
+
+#define CHECK(x)                                                               \
+    dbg::DebugOutput(__FILE__, __LINE__, __func__)                             \
+        .checked_print({DBG_MAP(DBG_STRINGIFY, x)},                            \
+                       {DBG_MAP(DBG_TYPE_NAME, x)}, x)
+
+#define CHECK_WITH_ERR(x, e)                                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v) {                                                              \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print({DBG_MAP(DBG_STRINGIFY, x)},                            \
+                       {DBG_MAP(DBG_TYPE_NAME, x)}, v);                        \
+            return nncase::err(e);                                             \
+        }                                                                      \
+    }
+
+#define checked_dbg(x)                                                         \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok()) {                                                      \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+        }                                                                      \
+    }
+
+#define checked_try(x)                                                         \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok()) {                                                      \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define checked_try_var(name, x)                                               \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define checked_try_set(name, x)                                               \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            dbg::DebugOutput(__FILE__, __LINE__, __func__)                     \
+                .print_err(v.unwrap_err().message());                          \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+        }                                                                      \
+    }
+
+#define dbg(...)                                                               \
+    dbg::DebugOutput(__FILE__, __LINE__, __func__)                             \
+        .print({DBG_MAP(DBG_STRINGIFY, __VA_ARGS__)},                          \
+               {DBG_MAP(DBG_TYPE_NAME, __VA_ARGS__)}, __VA_ARGS__)
+
+#ifndef NDEBUG
+#define dbg_check(...)                                                         \
+    if (!(__VA_ARGS__)) {                                                      \
+        dbg::DebugOutput(__FILE__, __LINE__, __func__)                         \
+            .print({DBG_MAP(DBG_STRINGIFY, __VA_ARGS__)},                      \
+                   {DBG_MAP(DBG_TYPE_NAME, __VA_ARGS__)}, __VA_ARGS__);        \
+        nncase::fail_fast(#__VA_ARGS__);                                       \
+    }
+#else
+#define dbg_check(...)
+#endif
+
+#else
+#define dbg(...) dbg::identity(__VA_ARGS__)
+#endif // DBG_MACRO_DISABLE
+
+#endif // DBG_MACRO_DBG_H
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/debug.h b/third_party/nncase/x86_64/include/nncase/runtime/debug.h
new file mode 100644
index 0000000..461c029
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/debug.h
@@ -0,0 +1,30 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <string>
+
+namespace nncase {
+inline std::string to_string(typecode_t dt) {
+    switch (dt) {
+#define DEFINE_TYPECODE(id, name, value)                                       \
+    case dt_##id:                                                              \
+        return #name;
+#include <nncase/runtime/typecodes.def>
+#undef DEFINE_TYPECODE
+    default:
+        throw std::invalid_argument("invalid typecode.");
+    }
+}
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/dump_manager.h b/third_party/nncase/x86_64/include/nncase/runtime/dump_manager.h
new file mode 100644
index 0000000..e6caabf
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/dump_manager.h
@@ -0,0 +1,55 @@
+#pragma once
+#include <fstream>
+#include <iostream>
+#include <nncase/runtime/datatypes.h>
+#include <nncase/runtime/host_buffer.h>
+#include <nncase/runtime/stackvm/opcode.h>
+#include <nncase/tensor.h>
+#include <nncase/type.h>
+#include <nncase/value.h>
+#include <sstream>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class NNCASE_API dump_manager {
+
+  private:
+    bool append_;
+    int count_ = 1;
+    std::string current_op_;
+    std::string dump_root_;
+
+  public:
+    void set_current_op(const std::string &op) { current_op_ = op; }
+
+    std::string get_current_op() { return current_op_; }
+
+    std::string dump_path();
+
+    std::string get_dump_root() { return dump_root_; }
+
+    std::ofstream get_stream() { return get_stream(dump_path()); }
+
+    std::ofstream get_stream(const std::string &path);
+
+    int get_count() { return count_; }
+
+    void incr_count() {
+        count_++;
+        append_ = false;
+    }
+
+    void set_append(bool app) { append_ = app; }
+
+    void set_dump_root(std::string root);
+
+    void dump_op(nncase::runtime::stackvm::tensor_function_t tensor_funct);
+
+    void dump_op(const std::string &op);
+
+    void dump_output(nncase::value_t value);
+
+    void dump_input(nncase::value_t value, std::string name);
+};
+
+END_NS_NNCASE_RUNTIME
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/error.h b/third_party/nncase/x86_64/include/nncase/runtime/error.h
new file mode 100644
index 0000000..9d99869
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/error.h
@@ -0,0 +1,48 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <system_error>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+enum class nncase_errc {
+    invalid_model_indentifier = 0x01,
+    invalid_model_checksum = 0x02,
+    invalid_model_version = 0x03,
+    runtime_not_found = 0x04,
+    datatype_mismatch = 0x05,
+    shape_mismatch = 0x06,
+    invalid_memory_location = 0x07,
+    runtime_register_not_found = 0x08,
+    stackvm_illegal_instruction = 0x0100,
+    stackvm_illegal_target = 0x0101,
+    stackvm_stack_overflow = 0x0102,
+    stackvm_stack_underflow = 0x0103,
+    stackvm_unknow_custom_call = 0x0104,
+    stackvm_duplicate_custom_call = 0x0105,
+    nnil_illegal_instruction = 0x0200,
+};
+
+NNCASE_API const std::error_category &nncase_category() noexcept;
+NNCASE_API std::error_code make_error_code(nncase_errc code);
+NNCASE_API std::error_condition make_error_condition(nncase_errc code);
+
+END_NS_NNCASE_RUNTIME
+
+namespace std {
+template <>
+struct is_error_condition_enum<nncase::runtime::nncase_errc> : true_type {};
+} // namespace std
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/half.h b/third_party/nncase/x86_64/include/nncase/runtime/half.h
new file mode 100644
index 0000000..2a53417
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/half.h
@@ -0,0 +1,304 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cmath>
+#include <cstdint>
+#include <float.h>
+#include <functional>
+#include <limits>
+#include <nncase/compiler_defs.h>
+
+namespace nncase {
+struct fp16_from_raw_t {
+    explicit fp16_from_raw_t() = default;
+};
+
+NNCASE_INLINE_VAR constexpr fp16_from_raw_t fp16_from_raw{};
+
+struct half {
+  private:
+    union fp32 {
+        uint32_t u32;
+        float f32;
+
+        uint16_t u16() const noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<const uint16_t *>(&u32)[index];
+        }
+
+        uint16_t &u16() noexcept {
+            constexpr size_t index = NNCASE_LITTLE_ENDIAN ? 1 : 0;
+            return reinterpret_cast<uint16_t *>(&u32)[index];
+        }
+    };
+
+    static constexpr uint16_t ZERO_VALUE = 0;
+
+    // this is quiet NaN, sNaN only used for send signal
+    static constexpr uint16_t NAN_VALUE = 0x7e00;
+
+  public:
+    half() noexcept = default;
+
+    explicit half(float v) noexcept : value_(round_to_half(v).value_) {}
+
+    template <class T,
+              class = std::enable_if_t<std::is_integral<T>::value ||
+                                       std::is_floating_point<T>::value>>
+    explicit half(const T &val) noexcept : half(static_cast<float>(val)) {}
+
+    half(int &&val) noexcept : half(static_cast<float>(val)) {}
+
+    constexpr half(fp16_from_raw_t, uint16_t value) noexcept : value_(value) {}
+
+    operator float() const noexcept {
+        const fp32 magic = {113 << 23};
+        const unsigned int shifted_exp = 0x7c00
+                                         << 13; // exponent mask after shift
+        fp32 o;
+
+        o.u32 = (value_ & 0x7fff) << 13;        // exponent/mantissa bits
+        unsigned int exp = shifted_exp & o.u32; // just the exponent
+        o.u32 += (127 - 15) << 23;              // exponent adjust
+
+        // handle exponent special cases
+        if (exp == shifted_exp) {      // Inf/NaN?
+            o.u32 += (128 - 16) << 23; // extra exp adjust
+        } else if (exp == 0) {         // Zero/Denormal?
+            o.u32 += 1 << 23;          // extra exp adjust
+            o.f32 -= magic.f32;        // renormalize
+        }
+
+        o.u32 |= (value_ & 0x8000) << 16; // sign bit
+        return o.f32;
+    }
+
+    const uint16_t &raw() const noexcept { return value_; }
+    uint16_t &raw() noexcept { return value_; }
+
+    static constexpr half from_raw(uint16_t v) noexcept {
+        return half(nncase::fp16_from_raw, v);
+    }
+
+    static half round_to_half(float v) {
+        fp32 f;
+        f.f32 = v;
+        const fp32 f32infy = {255 << 23};
+        const fp32 f16max = {(127 + 16) << 23};
+        const fp32 denorm_magic = {((127 - 15) + (23 - 10) + 1) << 23};
+        unsigned int sign_mask = 0x80000000u;
+
+        unsigned int sign = f.u32 & sign_mask;
+        f.u32 ^= sign;
+
+        // NOTE all the integer compares in this function can be safely
+        // compiled into signed compares since all operands are below
+        // 0x80000000. Important if you want fast straight SSE2 code
+        // (since there's no unsigned PCMPGTD).
+        half o;
+        if (f.u32 >= f16max.u32) // result is Inf or NaN (all exponent bits set)
+        {
+            o.value_ = (f.u32 > f32infy.u32) ? 0x7e00
+                                             : 0x7c00; // NaN->qNaN and Inf->Inf
+        } else {
+            if (f.u32 < (113 << 23)) { // resulting FP16 is subnormal or zero
+                // use a magic value to align our 10 mantissa bits at the bottom
+                // of the float. as long as FP addition is round-to-nearest-even
+                // this just works.
+                f.f32 += denorm_magic.f32;
+
+                // and one integer subtract of the bias later, we have our final
+                // float!
+                o.value_ = static_cast<uint16_t>(f.u32 - denorm_magic.u32);
+            } else {
+                unsigned int mant_odd =
+                    (f.u32 >> 13) & 1; // resulting mantissa is odd
+
+                // update exponent, rounding bias part 1
+                // Equivalent to `f.u32 += ((unsigned int)(15 - 127) << 23) +
+                // 0xfff`, but without arithmetic overflow.
+                f.u32 += 0xc8000fffU;
+                // rounding bias part 2
+                f.u32 += mant_odd;
+                // take the bits!
+                o.value_ = static_cast<uint16_t>(f.u32 >> 13);
+            }
+        }
+        o.value_ |= static_cast<uint16_t>(sign >> 16);
+        return o;
+    }
+
+    static constexpr half epsilon() noexcept { return from_raw(0x0800); }
+
+    static constexpr half highest() noexcept { return from_raw(0x7bff); }
+
+    static constexpr half min() noexcept { return from_raw(0x0400); }
+
+    static constexpr half lowest() noexcept { return from_raw(0xfbff); }
+
+    static constexpr half quiet_NaN() noexcept { return from_raw(0x7e00); }
+
+    static constexpr half signaling_NaN() noexcept { return from_raw(0x7d00); }
+
+    static constexpr half infinity() noexcept { return from_raw(0x7c00); }
+
+    constexpr bool zero() const noexcept {
+        return (value_ & 0x7FFF) == ZERO_VALUE;
+    }
+
+    void operator=(const float &v) noexcept {
+        value_ = (round_to_half(v).value_);
+    }
+
+  private:
+    uint16_t value_;
+};
+
+#define DEFINE_FP16_BINARY_FP16RET(x)                                          \
+    inline half operator x(half a, half b) noexcept {                          \
+        return half::round_to_half(float(a) x float(b));                       \
+    }
+
+#define DEFINE_FP16_BINARY_BOOLRET(x)                                          \
+    inline bool operator x(half a, half b) noexcept {                          \
+        return float(a) x float(b);                                            \
+    }
+
+DEFINE_FP16_BINARY_FP16RET(+)
+DEFINE_FP16_BINARY_FP16RET(-)
+DEFINE_FP16_BINARY_FP16RET(*)
+DEFINE_FP16_BINARY_FP16RET(/)
+DEFINE_FP16_BINARY_BOOLRET(<)
+DEFINE_FP16_BINARY_BOOLRET(<=)
+DEFINE_FP16_BINARY_BOOLRET(>=)
+DEFINE_FP16_BINARY_BOOLRET(>)
+
+#define DEFINE_FP16_BINARY_SELF_MOD(x, op)                                     \
+    inline half &operator x(half &a, half b) noexcept {                        \
+        a = a op b;                                                            \
+        return a;                                                              \
+    }
+
+DEFINE_FP16_BINARY_SELF_MOD(+=, +)
+DEFINE_FP16_BINARY_SELF_MOD(-=, -)
+DEFINE_FP16_BINARY_SELF_MOD(*=, *)
+DEFINE_FP16_BINARY_SELF_MOD(/=, /)
+
+inline half operator-(half a) noexcept {
+    return half::round_to_half(-float(a));
+}
+
+inline bool operator==(const half &lhs, const half &rhs) noexcept {
+    return lhs.raw() == rhs.raw();
+}
+
+inline bool operator!=(const half &lhs, const half &rhs) noexcept {
+    return lhs.raw() != rhs.raw();
+}
+} // namespace nncase
+
+namespace std {
+template <> struct hash<nncase::half> {
+    size_t operator()(const nncase::half &v) const {
+        return hash<float>()(static_cast<float>(v));
+    }
+};
+
+template <> struct numeric_limits<nncase::half> {
+    static constexpr float_denorm_style has_denorm = std::denorm_present;
+    static constexpr bool has_infinity = true;
+    static constexpr bool has_quiet_NaN = true;
+    static constexpr bool has_signaling_NaN = true;
+    static constexpr bool is_bounded = false;
+    static constexpr bool is_iec559 = true;
+    static constexpr bool is_signed = true;
+    static constexpr bool is_specialized = true;
+    static constexpr float_round_style round_style = std::round_to_nearest;
+    static constexpr int radix = FLT_RADIX;
+
+    NNCASE_UNUSED static constexpr nncase::half(min)() noexcept {
+        return nncase::half::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half(max)() noexcept {
+        return nncase::half::highest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half lowest() noexcept {
+        return nncase::half::lowest();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half epsilon() noexcept {
+        return nncase::half::epsilon();
+    }
+
+    NNCASE_UNUSED static nncase::half round_error() noexcept {
+        return nncase::half((double)0.5);
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half denorm_min() noexcept {
+        return nncase::half::min();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half infinity() noexcept {
+        return nncase::half::infinity();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half quiet_NaN() noexcept {
+        return nncase::half::quiet_NaN();
+    }
+
+    NNCASE_UNUSED static constexpr nncase::half signaling_NaN() noexcept {
+        return nncase::half::signaling_NaN();
+    }
+
+    static constexpr int digits = 11;
+    static const int min_exponent = -13;
+    static const int min_exponent10 = -4;
+    static const int max_exponent = 16;
+    static const int max_exponent10 = 4;
+};
+
+using nncase::half;
+inline bool isinf(const half &a) { return std::isinf(float(a)); }
+inline bool isnan(const half &a) { return std::isnan(float(a)); }
+inline bool isfinite(const half &a) { return std::isfinite(float(a)); }
+inline half abs(const half &a) { return half::round_to_half(fabsf(float(a))); }
+inline half exp(const half &a) { return half::round_to_half(expf(float(a))); }
+inline half log(const half &a) { return half::round_to_half(logf(float(a))); }
+inline half log10(const half &a) {
+    return half::round_to_half(log10f(float(a)));
+}
+inline half sqrt(const half &a) { return half::round_to_half(sqrtf(float(a))); }
+inline half pow(const half &a, const half &b) {
+    return half::round_to_half(powf(float(a), float(b)));
+}
+
+inline half sin(const half &a) { return half::round_to_half(sinf(float(a))); }
+inline half cos(const half &a) { return half::round_to_half(cosf(float(a))); }
+inline half tan(const half &a) { return half::round_to_half(tanf(float(a))); }
+inline half tanh(const half &a) { return half::round_to_half(tanhf(float(a))); }
+inline half floor(const half &a) {
+    return half::round_to_half(floorf(float(a)));
+}
+inline half ceil(const half &a) { return half::round_to_half(ceilf(float(a))); }
+inline half round(const half &a) {
+    return half::round_to_half(roundf(float(a)));
+}
+inline half nearbyint(const half &a) {
+    return half::round_to_half(nearbyintf(float(a)));
+}
+inline long lrint(const half &a) { return lrintf(float(a)); }
+} // namespace std
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/host_buffer.h b/third_party/nncase/x86_64/include/nncase/runtime/host_buffer.h
new file mode 100644
index 0000000..360ccbe
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/host_buffer.h
@@ -0,0 +1,108 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "buffer.h"
+#include <nncase/runtime/small_vector.hpp>
+#include <stack>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class host_buffer_node;
+using host_buffer_t = object_t<host_buffer_node>;
+
+class NNCASE_API mapped_buffer {
+  public:
+    mapped_buffer() noexcept;
+    mapped_buffer(host_buffer_t buffer, gsl::span<gsl::byte> span) noexcept;
+    mapped_buffer(mapped_buffer &&other) noexcept;
+    mapped_buffer(const mapped_buffer &) = delete;
+    ~mapped_buffer();
+
+    mapped_buffer &operator=(mapped_buffer &&) noexcept;
+    mapped_buffer &operator=(const mapped_buffer &) = delete;
+
+    result<void> unmap() noexcept;
+    void release() noexcept;
+
+    gsl::span<gsl::byte> buffer() const noexcept { return span_; }
+
+  private:
+    host_buffer_t buffer_;
+    gsl::span<gsl::byte> span_;
+};
+
+class NNCASE_API host_buffer_node : public buffer_node {
+    DEFINE_OBJECT_KIND(buffer_node, object_host_buffer);
+
+  public:
+    host_buffer_node(
+        size_t size_bytes, buffer_allocator &allocator,
+        host_sync_status_t host_sync_status = host_sync_status_t::valid);
+
+    host_sync_status_t host_sync_status() const noexcept {
+        return host_sync_status_;
+    }
+
+    void host_sync_status(host_sync_status_t status) noexcept {
+        host_sync_status_ = status;
+    }
+
+    result<mapped_buffer> map(map_access_t access) noexcept;
+    result<void> unmap() noexcept;
+    result<void> sync(sync_op_t op, bool force = false) noexcept;
+
+    virtual bool has_physical_address() const noexcept = 0;
+    virtual result<uintptr_t> physical_address() noexcept = 0;
+
+    result<void>
+    copy_to(buffer_t dest, size_t src_start, size_t dest_start,
+            datatype_t datatype, gsl::span<const size_t> shape,
+            gsl::span<const size_t> src_strides,
+            gsl::span<const size_t> dest_strides) noexcept override;
+
+  protected:
+    virtual result<gsl::span<gsl::byte>> map_core(map_access_t access) = 0;
+    virtual result<void> unmap_core(map_access_t access) = 0;
+    virtual result<void> sync_core(sync_op_t op) = 0;
+
+  private:
+    host_sync_status_t host_sync_status_;
+    std::stack<map_access_t, itlib::small_vector<map_access_t, 2>>
+        access_history_;
+};
+
+class NNCASE_API host_buffer_slice : public buffer_slice {
+  public:
+    host_buffer_slice() noexcept = default;
+    host_buffer_slice(host_buffer_t buffer) noexcept
+        : buffer_slice(std::move(buffer)) {}
+
+    host_buffer_slice(host_buffer_t buffer, size_t start,
+                      size_t length) noexcept
+        : buffer_slice(std::move(buffer), start, length) {}
+
+    const host_buffer_t &buffer() const noexcept {
+        return reinterpret_cast<const host_buffer_t &>(buffer_slice::buffer());
+    }
+
+    result<mapped_buffer> map(map_access_t access) noexcept;
+    result<void> unmap() noexcept;
+    result<void> sync(sync_op_t op, bool force = false) noexcept;
+
+    bool has_physical_address() const noexcept;
+    result<uintptr_t> physical_address() noexcept;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/incbin.h b/third_party/nncase/x86_64/include/nncase/runtime/incbin.h
new file mode 100644
index 0000000..bb2348b
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/incbin.h
@@ -0,0 +1,369 @@
+/**
+ * @file incbin.h
+ * @author Dale Weiler
+ * @brief Utility for including binary files
+ *
+ * Facilities for including binary files into the current translation unit and
+ * making use from them externally in other translation units.
+ */
+// clang-format off
+#ifndef INCBIN_HDR
+#define INCBIN_HDR
+#include <limits.h>
+#if   defined(__AVX512BW__) || \
+      defined(__AVX512CD__) || \
+      defined(__AVX512DQ__) || \
+      defined(__AVX512ER__) || \
+      defined(__AVX512PF__) || \
+      defined(__AVX512VL__) || \
+      defined(__AVX512F__)
+# define INCBIN_ALIGNMENT_INDEX 6
+#elif defined(__AVX__)      || \
+      defined(__AVX2__)
+# define INCBIN_ALIGNMENT_INDEX 5
+#elif defined(__SSE__)      || \
+      defined(__SSE2__)     || \
+      defined(__SSE3__)     || \
+      defined(__SSSE3__)    || \
+      defined(__SSE4_1__)   || \
+      defined(__SSE4_2__)   || \
+      defined(__neon__)
+# define INCBIN_ALIGNMENT_INDEX 4
+#elif ULONG_MAX != 0xffffffffu
+# define INCBIN_ALIGNMENT_INDEX 3
+# else
+# define INCBIN_ALIGNMENT_INDEX 2
+#endif
+
+/* Lookup table of (1 << n) where `n' is `INCBIN_ALIGNMENT_INDEX' */
+#define INCBIN_ALIGN_SHIFT_0 1
+#define INCBIN_ALIGN_SHIFT_1 2
+#define INCBIN_ALIGN_SHIFT_2 4
+#define INCBIN_ALIGN_SHIFT_3 8
+#define INCBIN_ALIGN_SHIFT_4 16
+#define INCBIN_ALIGN_SHIFT_5 32
+#define INCBIN_ALIGN_SHIFT_6 64
+
+/* Actual alignment value */
+#define INCBIN_ALIGNMENT \
+    INCBIN_CONCATENATE( \
+        INCBIN_CONCATENATE(INCBIN_ALIGN_SHIFT, _), \
+        INCBIN_ALIGNMENT_INDEX)
+
+/* Stringize */
+#define INCBIN_STR(X) \
+    #X
+#define INCBIN_STRINGIZE(X) \
+    INCBIN_STR(X)
+/* Concatenate */
+#define INCBIN_CAT(X, Y) \
+    X ## Y
+#define INCBIN_CONCATENATE(X, Y) \
+    INCBIN_CAT(X, Y)
+/* Deferred macro expansion */
+#define INCBIN_EVAL(X) \
+    X
+#define INCBIN_INVOKE(N, ...) \
+    INCBIN_EVAL(N(__VA_ARGS__))
+
+/* Green Hills uses a different directive for including binary data */
+#if defined(__ghs__)
+#  if (__ghs_asm == 2)
+#    define INCBIN_MACRO ".file"
+/* Or consider the ".myrawdata" entry in the ld file */
+#  else
+#    define INCBIN_MACRO "\tINCBIN"
+#  endif
+#else
+#  define INCBIN_MACRO ".incbin"
+#endif
+
+#ifndef _MSC_VER
+#  define INCBIN_ALIGN \
+    __attribute__((aligned(INCBIN_ALIGNMENT)))
+#else
+#  define INCBIN_ALIGN __declspec(align(INCBIN_ALIGNMENT))
+#endif
+
+#if defined(__arm__) || /* GNU C and RealView */ \
+    defined(__arm) || /* Diab */ \
+    defined(_ARM) /* ImageCraft */
+#  define INCBIN_ARM
+#endif
+
+#ifdef __GNUC__
+/* Utilize .balign where supported */
+#  define INCBIN_ALIGN_HOST ".balign " INCBIN_STRINGIZE(INCBIN_ALIGNMENT) "\n"
+#  define INCBIN_ALIGN_BYTE ".balign 1\n"
+#elif defined(INCBIN_ARM)
+/*
+ * On arm assemblers, the alignment value is calculated as (1 << n) where `n' is
+ * the shift count. This is the value passed to `.align'
+ */
+#  define INCBIN_ALIGN_HOST ".align " INCBIN_STRINGIZE(INCBIN_ALIGNMENT_INDEX) "\n"
+#  define INCBIN_ALIGN_BYTE ".align 0\n"
+#else
+/* We assume other inline assembler's treat `.align' as `.balign' */
+#  define INCBIN_ALIGN_HOST ".align " INCBIN_STRINGIZE(INCBIN_ALIGNMENT) "\n"
+#  define INCBIN_ALIGN_BYTE ".align 1\n"
+#endif
+
+/* INCBIN_CONST is used by incbin.c generated files */
+#if defined(__cplusplus)
+#  define INCBIN_EXTERNAL extern "C"
+#  define INCBIN_CONST    extern const
+#else
+#  define INCBIN_EXTERNAL extern
+#  define INCBIN_CONST    const
+#endif
+
+/**
+ * @brief Optionally override the linker section into which data is emitted.
+ *
+ * @warning If you use this facility, you'll have to deal with platform-specific linker output
+ * section naming on your own
+ *
+ * Overriding the default linker output section, e.g for esp8266/Arduino:
+ * @code
+ * #define INCBIN_OUTPUT_SECTION ".irom.text"
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ * // Data is emitted into program memory that never gets copied to RAM
+ * @endcode
+ */
+#if !defined(INCBIN_OUTPUT_SECTION)
+#  if defined(__APPLE__)
+#    define INCBIN_OUTPUT_SECTION         ".const_data"
+#  else
+#    define INCBIN_OUTPUT_SECTION         ".rodata"
+#  endif
+#endif
+
+#if defined(__APPLE__)
+/* The directives are different for Apple branded compilers */
+#  define INCBIN_SECTION         INCBIN_OUTPUT_SECTION "\n"
+#  define INCBIN_GLOBAL(NAME)    ".globl " INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME "\n"
+#  define INCBIN_INT             ".long "
+#  define INCBIN_MANGLE          "_"
+#  define INCBIN_BYTE            ".byte "
+#  define INCBIN_TYPE(...)
+#else
+#  define INCBIN_SECTION         ".section " INCBIN_OUTPUT_SECTION "\n"
+#  define INCBIN_GLOBAL(NAME)    ".global " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME "\n"
+#  if defined(__ghs__)
+#    define INCBIN_INT           ".word "
+#  else
+#    define INCBIN_INT           ".int "
+#  endif
+#  if defined(__USER_LABEL_PREFIX__)
+#    define INCBIN_MANGLE        INCBIN_STRINGIZE(__USER_LABEL_PREFIX__)
+#  else
+#    define INCBIN_MANGLE        ""
+#  endif
+#  if defined(INCBIN_ARM)
+/* On arm assemblers, `@' is used as a line comment token */
+#    define INCBIN_TYPE(NAME)    ".type " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME ", %object\n"
+#  elif defined(__MINGW32__) || defined(__MINGW64__)
+/* Mingw doesn't support this directive either */
+#    define INCBIN_TYPE(NAME)
+#  else
+/* It's safe to use `@' on other architectures */
+#    define INCBIN_TYPE(NAME)    ".type " INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME ", @object\n"
+#  endif
+#  define INCBIN_BYTE            ".byte "
+#endif
+
+/* List of style types used for symbol names */
+#define INCBIN_STYLE_CAMEL 0
+#define INCBIN_STYLE_SNAKE 1
+
+/**
+ * @brief Specify the prefix to use for symbol names.
+ *
+ * By default this is `g', producing symbols of the form:
+ * @code
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char gFooData[];
+ * // const unsigned char *const gFooEnd;
+ * // const unsigned int gFooSize;
+ * @endcode
+ *
+ * If however you specify a prefix before including: e.g:
+ * @code
+ * #define INCBIN_PREFIX incbin
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols instead:
+ * // const unsigned char incbinFooData[];
+ * // const unsigned char *const incbinFooEnd;
+ * // const unsigned int incbinFooSize;
+ * @endcode
+ */
+#if !defined(INCBIN_PREFIX)
+#  define INCBIN_PREFIX g
+#endif
+
+/**
+ * @brief Specify the style used for symbol names.
+ *
+ * Possible options are
+ * - INCBIN_STYLE_CAMEL "CamelCase"
+ * - INCBIN_STYLE_SNAKE "snake_case"
+ *
+ * Default option is *INCBIN_STYLE_CAMEL* producing symbols of the form:
+ * @code
+ * #include "incbin.h"
+ * INCBIN(Foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>FooData[];
+ * // const unsigned char *const <prefix>FooEnd;
+ * // const unsigned int <prefix>FooSize;
+ * @endcode
+ *
+ * If however you specify a style before including: e.g:
+ * @code
+ * #define INCBIN_STYLE INCBIN_STYLE_SNAKE
+ * #include "incbin.h"
+ * INCBIN(foo, "foo.txt");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>foo_data[];
+ * // const unsigned char *const <prefix>foo_end;
+ * // const unsigned int <prefix>foo_size;
+ * @endcode
+ */
+#if !defined(INCBIN_STYLE)
+#  define INCBIN_STYLE INCBIN_STYLE_CAMEL
+#endif
+
+/* Style lookup tables */
+#define INCBIN_STYLE_0_DATA Data
+#define INCBIN_STYLE_0_END End
+#define INCBIN_STYLE_0_SIZE Size
+#define INCBIN_STYLE_1_DATA _data
+#define INCBIN_STYLE_1_END _end
+#define INCBIN_STYLE_1_SIZE _size
+
+/* Style lookup: returning identifier */
+#define INCBIN_STYLE_IDENT(TYPE) \
+    INCBIN_CONCATENATE( \
+        INCBIN_STYLE_, \
+        INCBIN_CONCATENATE( \
+            INCBIN_EVAL(INCBIN_STYLE), \
+            INCBIN_CONCATENATE(_, TYPE)))
+
+/* Style lookup: returning string literal */
+#define INCBIN_STYLE_STRING(TYPE) \
+    INCBIN_STRINGIZE( \
+        INCBIN_STYLE_IDENT(TYPE)) \
+
+/* Generate the global labels by indirectly invoking the macro with our style
+ * type and concatenating the name against them. */
+#define INCBIN_GLOBAL_LABELS(NAME, TYPE) \
+    INCBIN_INVOKE( \
+        INCBIN_GLOBAL, \
+        INCBIN_CONCATENATE( \
+            NAME, \
+            INCBIN_INVOKE( \
+                INCBIN_STYLE_IDENT, \
+                TYPE))) \
+    INCBIN_INVOKE( \
+        INCBIN_TYPE, \
+        INCBIN_CONCATENATE( \
+            NAME, \
+            INCBIN_INVOKE( \
+                INCBIN_STYLE_IDENT, \
+                TYPE)))
+
+/**
+ * @brief Externally reference binary data included in another translation unit.
+ *
+ * Produces three external symbols that reference the binary data included in
+ * another translation unit.
+ *
+ * The symbol names are a concatenation of `INCBIN_PREFIX' before *NAME*; with
+ * "Data", as well as "End" and "Size" after. An example is provided below.
+ *
+ * @param NAME The name given for the binary data
+ *
+ * @code
+ * INCBIN_EXTERN(Foo);
+ *
+ * // Now you have the following symbols:
+ * // extern const unsigned char <prefix>FooData[];
+ * // extern const unsigned char *const <prefix>FooEnd;
+ * // extern const unsigned int <prefix>FooSize;
+ * @endcode
+ */
+#define INCBIN_EXTERN(NAME) \
+    INCBIN_EXTERNAL const INCBIN_ALIGN unsigned char \
+        INCBIN_CONCATENATE( \
+            INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+            INCBIN_STYLE_IDENT(DATA))[]; \
+    INCBIN_EXTERNAL const INCBIN_ALIGN unsigned char *const \
+    INCBIN_CONCATENATE( \
+        INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+        INCBIN_STYLE_IDENT(END)); \
+    INCBIN_EXTERNAL const unsigned int \
+        INCBIN_CONCATENATE( \
+            INCBIN_CONCATENATE(INCBIN_PREFIX, NAME), \
+            INCBIN_STYLE_IDENT(SIZE))
+
+/**
+ * @brief Include a binary file into the current translation unit.
+ *
+ * Includes a binary file into the current translation unit, producing three symbols
+ * for objects that encode the data and size respectively.
+ *
+ * The symbol names are a concatenation of `INCBIN_PREFIX' before *NAME*; with
+ * "Data", as well as "End" and "Size" after. An example is provided below.
+ *
+ * @param NAME The name to associate with this binary data (as an identifier.)
+ * @param FILENAME The file to include (as a string literal.)
+ *
+ * @code
+ * INCBIN(Icon, "icon.png");
+ *
+ * // Now you have the following symbols:
+ * // const unsigned char <prefix>IconData[];
+ * // const unsigned char *const <prefix>IconEnd;
+ * // const unsigned int <prefix>IconSize;
+ * @endcode
+ *
+ * @warning This must be used in global scope
+ * @warning The identifiers may be different if INCBIN_STYLE is not default
+ *
+ * To externally reference the data included by this in another translation unit
+ * please @see INCBIN_EXTERN.
+ */
+#ifdef _MSC_VER
+#define INCBIN(NAME, FILENAME) \
+    INCBIN_EXTERN(NAME)
+#else
+#define INCBIN(NAME, FILENAME) \
+    __asm__(INCBIN_SECTION \
+            INCBIN_GLOBAL_LABELS(NAME, DATA) \
+            INCBIN_ALIGN_HOST \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(DATA) ":\n" \
+            INCBIN_MACRO " \"" FILENAME "\"\n" \
+            INCBIN_GLOBAL_LABELS(NAME, END) \
+            INCBIN_ALIGN_BYTE \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(END) ":\n" \
+                INCBIN_BYTE "1\n" \
+            INCBIN_GLOBAL_LABELS(NAME, SIZE) \
+            INCBIN_ALIGN_HOST \
+            INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(SIZE) ":\n" \
+                INCBIN_INT INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(END) " - " \
+                           INCBIN_MANGLE INCBIN_STRINGIZE(INCBIN_PREFIX) #NAME INCBIN_STYLE_STRING(DATA) "\n" \
+            INCBIN_ALIGN_HOST \
+            ".text\n" \
+    ); \
+    INCBIN_EXTERN(NAME)
+
+#endif
+#endif
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/interpreter.h b/third_party/nncase/x86_64/include/nncase/runtime/interpreter.h
new file mode 100644
index 0000000..a8f5814
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/interpreter.h
@@ -0,0 +1,120 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "allocator.h"
+#include "dump_manager.h"
+#include "model.h"
+#include "result.h"
+#include "runtime_module.h"
+#include "runtime_tensor.h"
+#include <gsl/gsl-lite.hpp>
+#include <istream>
+#include <memory>
+#include <nncase/shape.h>
+#include <nncase/tensor.h>
+#include <nncase/type.h>
+#include <unordered_map>
+#include <variant>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class NNCASE_API options_dict {
+  public:
+    template <class T> result<T> get_scalar_opt(const char *name) {
+        try_var(value, get<scalar>(name));
+        return value.template as<T>();
+    }
+
+    template <class T> result<T> get(const char *name) {
+        auto it = values_.find(name);
+        if (it != values_.end())
+            return ok(std::get<T>(it->second));
+        else
+            return err(std::errc::result_out_of_range);
+    }
+
+    template <class T> result<void> set(const char *name, T value) {
+        values_[name] = value;
+        return ok();
+    }
+
+  private:
+    std::unordered_map<const char *, std::variant<scalar, std::string>> values_;
+};
+
+struct tensor_desc {
+    typecode_t datatype;
+    size_t start;
+    size_t size;
+};
+
+class NNCASE_API interpreter {
+  public:
+    interpreter() noexcept;
+    interpreter(interpreter &) = delete;
+    interpreter(interpreter &&) = default;
+
+    [[nodiscard]] result<void> load_model(gsl::span<const gsl::byte> buffer,
+                                          bool copy_buffer = false) noexcept;
+
+    [[nodiscard]] result<void> load_model(std::istream &stream) noexcept;
+
+    options_dict &options() noexcept;
+    result<runtime_module *> find_module_by_id(size_t index) noexcept;
+    result<size_t> find_id_by_module(runtime_module *module) noexcept;
+
+    /* V1 APIs */
+
+    size_t inputs_size() const noexcept;
+    size_t outputs_size() const noexcept;
+    tensor_desc input_desc(size_t index) const noexcept;
+    tensor_desc output_desc(size_t index) const noexcept;
+    dims_t input_shape(size_t index) const noexcept;
+    dims_t output_shape(size_t index) const noexcept;
+    result<runtime_tensor> input_tensor(size_t index) noexcept;
+    result<void> input_tensor(size_t index, runtime_tensor tensor) noexcept;
+    result<runtime_tensor> output_tensor(size_t index) noexcept;
+    result<void> output_tensor(size_t index, runtime_tensor tensor) noexcept;
+
+    result<void> run() noexcept;
+
+    /* V2 APIs */
+
+    result<runtime_function *>
+    find_function_by_name(std::string_view name) noexcept;
+    result<runtime_function *> entry_function() noexcept;
+    std::shared_ptr<nncase::runtime::dump_manager> dump_manager() noexcept {
+        if (!dump_manager_) {
+            dump_manager_ = std::make_shared<nncase::runtime::dump_manager>();
+        }
+        return dump_manager_;
+    }
+
+  private:
+    tensor_type input_tensor_type(size_t index) const noexcept;
+    tensor_type output_tensor_type(size_t index) const noexcept;
+
+    result<void> initialize_model(const model_header &header) noexcept;
+
+  private:
+    std::shared_ptr<nncase::runtime::dump_manager> dump_manager_;
+    std::vector<std::unique_ptr<runtime_module>> modules_;
+    runtime_function *entry_function_;
+    options_dict options_;
+    std::vector<runtime_tensor> input_tensors_;
+    std::vector<runtime_tensor> output_tensors_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/model.h b/third_party/nncase/x86_64/include/nncase/runtime/model.h
new file mode 100644
index 0000000..45c67c6
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/model.h
@@ -0,0 +1,101 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include <cassert>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+inline constexpr size_t MAX_SECTION_NAME_LENGTH = 16;
+inline constexpr size_t MAX_MODULE_KIND_LENGTH = 16;
+inline constexpr uint32_t MODEL_HAS_NO_ENTRY = -1;
+
+typedef std::array<char, MAX_MODULE_KIND_LENGTH> module_kind_t;
+
+template <std::size_t N, std::size_t... Is>
+constexpr module_kind_t to_module_kind(const char (&a)[N],
+                                       std::index_sequence<Is...>) {
+    return {{a[Is]...}};
+}
+
+template <std::size_t N>
+constexpr module_kind_t to_module_kind(const char (&a)[N]) {
+    return to_module_kind(a, std::make_index_sequence<N>());
+}
+
+struct model_header {
+    uint32_t identifier;
+    uint32_t version;
+    uint32_t flags;
+    uint32_t alignment;
+    uint32_t modules;
+    uint32_t entry_module;
+    uint32_t entry_function;
+    uint32_t reserved0;
+};
+
+struct function_header {
+    uint32_t parameters;
+    uint32_t sections;
+    uint64_t entrypoint;
+    uint64_t text_size;
+    uint64_t size;
+};
+
+struct module_header {
+    module_kind_t kind;
+    uint32_t version;
+    uint32_t sections;
+    uint32_t functions;
+    uint32_t reserved0;
+    uint64_t size;
+};
+
+struct section_header {
+    char name[MAX_SECTION_NAME_LENGTH];
+    uint32_t flags;
+    uint32_t reserved0;
+    uint64_t size;
+    uint64_t body_start;
+    uint64_t body_size;
+    uint64_t memory_size;
+};
+
+NNCASE_INLINE_VAR constexpr uint32_t SECTION_MERGED_INTO_RDATA = 1;
+
+struct shape_header {
+    uint32_t size;
+
+    shape_header() = delete;
+    shape_header(shape_header &) = delete;
+    shape_header &operator=(shape_header &) = delete;
+
+    const uint32_t *begin() const noexcept {
+        return reinterpret_cast<const uint32_t *>(
+            reinterpret_cast<uintptr_t>(this) + sizeof(shape_header));
+    }
+
+    const uint32_t *end() const noexcept { return begin() + size; }
+
+    uint32_t operator[](size_t index) const {
+        assert(index < size);
+        return begin()[index];
+    }
+};
+
+NNCASE_INLINE_VAR constexpr uint32_t MODEL_IDENTIFIER = 'KMDL';
+NNCASE_INLINE_VAR constexpr uint32_t MODEL_VERSION = 7;
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/nnil.h b/third_party/nncase/x86_64/include/nncase/runtime/nnil.h
new file mode 100644
index 0000000..66b79e9
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/nnil.h
@@ -0,0 +1,123 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include "span_reader.h"
+#include <array>
+#include <cassert>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef enum _nnil_opcode {
+    nnil_nop = 0x00,
+    nnil_dup = 0x01,
+    nnil_pop = 0x02,
+    nnil_lda_0 = 0x03,
+    nnil_ldc_r4_0 = 0x04,
+    nnil_ldc_r4_1 = 0x05,
+    nnil_ldc_r4 = 0x06,
+    nnil_abs = 0x20,
+    nnil_ceil = 0x21,
+    nnil_cos = 0x22,
+    nnil_exp = 0x23,
+    nnil_floor = 0x24,
+    nnil_log = 0x25,
+    nnil_neg = 0x26,
+    nnil_rsqrt = 0x27,
+    nnil_sin = 0x28,
+    nnil_sqrt = 0x29,
+    nnil_square = 0x2A,
+    nnil_tanh = 0x2B,
+    nnil_bitwise_not = 0x2C,
+    nnil_logical_not = 0x2D,
+    nnil_round = 0x2E,
+    nnil_acos = 0x2F,
+    nnil_asin = 0x30,
+    nnil_sign = 0x31,
+    nnil_add = 0x40,
+    nnil_sub = 0x41,
+    nnil_mul = 0x42,
+    nnil_div = 0x43,
+    nnil_min = 0x44,
+    nnil_max = 0x45,
+    nnil_pow = 0x46,
+    nnil_clamp = 0x80,
+    nnil_ret = 0xA0
+} nnil_opcode_t;
+
+typedef struct _nnil_ldc_r4 {
+    float r4;
+} nnil_ldc_r4_t;
+
+typedef struct _nnil_op {
+    nnil_opcode_t opcode;
+
+    union {
+        nnil_ldc_r4_t ldc_r4;
+    };
+} nnil_op_t;
+
+class nnil_reader {
+  public:
+    nnil_reader(span_reader &reader) : reader_(reader) {}
+
+    bool avail() const noexcept { return !reader_.empty(); }
+
+    nnil_op_t next() {
+        assert(avail());
+        nnil_op_t op;
+        op.opcode = (nnil_opcode_t)reader_.read<uint8_t>();
+
+        switch (op.opcode) {
+        case nnil_ldc_r4:
+            op.ldc_r4 = reader_.read_unaligned<nnil_ldc_r4_t>();
+            break;
+        default:
+            break;
+        }
+
+        return op;
+    }
+
+  private:
+    span_reader &reader_;
+};
+
+class nnil_evalstack {
+  public:
+    nnil_evalstack() noexcept : top(0) {}
+
+    void push(float value) {
+        assert(top < _stack.size());
+        _stack[top++] = value;
+    }
+
+    float pop() {
+        assert(top > 0);
+        return _stack[--top];
+    }
+
+    void dup() {
+        assert(top > 0);
+        _stack[top] = _stack[top - 1];
+        top++;
+    }
+
+  private:
+    std::array<float, 64> _stack;
+    size_t top;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/result.h b/third_party/nncase/x86_64/include/nncase/runtime/result.h
new file mode 100644
index 0000000..39fd0aa
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/result.h
@@ -0,0 +1,401 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include <functional>
+#include <string_view>
+#include <system_error>
+#include <type_traits>
+
+namespace nncase {
+#define try_(x)                                                                \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (!v.is_ok())                                                        \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+#define try_var(name, x)                                                       \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok())                                                         \
+            name = std::move(v.unwrap());                                      \
+        else                                                                   \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+#define try_var_err(name, x, e)                                                \
+    typename decltype((x))::value_type name;                                   \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok()) {                                                       \
+            name = std::move(v.unwrap());                                      \
+        } else {                                                               \
+            e = nncase::err(std::move(v.unwrap_err()));                        \
+            return;                                                            \
+        }                                                                      \
+    }
+
+#define try_set(name, x)                                                       \
+    {                                                                          \
+        auto v = (x);                                                          \
+        if (v.is_ok())                                                         \
+            name = std::move(v.unwrap());                                      \
+        else                                                                   \
+            return nncase::err(std::move(v.unwrap_err()));                     \
+    }
+
+[[noreturn]] inline void fail_fast(const char *message) {
+    fprintf(stderr, "terminate:%s\n", message);
+    // auto exit for pld
+    fprintf(stderr, "}");
+    std::terminate();
+}
+
+template <class T> class NNCASE_NODISCARD result;
+
+namespace detail {
+enum class result_type { ok, err };
+
+struct ok_t {};
+NNCASE_INLINE_VAR ok_t constexpr ok_v = {};
+
+template <class T> NNCASE_INLINE_VAR bool constexpr is_result_v = false;
+template <class T>
+NNCASE_INLINE_VAR bool constexpr is_result_v<result<T>> = true;
+
+template <class T, class U, class Func> class map_call_impl {
+    result<U> operator()(Func &&func, T &value) noexcept {
+        return ok(func(value));
+    }
+};
+
+template <class T, class Func> struct map_traits {
+    using U = invoke_result_t<Func, T>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+    using result_t = result<U>;
+
+    result<U> operator()(Func &&func, T &value) noexcept {
+        return map_call_impl<T, U, Func>()(std::forward<Func>(func), value);
+    }
+};
+
+template <class Func> struct map_traits<void, Func> {
+    using U = invoke_result_t<Func>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+    using result_t = result<U>;
+
+    result<U> operator()(Func &&func) noexcept {
+        return map_call_impl<void, U, Func>()(std::forward<Func>(func));
+    }
+};
+
+template <class T, class Func> struct map_err_traits {
+    using U = invoke_result_t<Func, std::error_condition>;
+    static_assert(
+        !is_result_v<U>,
+        "Cannot map a callback returning result, use and_then instead");
+
+    result<U> operator()(Func &&func, std::error_condition &value) noexcept {
+        return err(func(value));
+    }
+};
+
+template <class T, class Func> struct map_err_traits;
+
+template <class T, class Func> struct and_then_traits {
+    using result_t = invoke_result_t<Func, T>;
+    using traits_t = typename result_t::traits;
+    using U = typename traits_t::ok_type;
+    static_assert(
+        is_result_v<result_t>,
+        "Cannot then a callback not returning result, use map instead");
+
+    result_t operator()(Func &&func, T &value) noexcept { return func(value); }
+};
+
+template <class Func> struct and_then_traits<void, Func> {
+    using result_t = invoke_result_t<Func>;
+    using traits_t = typename result_t::traits;
+    using U = typename traits_t::ok_type;
+    static_assert(
+        is_result_v<result_t>,
+        "Cannot then a callback not returning result, use map instead");
+
+    result_t operator()(Func &&func) noexcept { return func(); }
+};
+} // namespace detail
+
+template <class T> class NNCASE_NODISCARD result {
+  public:
+    static_assert(!detail::is_result_v<T>, "Cannot use nested result");
+
+    using value_type = T;
+
+    template <class... Args>
+    result(detail::ok_t, Args... args)
+        : type_(detail::result_type::ok), ok_(std::forward<Args>(args)...) {}
+
+    result(std::error_condition err) noexcept
+        : type_(detail::result_type::err), err_(std::move(err)) {}
+
+    result(const result &other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(other.ok_);
+        else
+            new (&err_) std::error_condition(other.err_);
+    }
+
+    result(result &&other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+    }
+
+    template <class U, class = std::enable_if_t<std::is_convertible_v<U, T>>>
+    result(result<U> &&other) : type_(other.type_) {
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+    }
+
+    ~result() { destroy(); }
+
+    result &operator=(const result &other) noexcept {
+        destroy();
+        type_ = other.type_;
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(other.ok_);
+        else
+            new (&err_) std::error_condition(other.err_);
+        return *this;
+    }
+
+    result &operator=(result &&other) noexcept {
+        destroy();
+        type_ = other.type_;
+        if (type_ == detail::result_type::ok)
+            new (&ok_) T(std::move(other.ok_));
+        else
+            new (&err_) std::error_condition(std::move(other.err_));
+        return *this;
+    }
+
+    constexpr bool is_ok() const noexcept {
+        return type_ == detail::result_type::ok;
+    }
+
+    constexpr bool is_err() const noexcept {
+        return type_ == detail::result_type::err;
+    }
+
+    constexpr T &unwrap() &noexcept {
+        if (is_ok())
+            return ok_;
+        else
+            std::terminate();
+    }
+
+    constexpr T &&unwrap() &&noexcept {
+        if (is_ok())
+            return std::move(ok_);
+        else
+            std::terminate();
+    }
+
+    constexpr T &unwrap_or_throw() & {
+        if (is_ok())
+            return ok_;
+        else
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    constexpr T &&unwrap_or_throw() && {
+        if (is_ok())
+            return std::move(ok_);
+        else
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    constexpr std::error_condition &unwrap_err() noexcept {
+        if (is_ok())
+            std::terminate();
+        else
+            return err_;
+    }
+
+    constexpr T &expect(gsl::cstring_span message) &noexcept {
+        if (is_ok())
+            return ok_;
+        else {
+            fail_fast(message.data());
+        }
+    }
+
+    constexpr T &&expect(gsl::cstring_span message) &&noexcept {
+        if (is_ok())
+            return std::move(ok_);
+        else {
+            fail_fast(message.data());
+        }
+    }
+
+    template <class Func, class Traits = detail::map_traits<T, Func>>
+    constexpr typename Traits::result_t &&map(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func), std::move(ok_));
+        else
+            return std::move(*this);
+    }
+
+    template <class Func, class Traits = detail::map_err_traits<T, Func>>
+    constexpr typename Traits::result_t &&map_err(Func &&func) &&noexcept {
+        if (is_ok())
+            return std::move(*this);
+        else
+            return Traits()(std::forward<Func>(func), err_);
+    }
+
+    template <class Func, class Traits = detail::and_then_traits<T, Func>>
+    constexpr typename Traits::result_t &&and_then(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func), ok_);
+        else
+            return std::move(*this);
+    }
+
+  private:
+    void destroy() {
+        if (is_ok())
+            std::destroy_at(&ok_);
+        else
+            std::destroy_at(&err_);
+    }
+
+  private:
+    template <class U> friend class result;
+
+    detail::result_type type_;
+    union {
+        T ok_;
+        std::error_condition err_;
+    };
+};
+
+template <> class NNCASE_NODISCARD result<void> {
+  public:
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wnull-dereference"
+    result() noexcept : err_(0, *(std::error_category *)nullptr) {}
+#pragma GCC diagnostic pop
+
+    result(std::error_condition err) noexcept : err_(std::move(err)) {}
+
+    bool is_ok() const noexcept { return !is_err(); }
+    bool is_err() const noexcept { return (bool)err_; }
+
+    void unwrap() noexcept {
+        if (is_err())
+            std::terminate();
+    }
+
+    void unwrap_or_throw() {
+        if (is_err())
+            throw std::runtime_error(unwrap_err().message());
+    }
+
+    std::error_condition &unwrap_err() noexcept {
+        if (is_ok())
+            std::terminate();
+        else
+            return err_;
+    }
+
+    void expect(gsl::cstring_span message) noexcept {
+        if (is_err())
+            fail_fast(message.data());
+    }
+
+    template <class Func, class Traits = detail::map_traits<void, Func>>
+    typename Traits::result_t &&map(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func));
+        else
+            return std::move(*this);
+    }
+
+    template <class Func, class Traits = detail::map_err_traits<void, Func>>
+    typename Traits::result_t &&map_err(Func &&func) &&noexcept {
+        if (is_ok())
+            return std::move(*this);
+        else
+            return Traits()(std::forward<Func>(func), err_);
+    }
+
+    template <class Func, class Traits = detail::and_then_traits<void, Func>>
+    typename Traits::result_t &&and_then(Func &&func) &&noexcept {
+        if (is_ok())
+            return Traits()(std::forward<Func>(func));
+        else
+            return std::move(*this);
+    }
+
+  private:
+    std::error_condition err_;
+};
+
+inline result<void> ok() { return {}; }
+
+template <class T, class... Args> constexpr result<T> ok(Args &&...args) {
+    return {detail::ok_v, std::forward<Args>(args)...};
+}
+
+template <class T> constexpr result<std::decay_t<T>> ok(T &&value) {
+    return {detail::ok_v, std::forward<T>(value)};
+}
+
+inline std::error_condition err(std::error_condition value) noexcept {
+    return value;
+}
+
+template <class ErrCode, class = std::enable_if_t<
+                             std::is_error_condition_enum<ErrCode>::value>>
+std::error_condition err(ErrCode value) {
+    return err(std::error_condition(value));
+}
+
+namespace detail {
+template <class T, class Func> class map_call_impl<T, void, Func> {
+    result<void> operator()(Func &&func, T &value) noexcept {
+        func(value);
+        return ok();
+    }
+};
+
+template <class Func> class map_call_impl<void, void, Func> {
+    result<void> operator()(Func &&func) noexcept {
+        func();
+        return ok();
+    }
+};
+} // namespace detail
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_function.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_function.h
new file mode 100644
index 0000000..ba2515c
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_function.h
@@ -0,0 +1,72 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "model.h"
+#include "result.h"
+#include "runtime_section_context.h"
+#include <nncase/runtime/stream_reader.h>
+#include <nncase/type.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class interpreter;
+class runtime_module;
+struct runtime_module_init_context;
+
+struct NNCASE_API runtime_function_init_context
+    : public runtime_section_context {
+    virtual runtime_module_init_context &module_init_context() noexcept = 0;
+    virtual const function_header &header() noexcept = 0;
+};
+
+class NNCASE_API runtime_function {
+  public:
+    runtime_function(runtime_module &rt_module);
+    runtime_function(const runtime_function &) = delete;
+    virtual ~runtime_function() = default;
+    runtime_function &operator=(const runtime_function &) = delete;
+
+    result<void>
+    initialize(gsl::span<const gsl::byte> payload,
+               runtime_module_init_context &module_init_context) noexcept;
+    result<void>
+    initialize(stream_reader &reader,
+               runtime_module_init_context &module_init_context) noexcept;
+
+    runtime_module &module() const noexcept;
+
+    uint32_t parameters_size() const noexcept;
+    result<type> parameter_type(size_t index) const noexcept;
+    const type &return_type() const noexcept;
+
+    result<value_t> invoke(gsl::span<value_t> parameters,
+                           value_t return_value = nullptr) noexcept;
+
+  protected:
+    virtual result<void>
+    initialize_core(runtime_function_init_context &context) noexcept = 0;
+
+    virtual result<value_t> invoke_core(gsl::span<value_t> parameters,
+                                        value_t return_value) noexcept = 0;
+
+  private:
+    function_header header_;
+    runtime_module &rt_module_;
+    std::vector<type> parameter_types_;
+    type return_type_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_loader.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_loader.h
new file mode 100644
index 0000000..e5e5df4
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_loader.h
@@ -0,0 +1,42 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <memory>
+#include <nncase/runtime/error.h>
+#include <nncase/runtime/model.h>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/runtime_module.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef void (*rt_module_activator_t)(
+    result<std::unique_ptr<runtime_module>> &result);
+typedef void (*rt_module_collector_t)(
+    result<
+        std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+        &result);
+
+#define RUNTIME_MODULE_ACTIVATOR_NAME create_runtime_module
+#define RUNTIME_MODULE_COLLECTOR_NAME collect_custom_call
+
+struct runtime_registration {
+    module_kind_t id;
+    rt_module_activator_t activator;
+    rt_module_collector_t collector;
+};
+
+extern runtime_registration builtin_runtimes[];
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_module.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_module.h
new file mode 100644
index 0000000..194dd3b
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_module.h
@@ -0,0 +1,81 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "model.h"
+#include "result.h"
+#include "runtime_function.h"
+#include "runtime_section_context.h"
+#include "span_reader.h"
+#include "stream_reader.h"
+#include <nncase/kernels/kernel_context.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class interpreter;
+
+struct NNCASE_API runtime_module_init_context : public runtime_section_context {
+    virtual interpreter &interp() noexcept = 0;
+    virtual const module_header &header() noexcept = 0;
+};
+
+class NNCASE_API runtime_module {
+  public:
+    static result<std::unique_ptr<runtime_module>>
+    create(const module_kind_t &kind);
+
+    using custom_call_type = result<value_t> (*)(
+        gsl::span<const gsl::byte>, const std::vector<value_t> &,
+        const kernels::kernel_context &);
+
+    static result<
+        std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+    collect(const module_kind_t &kind);
+
+    runtime_module() = default;
+    runtime_module(const runtime_module &) = delete;
+    virtual ~runtime_module() = default;
+    runtime_module &operator=(const runtime_module &) = delete;
+
+    result<void> initialize(gsl::span<const gsl::byte> payload,
+                            interpreter &interp) noexcept;
+    result<void> initialize(stream_reader &reader,
+                            interpreter &interp) noexcept;
+    const module_kind_t &kind() const noexcept;
+
+    interpreter &interp() const noexcept { return *interp_; }
+
+    result<runtime_function *> find_function_by_id(size_t index) noexcept;
+
+    result<size_t> find_id_by_function(runtime_function *function) noexcept;
+
+  protected:
+    virtual result<void>
+    initialize_before_functions(runtime_module_init_context &context) noexcept;
+    virtual result<void>
+    initialize_after_functions(runtime_module_init_context &context) noexcept;
+    virtual result<std::unique_ptr<runtime_function>>
+    create_function() noexcept = 0;
+
+    gsl::span<std::unique_ptr<runtime_function>> functions() noexcept {
+        return functions_;
+    }
+
+  private:
+    module_header header_;
+    std::vector<std::unique_ptr<runtime_function>> functions_;
+    interpreter *interp_ = nullptr;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_op_utility.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_op_utility.h
new file mode 100644
index 0000000..f06d9e7
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_op_utility.h
@@ -0,0 +1,238 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include "result.h"
+#include <numeric>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+inline size_t get_bytes(const datatype_t &type) { return type->size_bytes(); }
+
+template <class TShape> inline size_t compute_size(const TShape &shape) {
+    return std::accumulate(shape.begin(), shape.end(), 1,
+                           std::multiplies<size_t>());
+}
+
+template <class TShape>
+inline size_t get_bytes(const datatype_t &type, const TShape &shape) {
+    return compute_size(shape) * get_bytes(type);
+}
+
+template <class TShape>
+inline size_t compute_size(const TShape &shape, const TShape &strides) {
+    size_t max_stride = 1, max_shape = 1;
+    for (size_t i = 0; i < shape.size(); i++) {
+        if ((shape[i] == 1 ? 0 : strides[i]) >= max_stride) {
+            max_stride = strides[i];
+            max_shape = shape[i];
+        }
+    }
+    size_t size = max_stride * max_shape;
+    return size;
+}
+
+template <class TShape>
+inline size_t get_bytes(const datatype_t &type, const TShape &shape,
+                        const TShape &strides) {
+    return compute_size(shape, strides) * get_bytes(type);
+}
+
+namespace detail {
+template <class shape_type, class strides_type, class bs_ptr>
+inline std::size_t compute_strides(const shape_type &shape,
+                                   strides_type &strides,
+                                   [[maybe_unused]] bs_ptr bs) {
+    using strides_value_type = typename std::decay_t<strides_type>::value_type;
+    strides_value_type data_size = 1;
+    for (std::size_t i = shape.size(); i != 0; --i) {
+        strides[i - 1] = data_size;
+        data_size =
+            strides[i - 1] * static_cast<strides_value_type>(shape[i - 1]);
+    }
+    return static_cast<std::size_t>(data_size);
+}
+} // namespace detail
+
+template <class shape_type, class strides_type>
+inline std::size_t compute_strides(const shape_type &shape,
+                                   strides_type &strides) {
+    return detail::compute_strides(shape, strides, nullptr);
+}
+
+inline strides_t get_default_strides(gsl::span<const size_t> shape) {
+    strides_t strides(shape.size());
+    compute_strides(shape, strides);
+    return strides;
+}
+
+template <class TShape>
+TShape convert_shape_type(const TShape &shape, datatype_t src,
+                          datatype_t dest) {
+    const auto src_size = get_bytes(src);
+    const auto dest_size = get_bytes(dest);
+
+    TShape new_shape = shape;
+    if (!new_shape.empty()) {
+        auto &v = new_shape.back();
+        v = new_shape.back() * src_size / dest_size;
+    }
+
+    return new_shape;
+}
+
+template <class TShape>
+result<TShape> convert_strides_type(const TShape &strides, datatype_t src,
+                                    datatype_t dest) {
+    const auto src_size = get_bytes(src);
+    const auto dest_size = get_bytes(dest);
+
+    if (src_size == dest_size)
+        return ok(strides);
+
+    TShape new_strides = strides;
+    // 1. Except last dim
+    for (size_t i = 0; i < new_strides.size() - 1; i++) {
+        auto &v = new_strides[i];
+        if (v == 0)
+            v = 1;
+        v = v * src_size / dest_size;
+    }
+
+    // 2. Last dim
+    if (!new_strides.empty()) {
+        // 2.1. If last dim is not 0 or 1, unsupported
+        auto last_dim = new_strides.back();
+        if (last_dim != 0 || last_dim != 1)
+            return err(std::errc::not_supported);
+    }
+
+    return ok(new_strides);
+}
+
+template <int32_t Bits, class T> uint8_t count_leading_zeros(T value) {
+    uint8_t num_zeroes = 0;
+    for (int32_t i = Bits - 1; i >= 0; i--) {
+        if ((value & (1ULL << i)) == 0)
+            ++num_zeroes;
+        else
+            break;
+    }
+
+    return num_zeroes;
+}
+
+template <class T = uint64_t> inline T bit_mask(uint8_t shift) {
+    return (T(1) << shift) - 1;
+}
+
+template <class T, bool Banker = false> T carry_shift(T value, int32_t shift) {
+    if (shift > 0) {
+        if (Banker) {
+            T result;
+            // Sign |  Int (T - shift - 1 bits) | Frac (shift bits)
+            //  S      IIII                       FFF
+            auto integral = value >> shift;
+            auto fractional = value & bit_mask(shift);
+            auto sign = value < 0 ? -1 : 1;
+            auto half = size_t(1) << (shift - 1);
+
+            // frac < 0.5
+            if (fractional < half) {
+                return integral;
+            }
+            // frac > 0.5
+            else if (fractional > half) {
+                return integral + sign;
+            }
+            // frac == 0.5
+            else {
+                // odd
+                if (integral & 1)
+                    return integral + sign;
+                // even
+                else
+                    return integral;
+            }
+
+            return result;
+        } else {
+            value += T(1) << (shift - 1);
+            value >>= shift;
+        }
+    } else if (shift < 0) {
+        value = value << (-shift);
+    }
+
+    return value;
+}
+
+template <bool Banker = false>
+inline int32_t mul_and_carry_shift(int32_t value, int32_t mul, int32_t shift) {
+    return (int32_t)carry_shift<int64_t, Banker>((int64_t)value * mul, shift);
+}
+
+template <size_t Bits, bool Signed = true, class T = int64_t>
+inline bool within_range(T value) noexcept {
+    if constexpr (Signed) {
+        auto min = -(1LL << (Bits - 1));
+        auto max = (1LL << (Bits - 1)) - 1;
+        return value >= min && value <= max;
+    } else {
+        auto min = 0ULL;
+        auto max = (1ULL << Bits) - 1;
+        return value >= min && value <= max;
+    }
+}
+
+template <class T> inline T clamp(T value, T min, T max) {
+    return std::min(max, std::max(value, min));
+}
+
+template <uint8_t Bits> inline int32_t clamp(int32_t value) {
+    auto min = std::numeric_limits<int32_t>::lowest() >> (32 - Bits);
+    auto max = std::numeric_limits<int32_t>::max() >> (32 - Bits);
+    return clamp(value, min, max);
+}
+
+inline bool is_contiguous(gsl::span<const size_t> shape,
+                          gsl::span<const size_t> strides) {
+    size_t data_size = 1;
+    for (std::size_t i = shape.size(); i != 0; --i) {
+        if (strides[i - 1] != data_size) {
+            return false;
+        }
+        data_size *= shape[i - 1];
+    }
+    return true;
+}
+
+inline int
+get_last_not_contiguous_index(gsl::span<const size_t> strides,
+                              gsl::span<const size_t> default_strides) {
+    for (int i = strides.size() - 1; i >= 0; --i) {
+        if (strides[i] != default_strides[i]) {
+            return i + 1;
+        }
+    }
+    return -1;
+}
+
+template <size_t A, size_t B>
+constexpr auto is_not_equal =
+    std::integral_constant<bool, std::not_equal_to<size_t>{}(A, B)>{};
+
+struct DefaultCallable {};
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_section_context.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_section_context.h
new file mode 100644
index 0000000..0777257
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_section_context.h
@@ -0,0 +1,51 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "host_buffer.h"
+#include "model.h"
+#include "result.h"
+#include "span_reader.h"
+#include "stream_reader.h"
+#include <nncase/type.h>
+#include <nncase/value.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+struct NNCASE_API runtime_section_context {
+    virtual bool is_section_pinned() const noexcept = 0;
+    virtual result<gsl::span<const gsl::byte>>
+    section(const char *name) noexcept = 0;
+    virtual result<stream_reader *>
+    seek_section(const char *name, section_header &header) noexcept = 0;
+
+    result<gsl::span<const gsl::byte>>
+    get_or_read_section(const char *name, host_buffer_t &storage,
+                        bool allocate_shared) noexcept;
+
+    template <class TCallable>
+    result<void> read_section(const char *name, TCallable &&callable) noexcept {
+        auto section_span_r = section(name);
+        if (section_span_r.is_ok()) {
+            span_reader sr(std::move(section_span_r).unwrap());
+            return callable(sr, sr.avail());
+        } else {
+            section_header header;
+            try_var(sr, seek_section(name, header));
+            return callable(*sr, (size_t)header.body_size);
+        }
+    }
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/runtime_tensor.h b/third_party/nncase/x86_64/include/nncase/runtime/runtime_tensor.h
new file mode 100644
index 0000000..8a480f0
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/runtime_tensor.h
@@ -0,0 +1,108 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "datatypes.h"
+#include "host_buffer.h"
+#include "model.h"
+#include "result.h"
+#include <functional>
+#include <memory>
+#include <nncase/tensor.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+// V1 APIs
+
+class NNCASE_API runtime_tensor {
+  public:
+    runtime_tensor() noexcept;
+    explicit runtime_tensor(tensor impl) noexcept;
+
+    typecode_t datatype() const noexcept;
+    gsl::span<const size_t> shape() const noexcept;
+    gsl::span<const size_t> strides() const noexcept;
+    bool empty() const noexcept;
+    bool is_host() const noexcept;
+    bool is_contiguous() const noexcept;
+
+    bool can_copy_to_without_staging(const runtime_tensor &dest) const noexcept;
+    result<void> copy_to(runtime_tensor &dest) noexcept;
+    result<runtime_tensor> to_host() noexcept;
+
+    void reset() noexcept;
+
+    tensor impl() const noexcept { return impl_; }
+
+  private:
+    tensor impl_;
+};
+
+NNCASE_API bool operator==(const runtime_tensor &lhs,
+                           const runtime_tensor &rhs) noexcept;
+NNCASE_API bool operator!=(const runtime_tensor &lhs,
+                           const runtime_tensor &rhs) noexcept;
+
+namespace host_runtime_tensor {
+
+typedef enum memory_pool_ {
+    pool_shared_first,
+    pool_cpu_only,
+    pool_shared
+} memory_pool_t;
+
+typedef std::function<void(gsl::byte *)> data_deleter_t;
+
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape,
+       memory_pool_t pool = pool_cpu_only) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, gsl::span<gsl::byte> data, bool copy,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, gsl::span<gsl::byte> data,
+       data_deleter_t data_deleter, memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       memory_pool_t pool = pool_cpu_only) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       gsl::span<gsl::byte> data, bool copy,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+NNCASE_API result<runtime_tensor>
+create(typecode_t datatype, dims_t shape, strides_t strides,
+       gsl::span<gsl::byte> data, data_deleter_t data_deleter,
+       memory_pool_t pool = pool_cpu_only,
+       uintptr_t physical_address = 0) noexcept;
+
+NNCASE_API result<memory_pool_t>
+memory_pool(const runtime_tensor &tensor) noexcept;
+NNCASE_API result<mapped_buffer> map(runtime_tensor &tensor,
+                                     map_access_t access) noexcept;
+NNCASE_API result<void> sync(runtime_tensor &tensor, sync_op_t op,
+                             bool force = false) noexcept;
+} // namespace host_runtime_tensor
+
+namespace hrt = host_runtime_tensor;
+
+namespace detail {
+NNCASE_API result<tensor>
+create(datatype_t datatype, dims_t shape,
+       hrt::memory_pool_t pool = hrt::pool_cpu_only) noexcept;
+}
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.h b/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.h
new file mode 100644
index 0000000..676a094
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.h
@@ -0,0 +1,30 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "runtime_tensor_impl.h"
+
+BEGIN_NS_NNCASE_RUNTIME
+
+namespace detail {
+class host_runtime_tensor_impl;
+}
+
+END_NS_NNCASE_RUNTIME
+
+#ifndef NNCASE_SHARED_RUNTIME_TENSOR_PLATFORM_HEADER
+#include "shared_runtime_tensor.platform.h"
+#else
+#include NNCASE_SHARED_RUNTIME_TENSOR_PLATFORM_HEADER
+#endif
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.platform.h b/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.platform.h
new file mode 100644
index 0000000..6cf6c81
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/shared_runtime_tensor.platform.h
@@ -0,0 +1,43 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "runtime_tensor_impl.h"
+
+BEGIN_NS_NNCASE_RUNTIME
+
+namespace detail {
+struct host_memory_block;
+
+struct NNCASE_API physical_memory_block {
+    uintptr_t physical_address;
+    bool owned;
+
+    physical_memory_block() noexcept;
+    ~physical_memory_block();
+    physical_memory_block(const physical_memory_block &) = delete;
+    physical_memory_block(physical_memory_block &&other) noexcept;
+    physical_memory_block &operator=(const physical_memory_block &) = delete;
+    physical_memory_block &operator=(physical_memory_block &&other) noexcept;
+
+    void free(NNCASE_UNUSED host_memory_block &block) noexcept;
+
+    static result<void> acknowledge(host_memory_block &block) noexcept;
+    static result<void> allocate(host_memory_block &block) noexcept;
+    static result<void> sync(host_memory_block &block,
+                             host_runtime_tensor::sync_op_t op) noexcept;
+};
+} // namespace detail
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/simple_types.h b/third_party/nncase/x86_64/include/nncase/runtime/simple_types.h
new file mode 100644
index 0000000..cebc780
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/simple_types.h
@@ -0,0 +1,192 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../compiler_defs.h"
+#include "bfloat16.h"
+#include "half.h"
+#include "small_vector.hpp"
+#include <array>
+
+namespace nncase {
+typedef enum : uint8_t {
+#define DEFINE_TYPECODE(id, name, value) dt_##id = value,
+#include "typecodes.def"
+#undef DEFINE_TYPECODE
+} typecode_t;
+
+struct scalar {
+    typecode_t type;
+    std::aligned_storage_t<8> storage;
+
+    scalar() = default;
+
+    scalar(int8_t value) noexcept {
+        type = dt_int8;
+        as<int8_t>() = value;
+    }
+
+    scalar(int16_t value) noexcept {
+        type = dt_int16;
+        as<int16_t>() = value;
+    }
+
+    scalar(int32_t value) noexcept {
+        type = dt_int32;
+        as<int32_t>() = value;
+    }
+
+    scalar(uint8_t value) noexcept {
+        type = dt_uint8;
+        as<uint8_t>() = value;
+    }
+
+    scalar(uint16_t value) noexcept {
+        type = dt_uint16;
+        as<uint16_t>() = value;
+    }
+
+    scalar(uint32_t value) noexcept {
+        type = dt_uint32;
+        as<uint32_t>() = value;
+    }
+
+    scalar(bfloat16 value) noexcept {
+        type = dt_bfloat16;
+        as<bfloat16>() = value;
+    }
+
+    scalar(half value) noexcept {
+        type = dt_float16;
+        as<half>() = value;
+    }
+
+    scalar(float value) noexcept {
+        type = dt_float32;
+        as<float>() = value;
+    }
+
+    template <class T> T &as() noexcept {
+        return *reinterpret_cast<T *>(&storage);
+    }
+
+    template <class T> const T &as() const noexcept {
+        return *reinterpret_cast<const T *>(&storage);
+    }
+};
+
+inline constexpr size_t typecode_bytes(typecode_t typecode) {
+    switch (typecode) {
+    case dt_boolean:
+    case dt_uint8:
+    case dt_int8:
+        return 1;
+    case dt_uint16:
+    case dt_int16:
+    case dt_float16:
+    case dt_bfloat16:
+        return 2;
+    case dt_uint32:
+    case dt_int32:
+    case dt_float32:
+        return 4;
+    case dt_uint64:
+    case dt_int64:
+    case dt_float64:
+        return 8;
+    case dt_pointer:
+        return sizeof(intptr_t);
+    default:
+        return -1;
+    }
+}
+
+struct padding {
+    int32_t before;
+    int32_t after;
+    int32_t interior = 0;
+
+    int32_t sum() const noexcept { return before + after; }
+
+    static padding zero() noexcept { return {}; }
+};
+
+using uuid_t = std::array<uint8_t, 16>;
+using dims_t = itlib::small_vector<size_t, 8>;
+using axes_t = itlib::small_vector<int64_t, 8>;
+using strides_t = itlib::small_vector<size_t, 8>;
+using paddings_t = itlib::small_vector<padding, 4>;
+
+template <class... Ints>
+auto fixed_dims(Ints &&...values) -> std::array<size_t, sizeof...(Ints)> {
+    return {(size_t)values...};
+}
+
+template <class T> struct value_range {
+    T min;
+    T max;
+
+    static constexpr value_range<T> full() noexcept {
+        if (std::is_floating_point<T>::value ||
+            std::is_same<T, bfloat16>::value || std::is_same<T, half>::value)
+            return {-std::numeric_limits<T>::infinity(),
+                    std::numeric_limits<T>::infinity()};
+        else
+            return {std::numeric_limits<T>::lowest(),
+                    std::numeric_limits<T>::max()};
+    }
+
+    static constexpr value_range<T> nonnegative() noexcept {
+        return {0, std::numeric_limits<T>::max()};
+    }
+
+    constexpr T length() const noexcept { return max - min; }
+};
+
+typedef struct _quant_param {
+    int32_t zero_point;
+    float scale;
+
+    template <class T> constexpr value_range<float> range() const noexcept {
+        return {(std::numeric_limits<T>::lowest() - zero_point) * scale,
+                (std::numeric_limits<T>::max() - zero_point) * scale};
+    }
+} quant_param_t;
+
+inline bool operator==(const quant_param_t &lhs,
+                       const quant_param_t &rhs) noexcept {
+    return lhs.zero_point == rhs.zero_point && lhs.scale == rhs.scale;
+}
+
+inline bool almost_equal(const quant_param_t &lhs,
+                         const quant_param_t &rhs) noexcept {
+    return lhs.zero_point == rhs.zero_point &&
+           fabs(lhs.scale - rhs.scale) <= std::numeric_limits<float>::epsilon();
+}
+
+namespace runtime {
+typedef enum sync_op_ { sync_invalidate, sync_write_back } sync_op_t;
+
+typedef enum map_access_ {
+    map_none = 0,
+    map_read = 1,
+    map_write = 2,
+    map_read_write = 3
+} map_access_t;
+
+DEFINE_ENUM_BITMASK_OPERATORS(map_access_t)
+
+enum class host_sync_status_t { valid, need_invalidate, need_write_back };
+} // namespace runtime
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/small_vector.hpp b/third_party/nncase/x86_64/include/nncase/runtime/small_vector.hpp
new file mode 100644
index 0000000..1f541ed
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/small_vector.hpp
@@ -0,0 +1,1003 @@
+// itlib-small-vector v1.00
+//
+// std::vector-like class with a static buffer for initial capacity
+//
+// MIT License:
+// Copyright(c) 2016-2018 Chobolabs Inc.
+// Copyright(c) 2020 Borislav Stanimirov
+//
+// Permission is hereby granted, free of charge, to any person obtaining
+// a copy of this software and associated documentation files(the
+// "Software"), to deal in the Software without restriction, including
+// without limitation the rights to use, copy, modify, merge, publish,
+// distribute, sublicense, and / or sell copies of the Software, and to
+// permit persons to whom the Software is furnished to do so, subject to
+// the following conditions :
+//
+// The above copyright notice and this permission notice shall be
+// included in all copies or substantial portions of the Software.
+//
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+// NONINFRINGEMENT.IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
+// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+//
+//
+//                  VERSION HISTORY
+//
+//  1.00 (2020-10-14) Rebranded release from chobo-small-vector
+//
+//
+//                  DOCUMENTATION
+//
+// Simply include this file wherever you need.
+// It defines the class itlib::small_vector, which is a drop-in replacement of
+// std::vector, but with an initial capacity as a template argument.
+// It gives you the benefits of using std::vector, at the cost of having a
+// statically allocated buffer for the initial capacity, which gives you
+// cache-local data when the vector is small (smaller than the initial
+// capacity).
+//
+// When the size exceeds the capacity, the vector allocates memory via the
+// provided allocator, falling back to classic std::vector behavior.
+//
+// The second size_t template argument, RevertToStaticSize, is used when a
+// small_vector which has already switched to dynamically allocated size reduces
+// its size to a number smaller than that. In this case the vector's buffer
+// switches back to the staticallly allocated one
+//
+// A default value for the initial static capacity is provided so a replacement
+// in an existing code is possible with minimal changes to it.
+//
+// Example:
+//
+// itlib::small_vector<int, 4, 5> myvec; // a small_vector of size 0, initial
+// capacity 4, and revert size 4 (smaller than 5) myvec.resize(2); // vector is
+// {0,0} in static buffer myvec[1] = 11; // vector is {0,11} in static buffer
+// myvec.push_back(7); // vector is {0,11,7}  in static buffer
+// myvec.insert(myvec.begin() + 1, 3); // vector is {0,3,11,7} in static buffer
+// myvec.push_back(5); // vector is {0,3,11,7,5} in dynamically allocated memory
+// buffer myvec.erase(myvec.begin());  // vector is {3,11,7,5} back in static
+// buffer myvec.resize(5); // vector is {3,11,7,5,0} back in dynamically
+// allocated memory
+//
+//
+// Reference:
+//
+// itlib::small_vector is fully compatible with std::vector with
+// the following exceptions:
+// * when reducing the size with erase or resize the new size may fall below
+//   RevertToStaticSize (if it is not 0). In such a case the vector will
+//   revert to using its static buffer, invalidating all iterators (contrary
+//   to the standard)
+// * a method is added `revert_to_static()` which reverts to the static buffer
+//   if possible, but doesn't free the dynamically allocated one
+//
+// Other notes:
+//
+// * the default value for RevertToStaticSize is zero. This means that once a
+// dynamic
+//   buffer is allocated the data will never be put into the static one, even if
+//   the size allows it. Even if clear() is called. The only way to do so is to
+//   call shrink_to_fit() or revert_to_static()
+// * shrink_to_fit will free and reallocate if size != capacity and the data
+//   doesn't fit into the static buffer. It also will revert to the static
+//   buffer whenever possible regardless of the RevertToStaticSize value
+//
+//
+//                  Configuration
+//
+// The library has two configuration options. They can be set as #define-s
+// before including the header file, but it is recommended to change the code
+// of the library itself with the values you want, especially if you include
+// the library in many compilation units (as opposed to, say, a precompiled
+// header or a central header).
+//
+//                  Config out of range error handling
+//
+// An out of range error is a runtime error which is triggered when a method is
+// called with an iterator that doesn't belong to the vector's current range.
+// For example: vec.erase(vec.end() + 1);
+//
+// This is set by defining ITLIB_SMALL_VECTOR_ERROR_HANDLING to one of the
+// following values:
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE - no error handling. Crashes WILL
+//      ensue if the error is triggered.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW - std::out_of_range is thrown.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT - asserions are triggered.
+// * ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW - combines assert and
+//      throw to catch errors more easily in debug mode
+//
+// To set this setting by editing the file change the line:
+// ```
+// #   define ITLIB_SMALL_VECTOR_ERROR_HANDLING
+// ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+// ```
+// to the default setting of your choice
+//
+//                  Config bounds checks:
+//
+// By default bounds checks are made in debug mode (via an asser) when accessing
+// elements (with `at` or `[]`). Iterators are not checked (yet...)
+//
+// To disable them, you can define ITLIB_SMALL_VECTOR_NO_DEBUG_BOUNDS_CHECK
+// before including the header.
+//
+//
+//                  TESTS
+//
+// You can find unit tests for small_vector in its official repo:
+// https://github.com/iboB/itlib/blob/master/test/
+//
+#pragma once
+
+#include <cstddef>
+#include <gsl/gsl-lite.hpp>
+#include <memory>
+#include <type_traits>
+
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE 0
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW 1
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT 2
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW 3
+
+#if !defined(ITLIB_SMALL_VECTOR_ERROR_HANDLING)
+#define ITLIB_SMALL_VECTOR_ERROR_HANDLING                                      \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+#endif
+
+#if ITLIB_SMALL_VECTOR_ERROR_HANDLING == ITLIB_SMALL_VECTOR_ERROR_HANDLING_NONE
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond)
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_THROW
+#include <stdexcept>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond)                             \
+    if (cond)                                                                  \
+    throw std::out_of_range("itlib::small_vector out of range")
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT
+#include <cassert>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond, rescue_return)              \
+    assert(!(cond) && "itlib::small_vector out of range")
+#elif ITLIB_SMALL_VECTOR_ERROR_HANDLING ==                                     \
+    ITLIB_SMALL_VECTOR_ERROR_HANDLING_ASSERT_AND_THROW
+#include <cassert>
+#include <stdexcept>
+#define I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(cond, rescue_return)              \
+    do {                                                                       \
+        if (cond) {                                                            \
+            assert(false && "itlib::small_vector out of range");               \
+            throw std::out_of_range("itlib::small_vector out of range");       \
+        }                                                                      \
+    } while (false)
+#else
+#error "Unknown ITLIB_SMALL_VECTOR_ERRROR_HANDLING"
+#endif
+
+#if defined(ITLIB_SMALL_VECTOR_NO_DEBUG_BOUNDS_CHECK)
+#define I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i)
+#else
+#include <cassert>
+#define I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i) assert((i) < this->size())
+#endif
+
+namespace itlib {
+
+template <typename T, size_t StaticCapacity = 16, size_t RevertToStaticSize = 0,
+          class Alloc = std::allocator<T>>
+struct small_vector : Alloc {
+    static_assert(RevertToStaticSize <= StaticCapacity + 1,
+                  "itlib::small_vector: the revert-to-static size shouldn't "
+                  "exceed the static capacity by more than one");
+
+    using atraits = std::allocator_traits<Alloc>;
+
+  public:
+    using allocator_type = Alloc;
+    using value_type = typename atraits::value_type;
+    using size_type = typename atraits::size_type;
+    using difference_type = typename atraits::difference_type;
+    using reference = T &;
+    using const_reference = const T &;
+    using pointer = typename atraits::pointer;
+    using const_pointer = typename atraits::const_pointer;
+    using iterator = pointer;
+    using const_iterator = const_pointer;
+    using reverse_iterator = std::reverse_iterator<iterator>;
+    using const_reverse_iterator = std::reverse_iterator<const_iterator>;
+
+    static constexpr size_t static_capacity = StaticCapacity;
+    static constexpr intptr_t revert_to_static_size = RevertToStaticSize;
+
+    small_vector() : small_vector(Alloc()) {}
+
+    small_vector(const Alloc &alloc)
+        : Alloc(alloc),
+          m_capacity(StaticCapacity),
+          m_dynamic_capacity(0),
+          m_dynamic_data(nullptr) {
+        m_begin = m_end = static_begin_ptr();
+    }
+
+    explicit small_vector(size_t count, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        resize(count);
+    }
+
+    explicit small_vector(size_t count, const T &value,
+                          const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(count, value);
+    }
+
+    template <class InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    small_vector(InputIterator first, InputIterator last,
+                 const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(first, last);
+    }
+
+    small_vector(std::initializer_list<T> l, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(l);
+    }
+
+    template <class U>
+    small_vector(gsl::span<U> c, const Alloc &alloc = Alloc())
+        : small_vector(alloc) {
+        assign_impl(c.begin(), c.end());
+    }
+
+    small_vector(const small_vector &v)
+        : small_vector(v, atraits::select_on_container_copy_construction(
+                              v.get_allocator())) {}
+
+    small_vector(const small_vector &v, const Alloc &alloc)
+        : Alloc(alloc), m_dynamic_capacity(0), m_dynamic_data(nullptr) {
+        if (v.size() > StaticCapacity) {
+            m_dynamic_capacity = v.size();
+            m_begin = m_end = m_dynamic_data =
+                atraits::allocate(get_alloc(), m_dynamic_capacity);
+            m_capacity = v.size();
+        } else {
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        }
+
+        for (auto p = v.m_begin; p != v.m_end; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+    }
+
+    small_vector(small_vector &&v)
+        : Alloc(std::move(v.get_alloc())),
+          m_capacity(v.m_capacity),
+          m_dynamic_capacity(v.m_dynamic_capacity),
+          m_dynamic_data(v.m_dynamic_data) {
+        if (v.m_begin == v.static_begin_ptr()) {
+            m_begin = m_end = static_begin_ptr();
+            for (auto p = v.m_begin; p != v.m_end; ++p) {
+                atraits::construct(get_alloc(), m_end, std::move(*p));
+                ++m_end;
+            }
+
+            v.clear();
+        } else {
+            m_begin = v.m_begin;
+            m_end = v.m_end;
+        }
+
+        v.m_dynamic_capacity = 0;
+        v.m_dynamic_data = nullptr;
+        v.m_begin = v.m_end = v.static_begin_ptr();
+        v.m_capacity = StaticCapacity;
+    }
+
+    ~small_vector() {
+        clear();
+
+        if (m_dynamic_data) {
+            atraits::deallocate(get_alloc(), m_dynamic_data,
+                                m_dynamic_capacity);
+        }
+    }
+
+    small_vector &operator=(const small_vector &v) {
+        if (this == &v) {
+            // prevent self usurp
+            return *this;
+        }
+
+        clear();
+
+        m_begin = m_end = choose_data(v.size());
+
+        for (auto p = v.m_begin; p != v.m_end; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+
+        update_capacity();
+
+        return *this;
+    }
+
+    small_vector &operator=(small_vector &&v) {
+        clear();
+
+        get_alloc() = std::move(v.get_alloc());
+        m_capacity = v.m_capacity;
+        m_dynamic_capacity = v.m_dynamic_capacity;
+        m_dynamic_data = v.m_dynamic_data;
+
+        if (v.m_begin == v.static_begin_ptr()) {
+            m_begin = m_end = static_begin_ptr();
+            for (auto p = v.m_begin; p != v.m_end; ++p) {
+                atraits::construct(get_alloc(), m_end, std::move(*p));
+                ++m_end;
+            }
+
+            v.clear();
+        } else {
+            m_begin = v.m_begin;
+            m_end = v.m_end;
+        }
+
+        v.m_dynamic_capacity = 0;
+        v.m_dynamic_data = nullptr;
+        v.m_begin = v.m_end = v.static_begin_ptr();
+        v.m_capacity = StaticCapacity;
+
+        return *this;
+    }
+
+    void assign(size_type count, const T &value) {
+        clear();
+        assign_impl(count, value);
+    }
+
+    template <class InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    void assign(InputIterator first, InputIterator last) {
+        clear();
+        assign_impl(first, last);
+    }
+
+    void assign(std::initializer_list<T> ilist) {
+        clear();
+        assign_impl(ilist);
+    }
+
+    allocator_type get_allocator() const { return get_alloc(); }
+
+    const_reference at(size_type i) const {
+        I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i);
+        return *(m_begin + i);
+    }
+
+    reference at(size_type i) {
+        I_ITLIB_SMALL_VECTOR_BOUNDS_CHECK(i);
+        return *(m_begin + i);
+    }
+
+    const_reference operator[](size_type i) const { return at(i); }
+
+    reference operator[](size_type i) { return at(i); }
+
+    const_reference front() const { return at(0); }
+
+    reference front() { return at(0); }
+
+    const_reference back() const { return *(m_end - 1); }
+
+    reference back() { return *(m_end - 1); }
+
+    const_pointer data() const noexcept { return m_begin; }
+
+    pointer data() noexcept { return m_begin; }
+
+    // iterators
+    iterator begin() noexcept { return m_begin; }
+
+    const_iterator begin() const noexcept { return m_begin; }
+
+    const_iterator cbegin() const noexcept { return m_begin; }
+
+    iterator end() noexcept { return m_end; }
+
+    const_iterator end() const noexcept { return m_end; }
+
+    const_iterator cend() const noexcept { return m_end; }
+
+    reverse_iterator rbegin() noexcept { return reverse_iterator(end()); }
+
+    const_reverse_iterator rbegin() const noexcept {
+        return const_reverse_iterator(end());
+    }
+
+    const_reverse_iterator crbegin() const noexcept {
+        return const_reverse_iterator(end());
+    }
+
+    reverse_iterator rend() noexcept { return reverse_iterator(begin()); }
+
+    const_reverse_iterator rend() const noexcept {
+        return const_reverse_iterator(begin());
+    }
+
+    const_reverse_iterator crend() const noexcept {
+        return const_reverse_iterator(begin());
+    }
+
+    // capacity
+    bool empty() const noexcept { return m_begin == m_end; }
+
+    size_t size() const noexcept { return m_end - m_begin; }
+
+    size_t max_size() const noexcept { return atraits::max_size(); }
+
+    void reserve(size_type new_cap) {
+        if (new_cap <= m_capacity)
+            return;
+
+        auto new_buf = choose_data(new_cap);
+
+        assert(new_buf !=
+               m_begin); // should've been handled by new_cap <= m_capacity
+        assert(
+            new_buf !=
+            static_begin_ptr()); // we should never reserve into static memory
+
+        const auto s = size();
+        if (s < RevertToStaticSize) {
+            // we've allocated enough memory for the dynamic buffer but don't
+            // move there until we have to
+            return;
+        }
+
+        // now we need to transfer the existing elements into the new buffer
+        for (size_type i = 0; i < s; ++i) {
+            atraits::construct(get_alloc(), new_buf + i,
+                               std::move(*(m_begin + i)));
+        }
+
+        // free old elements
+        for (size_type i = 0; i < s; ++i) {
+            atraits::destroy(get_alloc(), m_begin + i);
+        }
+
+        if (m_begin != static_begin_ptr()) {
+            // we've moved from dyn to dyn memory, so deallocate the old one
+            atraits::deallocate(get_alloc(), m_begin, m_capacity);
+        }
+
+        m_begin = new_buf;
+        m_end = new_buf + s;
+        m_capacity = m_dynamic_capacity;
+    }
+
+    size_t capacity() const noexcept { return m_capacity; }
+
+    void shrink_to_fit() {
+        const auto s = size();
+
+        if (s == m_capacity)
+            return;
+        if (m_begin == static_begin_ptr())
+            return;
+
+        auto old_end = m_end;
+
+        if (s < StaticCapacity) {
+            // revert to static capacity
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        } else {
+            // alloc new smaller buffer
+            m_begin = m_end = atraits::allocate(get_alloc(), s);
+            m_capacity = s;
+        }
+
+        for (auto p = m_dynamic_data; p != old_end; ++p) {
+            atraits::construct(get_alloc(), m_end, std::move(*p));
+            ++m_end;
+            atraits::destroy(get_alloc(), p);
+        }
+
+        atraits::deallocate(get_alloc(), m_dynamic_data, m_dynamic_capacity);
+        m_dynamic_data = nullptr;
+        m_dynamic_capacity = 0;
+    }
+
+    void revert_to_static() {
+        const auto s = size();
+        if (m_begin == static_begin_ptr())
+            return; // we're already there
+        if (s > StaticCapacity)
+            return; // nothing we can do
+
+        // revert to static capacity
+        auto old_end = m_end;
+        m_begin = m_end = static_begin_ptr();
+        m_capacity = StaticCapacity;
+        for (auto p = m_dynamic_data; p != old_end; ++p) {
+            atraits::construct(get_alloc(), m_end, std::move(*p));
+            ++m_end;
+            atraits::destroy(get_alloc(), p);
+        }
+    }
+
+    // modifiers
+    void clear() noexcept {
+        for (auto p = m_begin; p != m_end; ++p) {
+            atraits::destroy(get_alloc(), p);
+        }
+
+        if (RevertToStaticSize > 0) {
+            m_begin = m_end = static_begin_ptr();
+            m_capacity = StaticCapacity;
+        } else {
+            m_end = m_begin;
+        }
+    }
+
+    iterator insert(const_iterator position, const value_type &val) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, val);
+        return pos;
+    }
+
+    iterator insert(const_iterator position, value_type &&val) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, std::move(val));
+        return pos;
+    }
+
+    iterator insert(const_iterator position, size_type count,
+                    const value_type &val) {
+        auto pos = grow_at(position, count);
+        for (size_type i = 0; i < count; ++i) {
+            atraits::construct(get_alloc(), pos + i, val);
+        }
+        return pos;
+    }
+
+    template <typename InputIterator,
+              typename = decltype(*std::declval<InputIterator>())>
+    iterator insert(const_iterator position, InputIterator first,
+                    InputIterator last) {
+        auto pos = grow_at(position, last - first);
+        auto np = pos;
+        for (auto p = first; p != last; ++p, ++np) {
+            atraits::construct(get_alloc(), np, *p);
+        }
+        return pos;
+    }
+
+    iterator insert(const_iterator position, std::initializer_list<T> ilist) {
+        auto pos = grow_at(position, ilist.size());
+        size_type i = 0;
+        for (auto &elem : ilist) {
+            atraits::construct(get_alloc(), pos + i, elem);
+            ++i;
+        }
+        return pos;
+    }
+
+    template <typename... Args>
+    iterator emplace(const_iterator position, Args &&...args) {
+        auto pos = grow_at(position, 1);
+        atraits::construct(get_alloc(), pos, std::forward<Args>(args)...);
+        return pos;
+    }
+
+    iterator erase(const_iterator position) { return shrink_at(position, 1); }
+
+    iterator erase(const_iterator first, const_iterator last) {
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(first > last);
+        return shrink_at(first, last - first);
+    }
+
+    void push_back(const_reference val) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, val);
+    }
+
+    void push_back(T &&val) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, std::move(val));
+    }
+
+    template <typename... Args> reference emplace_back(Args &&...args) {
+        auto pos = grow_at(m_end, 1);
+        atraits::construct(get_alloc(), pos, std::forward<Args>(args)...);
+        return *pos;
+    }
+
+    void pop_back() { shrink_at(m_end - 1, 1); }
+
+    void resize(size_type n, const value_type &v) {
+        auto new_buf = choose_data(n);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            auto new_end = m_begin + n;
+
+            while (m_end > new_end) {
+                atraits::destroy(get_alloc(), --m_end);
+            }
+
+            while (new_end > m_end) {
+                atraits::construct(get_alloc(), m_end++, v);
+            }
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            const auto s = size();
+            const auto num_transfer = n < s ? n : s;
+
+            for (size_type i = 0; i < num_transfer; ++i) {
+                atraits::construct(get_alloc(), new_buf + i,
+                                   std::move(*(m_begin + i)));
+            }
+
+            // free obsoletes
+            for (size_type i = 0; i < s; ++i) {
+                atraits::destroy(get_alloc(), m_begin + i);
+            }
+
+            // construct new elements
+            for (size_type i = num_transfer; i < n; ++i) {
+                atraits::construct(get_alloc(), new_buf + i, v);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            if (new_buf == static_begin_ptr()) {
+                m_capacity = StaticCapacity;
+            } else {
+                m_capacity = m_dynamic_capacity;
+            }
+
+            m_begin = new_buf;
+            m_end = new_buf + n;
+        }
+    }
+
+    void resize(size_type n) {
+        auto new_buf = choose_data(n);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            auto new_end = m_begin + n;
+
+            while (m_end > new_end) {
+                atraits::destroy(get_alloc(), --m_end);
+            }
+
+            while (new_end > m_end) {
+                atraits::construct(get_alloc(), m_end++);
+            }
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            const auto s = size();
+            const auto num_transfer = n < s ? n : s;
+
+            for (size_type i = 0; i < num_transfer; ++i) {
+                atraits::construct(get_alloc(), new_buf + i,
+                                   std::move(*(m_begin + i)));
+            }
+
+            // free obsoletes
+            for (size_type i = 0; i < n; ++i) {
+                atraits::destroy(get_alloc(), m_begin + i);
+            }
+
+            // construct new elements
+            for (size_type i = num_transfer; i < s; ++i) {
+                atraits::construct(get_alloc(), new_buf + i);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            if (new_buf == static_begin_ptr()) {
+                m_capacity = StaticCapacity;
+            } else {
+                m_capacity = m_dynamic_capacity;
+            }
+
+            m_begin = new_buf;
+            m_end = new_buf + n;
+        }
+    }
+
+  private:
+    T *static_begin_ptr() {
+        return reinterpret_cast<pointer>(m_static_data + 0);
+    }
+
+    // increase the size by splicing the elements in such a way that
+    // a hole of uninitialized elements is left at position, with size num
+    // returns the (potentially new) address of the hole
+    T *grow_at(const T *cp, size_t num) {
+        auto position = const_cast<T *>(cp);
+
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(position < m_begin ||
+                                             position > m_end);
+
+        const auto s = size();
+        auto new_buf = choose_data(s + num);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            m_end = m_begin + s + num;
+
+            for (auto p = m_end - num - 1; p >= position; --p) {
+                atraits::construct(get_alloc(), p + num, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            return position;
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            position = new_buf + (position - m_begin);
+
+            auto p = m_begin;
+            auto np = new_buf;
+
+            for (; np != position; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+            }
+
+            np += num;
+            for (; p != m_end; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+            }
+
+            // destroy old
+            for (p = m_begin; p != m_end; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            if (m_begin != static_begin_ptr()) {
+                // we've moved from dyn to dyn memory, so deallocate the old one
+                atraits::deallocate(get_alloc(), m_begin, m_capacity);
+            }
+
+            m_capacity = m_dynamic_capacity;
+
+            m_begin = new_buf;
+            m_end = new_buf + s + num;
+
+            return position;
+        }
+    }
+
+    T *shrink_at(const T *cp, size_t num) {
+        auto position = const_cast<T *>(cp);
+
+        I_ITLIB_SMALL_VECTOR_OUT_OF_RANGE_IF(
+            position < m_begin || position > m_end || position + num > m_end);
+
+        const auto s = size();
+        if (s - num == 0) {
+            clear();
+            return m_end;
+        }
+
+        auto new_buf = choose_data(s - num);
+
+        if (new_buf == m_begin) {
+            // no special transfers needed
+
+            for (auto p = position, np = position + num; np != m_end;
+                 ++p, ++np) {
+                atraits::destroy(get_alloc(), p);
+                atraits::construct(get_alloc(), p, std::move(*np));
+            }
+
+            for (auto p = m_end - num; p != m_end; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            m_end -= num;
+        } else {
+            // we need to transfer the elements into the new buffer
+
+            assert(new_buf ==
+                   static_begin_ptr()); // since we're shrinking that's the only
+                                        // way to have a new buffer
+
+            m_capacity = StaticCapacity;
+
+            auto p = m_begin, np = new_buf;
+            for (; p != position; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            for (; p != position + num; ++p) {
+                atraits::destroy(get_alloc(), p);
+            }
+
+            for (; np != new_buf + s - num; ++p, ++np) {
+                atraits::construct(get_alloc(), np, std::move(*p));
+                atraits::destroy(get_alloc(), p);
+            }
+
+            position = new_buf + (position - m_begin);
+            m_begin = new_buf;
+            m_end = np;
+        }
+
+        return ++position;
+    }
+
+    void assign_impl(size_type count, const T &value) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(count);
+        for (size_type i = 0; i < count; ++i) {
+            atraits::construct(get_alloc(), m_end, value);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    template <class InputIterator>
+    void assign_impl(InputIterator first, InputIterator last) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(last - first);
+        for (auto p = first; p != last; ++p) {
+            atraits::construct(get_alloc(), m_end, *p);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    void assign_impl(std::initializer_list<T> ilist) {
+        assert(m_begin);
+        assert(m_begin == m_end);
+
+        m_begin = m_end = choose_data(ilist.size());
+        for (auto &elem : ilist) {
+            atraits::construct(get_alloc(), m_end, elem);
+            ++m_end;
+        }
+
+        update_capacity();
+    }
+
+    void update_capacity() {
+        if (m_begin == static_begin_ptr()) {
+            m_capacity = StaticCapacity;
+        } else {
+            m_capacity = m_dynamic_capacity;
+        }
+    }
+
+    T *choose_data(size_t desired_capacity) {
+        if (m_begin == m_dynamic_data) {
+            // we're at the dyn buffer, so see if it needs resize or revert to
+            // static
+
+            if (desired_capacity > m_dynamic_capacity) {
+                while (m_dynamic_capacity < desired_capacity) {
+                    // grow by roughly 1.5
+                    m_dynamic_capacity *= 3;
+                    ++m_dynamic_capacity;
+                    m_dynamic_capacity /= 2;
+                }
+
+                m_dynamic_data =
+                    atraits::allocate(get_alloc(), m_dynamic_capacity);
+                return m_dynamic_data;
+            } else if (desired_capacity < RevertToStaticSize) {
+                // we're reverting to the static buffer
+                return static_begin_ptr();
+            } else {
+                // if the capacity and we don't revert to static, just do
+                // nothing
+                return m_dynamic_data;
+            }
+        } else {
+            assert(m_begin == static_begin_ptr()); // corrupt begin ptr?
+
+            if (desired_capacity > StaticCapacity) {
+                // we must move to dyn memory
+
+                // see if we have enough
+                if (desired_capacity > m_dynamic_capacity) {
+                    // we need to allocate more
+                    // we don't have anything to destroy, so we can also
+                    // deallocate the buffer
+                    if (m_dynamic_data) {
+                        atraits::deallocate(get_alloc(), m_dynamic_data,
+                                            m_dynamic_capacity);
+                    }
+
+                    m_dynamic_capacity = desired_capacity;
+                    m_dynamic_data =
+                        atraits::allocate(get_alloc(), m_dynamic_capacity);
+                }
+
+                return m_dynamic_data;
+            } else {
+                // we have enough capacity as it is
+                return static_begin_ptr();
+            }
+        }
+    }
+
+    allocator_type &get_alloc() { return static_cast<allocator_type &>(*this); }
+    const allocator_type &get_alloc() const {
+        return static_cast<const allocator_type &>(*this);
+    }
+
+    pointer m_begin;
+    pointer m_end;
+
+    size_t m_capacity;
+    typename std::aligned_storage<sizeof(T), std::alignment_of<T>::value>::type
+        m_static_data[StaticCapacity];
+
+    size_t m_dynamic_capacity;
+    pointer m_dynamic_data;
+};
+
+template <typename T, size_t StaticCapacity, size_t RevertToStaticSize,
+          class Alloc>
+bool operator==(
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &a,
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &b) {
+    if (a.size() != b.size()) {
+        return false;
+    }
+
+    for (size_t i = 0; i < a.size(); ++i) {
+        if (a[i] != b[i])
+            return false;
+    }
+
+    return true;
+}
+
+template <typename T, size_t StaticCapacity, size_t RevertToStaticSize,
+          class Alloc>
+bool operator!=(
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &a,
+    const small_vector<T, StaticCapacity, RevertToStaticSize, Alloc> &b) {
+    if (a.size() != b.size()) {
+        return true;
+    }
+
+    for (size_t i = 0; i < a.size(); ++i) {
+        if (a[i] != b[i])
+            return true;
+    }
+
+    return false;
+}
+
+} // namespace itlib
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/span_reader.h b/third_party/nncase/x86_64/include/nncase/runtime/span_reader.h
new file mode 100644
index 0000000..720bc48
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/span_reader.h
@@ -0,0 +1,145 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+#include <iterator>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/dbg.h>
+#include <string>
+#include <vector>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class span_reader {
+  public:
+    span_reader(gsl::span<const gsl::byte> span)
+        : begin_(span.begin()), end_(span.end()) {}
+
+    const gsl::byte *tell() const noexcept { return begin_; }
+    bool empty() const noexcept { return begin_ == end_; }
+    size_t avail() const noexcept { return end_ - begin_; }
+
+    void seek(const gsl::byte *pos) noexcept { begin_ = pos; }
+
+    template <class T> T read() {
+        auto value = *reinterpret_cast<const T *>(begin_);
+        advance(sizeof(T));
+        return value;
+    }
+
+    template <class T> T read_unaligned() {
+        alignas(T) uint8_t storage[sizeof(T)];
+        std::memcpy(storage, begin_, sizeof(T));
+        advance(sizeof(T));
+        return *reinterpret_cast<const T *>(storage);
+    }
+
+    template <class T> void read(T &value) {
+        value = *reinterpret_cast<const T *>(begin_);
+        advance(sizeof(T));
+    }
+
+    template <class T> void read_span(gsl::span<const T> &span, size_t size) {
+        span = {reinterpret_cast<const T *>(begin_), size};
+        advance(sizeof(T) * size);
+    }
+
+    template <class T = gsl::byte> gsl::span<const T> read_span(size_t size) {
+        gsl::span<const T> span(reinterpret_cast<const T *>(begin_), size);
+        advance(sizeof(T) * size);
+        return span;
+    }
+
+    std::string read_string() {
+        auto span = read_until((gsl::byte)0).as_span<const char>();
+        advance(1);
+        return {span.begin(), span.end()};
+    }
+
+    std::vector<std::string> read_string_array() {
+        std::vector<std::string> array;
+        while (true) {
+            if (peek<char>() == '\0') {
+                advance(1);
+                break;
+            }
+            array.emplace_back(read_string());
+        }
+        return array;
+    }
+
+    void read_avail(gsl::span<const gsl::byte> &span) {
+        span = {begin_, end_};
+        begin_ = end_;
+    }
+
+    gsl::span<const gsl::byte> read_until(gsl::byte value) {
+        auto it = std::find(begin_, end_, value);
+        return read_span((size_t)std::distance(begin_, it));
+    }
+
+    gsl::span<const gsl::byte> read_avail() {
+        gsl::span<const gsl::byte> span;
+        read_avail(span);
+        return span;
+    }
+
+    gsl::span<const gsl::byte> peek_avail() { return {begin_, end_}; }
+
+    template <class T> T peek_with_offset(size_t offset) {
+        auto value = *reinterpret_cast<const T *>(begin_ + offset);
+        return value;
+    }
+
+    template <class T> T peek() { return peek_with_offset<T>(0); }
+
+    template <class T> T peek_unaligned_with_offset(size_t offset) {
+        T value;
+        std::memcpy(&value, begin_ + offset, sizeof(T));
+        return value;
+    }
+
+    template <class T> T peek_unaligned() {
+        return peek_unaligned_with_offset<T>(0);
+    }
+
+    template <class T> const T *peek_ref() {
+        auto ptr = reinterpret_cast<const T *>(begin_);
+        return ptr;
+    }
+
+    template <class T> const T *get_ref() {
+        auto ptr = peek_ref<T>();
+        advance(sizeof(T));
+        return ptr;
+    }
+
+    template <class T> void get_ref(const T *&ptr) { ptr = get_ref<T>(); }
+
+    void skip(size_t count) { advance(count); }
+
+  private:
+    void advance(size_t count) {
+        begin_ += count;
+        dbg_check(begin_ <= end_);
+    }
+
+  private:
+    const gsl::byte *begin_;
+    const gsl::byte *end_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_profile.h b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_profile.h
new file mode 100644
index 0000000..013cbae
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_profile.h
@@ -0,0 +1,49 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "opcode.h"
+#include <iomanip>
+#include <iostream>
+#include <tuple>
+#include <vector>
+
+extern "C" {
+double get_ms_time();
+}
+
+class op_profile {
+  public:
+    op_profile(const std::string &op_name, uint8_t op_type)
+        : op_name_(op_name), op_type_(op_type) {
+        begin_ = get_ms_time();
+    }
+
+    ~op_profile() {
+        end_ = get_ms_time();
+        op_timing_.push_back(std::make_tuple(op_name_, op_type_, begin_, end_));
+    }
+
+    static void print();
+
+  public:
+    static std::vector<std::tuple<std::string, uint8_t, double, double>>
+        op_timing_;
+
+  private:
+    double begin_;
+    double end_;
+    std::string op_name_;
+    uint8_t op_type_;
+};
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_reader.h b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_reader.h
new file mode 100644
index 0000000..52670fb
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/op_reader.h
@@ -0,0 +1,1895 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../error.h"
+#include "../result.h"
+#include "../span_reader.h"
+#include "opcode.h"
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+template <opcode_t Op> struct op_reader;
+
+template <> struct op_reader<opcode_t::NOP> {
+    nop_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        nop_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR> {
+    br_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR_TRUE> {
+    br_true_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_true_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BR_FALSE> {
+    br_false_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        br_false_op_t op;
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::RET> {
+    ret_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ret_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CALL> {
+    call_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        call_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        op.target = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::ECALL> {
+    ecall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ecall_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::EXTCALL> {
+    extcall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        extcall_op_t op;
+        op.args = reader.read_unaligned<uint16_t>();
+        op.is_prim_func = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CUSCALL> {
+    cuscall_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cuscall_op_t op;
+        op.registered_name = reader.read_string();
+        op.fields_span = reader.read_span(reader.read_unaligned<uint32_t>());
+        op.args = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::THROW> {
+    throw_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        throw_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::BREAK> {
+    break_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        break_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4> {
+    ldc_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_op_t op;
+        op.imm = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDNULL> {
+    ldnull_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldnull_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4_0> {
+    ldc_i4_0_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_0_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_I4_1> {
+    ldc_i4_1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_i4_1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDC_R4> {
+    ldc_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldc_r4_op_t op;
+        op.imm = reader.read_unaligned<float>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I1> {
+    ldind_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I2> {
+    ldind_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I4> {
+    ldind_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_I> {
+    ldind_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U1> {
+    ldind_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U2> {
+    ldind_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U4> {
+    ldind_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_U> {
+    ldind_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_BR2> {
+    ldind_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDIND_R4> {
+    ldind_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldind_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I1> {
+    stind_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I2> {
+    stind_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I4> {
+    stind_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_I> {
+    stind_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_BR2> {
+    stind_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STIND_R4> {
+    stind_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stind_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LEA_GP> {
+    lea_gp_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        lea_gp_op_t op;
+        op.gpid = reader.read_unaligned<uint8_t>();
+        op.offset = reader.read_unaligned<int64_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I1> {
+    ldelem_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I2> {
+    ldelem_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I4> {
+    ldelem_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_I> {
+    ldelem_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U1> {
+    ldelem_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U2> {
+    ldelem_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U4> {
+    ldelem_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_U> {
+    ldelem_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_BR2> {
+    ldelem_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDELEM_R4> {
+    ldelem_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldelem_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I1> {
+    stelem_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I2> {
+    stelem_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I4> {
+    stelem_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_I> {
+    stelem_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_BR2> {
+    stelem_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STELEM_R4> {
+    stelem_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stelem_r4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG> {
+    ldarg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_0> {
+    ldarg_0_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_0_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_1> {
+    ldarg_1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_2> {
+    ldarg_2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_3> {
+    ldarg_3_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_3_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_4> {
+    ldarg_4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDARG_5> {
+    ldarg_5_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldarg_5_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTUPLE_ELEM> {
+    ldtuple_elem_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtuple_elem_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTUPLE> {
+    ldtuple_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtuple_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDDATATYPE> {
+    lddatatype_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        lddatatype_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDTENSOR> {
+    ldtensor_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldtensor_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDLOCAL> {
+    ldlocal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldlocal_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::STLOCAL> {
+    stlocal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        stlocal_op_t op;
+        op.index = reader.read_unaligned<uint16_t>();
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::LDSCALAR> {
+    ldscalar_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ldscalar_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DUP> {
+    dup_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        dup_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::POP> {
+    pop_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        pop_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::NEG> {
+    neg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        neg_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::ADD> {
+    add_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        add_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SUB> {
+    sub_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        sub_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::MUL> {
+    mul_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        mul_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DIV> {
+    div_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        div_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::DIV_U> {
+    div_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        div_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::REM> {
+    rem_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        rem_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::REM_U> {
+    rem_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        rem_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::AND> {
+    and_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        and_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::OR> {
+    or_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        or_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::XOR> {
+    xor_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        xor_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::NOT> {
+    not_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        not_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHL> {
+    shl_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shl_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHR> {
+    shr_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shr_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::SHR_U> {
+    shr_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        shr_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLT> {
+    clt_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        clt_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLT_U> {
+    clt_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        clt_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLE> {
+    cle_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cle_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CLE_U> {
+    cle_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cle_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CEQ> {
+    ceq_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        ceq_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGE> {
+    cge_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cge_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGE_U> {
+    cge_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cge_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGT> {
+    cgt_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cgt_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CGT_U> {
+    cgt_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cgt_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CNE> {
+    cne_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        cne_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I1> {
+    conv_i1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I2> {
+    conv_i2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I4> {
+    conv_i4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_I> {
+    conv_i_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_i_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U1> {
+    conv_u1_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u1_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U2> {
+    conv_u2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U4> {
+    conv_u4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u4_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_U> {
+    conv_u_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_u_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_BR2> {
+    conv_br2_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_br2_op_t op;
+        return op;
+    }
+};
+
+template <> struct op_reader<opcode_t::CONV_R4> {
+    conv_r4_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        conv_r4_op_t op;
+        return op;
+    }
+};
+
+template <tensor_function_t Op> struct tensor_op_reader;
+
+template <> struct tensor_op_reader<tensor_function_t::batch_normalization> {
+    tensor_batch_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_batch_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::batch_to_space> {
+    tensor_batch_to_space_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_batch_to_space_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::binary> {
+    tensor_binary_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_binary_op_t op;
+        op.binary_op =
+            static_cast<binary_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::bitcast> {
+    tensor_bitcast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_bitcast_op_t op;
+        op.type = reader.read_unaligned<prim_type_t>();
+        op.new_type = reader.read_unaligned<prim_type_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::broadcast> {
+    tensor_broadcast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_broadcast_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::broadcast_shape> {
+    tensor_broadcast_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_broadcast_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::bucket_pad> {
+    tensor_bucket_pad_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_bucket_pad_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::cast> {
+    tensor_cast_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_cast_op_t op;
+        op.new_type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        op.cast_mode =
+            static_cast<cast_mode_t>(reader.read_unaligned<uint32_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::celu> {
+    tensor_celu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_celu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::clamp> {
+    tensor_clamp_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_clamp_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::compare> {
+    tensor_compare_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_compare_op_t op;
+        op.compare_op =
+            static_cast<compare_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::concat> {
+    tensor_concat_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_concat_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::condition> {
+    tensor_condition_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_condition_op_t op;
+        op.can_fold_const_call = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::constant_of_shape> {
+    tensor_constant_of_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_constant_of_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d> {
+    tensor_conv2d_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_shape> {
+    tensor_conv2d_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_transpose> {
+    tensor_conv2d_transpose_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_transpose_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::conv2d_transpose_shape> {
+    tensor_conv2d_transpose_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_conv2d_transpose_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::cum_sum> {
+    tensor_cum_sum_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_cum_sum_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::dequantize> {
+    tensor_dequantize_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_dequantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::elu> {
+    tensor_elu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_elu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::erf> {
+    tensor_erf_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_erf_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::expand> {
+    tensor_expand_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_expand_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fake_dequantize> {
+    tensor_fake_dequantize_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fake_dequantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fake_quantize> {
+    tensor_fake_quantize_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fake_quantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::fix_shape> {
+    tensor_fix_shape_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_fix_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::flatten> {
+    tensor_flatten_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_flatten_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather> {
+    tensor_gather_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather_elements> {
+    tensor_gather_elements_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_elements_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gather_nd> {
+    tensor_gather_nd_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gather_nd_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::gelu> {
+    tensor_gelu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_gelu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::get_item> {
+    tensor_get_item_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_get_item_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::get_paddings> {
+    tensor_get_paddings_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_get_paddings_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hard_sigmoid> {
+    tensor_hard_sigmoid_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hard_sigmoid_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hard_swish> {
+    tensor_hard_swish_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hard_swish_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::hardmax> {
+    tensor_hardmax_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_hardmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::index_of> {
+    tensor_index_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_index_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::instance_normalization> {
+    tensor_instance_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_instance_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::l2_normalization> {
+    tensor_l2_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_l2_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::layer_norm> {
+    tensor_layer_norm_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_layer_norm_op_t op;
+        op.axis = reader.read_unaligned<int32_t>();
+        op.epsilon = reader.read_unaligned<float>();
+        op.use_mean = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::leaky_relu> {
+    tensor_leaky_relu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_leaky_relu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::log_softmax> {
+    tensor_log_softmax_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_log_softmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lp_normalization> {
+    tensor_lp_normalization_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lp_normalization_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lrn> {
+    tensor_lrn_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lrn_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::lstm> {
+    tensor_lstm_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_lstm_op_t op;
+        op.direction =
+            static_cast<lstmdirection_t>(reader.read_unaligned<uint32_t>());
+        op.layout =
+            static_cast<lstmlayout_t>(reader.read_unaligned<uint32_t>());
+        op.activations = reader.read_string_array();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::mat_mul> {
+    tensor_mat_mul_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_mat_mul_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::mat_mul_shape> {
+    tensor_mat_mul_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_mat_mul_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::normal> {
+    tensor_normal_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_normal_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::normal_like> {
+    tensor_normal_like_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_normal_like_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::one_hot> {
+    tensor_one_hot_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_one_hot_op_t op;
+        op.one_hot_mode =
+            static_cast<one_hot_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::pad> {
+    tensor_pad_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_pad_op_t op;
+        op.pad_mode = static_cast<pad_mode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::prelu> {
+    tensor_prelu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_prelu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::prod> {
+    tensor_prod_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_prod_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::quant_param_of> {
+    tensor_quant_param_of_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_quant_param_of_op_t op;
+        op.quant_mode =
+            static_cast<quant_mode_t>(reader.read_unaligned<uint32_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::quantize> {
+    tensor_quantize_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_quantize_op_t op;
+        op.target_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::range> {
+    tensor_range_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_range_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::range_of> {
+    tensor_range_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_range_of_op_t op;
+        op.is_range_of_weight = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::rank> {
+    tensor_rank_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_rank_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce> {
+    tensor_reduce_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_op_t op;
+        op.reduce_op =
+            static_cast<reduce_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce_arg> {
+    tensor_reduce_arg_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_arg_op_t op;
+        op.reduce_arg_op =
+            static_cast<reduce_arg_op_t>(reader.read_unaligned<uint8_t>());
+        op.dest_type =
+            static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reduce_window2d> {
+    tensor_reduce_window2d_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reduce_window2d_op_t op;
+        op.reduce_op =
+            static_cast<reduce_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::relu> {
+    tensor_relu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_relu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::relu6> {
+    tensor_relu6_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_relu6_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::require> {
+    tensor_require_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_require_op_t op;
+        op.message = reader.read_string();
+        op.can_fold_const_call = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reshape> {
+    tensor_reshape_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reshape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reshape_shape> {
+    tensor_reshape_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reshape_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::resize_image> {
+    tensor_resize_image_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_resize_image_op_t op;
+        op.resize_mode =
+            static_cast<image_resize_mode_t>(reader.read_unaligned<uint8_t>());
+        op.transformation_mode =
+            static_cast<image_resize_transformation_mode_t>(
+                reader.read_unaligned<uint32_t>());
+        op.nearest_mode = static_cast<image_resize_nearest_mode_t>(
+            reader.read_unaligned<uint32_t>());
+        op.is_tfresize = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::reverse_sequence> {
+    tensor_reverse_sequence_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_reverse_sequence_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::scatter_nd> {
+    tensor_scatter_nd_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_scatter_nd_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::select> {
+    tensor_select_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_select_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::selu> {
+    tensor_selu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_selu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::shape_of> {
+    tensor_shape_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_shape_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::sigmoid> {
+    tensor_sigmoid_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_sigmoid_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::size_of> {
+    tensor_size_of_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_size_of_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::slice> {
+    tensor_slice_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_slice_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softmax> {
+    tensor_softmax_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softmax_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softplus> {
+    tensor_softplus_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softplus_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::softsign> {
+    tensor_softsign_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_softsign_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::space_to_batch> {
+    tensor_space_to_batch_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_space_to_batch_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::split> {
+    tensor_split_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_split_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::squeeze> {
+    tensor_squeeze_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_squeeze_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::squeeze_shape> {
+    tensor_squeeze_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_squeeze_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::stack> {
+    tensor_stack_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_stack_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::swish> {
+    tensor_swish_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_swish_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::tile> {
+    tensor_tile_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_tile_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::top_k> {
+    tensor_top_k_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_top_k_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::transpose> {
+    tensor_transpose_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_transpose_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::transpose_shape> {
+    tensor_transpose_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_transpose_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::trilu> {
+    tensor_trilu_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_trilu_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unary> {
+    tensor_unary_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unary_op_t op;
+        op.unary_op = static_cast<unary_op_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::uniform> {
+    tensor_uniform_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_uniform_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::uniform_like> {
+    tensor_uniform_like_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_uniform_like_op_t op;
+        op.type = static_cast<typecode_t>(reader.read_unaligned<uint8_t>());
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unsqueeze> {
+    tensor_unsqueeze_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unsqueeze_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::unsqueeze_shape> {
+    tensor_unsqueeze_shape_op_t
+    operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_unsqueeze_shape_op_t op;
+        return op;
+    }
+};
+
+template <> struct tensor_op_reader<tensor_function_t::where> {
+    tensor_where_op_t operator()(NNCASE_UNUSED span_reader &reader) const {
+        tensor_where_op_t op;
+        op.is_tf_where = reader.read_unaligned<bool>();
+        return op;
+    }
+};
+
+class NNCASE_API tensor_op_visitor {
+  public:
+    result<void> visit(tensor_function_t tensor_funct,
+                       span_reader &reader) noexcept;
+
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_batch_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::batch_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_batch_to_space_op_t &op) noexcept {
+        return default_visit(tensor_function_t::batch_to_space, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_binary_op_t &op) noexcept {
+        return default_visit(tensor_function_t::binary, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_bitcast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::bitcast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_broadcast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::broadcast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_broadcast_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::broadcast_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_bucket_pad_op_t &op) noexcept {
+        return default_visit(tensor_function_t::bucket_pad, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_cast_op_t &op) noexcept {
+        return default_visit(tensor_function_t::cast, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_celu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::celu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_clamp_op_t &op) noexcept {
+        return default_visit(tensor_function_t::clamp, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_compare_op_t &op) noexcept {
+        return default_visit(tensor_function_t::compare, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_concat_op_t &op) noexcept {
+        return default_visit(tensor_function_t::concat, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_condition_op_t &op) noexcept {
+        return default_visit(tensor_function_t::condition, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_constant_of_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::constant_of_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_transpose_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_transpose, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_conv2d_transpose_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::conv2d_transpose_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_cum_sum_op_t &op) noexcept {
+        return default_visit(tensor_function_t::cum_sum, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_dequantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::dequantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_elu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::elu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_erf_op_t &op) noexcept {
+        return default_visit(tensor_function_t::erf, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_expand_op_t &op) noexcept {
+        return default_visit(tensor_function_t::expand, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fake_dequantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fake_dequantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fake_quantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fake_quantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_fix_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::fix_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_flatten_op_t &op) noexcept {
+        return default_visit(tensor_function_t::flatten, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_elements_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather_elements, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gather_nd_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gather_nd, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_gelu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::gelu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_get_item_op_t &op) noexcept {
+        return default_visit(tensor_function_t::get_item, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_get_paddings_op_t &op) noexcept {
+        return default_visit(tensor_function_t::get_paddings, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hard_sigmoid_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hard_sigmoid, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hard_swish_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hard_swish, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_hardmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::hardmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_index_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::index_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_instance_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::instance_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_l2_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::l2_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_layer_norm_op_t &op) noexcept {
+        return default_visit(tensor_function_t::layer_norm, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_leaky_relu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::leaky_relu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_log_softmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::log_softmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lp_normalization_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lp_normalization, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lrn_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lrn, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_lstm_op_t &op) noexcept {
+        return default_visit(tensor_function_t::lstm, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_mat_mul_op_t &op) noexcept {
+        return default_visit(tensor_function_t::mat_mul, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_mat_mul_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::mat_mul_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_normal_op_t &op) noexcept {
+        return default_visit(tensor_function_t::normal, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_normal_like_op_t &op) noexcept {
+        return default_visit(tensor_function_t::normal_like, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_one_hot_op_t &op) noexcept {
+        return default_visit(tensor_function_t::one_hot, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_pad_op_t &op) noexcept {
+        return default_visit(tensor_function_t::pad, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_prelu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::prelu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_prod_op_t &op) noexcept {
+        return default_visit(tensor_function_t::prod, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_quant_param_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::quant_param_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_quantize_op_t &op) noexcept {
+        return default_visit(tensor_function_t::quantize, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_range_op_t &op) noexcept {
+        return default_visit(tensor_function_t::range, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_range_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::range_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_rank_op_t &op) noexcept {
+        return default_visit(tensor_function_t::rank, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_arg_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce_arg, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reduce_window2d_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reduce_window2d, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_relu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::relu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_relu6_op_t &op) noexcept {
+        return default_visit(tensor_function_t::relu6, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_require_op_t &op) noexcept {
+        return default_visit(tensor_function_t::require, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reshape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reshape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reshape_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reshape_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_resize_image_op_t &op) noexcept {
+        return default_visit(tensor_function_t::resize_image, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_reverse_sequence_op_t &op) noexcept {
+        return default_visit(tensor_function_t::reverse_sequence, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_scatter_nd_op_t &op) noexcept {
+        return default_visit(tensor_function_t::scatter_nd, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_select_op_t &op) noexcept {
+        return default_visit(tensor_function_t::select, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_selu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::selu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_shape_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::shape_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_sigmoid_op_t &op) noexcept {
+        return default_visit(tensor_function_t::sigmoid, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_size_of_op_t &op) noexcept {
+        return default_visit(tensor_function_t::size_of, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_slice_op_t &op) noexcept {
+        return default_visit(tensor_function_t::slice, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softmax_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softmax, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softplus_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softplus, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_softsign_op_t &op) noexcept {
+        return default_visit(tensor_function_t::softsign, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_space_to_batch_op_t &op) noexcept {
+        return default_visit(tensor_function_t::space_to_batch, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_split_op_t &op) noexcept {
+        return default_visit(tensor_function_t::split, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_squeeze_op_t &op) noexcept {
+        return default_visit(tensor_function_t::squeeze, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_squeeze_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::squeeze_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_stack_op_t &op) noexcept {
+        return default_visit(tensor_function_t::stack, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_swish_op_t &op) noexcept {
+        return default_visit(tensor_function_t::swish, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_tile_op_t &op) noexcept {
+        return default_visit(tensor_function_t::tile, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_top_k_op_t &op) noexcept {
+        return default_visit(tensor_function_t::top_k, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_transpose_op_t &op) noexcept {
+        return default_visit(tensor_function_t::transpose, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_transpose_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::transpose_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_trilu_op_t &op) noexcept {
+        return default_visit(tensor_function_t::trilu, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unary_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unary, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_uniform_op_t &op) noexcept {
+        return default_visit(tensor_function_t::uniform, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_uniform_like_op_t &op) noexcept {
+        return default_visit(tensor_function_t::uniform_like, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unsqueeze_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unsqueeze, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_unsqueeze_shape_op_t &op) noexcept {
+        return default_visit(tensor_function_t::unsqueeze_shape, &op);
+    }
+    virtual result<void>
+    visit(NNCASE_UNUSED const tensor_where_op_t &op) noexcept {
+        return default_visit(tensor_function_t::where, &op);
+    }
+
+  protected:
+    virtual result<void>
+    default_visit(NNCASE_UNUSED tensor_function_t tensor_funct,
+                  NNCASE_UNUSED const void *op) noexcept {
+        return err(std::errc::not_supported);
+    }
+};
+
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/stackvm/opcode.h b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/opcode.h
new file mode 100644
index 0000000..888ae24
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/opcode.h
@@ -0,0 +1,1249 @@
+/* This file is generated by tools/stackvm_gen/IsaGen at 9/20/2023 10:17:07 AM
+ * +00:00.
+ *
+ * Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../datatypes.h"
+#include <vector>
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+// Enums
+
+enum class opcode_t : uint8_t {
+    NOP = 0,
+    LDNULL = 1,
+    LDC_I4 = 2,
+    LDC_I4_0 = 3,
+    LDC_I4_1 = 4,
+    LDC_R4 = 5,
+    LDIND_I1 = 6,
+    LDIND_I2 = 7,
+    LDIND_I4 = 8,
+    LDIND_I = 9,
+    LDIND_U1 = 10,
+    LDIND_U2 = 11,
+    LDIND_U4 = 12,
+    LDIND_U = 13,
+    LDIND_BR2 = 14,
+    LDIND_R4 = 15,
+    STIND_I1 = 16,
+    STIND_I2 = 17,
+    STIND_I4 = 18,
+    STIND_I = 19,
+    STIND_BR2 = 20,
+    STIND_R4 = 21,
+    LEA_GP = 22,
+    LDELEM_I1 = 23,
+    LDELEM_I2 = 24,
+    LDELEM_I4 = 25,
+    LDELEM_I = 26,
+    LDELEM_U1 = 27,
+    LDELEM_U2 = 28,
+    LDELEM_U4 = 29,
+    LDELEM_U = 30,
+    LDELEM_BR2 = 31,
+    LDELEM_R4 = 32,
+    STELEM_I1 = 33,
+    STELEM_I2 = 34,
+    STELEM_I4 = 35,
+    STELEM_I = 36,
+    STELEM_BR2 = 37,
+    STELEM_R4 = 38,
+    LDARG = 39,
+    LDARG_0 = 40,
+    LDARG_1 = 41,
+    LDARG_2 = 42,
+    LDARG_3 = 43,
+    LDARG_4 = 44,
+    LDARG_5 = 45,
+    DUP = 46,
+    POP = 47,
+    LDLOCAL = 48,
+    STLOCAL = 49,
+    LDTUPLE_ELEM = 50,
+    LDTUPLE = 51,
+    LDDATATYPE = 52,
+    LDTENSOR = 53,
+    LDSCALAR = 54,
+    NEG = 55,
+    ADD = 56,
+    SUB = 57,
+    MUL = 58,
+    DIV = 59,
+    DIV_U = 60,
+    REM = 61,
+    REM_U = 62,
+    AND = 63,
+    OR = 64,
+    XOR = 65,
+    NOT = 66,
+    SHL = 67,
+    SHR = 68,
+    SHR_U = 69,
+    CLT = 70,
+    CLT_U = 71,
+    CLE = 72,
+    CLE_U = 73,
+    CEQ = 74,
+    CGE = 75,
+    CGE_U = 76,
+    CGT = 77,
+    CGT_U = 78,
+    CNE = 79,
+    CONV_I1 = 80,
+    CONV_I2 = 81,
+    CONV_I4 = 82,
+    CONV_I = 83,
+    CONV_U1 = 84,
+    CONV_U2 = 85,
+    CONV_U4 = 86,
+    CONV_U = 87,
+    CONV_BR2 = 88,
+    CONV_R4 = 89,
+    BR = 90,
+    BR_TRUE = 91,
+    BR_FALSE = 92,
+    RET = 93,
+    CALL = 94,
+    ECALL = 95,
+    EXTCALL = 96,
+    CUSCALL = 97,
+    THROW = 98,
+    BREAK = 99,
+    TENSOR = 100,
+};
+
+enum class tensor_function_t : uint16_t {
+    batch_normalization = 0,
+    batch_to_space = 1,
+    celu = 8,
+    conv2d = 14,
+    conv2d_transpose = 16,
+    elu = 20,
+    erf = 21,
+    gelu = 30,
+    hardmax = 33,
+    hard_sigmoid = 34,
+    hard_swish = 35,
+    instance_normalization = 37,
+    l2_normalization = 38,
+    layer_norm = 39,
+    leaky_relu = 40,
+    log_softmax = 41,
+    lp_normalization = 42,
+    lrn = 43,
+    one_hot = 49,
+    pad = 50,
+    prelu = 51,
+    reduce_window2d = 60,
+    relu = 61,
+    relu6 = 62,
+    selu = 70,
+    sigmoid = 72,
+    softmax = 75,
+    softplus = 76,
+    softsign = 77,
+    space_to_batch = 78,
+    swish = 83,
+    binary = 2,
+    clamp = 9,
+    compare = 10,
+    condition = 12,
+    cum_sum = 18,
+    dequantize = 19,
+    fake_dequantize = 23,
+    fake_quantize = 24,
+    mat_mul = 45,
+    quantize = 53,
+    quant_param_of = 54,
+    range_of = 56,
+    reduce = 58,
+    reduce_arg = 59,
+    require = 63,
+    select = 69,
+    unary = 89,
+    bitcast = 3,
+    broadcast = 4,
+    bucket_pad = 6,
+    cast = 7,
+    concat = 11,
+    constant_of_shape = 13,
+    expand = 22,
+    fix_shape = 25,
+    flatten = 26,
+    gather = 27,
+    gather_elements = 28,
+    gather_nd = 29,
+    get_item = 31,
+    index_of = 36,
+    prod = 52,
+    range = 55,
+    rank = 57,
+    reshape = 64,
+    reverse_sequence = 67,
+    scatter_nd = 68,
+    shape_of = 71,
+    size_of = 73,
+    slice = 74,
+    split = 79,
+    squeeze = 80,
+    stack = 82,
+    tile = 84,
+    top_k = 85,
+    transpose = 86,
+    trilu = 88,
+    unsqueeze = 92,
+    where = 94,
+    broadcast_shape = 5,
+    conv2d_shape = 15,
+    conv2d_transpose_shape = 17,
+    get_paddings = 32,
+    mat_mul_shape = 46,
+    reshape_shape = 65,
+    squeeze_shape = 81,
+    transpose_shape = 87,
+    unsqueeze_shape = 93,
+    lstm = 44,
+    normal = 47,
+    normal_like = 48,
+    uniform = 90,
+    uniform_like = 91,
+    resize_image = 66,
+};
+
+enum class binary_op_t : uint8_t {
+    add = 0,
+    sub = 1,
+    mul = 2,
+    div = 3,
+    mod = 4,
+    min = 5,
+    max = 6,
+    pow = 7,
+    bitwise_and = 8,
+    bitwise_or = 9,
+    bitwise_xor = 10,
+    logical_and = 11,
+    logical_or = 12,
+    logical_xor = 13,
+    left_shift = 14,
+    right_shift = 15,
+};
+
+enum class cast_mode_t : int32_t {
+    kdefault = 0,
+    exact = 1,
+    check_overflow = 2,
+    reinterpret = 3,
+};
+
+enum class compare_op_t : uint8_t {
+    equal = 0,
+    not_equal = 1,
+    lower_than = 2,
+    lower_or_equal = 3,
+    greater_than = 4,
+    greater_or_equal = 5,
+};
+
+enum class pad_mode_t : uint8_t {
+    constant = 0,
+    reflect = 1,
+    symmetric = 2,
+    edge = 3,
+};
+
+enum class lstmdirection_t : int32_t {
+    forward = 0,
+    reverse = 1,
+    bidirectional = 2,
+};
+
+enum class lstmlayout_t : int32_t {
+    zero = 0,
+    one = 1,
+};
+
+enum class one_hot_mode_t : uint8_t {
+    normal = 0,
+    process_neg = 1,
+};
+
+enum class quant_mode_t : int32_t {
+    unsigned_mode = 0,
+    signed_symmetric_mode = 1,
+    signed_asymmetric_mode = 2,
+};
+
+enum class reduce_op_t : uint8_t {
+    mean = 0,
+    min = 1,
+    max = 2,
+    sum = 3,
+    prod = 4,
+};
+
+enum class reduce_arg_op_t : uint8_t {
+    arg_min = 0,
+    arg_max = 1,
+};
+
+enum class image_resize_mode_t : uint8_t {
+    bilinear = 0,
+    nearest_neighbor = 1,
+};
+
+enum class image_resize_transformation_mode_t : int32_t {
+    half_pixel = 0,
+    pytorch_half_pixel = 1,
+    align_corners = 2,
+    asymmetric = 3,
+    tfcrop_and_resize = 4,
+};
+
+enum class image_resize_nearest_mode_t : int32_t {
+    round_prefer_floor = 0,
+    round_prefer_ceil = 1,
+    floor = 2,
+    ceil = 3,
+};
+
+enum class unary_op_t : uint8_t {
+    abs = 0,
+    acos = 1,
+    acosh = 2,
+    asin = 3,
+    asinh = 4,
+    ceil = 5,
+    cos = 6,
+    cosh = 7,
+    exp = 8,
+    floor = 9,
+    log = 10,
+    neg = 11,
+    round = 12,
+    rsqrt = 13,
+    sin = 14,
+    sinh = 15,
+    sign = 16,
+    sqrt = 17,
+    square = 18,
+    tanh = 19,
+    bitwise_not = 20,
+    logical_not = 21,
+};
+
+// Instructions
+
+struct nop_op_t {};
+
+struct br_op_t {
+    int32_t target;
+};
+
+struct br_true_op_t {
+    int32_t target;
+};
+
+struct br_false_op_t {
+    int32_t target;
+};
+
+struct ret_op_t {};
+
+struct call_op_t {
+    uint16_t args;
+    int32_t target;
+};
+
+struct ecall_op_t {
+    uint16_t args;
+};
+
+struct extcall_op_t {
+    uint16_t args;
+    bool is_prim_func;
+};
+
+struct cuscall_op_t {
+    std::string registered_name;
+    gsl::span<const gsl::byte> fields_span;
+    uint16_t args;
+};
+
+struct throw_op_t {};
+
+struct break_op_t {};
+
+struct ldc_i4_op_t {
+    int32_t imm;
+};
+
+struct ldnull_op_t {};
+
+struct ldc_i4_0_op_t {};
+
+struct ldc_i4_1_op_t {};
+
+struct ldc_r4_op_t {
+    float imm;
+};
+
+struct ldind_i1_op_t {};
+
+struct ldind_i2_op_t {};
+
+struct ldind_i4_op_t {};
+
+struct ldind_i_op_t {};
+
+struct ldind_u1_op_t {};
+
+struct ldind_u2_op_t {};
+
+struct ldind_u4_op_t {};
+
+struct ldind_u_op_t {};
+
+struct ldind_br2_op_t {};
+
+struct ldind_r4_op_t {};
+
+struct stind_i1_op_t {};
+
+struct stind_i2_op_t {};
+
+struct stind_i4_op_t {};
+
+struct stind_i_op_t {};
+
+struct stind_br2_op_t {};
+
+struct stind_r4_op_t {};
+
+struct lea_gp_op_t {
+    uint8_t gpid;
+    int64_t offset;
+};
+
+struct ldelem_i1_op_t {};
+
+struct ldelem_i2_op_t {};
+
+struct ldelem_i4_op_t {};
+
+struct ldelem_i_op_t {};
+
+struct ldelem_u1_op_t {};
+
+struct ldelem_u2_op_t {};
+
+struct ldelem_u4_op_t {};
+
+struct ldelem_u_op_t {};
+
+struct ldelem_br2_op_t {};
+
+struct ldelem_r4_op_t {};
+
+struct stelem_i1_op_t {};
+
+struct stelem_i2_op_t {};
+
+struct stelem_i4_op_t {};
+
+struct stelem_i_op_t {};
+
+struct stelem_br2_op_t {};
+
+struct stelem_r4_op_t {};
+
+struct ldarg_op_t {
+    uint16_t index;
+};
+
+struct ldarg_0_op_t {};
+
+struct ldarg_1_op_t {};
+
+struct ldarg_2_op_t {};
+
+struct ldarg_3_op_t {};
+
+struct ldarg_4_op_t {};
+
+struct ldarg_5_op_t {};
+
+struct ldtuple_elem_op_t {};
+
+struct ldtuple_op_t {};
+
+struct lddatatype_op_t {};
+
+struct ldtensor_op_t {};
+
+struct ldlocal_op_t {
+    uint16_t index;
+};
+
+struct stlocal_op_t {
+    uint16_t index;
+};
+
+struct ldscalar_op_t {};
+
+struct dup_op_t {};
+
+struct pop_op_t {};
+
+struct neg_op_t {};
+
+struct add_op_t {};
+
+struct sub_op_t {};
+
+struct mul_op_t {};
+
+struct div_op_t {};
+
+struct div_u_op_t {};
+
+struct rem_op_t {};
+
+struct rem_u_op_t {};
+
+struct and_op_t {};
+
+struct or_op_t {};
+
+struct xor_op_t {};
+
+struct not_op_t {};
+
+struct shl_op_t {};
+
+struct shr_op_t {};
+
+struct shr_u_op_t {};
+
+struct clt_op_t {};
+
+struct clt_u_op_t {};
+
+struct cle_op_t {};
+
+struct cle_u_op_t {};
+
+struct ceq_op_t {};
+
+struct cge_op_t {};
+
+struct cge_u_op_t {};
+
+struct cgt_op_t {};
+
+struct cgt_u_op_t {};
+
+struct cne_op_t {};
+
+struct conv_i1_op_t {};
+
+struct conv_i2_op_t {};
+
+struct conv_i4_op_t {};
+
+struct conv_i_op_t {};
+
+struct conv_u1_op_t {};
+
+struct conv_u2_op_t {};
+
+struct conv_u4_op_t {};
+
+struct conv_u_op_t {};
+
+struct conv_br2_op_t {};
+
+struct conv_r4_op_t {};
+
+// Tensor instructions
+
+struct tensor_batch_normalization_op_t {};
+
+struct tensor_batch_to_space_op_t {};
+
+struct tensor_binary_op_t {
+    binary_op_t binary_op;
+};
+
+struct tensor_bitcast_op_t {
+    prim_type_t type;
+    prim_type_t new_type;
+};
+
+struct tensor_broadcast_op_t {};
+
+struct tensor_broadcast_shape_op_t {};
+
+struct tensor_bucket_pad_op_t {};
+
+struct tensor_cast_op_t {
+    typecode_t new_type;
+    cast_mode_t cast_mode;
+};
+
+struct tensor_celu_op_t {};
+
+struct tensor_clamp_op_t {};
+
+struct tensor_compare_op_t {
+    compare_op_t compare_op;
+};
+
+struct tensor_concat_op_t {
+    int32_t axis;
+};
+
+struct tensor_condition_op_t {
+    bool can_fold_const_call;
+};
+
+struct tensor_constant_of_shape_op_t {};
+
+struct tensor_conv2d_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_conv2d_shape_op_t {};
+
+struct tensor_conv2d_transpose_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_conv2d_transpose_shape_op_t {};
+
+struct tensor_cum_sum_op_t {};
+
+struct tensor_dequantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_elu_op_t {};
+
+struct tensor_erf_op_t {};
+
+struct tensor_expand_op_t {};
+
+struct tensor_fake_dequantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_fake_quantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_fix_shape_op_t {};
+
+struct tensor_flatten_op_t {};
+
+struct tensor_gather_op_t {
+    int32_t axis;
+};
+
+struct tensor_gather_elements_op_t {};
+
+struct tensor_gather_nd_op_t {};
+
+struct tensor_gelu_op_t {};
+
+struct tensor_get_item_op_t {};
+
+struct tensor_get_paddings_op_t {};
+
+struct tensor_hard_sigmoid_op_t {};
+
+struct tensor_hard_swish_op_t {};
+
+struct tensor_hardmax_op_t {};
+
+struct tensor_index_of_op_t {};
+
+struct tensor_instance_normalization_op_t {};
+
+struct tensor_l2_normalization_op_t {};
+
+struct tensor_layer_norm_op_t {
+    int32_t axis;
+    float epsilon;
+    bool use_mean;
+};
+
+struct tensor_leaky_relu_op_t {};
+
+struct tensor_log_softmax_op_t {};
+
+struct tensor_lp_normalization_op_t {};
+
+struct tensor_lrn_op_t {};
+
+struct tensor_lstm_op_t {
+    lstmdirection_t direction;
+    lstmlayout_t layout;
+    std::vector<std::string> activations;
+};
+
+struct tensor_mat_mul_op_t {};
+
+struct tensor_mat_mul_shape_op_t {};
+
+struct tensor_normal_op_t {
+    typecode_t type;
+};
+
+struct tensor_normal_like_op_t {
+    typecode_t type;
+};
+
+struct tensor_one_hot_op_t {
+    one_hot_mode_t one_hot_mode;
+};
+
+struct tensor_pad_op_t {
+    pad_mode_t pad_mode;
+};
+
+struct tensor_prelu_op_t {};
+
+struct tensor_prod_op_t {};
+
+struct tensor_quant_param_of_op_t {
+    quant_mode_t quant_mode;
+};
+
+struct tensor_quantize_op_t {
+    typecode_t target_type;
+};
+
+struct tensor_range_op_t {};
+
+struct tensor_range_of_op_t {
+    bool is_range_of_weight;
+};
+
+struct tensor_rank_op_t {};
+
+struct tensor_reduce_op_t {
+    reduce_op_t reduce_op;
+};
+
+struct tensor_reduce_arg_op_t {
+    reduce_arg_op_t reduce_arg_op;
+    typecode_t dest_type;
+};
+
+struct tensor_reduce_window2d_op_t {
+    reduce_op_t reduce_op;
+};
+
+struct tensor_relu_op_t {};
+
+struct tensor_relu6_op_t {};
+
+struct tensor_require_op_t {
+    std::string message;
+    bool can_fold_const_call;
+};
+
+struct tensor_reshape_op_t {};
+
+struct tensor_reshape_shape_op_t {};
+
+struct tensor_resize_image_op_t {
+    image_resize_mode_t resize_mode;
+    image_resize_transformation_mode_t transformation_mode;
+    image_resize_nearest_mode_t nearest_mode;
+    bool is_tfresize;
+};
+
+struct tensor_reverse_sequence_op_t {};
+
+struct tensor_scatter_nd_op_t {};
+
+struct tensor_select_op_t {};
+
+struct tensor_selu_op_t {};
+
+struct tensor_shape_of_op_t {};
+
+struct tensor_sigmoid_op_t {};
+
+struct tensor_size_of_op_t {};
+
+struct tensor_slice_op_t {};
+
+struct tensor_softmax_op_t {};
+
+struct tensor_softplus_op_t {};
+
+struct tensor_softsign_op_t {};
+
+struct tensor_space_to_batch_op_t {};
+
+struct tensor_split_op_t {};
+
+struct tensor_squeeze_op_t {};
+
+struct tensor_squeeze_shape_op_t {};
+
+struct tensor_stack_op_t {};
+
+struct tensor_swish_op_t {};
+
+struct tensor_tile_op_t {};
+
+struct tensor_top_k_op_t {};
+
+struct tensor_transpose_op_t {};
+
+struct tensor_transpose_shape_op_t {};
+
+struct tensor_trilu_op_t {};
+
+struct tensor_unary_op_t {
+    unary_op_t unary_op;
+};
+
+struct tensor_uniform_op_t {
+    typecode_t type;
+};
+
+struct tensor_uniform_like_op_t {
+    typecode_t type;
+};
+
+struct tensor_unsqueeze_op_t {};
+
+struct tensor_unsqueeze_shape_op_t {};
+
+struct tensor_where_op_t {
+    bool is_tf_where;
+};
+
+inline std::string to_string(tensor_function_t tensor_funct) {
+    switch (tensor_funct) {
+    case tensor_function_t::batch_normalization:
+        return "batch_normalization";
+    case tensor_function_t::batch_to_space:
+        return "batch_to_space";
+    case tensor_function_t::celu:
+        return "celu";
+    case tensor_function_t::conv2d:
+        return "conv2d";
+    case tensor_function_t::conv2d_transpose:
+        return "conv2d_transpose";
+    case tensor_function_t::elu:
+        return "elu";
+    case tensor_function_t::erf:
+        return "erf";
+    case tensor_function_t::gelu:
+        return "gelu";
+    case tensor_function_t::hardmax:
+        return "hardmax";
+    case tensor_function_t::hard_sigmoid:
+        return "hard_sigmoid";
+    case tensor_function_t::hard_swish:
+        return "hard_swish";
+    case tensor_function_t::instance_normalization:
+        return "instance_normalization";
+    case tensor_function_t::l2_normalization:
+        return "l2_normalization";
+    case tensor_function_t::layer_norm:
+        return "layer_norm";
+    case tensor_function_t::leaky_relu:
+        return "leaky_relu";
+    case tensor_function_t::log_softmax:
+        return "log_softmax";
+    case tensor_function_t::lp_normalization:
+        return "lp_normalization";
+    case tensor_function_t::lrn:
+        return "lrn";
+    case tensor_function_t::one_hot:
+        return "one_hot";
+    case tensor_function_t::pad:
+        return "pad";
+    case tensor_function_t::prelu:
+        return "prelu";
+    case tensor_function_t::reduce_window2d:
+        return "reduce_window2d";
+    case tensor_function_t::relu:
+        return "relu";
+    case tensor_function_t::relu6:
+        return "relu6";
+    case tensor_function_t::selu:
+        return "selu";
+    case tensor_function_t::sigmoid:
+        return "sigmoid";
+    case tensor_function_t::softmax:
+        return "softmax";
+    case tensor_function_t::softplus:
+        return "softplus";
+    case tensor_function_t::softsign:
+        return "softsign";
+    case tensor_function_t::space_to_batch:
+        return "space_to_batch";
+    case tensor_function_t::swish:
+        return "swish";
+    case tensor_function_t::binary:
+        return "binary";
+    case tensor_function_t::clamp:
+        return "clamp";
+    case tensor_function_t::compare:
+        return "compare";
+    case tensor_function_t::condition:
+        return "condition";
+    case tensor_function_t::cum_sum:
+        return "cum_sum";
+    case tensor_function_t::dequantize:
+        return "dequantize";
+    case tensor_function_t::fake_dequantize:
+        return "fake_dequantize";
+    case tensor_function_t::fake_quantize:
+        return "fake_quantize";
+    case tensor_function_t::mat_mul:
+        return "mat_mul";
+    case tensor_function_t::quantize:
+        return "quantize";
+    case tensor_function_t::quant_param_of:
+        return "quant_param_of";
+    case tensor_function_t::range_of:
+        return "range_of";
+    case tensor_function_t::reduce:
+        return "reduce";
+    case tensor_function_t::reduce_arg:
+        return "reduce_arg";
+    case tensor_function_t::require:
+        return "require";
+    case tensor_function_t::select:
+        return "select";
+    case tensor_function_t::unary:
+        return "unary";
+    case tensor_function_t::bitcast:
+        return "bitcast";
+    case tensor_function_t::broadcast:
+        return "broadcast";
+    case tensor_function_t::bucket_pad:
+        return "bucket_pad";
+    case tensor_function_t::cast:
+        return "cast";
+    case tensor_function_t::concat:
+        return "concat";
+    case tensor_function_t::constant_of_shape:
+        return "constant_of_shape";
+    case tensor_function_t::expand:
+        return "expand";
+    case tensor_function_t::fix_shape:
+        return "fix_shape";
+    case tensor_function_t::flatten:
+        return "flatten";
+    case tensor_function_t::gather:
+        return "gather";
+    case tensor_function_t::gather_elements:
+        return "gather_elements";
+    case tensor_function_t::gather_nd:
+        return "gather_nd";
+    case tensor_function_t::get_item:
+        return "get_item";
+    case tensor_function_t::index_of:
+        return "index_of";
+    case tensor_function_t::prod:
+        return "prod";
+    case tensor_function_t::range:
+        return "range";
+    case tensor_function_t::rank:
+        return "rank";
+    case tensor_function_t::reshape:
+        return "reshape";
+    case tensor_function_t::reverse_sequence:
+        return "reverse_sequence";
+    case tensor_function_t::scatter_nd:
+        return "scatter_nd";
+    case tensor_function_t::shape_of:
+        return "shape_of";
+    case tensor_function_t::size_of:
+        return "size_of";
+    case tensor_function_t::slice:
+        return "slice";
+    case tensor_function_t::split:
+        return "split";
+    case tensor_function_t::squeeze:
+        return "squeeze";
+    case tensor_function_t::stack:
+        return "stack";
+    case tensor_function_t::tile:
+        return "tile";
+    case tensor_function_t::top_k:
+        return "top_k";
+    case tensor_function_t::transpose:
+        return "transpose";
+    case tensor_function_t::trilu:
+        return "trilu";
+    case tensor_function_t::unsqueeze:
+        return "unsqueeze";
+    case tensor_function_t::where:
+        return "where";
+    case tensor_function_t::broadcast_shape:
+        return "broadcast_shape";
+    case tensor_function_t::conv2d_shape:
+        return "conv2d_shape";
+    case tensor_function_t::conv2d_transpose_shape:
+        return "conv2d_transpose_shape";
+    case tensor_function_t::get_paddings:
+        return "get_paddings";
+    case tensor_function_t::mat_mul_shape:
+        return "mat_mul_shape";
+    case tensor_function_t::reshape_shape:
+        return "reshape_shape";
+    case tensor_function_t::squeeze_shape:
+        return "squeeze_shape";
+    case tensor_function_t::transpose_shape:
+        return "transpose_shape";
+    case tensor_function_t::unsqueeze_shape:
+        return "unsqueeze_shape";
+    case tensor_function_t::lstm:
+        return "lstm";
+    case tensor_function_t::normal:
+        return "normal";
+    case tensor_function_t::normal_like:
+        return "normal_like";
+    case tensor_function_t::uniform:
+        return "uniform";
+    case tensor_function_t::uniform_like:
+        return "uniform_like";
+    case tensor_function_t::resize_image:
+        return "resize_image";
+    }
+    return "unknown tensor_function_t";
+}
+
+inline std::string to_string(opcode_t code) {
+    switch (code) {
+    case opcode_t::NOP:
+        return "NOP";
+    case opcode_t::LDNULL:
+        return "LDNULL";
+    case opcode_t::LDC_I4:
+        return "LDC_I4";
+    case opcode_t::LDC_I4_0:
+        return "LDC_I4_0";
+    case opcode_t::LDC_I4_1:
+        return "LDC_I4_1";
+    case opcode_t::LDC_R4:
+        return "LDC_R4";
+    case opcode_t::LDIND_I1:
+        return "LDIND_I1";
+    case opcode_t::LDIND_I2:
+        return "LDIND_I2";
+    case opcode_t::LDIND_I4:
+        return "LDIND_I4";
+    case opcode_t::LDIND_I:
+        return "LDIND_I";
+    case opcode_t::LDIND_U1:
+        return "LDIND_U1";
+    case opcode_t::LDIND_U2:
+        return "LDIND_U2";
+    case opcode_t::LDIND_U4:
+        return "LDIND_U4";
+    case opcode_t::LDIND_U:
+        return "LDIND_U";
+    case opcode_t::LDIND_BR2:
+        return "LDIND_BR2";
+    case opcode_t::LDIND_R4:
+        return "LDIND_R4";
+    case opcode_t::STIND_I1:
+        return "STIND_I1";
+    case opcode_t::STIND_I2:
+        return "STIND_I2";
+    case opcode_t::STIND_I4:
+        return "STIND_I4";
+    case opcode_t::STIND_I:
+        return "STIND_I";
+    case opcode_t::STIND_BR2:
+        return "STIND_BR2";
+    case opcode_t::STIND_R4:
+        return "STIND_R4";
+    case opcode_t::LEA_GP:
+        return "LEA_GP";
+    case opcode_t::LDELEM_I1:
+        return "LDELEM_I1";
+    case opcode_t::LDELEM_I2:
+        return "LDELEM_I2";
+    case opcode_t::LDELEM_I4:
+        return "LDELEM_I4";
+    case opcode_t::LDELEM_I:
+        return "LDELEM_I";
+    case opcode_t::LDELEM_U1:
+        return "LDELEM_U1";
+    case opcode_t::LDELEM_U2:
+        return "LDELEM_U2";
+    case opcode_t::LDELEM_U4:
+        return "LDELEM_U4";
+    case opcode_t::LDELEM_U:
+        return "LDELEM_U";
+    case opcode_t::LDELEM_BR2:
+        return "LDELEM_BR2";
+    case opcode_t::LDELEM_R4:
+        return "LDELEM_R4";
+    case opcode_t::STELEM_I1:
+        return "STELEM_I1";
+    case opcode_t::STELEM_I2:
+        return "STELEM_I2";
+    case opcode_t::STELEM_I4:
+        return "STELEM_I4";
+    case opcode_t::STELEM_I:
+        return "STELEM_I";
+    case opcode_t::STELEM_BR2:
+        return "STELEM_BR2";
+    case opcode_t::STELEM_R4:
+        return "STELEM_R4";
+    case opcode_t::LDARG:
+        return "LDARG";
+    case opcode_t::LDARG_0:
+        return "LDARG_0";
+    case opcode_t::LDARG_1:
+        return "LDARG_1";
+    case opcode_t::LDARG_2:
+        return "LDARG_2";
+    case opcode_t::LDARG_3:
+        return "LDARG_3";
+    case opcode_t::LDARG_4:
+        return "LDARG_4";
+    case opcode_t::LDARG_5:
+        return "LDARG_5";
+    case opcode_t::DUP:
+        return "DUP";
+    case opcode_t::POP:
+        return "POP";
+    case opcode_t::LDLOCAL:
+        return "LDLOCAL";
+    case opcode_t::STLOCAL:
+        return "STLOCAL";
+    case opcode_t::LDTUPLE_ELEM:
+        return "LDTUPLE_ELEM";
+    case opcode_t::LDTUPLE:
+        return "LDTUPLE";
+    case opcode_t::LDDATATYPE:
+        return "LDDATATYPE";
+    case opcode_t::LDTENSOR:
+        return "LDTENSOR";
+    case opcode_t::LDSCALAR:
+        return "LDSCALAR";
+    case opcode_t::NEG:
+        return "NEG";
+    case opcode_t::ADD:
+        return "ADD";
+    case opcode_t::SUB:
+        return "SUB";
+    case opcode_t::MUL:
+        return "MUL";
+    case opcode_t::DIV:
+        return "DIV";
+    case opcode_t::DIV_U:
+        return "DIV_U";
+    case opcode_t::REM:
+        return "REM";
+    case opcode_t::REM_U:
+        return "REM_U";
+    case opcode_t::AND:
+        return "AND";
+    case opcode_t::OR:
+        return "OR";
+    case opcode_t::XOR:
+        return "XOR";
+    case opcode_t::NOT:
+        return "NOT";
+    case opcode_t::SHL:
+        return "SHL";
+    case opcode_t::SHR:
+        return "SHR";
+    case opcode_t::SHR_U:
+        return "SHR_U";
+    case opcode_t::CLT:
+        return "CLT";
+    case opcode_t::CLT_U:
+        return "CLT_U";
+    case opcode_t::CLE:
+        return "CLE";
+    case opcode_t::CLE_U:
+        return "CLE_U";
+    case opcode_t::CEQ:
+        return "CEQ";
+    case opcode_t::CGE:
+        return "CGE";
+    case opcode_t::CGE_U:
+        return "CGE_U";
+    case opcode_t::CGT:
+        return "CGT";
+    case opcode_t::CGT_U:
+        return "CGT_U";
+    case opcode_t::CNE:
+        return "CNE";
+    case opcode_t::CONV_I1:
+        return "CONV_I1";
+    case opcode_t::CONV_I2:
+        return "CONV_I2";
+    case opcode_t::CONV_I4:
+        return "CONV_I4";
+    case opcode_t::CONV_I:
+        return "CONV_I";
+    case opcode_t::CONV_U1:
+        return "CONV_U1";
+    case opcode_t::CONV_U2:
+        return "CONV_U2";
+    case opcode_t::CONV_U4:
+        return "CONV_U4";
+    case opcode_t::CONV_U:
+        return "CONV_U";
+    case opcode_t::CONV_BR2:
+        return "CONV_BR2";
+    case opcode_t::CONV_R4:
+        return "CONV_R4";
+    case opcode_t::BR:
+        return "BR";
+    case opcode_t::BR_TRUE:
+        return "BR_TRUE";
+    case opcode_t::BR_FALSE:
+        return "BR_FALSE";
+    case opcode_t::RET:
+        return "RET";
+    case opcode_t::CALL:
+        return "CALL";
+    case opcode_t::ECALL:
+        return "ECALL";
+    case opcode_t::EXTCALL:
+        return "EXTCALL";
+    case opcode_t::CUSCALL:
+        return "CUSCALL";
+    case opcode_t::THROW:
+        return "THROW";
+    case opcode_t::BREAK:
+        return "BREAK";
+    case opcode_t::TENSOR:
+        return "TENSOR";
+    }
+    return "unknown opcode_t";
+}
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/stackvm/runtime_module.h b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/runtime_module.h
new file mode 100644
index 0000000..a714cdd
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/stackvm/runtime_module.h
@@ -0,0 +1,31 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../runtime_module.h"
+
+BEGIN_NS_NNCASE_RT_MODULE(stackvm)
+
+NNCASE_INLINE_VAR constexpr module_kind_t stackvm_module_kind =
+    to_module_kind("stackvm");
+NNCASE_INLINE_VAR constexpr uint32_t stackvm_module_version = 1;
+
+NNCASE_API result<std::unique_ptr<runtime_module>>
+create_stackvm_runtime_module();
+
+NNCASE_API result<
+    std::vector<std::pair<std::string, runtime_module::custom_call_type>>>
+create_stackvm_custom_calls();
+
+END_NS_NNCASE_RT_MODULE
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/stream_reader.h b/third_party/nncase/x86_64/include/nncase/runtime/stream_reader.h
new file mode 100644
index 0000000..59999ac
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/stream_reader.h
@@ -0,0 +1,75 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <cstring>
+#include <gsl/gsl-lite.hpp>
+#include <istream>
+#include <iterator>
+#include <nncase/compiler_defs.h>
+#include <nncase/runtime/dbg.h>
+#include <string>
+#include <vector>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+class stream_reader {
+  public:
+    stream_reader(std::istream &stream) : stream_(stream) {}
+
+    std::streampos tell() const noexcept { return stream_.tellg(); }
+    bool empty() const noexcept { return !stream_.eof(); }
+
+    void seek(std::streampos pos) noexcept { stream_.seekg(pos); }
+
+    template <class T> T read() {
+        T value;
+        read(value);
+        return value;
+    }
+
+    template <class T> T read_unaligned() { return read<T>(); }
+
+    template <class T> T peek() {
+        T value;
+        auto pos = tell();
+        read(value);
+        seek(pos);
+        return value;
+    }
+
+    template <class T> T peek_unaligned() { return peek<T>(); }
+
+    template <class T> void read(T &value) {
+        stream_.read(reinterpret_cast<char *>(&value), sizeof(value));
+    }
+
+    template <class T> void read_span(gsl::span<T> span) {
+        size_t sub_data_size = 8388608;
+        for (size_t pos = 0; pos < span.size_bytes();) {
+            if (pos + sub_data_size >= span.size_bytes())
+                sub_data_size = span.size_bytes() - pos;
+            stream_.read(reinterpret_cast<char *>(span.data()) + pos,
+                         sub_data_size);
+            pos += sub_data_size;
+        }
+    }
+
+    void skip(size_t count) { stream_.seekg(count, std::ios::cur); }
+
+  private:
+    std::istream &stream_;
+};
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/tensor_util.h b/third_party/nncase/x86_64/include/nncase/runtime/tensor_util.h
new file mode 100644
index 0000000..c39fcb3
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/tensor_util.h
@@ -0,0 +1,29 @@
+#pragma once
+#include <cmath>
+#include <iostream>
+#include <nncase/runtime/simple_types.h>
+#include <string>
+
+namespace nncase::runtime {
+inline float dot(const float *v1, const float *v2, size_t size) {
+    float ret = 0.f;
+    for (size_t i = 0; i < size; i++) {
+        ret += v1[i] * v2[i];
+    }
+
+    return ret;
+}
+
+inline float cosine(const float *v1, const float *v2, size_t size) {
+    return dot(v1, v2, size) /
+           ((sqrt(dot(v1, v1, size)) * sqrt(dot(v2, v2, size))));
+}
+
+inline void dump_shape(gsl::span<const size_t> shape) {
+    std::cout << "shape:";
+    for (size_t i = 0; i < shape.size(); i++) {
+        std::cout << shape[i] << " ";
+    }
+    std::cout << "\n";
+}
+} // namespace nncase::runtime
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/type_serializer.h b/third_party/nncase/x86_64/include/nncase/runtime/type_serializer.h
new file mode 100644
index 0000000..dab234b
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/type_serializer.h
@@ -0,0 +1,38 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/span_reader.h>
+#include <nncase/runtime/stream_reader.h>
+#include <nncase/type.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+typedef enum : uint8_t {
+    type_sig_invalid,
+    type_sig_any,
+    type_sig_tensor,
+    type_sig_tuple,
+    type_sig_callable,
+    type_sig_end = 0xFF
+} type_signature_token_t;
+
+result<type> deserialize_type(span_reader &sr) noexcept;
+result<datatype_t> deserialize_datatype(span_reader &sr) noexcept;
+
+result<type> deserialize_type(stream_reader &sr) noexcept;
+result<datatype_t> deserialize_datatype(stream_reader &sr) noexcept;
+
+END_NS_NNCASE_RUNTIME
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/typecodes.def b/third_party/nncase/x86_64/include/nncase/runtime/typecodes.def
new file mode 100644
index 0000000..1ddeb1e
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/typecodes.def
@@ -0,0 +1,16 @@
+DEFINE_TYPECODE(boolean,    bool,   0x00)
+DEFINE_TYPECODE(utf8char,   u8char, 0x01)
+DEFINE_TYPECODE(int8,       i8,     0x02)
+DEFINE_TYPECODE(int16,      i16,    0x03)
+DEFINE_TYPECODE(int32,      i32,    0x04)
+DEFINE_TYPECODE(int64,      i64,    0x05)
+DEFINE_TYPECODE(uint8,      u8,     0x06)
+DEFINE_TYPECODE(uint16,     u16,    0x07)
+DEFINE_TYPECODE(uint32,     u32,    0x08)
+DEFINE_TYPECODE(uint64,     u64,    0x09)
+DEFINE_TYPECODE(float16,    f16,    0x0A)
+DEFINE_TYPECODE(float32,    f32,    0x0B)
+DEFINE_TYPECODE(float64,    f64,    0x0C)
+DEFINE_TYPECODE(bfloat16,   bf16,   0x0D)
+DEFINE_TYPECODE(pointer,    *,      0xF0)
+DEFINE_TYPECODE(valuetype,  val,    0xF1)
diff --git a/third_party/nncase/x86_64/include/nncase/runtime/util.h b/third_party/nncase/x86_64/include/nncase/runtime/util.h
new file mode 100644
index 0000000..9f56876
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/runtime/util.h
@@ -0,0 +1,596 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "../tensor.h"
+#include "allocator.h"
+#include "buffer.h"
+#include "error.h"
+#include "host_buffer.h"
+#include "runtime_tensor.h"
+#include "simple_types.h"
+#include <nncase/api.h>
+#include <nncase/runtime/runtime_op_utility.h>
+
+BEGIN_NS_NNCASE_RUNTIME
+
+// cast macro
+#define IN_CAST(_ty, _name) reinterpret_cast<const _ty *>(_name)
+#define OUT_CAST(_ty, _name) reinterpret_cast<_ty *>(_name)
+#define SCALAR_CAST(_ty, _name) *reinterpret_cast<const _ty *>(_name)
+#define IN_BYTE_CAST(_var) IN_CAST(gsl::byte, _var)
+#define OUT_BYTE_CAST(_var) OUT_CAST(gsl::byte, _var)
+
+// compare type
+// for typecode, datatype_t, tensor(tensor->dtype())
+inline result<bool> cmp_dt_impl(datatype_t lhs, datatype_t rhs) {
+    try_var(l, to_typecode(lhs));
+    try_var(r, to_typecode(rhs));
+    return ok(l == r);
+}
+
+inline bool cmp_dt(tensor lhs, tensor rhs) {
+    auto result = cmp_dt_impl(lhs->dtype(), rhs->dtype());
+    return result.is_ok() && result.unwrap();
+}
+
+inline bool cmp_dt(datatype_t lhs, datatype_t rhs) {
+    auto result = cmp_dt_impl(lhs, rhs);
+    return result.is_ok() && result.unwrap();
+}
+
+template <typename T> inline bool cmp_type(datatype_t dt) {
+    return cmp_dt(datatype_t::from_type<T>(), dt);
+}
+
+template <typename T> inline result<bool> type_only_check(tensor input) {
+    return cmp_dt_impl(input->dtype(), datatype_t::from_type<T>());
+}
+
+inline result<bool> float_only_check(tensor input) {
+    return cmp_dt_impl(input->dtype(), datatype_t::float32);
+}
+
+// tuple helper
+template <typename F>
+inline result<void> tuple_for_each_with_i(tuple inputs, F &&f) {
+    for (size_t i = 0; i < inputs->fields().size(); ++i) {
+        try_(f(inputs->fields()[i], i));
+    }
+    return ok();
+}
+
+// todo:not process nest tuple
+template <typename T, bool IsResult, typename F>
+inline result<std::vector<T>> get_from_tuple_with_result(tuple inputs, F &&f) {
+    std::vector<T> data(inputs->fields().size());
+    for (size_t i = 0; i < inputs->fields().size(); ++i) {
+        try_var(input, inputs->fields()[i].as<tensor>());
+        if constexpr (IsResult) {
+            try_var(in, f(input));
+            data[i] = in;
+        } else {
+            data[i] = f(input);
+        }
+    }
+    return ok(data);
+}
+
+template <typename T, typename F>
+inline result<std::vector<T>> get_from_tuple(tuple inputs, F &&f) {
+    return get_from_tuple_with_result<T, false>(inputs, f);
+}
+
+inline result<std::vector<dims_t>> get_shapes(tuple inputs) {
+    return get_from_tuple<dims_t>(inputs,
+                                  [](auto &input) { return input->shape(); });
+}
+
+inline result<std::vector<dims_t>> get_strides(tuple inputs) {
+    return get_from_tuple<dims_t>(inputs,
+                                  [](auto &input) { return input->strides(); });
+}
+
+// get input and output
+inline result<void> alloc_output(value_t &output, datatype_t dtype,
+                                 gsl::span<const size_t> out_shape) {
+    // TODO: copy back output
+    if (output.empty()) {
+        try_var(typecode, to_typecode(dtype));
+        try_var(out_tensor, hrt::create(typecode, dims_t(out_shape)));
+        output = out_tensor.impl();
+    } else {
+        try_var(
+            out_tensor,
+            output.as<tensor>()) if (out_tensor->shape() !=
+                                     out_shape) return err(nncase_errc::
+                                                               shape_mismatch);
+    }
+    return ok();
+}
+
+inline result<void> check_tuple_shape(value_t &outputs,
+                                      const std::vector<dims_t> &out_shapes) {
+    try_var(output_tuple, outputs.as<tuple>());
+    try_(tuple_for_each_with_i(
+        output_tuple, [&](auto &output, auto i) -> result<void> {
+            try_var(out_tensor, output.template as<tensor>());
+            if (out_tensor->shape() != gsl::span(out_shapes[i])) {
+                return err(nncase_errc::shape_mismatch);
+            } else {
+                return ok();
+            }
+        }));
+    return ok();
+}
+
+inline result<void> alloc_tuple_output(value_t &outputs,
+                                       const std::vector<datatype_t> dtypes,
+                                       const std::vector<dims_t> &out_shapes) {
+    if (outputs.empty()) {
+        auto size = out_shapes.size();
+        std::vector<value_t> fields(size);
+        for (size_t i = 0; i < size; ++i) {
+            auto output = value_t();
+            try_(alloc_output(output, dtypes[i], out_shapes[i]));
+            fields[i] = output;
+        }
+        outputs = tuple(std::in_place, std::move(fields));
+    } else {
+        try_(check_tuple_shape(outputs, out_shapes));
+    }
+    return ok();
+}
+
+inline result<void> alloc_output(value_t &outputs, datatype_t dtype,
+                                 const std::vector<dims_t> &out_shapes) {
+    if (outputs.empty()) {
+        auto size = out_shapes.size();
+        std::vector<value_t> fields(size);
+        for (size_t i = 0; i < size; ++i) {
+            auto output = value_t();
+            try_(alloc_output(output, dtype, out_shapes[i]));
+            fields[i] = output;
+        }
+        outputs = tuple(std::in_place, std::move(fields));
+    } else {
+        try_(check_tuple_shape(outputs, out_shapes));
+    }
+    return ok();
+}
+
+inline result<host_buffer_slice> get_host_buffer(tensor tensor) {
+    try_var(tensor_host, tensor->to_host());
+    try_var(tensor_buffer, tensor_host->buffer().as_host());
+    return ok(tensor_buffer);
+}
+
+inline result<gsl::span<gsl::byte>> get_output_span(tensor output) {
+    try_var(output_buffer, get_host_buffer(output));
+    try_var(output_map, output_buffer.map(map_write));
+    return ok(output_map.buffer());
+}
+
+inline result<gsl::byte *> get_output_data(tensor output) {
+    try_var(output_buffer, get_output_span(output));
+    return ok(output_buffer.data());
+}
+
+inline result<std::vector<gsl::byte *>> get_output_data(tuple outputs) {
+    return get_from_tuple_with_result<gsl::byte *, true>(
+        outputs, [](tensor &input) { return get_output_data(input); });
+}
+
+inline result<gsl::span<gsl::byte>> get_input_span(tensor input) {
+    try_var(input_buffer, get_host_buffer(input));
+    try_var(input_map, input_buffer.map(map_read));
+    return ok(input_map.buffer());
+}
+
+inline result<gsl::byte *> get_input_data(tensor input) {
+    try_var(input_buffer, get_input_span(input));
+    return ok(input_buffer.data());
+}
+
+inline result<std::vector<gsl::byte *>> get_input_data(tuple inputs) {
+    return get_from_tuple_with_result<gsl::byte *, true>(
+        inputs, [](tensor &input) { return get_input_data(input); });
+}
+
+inline result<std::vector<gsl::byte *>> get_readonly_span(tuple inputs) {
+    return get_input_data(inputs);
+}
+
+inline result<gsl::byte *> get_readonly_span(tensor input) {
+    return get_input_data(input);
+}
+
+// some macro about get value for tensor_ops.cpp
+// implicit define tensor/tuple for try_input[xxx] and try_output[xxx]
+// e.g. try_input(in_mem, input) ->
+// 1. in_mem: const gsl::byte*
+// 2. input_tensor: tensor
+#define try_alloc_output(_out_tensor, _dt, _shape, _is_tuple)                  \
+    try_(alloc_output(_out_tensor, _dt, _shape));
+
+#define try_input_impl(_var_name, _value_name, _value_kind)                    \
+    try_var(_value_name##_##_value_kind, _value_name.as<_value_kind>());       \
+    try_var(_var_name, get_input_data(_value_name##_##_value_kind))
+
+#define try_input(_var_name, _value_name)                                      \
+    try_input_impl(_var_name, _value_name, tensor)
+#define try_tuple_input(_var_name, _value_name)                                \
+    try_input_impl(_var_name, _value_name, tuple)
+
+#define try_input_with_value_type(_var_name, _value_name, _ty)                 \
+    try_input(__##_var_name, _value_name);                                     \
+    auto *_var_name = IN_CAST(_ty, __##_var_name);
+
+#define try_tuple_field0(_input0_name, _tuple_name)                            \
+    try_var(_input0_name, _tuple_name->fields()[0].as<tensor>());
+
+#define try_input_with_ty(_var_name, _value_name, _ty)                         \
+    try_input(__##_var_name, _value_name);                                     \
+    try_(type_only_check<_ty>(_value_name##_tensor));                          \
+    auto _var_name = reinterpret_cast<const _ty *>(__##_var_name)
+
+#define try_integer_input(_var_name, _value_name)                              \
+    try_input_with_ty(_var_name, _value_name, int64_t)
+
+#define try_f32_input(_var_name, _value_name)                                  \
+    try_input_with_ty(_var_name, _value_name, float)
+#define try_f32_output(_var_name, _value_name, _out_shape)                     \
+    try_output(__##_var_name, _value_name, dt_float32, _out_shape);            \
+    auto _var_name = reinterpret_cast<float *>(__##_var_name)
+
+// todo:when _value_kind is tuple, _value_name_tensor is a bad name
+#define try_output_impl(_var_name, _value_name, _dt, _out_shape, _value_kind,  \
+                        _is_tuple)                                             \
+    try_alloc_output(_value_name, _dt, _out_shape, _is_tuple);                 \
+    try_var(_value_name##_##_value_kind, _value_name.as<_value_kind>());       \
+    try_var(_var_name, get_output_data(_value_name##_##_value_kind))
+
+#define try_output(_var_name, _value_name, _dt, _out_shape)                    \
+    try_output_impl(_var_name, _value_name, _dt, _out_shape, tensor, false)
+
+#define try_output_like_input(_var_name, _value_name, _tensor)                 \
+    try_output(_var_name, _value_name, (_tensor)->dtype(), (_tensor)->shape())
+
+#define try_tuple_output(_var_name, _value_name, _dt, _out_shapes)             \
+    try_output_impl(_var_name, _value_name, _dt, _out_shapes, tuple, true)
+
+#define try_value_as(_var_name, _value_name, f_name)                           \
+    try_var(_var_name, value_as_##f_name(_value_name))
+#define try_strides(_var_name, _value_name)                                    \
+    try_value_as(_var_name, _value_name, strides)
+#define try_dims(_var_name, _value_name)                                       \
+    try_value_as(_var_name, _value_name, dims)
+#define try_positive_axes(_var_name, _value_name, _rank)                       \
+    try_var(_var_name, value_as_positive_axes(_value_name, _rank))
+
+#define try_axes(_var_name, _value_name)                                       \
+    try_var(_var_name, value_as_axes(_value_name))
+#define try_paddings(_var_name, _value_name)                                   \
+    try_value_as(_var_name, _value_name, paddings)
+#define try_value_as_t(_var_name, _value_name, _ty, f_name)                    \
+    try_var(_var_name, value_as_##f_name<_ty>(_value_name))
+#define try_to_scalar(_var_name, _value_name, _ty)                             \
+    try_var(_var_name, value_to_scalar<_ty>(_value_name))
+
+#define try_float_scalar(_var_name, _value_name)                               \
+    try_to_scalar(_var_name, _value_name, float)
+
+#define try_to_integer(_var_name, _value_name)                                 \
+    try_to_scalar(_var_name, _value_name, int64_t)
+
+#define try_positive_axis_with_rank(_var_name, _value_name, _rank)             \
+    try_to_scalar(__##_var_name, _value_name, int64_t);                        \
+    auto _var_name = positive_index(__##_var_name, _rank)
+
+#define try_positive_axis(_var_name, _value_name, _input_tensor)               \
+    try_positive_axis_with_rank(_var_name, _value_name,                        \
+                                _input_tensor->shape().size())
+
+#define try_typecode(_var_name, _tensor_name)                                  \
+    try_var(_var_name, to_typecode(_tensor_name->dtype()))
+
+#define try_ref(op, ...) try_(reference::op(__VA_ARGS__))
+
+// implicit set var name
+#define try_out_mem(_value_name, _dt, _out_shape)                              \
+    try_output(_value_name##_mem, _value_name, _dt, _out_shape)
+#define try_f32_out_mem(_value_name, _out_shape)                               \
+    try_f32_output(_value_name##_mem, _value_name, _out_shape)
+
+#define try_in_mem(_value_name) try_input(_value_name##_mem, _value_name)
+#define try_f32_in_mem(_value_name)                                            \
+    try_f32_input(_value_name##_mem, _value_name)
+
+#define try_float_scalar_v(_value_name) try_to_scalar_v(_value_name, float)
+
+#define try_to_scalar_v(_value_name, _ty)                                      \
+    try_to_scalar(_value_name##_value, _value_name, _ty)
+
+#define try_integer_v(_value_name)                                             \
+    try_to_integer(_value_name##_value, _value_name)
+
+#define try_dims_v(_value_name) try_dims(_value_name##_value, _value_name)
+
+// other cast macro
+#define to_tensor(_tensor_name, _value)                                        \
+    try_var(_tensor_name, _value.as<tensor>());
+
+#define to_tensor_t(_value) to_tensor(_value##_tensor, _value)
+
+#define KERNEL_FINISH return ok(output)
+#define TUPLE_FINISH return ok(output_tuple)
+
+// get data from value
+template <typename TI, typename TO>
+itlib::small_vector<TO, 8> to_vec(const gsl::byte *input, size_t size) {
+    auto in_ptr = reinterpret_cast<const TI *>(input);
+    auto vec = itlib::small_vector<TO, 8>(size);
+    for (size_t i = 0; i < size; ++i) {
+        vec[i] = (TO)in_ptr[i];
+    }
+    return vec;
+}
+
+#define RETURN_RESULT_SELECT(RETURN_RESULT_IMPL)                               \
+    RETURN_RESULT_IMPL(bool);                                                  \
+    RETURN_RESULT_IMPL(int8_t);                                                \
+    RETURN_RESULT_IMPL(uint8_t);                                               \
+    RETURN_RESULT_IMPL(int32_t);                                               \
+    RETURN_RESULT_IMPL(uint32_t);                                              \
+    RETURN_RESULT_IMPL(int64_t);                                               \
+    RETURN_RESULT_IMPL(uint64_t);                                              \
+    RETURN_RESULT_IMPL(float);                                                 \
+    RETURN_RESULT_IMPL(double);
+
+template <typename T>
+inline result<T> value_to_scalar([[maybe_unused]] value_t value) {
+    try_input(input, value);
+    // todo: maybe this is a bad way?
+#define RETURN_RESULT(_in_type)                                                \
+    if (cmp_type<_in_type>(value_tensor->dtype())) {                           \
+        return ok((T)(*reinterpret_cast<const _in_type *>(input)));            \
+    }
+    RETURN_RESULT_SELECT(RETURN_RESULT);
+    return err(nncase_errc::datatype_mismatch);
+#undef RETURN_RESULT
+}
+
+template <typename T>
+inline result<itlib::small_vector<T, 8>> value_as_Ts(value_t value) {
+    try_input(input, value);
+    assert(value_tensor->shape().size() <= 1);
+    auto size =
+        value_tensor->shape().size() == 0 ? 1 : value_tensor->shape()[0];
+#define RETURN_RESULT(_in_type)                                                \
+    if (cmp_type<_in_type>(value_tensor->dtype())) {                           \
+        return ok(to_vec<_in_type, T>(input, size));                           \
+    }
+
+    static_assert(std::is_same_v<T, int32_t> || std::is_same_v<T, uint32_t> ||
+                      std::is_same_v<T, int64_t> ||
+                      std::is_same_v<T, int64_t> || std::is_same_v<T, size_t>,
+                  "not suppported type");
+    RETURN_RESULT(int32_t);
+    RETURN_RESULT(uint32_t);
+    RETURN_RESULT(int64_t);
+    RETURN_RESULT(uint64_t);
+#undef RETURN_RESULT
+    return err(nncase_errc::datatype_mismatch);
+}
+
+inline result<dims_t> value_as_dims(value_t value) {
+    return value_as_Ts<dims_t::value_type>(value);
+}
+
+inline result<axes_t> value_as_axes(value_t value) {
+    return value_as_Ts<axes_t::value_type>(value);
+}
+
+inline size_t positive_index(int index, size_t rank) {
+    return index < 0 ? index + rank : index;
+}
+
+// todo:refactor, same as axes but should positive
+inline result<dims_t> value_as_positive_axes(value_t value, size_t rank) {
+    try_input(input, value);
+    assert(value_tensor->shape().size() == 1);
+    auto size = value_tensor->shape()[0];
+    auto axis = dims_t(size);
+    for (size_t i = 0; i < size; ++i) {
+        if (cmp_type<int32_t>(value_tensor->dtype())) {
+            axis[i] = (dims_t::value_type)positive_index(
+                IN_CAST(int32_t, input)[i], rank);
+        } else if (cmp_type<int64_t>(value_tensor->dtype())) {
+            axis[i] = (dims_t::value_type)positive_index(
+                IN_CAST(int64_t, input)[i], rank);
+        } else {
+            return err(nncase_errc::datatype_mismatch);
+        }
+    }
+    return ok(axis);
+}
+
+inline result<strides_t> value_as_strides(value_t value) {
+    return value_as_Ts<strides_t::value_type>(value);
+}
+
+inline size_t compute_size(tensor t) {
+    return compute_size(t->shape(), t->strides());
+}
+
+inline result<paddings_t> value_as_paddings([[maybe_unused]] value_t value) {
+    try_input(input, value);
+    auto size = compute_size(value_tensor);
+    auto dims = size / 2;
+    auto pads = paddings_t(dims);
+    auto dt = value_tensor->dtype();
+    for (size_t i = 0; i < dims; ++i) {
+        if (cmp_type<int32_t>(dt)) {
+            pads[i].before = *(IN_CAST(int32_t, input) + 2 * i);
+            pads[i].after = *(IN_CAST(int32_t, input) + 2 * i + 1);
+            pads[i].interior = 0;
+        } else if (cmp_type<int64_t>(dt)) {
+            pads[i].before = *(IN_CAST(int64_t, input) + 2 * i);
+            pads[i].after = *(IN_CAST(int64_t, input) + 2 * i + 1);
+            pads[i].interior = 0;
+        } else {
+            return err(nncase_errc::datatype_mismatch);
+        }
+    }
+    return ok(pads);
+}
+
+// kernel util
+inline bool is_contiguous(tensor tensor) {
+    return is_contiguous(tensor->shape(), tensor->strides());
+}
+
+#define not_impl_no_contiguous(tensor)                                         \
+    if (!is_contiguous(tensor)) {                                              \
+        return err(nncase_errc::shape_mismatch);                               \
+    }
+
+#define TYPE_SELECT(_typecode, _impl)                                          \
+    switch (_typecode) {                                                       \
+    case dt_float32:                                                           \
+        _impl(float);                                                          \
+    case dt_float16:                                                           \
+        _impl(half);                                                           \
+    case dt_bfloat16:                                                          \
+        _impl(bfloat16);                                                       \
+    case dt_int8:                                                              \
+        _impl(int8_t);                                                         \
+    case dt_int16:                                                             \
+        _impl(int16_t);                                                        \
+    case dt_int32:                                                             \
+        _impl(int32_t);                                                        \
+    case dt_int64:                                                             \
+        _impl(int64_t);                                                        \
+    case dt_uint8:                                                             \
+        _impl(uint8_t);                                                        \
+    case dt_uint16:                                                            \
+        _impl(uint16_t);                                                       \
+    case dt_uint32:                                                            \
+        _impl(uint32_t);                                                       \
+    case dt_uint64:                                                            \
+        _impl(uint64_t);                                                       \
+    case dt_float64:                                                           \
+        _impl(double);                                                         \
+    case dt_boolean:                                                           \
+        _impl(bool);                                                           \
+    default:                                                                   \
+        return err(std::errc::not_supported);                                  \
+    }
+
+// kernel dispatch for single input
+#define CONTIGUOUS_KERNEL(_op, _in_tensor, ...)                                \
+    if (is_contiguous(_in_tensor)) {                                           \
+        try_(optimized::_op(__VA_ARGS__))                                      \
+    } else {                                                                   \
+        try_(reference::_op(__VA_ARGS__))                                      \
+    }
+
+// used for op only do reshape
+inline tensor tensor_reshape(tensor in_tensor,
+                             gsl::span<const size_t> new_shape) {
+    auto strides = get_default_strides(new_shape);
+    return tensor(std::in_place, in_tensor->dtype(), new_shape, strides,
+                  in_tensor->buffer());
+}
+
+inline bool is_scalar(tensor t) noexcept { return t->shape().empty(); }
+inline bool is_scalar(gsl::span<const size_t> t) noexcept { return t.empty(); }
+
+template <typename F>
+inline result<void> integer_cast(datatype_t type, const gsl::byte *input,
+                                 F &&f) {
+    if (cmp_type<int32_t>(type)) {
+        try_(f(IN_CAST(int32_t, input)));
+    } else if (cmp_type<int64_t>(type)) {
+        try_(f(IN_CAST(int64_t, input)));
+    } else {
+        return err(nncase_errc::datatype_mismatch);
+    }
+    return ok();
+}
+
+// used for slice args
+inline std::tuple<axes_t, axes_t, axes_t>
+slice_fill(gsl::span<const size_t> in_shape, axes_t &begins_value,
+           axes_t &ends_value, axes_t &strides_value, axes_t axes_value) {
+    auto ndim = in_shape.size();
+    axes_t begin_values(ndim, 0);
+    axes_t end_values(in_shape.begin(), in_shape.end());
+    axes_t strides_values(ndim, 1);
+    for (size_t i = 0; i < ndim; ++i) {
+        const auto it = std::find_if(axes_value.begin(), axes_value.end(),
+                                     [i, ndim](const auto axis) {
+                                         return positive_index(axis, ndim) == i;
+                                     });
+        if (it != axes_value.end()) {
+            auto idx = std::distance(axes_value.begin(), it);
+            auto max = static_cast<int>(in_shape[i]);
+            auto min = (-1) * max - 1;
+
+            // check starts
+            begin_values[i] = begins_value[idx] < min   ? min
+                              : begins_value[idx] > max ? max
+                                                        : begins_value[idx];
+
+            // check stops
+            end_values[i] = ends_value[idx] < min   ? min
+                            : ends_value[idx] > max ? max
+                                                    : ends_value[idx];
+
+            // check steps
+            if (!strides_value.empty()) {
+                assert(strides_value[idx] != 0);
+                strides_values[i] = strides_value[idx];
+            }
+
+            // fixup begin_values
+            if ((strides_values[i] > 0 && end_values[i] > begin_values[i]) ||
+                (strides_values[i] < 0 && end_values[i] < begin_values[i])) {
+                begin_values[i] =
+                    begin_values[i] == min ? min + 1 : begin_values[i];
+                begin_values[i] =
+                    begin_values[i] == max ? max - 1 : begin_values[i];
+            }
+            if (begin_values[i] < 0)
+                begin_values[i] += max;
+            if (end_values[i] < 0)
+                end_values[i] += max;
+        }
+    }
+    return std::tuple(begin_values, end_values, strides_values);
+}
+
+inline dims_t to_4d(dims_t in_a_shape) {
+    auto size = 4 - in_a_shape.size();
+    for (size_t i = 0; i < size; ++i) {
+        in_a_shape.insert(in_a_shape.begin(), 1);
+    }
+    return in_a_shape;
+}
+
+inline void shrink_memory_pool() {
+    buffer_allocator::host().shrink_memory_pool();
+}
+
+END_NS_NNCASE_RUNTIME
\ No newline at end of file
diff --git a/third_party/nncase/x86_64/include/nncase/shape.h b/third_party/nncase/x86_64/include/nncase/shape.h
new file mode 100644
index 0000000..f835a0a
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/shape.h
@@ -0,0 +1,168 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "compiler_defs.h"
+#include <algorithm>
+#include <nncase/runtime/result.h>
+#include <nncase/runtime/simple_types.h>
+#include <nncase/runtime/small_vector.hpp>
+#include <optional>
+
+namespace nncase {
+struct unknown_dim_t {};
+
+inline constexpr unknown_dim_t unknown_dim;
+
+enum dim_kind_t { dim_unknown = 0, dim_fixed = 1 };
+
+using dim_value_t = int64_t;
+
+/** @brief Dimension */
+struct dim_t {
+    /** @brief Initialize an unknown dim */
+    constexpr dim_t(unknown_dim_t = unknown_dim) noexcept
+        : kind(dim_unknown), value(0) {}
+
+    /** @brief Initialize an fixed dim */
+    constexpr dim_t(dim_value_t value) noexcept
+        : kind(dim_fixed), value(value) {}
+
+    /** @brief Is this a fixed dim */
+    bool is_fixed() const noexcept { return kind == dim_fixed; }
+    /** @brief Is this an unknown dim */
+    bool is_unknown() const noexcept { return kind == dim_unknown; }
+
+    dim_value_t fixed_value() const {
+        assert(is_fixed());
+        return value;
+    }
+
+    dim_kind_t kind;
+    dim_value_t value;
+};
+
+struct scalar_shape_t {};
+
+inline constexpr scalar_shape_t scalar_shape;
+
+struct unranked_shape_t {};
+
+inline constexpr unranked_shape_t unranked_shape;
+
+struct invalid_shape_t {};
+
+inline constexpr invalid_shape_t invalid_shape;
+
+/** @brief Shape type */
+class NNCASE_API shape_t {
+    enum shape_kind_t {
+        shape_kind_fixed,
+        shape_kind_has_unknown_dim,
+        shape_kind_unranked,
+        shape_kind_invalid
+    };
+
+  public:
+    using value_type = dim_t;
+
+    /** @brief Initialize a scalar shape */
+    shape_t(scalar_shape_t) noexcept : kind_(shape_kind_fixed) {}
+
+    /** @brief Initialize an unranked shape */
+    shape_t(unranked_shape_t) noexcept : kind_(shape_kind_unranked) {}
+
+    /** @brief Initialize an invalid shape */
+    shape_t(invalid_shape_t) noexcept : kind_(shape_kind_invalid) {}
+
+    /** @brief Initialize a ranked shape */
+    template <class R>
+    shape_t(R dims) : kind_(kind_of(dims)), dims_(dims.begin(), dims.end()) {}
+
+    /** @brief Initialize a fixed shape */
+    shape_t(std::initializer_list<dim_value_t> dims) : kind_(shape_kind_fixed) {
+        dims_.reserve(dims.size());
+        std::transform(dims.begin(), dims.end(), std::back_inserter(dims_),
+                       [](dim_value_t dim) -> dim_t { return dim; });
+    }
+
+    /** @brief Get kind */
+    shape_kind_t kind() const noexcept { return kind_; }
+
+    /** @brief Is this a fixed shape */
+    bool is_fixed() const noexcept { return kind() == shape_kind_fixed; }
+    /** @brief Is this a scalar */
+    bool is_scalar() const noexcept {
+        return kind() == shape_kind_fixed && dims_.empty();
+    }
+    /** @brief Is this an ranked shape */
+    bool is_ranked() const noexcept { return is_fixed() || has_unknown_dim(); }
+    /** @brief Is this an unranked shape */
+    bool is_unranked() const noexcept { return kind() == shape_kind_unranked; }
+    /** @brief Has at least one unknown dimension */
+    bool has_unknown_dim() const noexcept {
+        return kind() == shape_kind_has_unknown_dim;
+    }
+    /** @brief Is this an invalid shape */
+    bool is_invalid() const noexcept { return kind() == shape_kind_invalid; }
+
+    /** @brief Get dimensions */
+    gsl::span<const dim_t> dims() const noexcept { return dims_; }
+
+    /** @brief Get rank */
+    std::optional<size_t> rank() const noexcept {
+        return is_ranked() ? std::make_optional(dims_.size()) : std::nullopt;
+    }
+
+    auto begin() const noexcept { return dims_.cbegin(); }
+    auto end() const noexcept { return dims_.cend(); }
+
+    const dim_t &front() const { return dims_.front(); }
+    const dim_t &back() const { return dims_.back(); }
+
+    /** @brief Get dimension */
+    const dim_t &dim(size_t index) const { return dims_.at(index); }
+    const dim_t &operator[](size_t index) const { return dim(index); }
+
+    /** @brief Set dimension */
+    void dim(size_t index, dim_t value);
+
+    /** @brief Place a new dim at back */
+    void push_back(dim_t value);
+    const dim_t &emplace_back(dim_t value);
+    /** @brief Place a new dim */
+    const dim_t *emplace(const dim_t *position, dim_t value);
+
+    /** @brief Remove the dim at back */
+    void pop_back();
+
+    /** @brief As fixed dims */
+    result<dims_t> as_fixed() const noexcept;
+
+  private:
+    template <class R> static shape_kind_t kind_of(R &&range) noexcept {
+        return std::any_of(range.begin(), range.end(),
+                           [](const dim_t &dim) { return dim.is_unknown(); })
+                   ? shape_kind_has_unknown_dim
+                   : shape_kind_fixed;
+    }
+
+    void update_kind(shape_kind_t before_kind,
+                     dim_kind_t new_dim_kind) noexcept;
+
+  private:
+    shape_kind_t kind_;
+    itlib::small_vector<dim_t, 8> dims_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/tensor.h b/third_party/nncase/x86_64/include/nncase/tensor.h
new file mode 100644
index 0000000..6ecc44b
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/tensor.h
@@ -0,0 +1,64 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object.h"
+#include "shape.h"
+#include "value.h"
+#include <nncase/runtime/buffer.h>
+#include <nncase/runtime/datatypes.h>
+
+namespace nncase {
+class tensor_node;
+using tensor = object_t<tensor_node>;
+
+class NNCASE_API tensor_node : public value_node {
+    DEFINE_OBJECT_KIND(value_node, object_tensor);
+
+  public:
+    tensor_node(datatype_t dtype, dims_t shape, strides_t strides,
+                runtime::buffer_slice buffer);
+
+    /** @brief Gets element type. */
+    const datatype_t &dtype() const noexcept { return dtype_; }
+
+    /** @brief Gets shape. */
+    gsl::span<const size_t> shape() const noexcept { return shape_; }
+
+    /** @brief Gets strides. */
+    gsl::span<const size_t> strides() const noexcept { return strides_; }
+
+    /** @brief Gets length. */
+    size_t length() const noexcept { return length_; }
+
+    /** @brief Gets buffer. */
+    const runtime::buffer_slice &buffer() const noexcept { return buffer_; }
+
+    /** @brief Gets whether buffer is contiguous. */
+    bool is_contiguous() const noexcept;
+
+    result<void> copy_from(tensor src) noexcept;
+    result<void> copy_to(tensor dest) const noexcept;
+    result<tensor> to_host() noexcept;
+
+    result<void> copy_to(value_t dest) const noexcept override;
+
+  private:
+    datatype_t dtype_;
+    dims_t shape_;
+    strides_t strides_;
+    size_t length_;
+    runtime::buffer_slice buffer_;
+};
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/type.h b/third_party/nncase/x86_64/include/nncase/type.h
new file mode 100644
index 0000000..7382328
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/type.h
@@ -0,0 +1,167 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "shape.h"
+#include <nncase/runtime/datatypes.h>
+
+namespace nncase {
+/** @brief Type node */
+class NNCASE_API type_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_type);
+
+  protected:
+    type_node() = default;
+};
+
+/** @brief Type */
+using type = object_t<type_node>;
+
+class any_type_node;
+
+/** @brief Any type */
+class any_type : public object_t<any_type_node> {
+  public:
+    using object_t::object_t;
+
+    static any_type value;
+};
+
+/** @brief Any type node */
+class NNCASE_API any_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_any_type);
+
+  public:
+};
+
+class invalid_type_node;
+
+/** @brief Invalid type */
+class invalid_type : public object_t<invalid_type_node> {
+  public:
+    using object_t::object_t;
+
+    static invalid_type value;
+};
+
+/** @brief Invalid type node */
+class NNCASE_API invalid_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_invalid_type);
+
+  public:
+    invalid_type_node() noexcept {}
+    invalid_type_node(std::string reason) noexcept
+        : reason_(std::move(reason)) {}
+
+    /** @brief Get reason */
+    const std::string &reason() const noexcept { return reason_; }
+    /** @brief Get mutable reason */
+    std::string &reason() noexcept { return reason_; }
+    /** @brief Set reason */
+    void reason(std::string value) noexcept { reason_ = std::move(value); }
+
+  private:
+    std::string reason_;
+};
+
+/** @brief Tensor type node */
+class NNCASE_API tensor_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_tensor_type);
+
+  public:
+    tensor_type_node(datatype_t dtype, shape_t shape) noexcept
+        : dtype_(std::move(dtype)), shape_(std::move(shape)) {}
+
+    /** @brief Is this a scalar type */
+    bool is_scalar() const noexcept { return shape_.is_scalar(); }
+    /** @brief Is this a tensor type */
+    bool is_tensor() const noexcept { return !shape_.is_scalar(); }
+
+    /** @brief Get element datatype */
+    datatype_t dtype() const noexcept { return dtype_; }
+    /** @brief Set element datatype */
+    void dtype(datatype_t value) noexcept { dtype_ = value; }
+
+    /** @brief Get shape */
+    const shape_t &shape() const noexcept { return shape_; }
+    /** @brief Get mutable shape */
+    shape_t &shape() noexcept { return shape_; }
+    /** @brief Set shape */
+    void shape(shape_t value) noexcept { shape_ = std::move(value); }
+
+  private:
+    datatype_t dtype_;
+    shape_t shape_;
+};
+
+/** @brief Tensor type */
+using tensor_type = object_t<tensor_type_node>;
+
+/** @brief Tuple type node */
+class NNCASE_API tuple_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_tuple_type);
+
+  public:
+    tuple_type_node(itlib::small_vector<type> fields) noexcept
+        : fields_(std::move(fields)) {}
+
+    /** @brief Get fields */
+    gsl::span<const type> fields() const noexcept { return fields_; }
+    /** @brief Get mutable fields */
+    itlib::small_vector<type> &shape() noexcept { return fields_; }
+    /** @brief Set fields */
+    void shape(itlib::small_vector<type> value) noexcept {
+        fields_ = std::move(value);
+    }
+
+  private:
+    itlib::small_vector<type> fields_;
+};
+
+/** @brief Tuple type */
+using tuple_type = object_t<tuple_type_node>;
+
+/** @brief Callable type node */
+class NNCASE_API callable_type_node : public type_node {
+    DEFINE_OBJECT_KIND(object_node, object_callable_type);
+
+  public:
+    callable_type_node(itlib::small_vector<type> parameters,
+                       type return_type) noexcept
+        : parameters_(std::move(parameters)), return_type_(return_type) {}
+
+    /** @brief Get parameters */
+    gsl::span<const type> parameters() const noexcept { return parameters_; }
+    /** @brief Get parameters */
+    itlib::small_vector<type> &parameters() noexcept { return parameters_; }
+    /** @brief Set parameters */
+    void parameters(itlib::small_vector<type> value) noexcept {
+        parameters_ = std::move(value);
+    }
+
+    /** @brief Get return type */
+    const type &return_type() const noexcept { return return_type_; }
+    /** @brief Get mutable return type */
+    type &return_type() noexcept { return return_type_; }
+    /** @brief Set return type */
+    void return_type(type value) noexcept { return_type_ = std::move(value); }
+
+  private:
+    itlib::small_vector<type> parameters_;
+    type return_type_;
+};
+
+/** @brief Callable type */
+using callable_type = object_t<callable_type_node>;
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/value.h b/third_party/nncase/x86_64/include/nncase/value.h
new file mode 100644
index 0000000..1389d08
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/value.h
@@ -0,0 +1,52 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#include "object.h"
+#include <vector>
+
+namespace nncase {
+
+class value_node;
+
+/** @brief Value */
+using value_t = object_t<value_node>;
+
+class NNCASE_API value_node : public object_node {
+    DEFINE_OBJECT_KIND(object_node, object_value);
+
+  public:
+    virtual result<void> copy_to(value_t dest) const noexcept = 0;
+};
+
+class NNCASE_API tuple_node : public value_node {
+    DEFINE_OBJECT_KIND(value_node, object_tuple);
+
+  public:
+    tuple_node() noexcept = default;
+    tuple_node(std::vector<value_t> fields) noexcept
+        : fields_(std::move(fields)) {}
+
+    gsl::span<const value_t> fields() const noexcept { return fields_; }
+    gsl::span<value_t> fields() noexcept { return fields_; }
+
+    result<void> copy_to(value_t dest) const noexcept override;
+
+  private:
+    std::vector<value_t> fields_;
+};
+
+/** @brief Tuple */
+using tuple = object_t<tuple_node>;
+} // namespace nncase
diff --git a/third_party/nncase/x86_64/include/nncase/version.h b/third_party/nncase/x86_64/include/nncase/version.h
new file mode 100644
index 0000000..000a31d
--- /dev/null
+++ b/third_party/nncase/x86_64/include/nncase/version.h
@@ -0,0 +1,17 @@
+/* Copyright 2019-2021 Canaan Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#pragma once
+#define NNCASE_VERSION "2.0.0"
+#define NNCASE_VERSION_SUFFIX "-"
diff --git a/third_party/nncase/x86_64/lib/_nncase.cpython-311-x86_64-linux-gnu.so b/third_party/nncase/x86_64/lib/_nncase.cpython-311-x86_64-linux-gnu.so
new file mode 100644
index 0000000..04dc875
Binary files /dev/null and b/third_party/nncase/x86_64/lib/_nncase.cpython-311-x86_64-linux-gnu.so differ
diff --git a/third_party/nncase/x86_64/lib/cmake/nncase/nncaseConfig.cmake b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseConfig.cmake
new file mode 100644
index 0000000..7d1a542
--- /dev/null
+++ b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseConfig.cmake
@@ -0,0 +1,3 @@
+include(${CMAKE_CURRENT_LIST_DIR}/nncaseTargets.cmake)
+find_package(gsl-lite REQUIRED)
+find_package(fmt REQUIRED)
diff --git a/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets-release.cmake b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets-release.cmake
new file mode 100644
index 0000000..b092019
--- /dev/null
+++ b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets-release.cmake
@@ -0,0 +1,19 @@
+#----------------------------------------------------------------
+# Generated CMake target import file for configuration "Release".
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Import target "nncaseruntime" for configuration "Release"
+set_property(TARGET nncaseruntime APPEND PROPERTY IMPORTED_CONFIGURATIONS RELEASE)
+set_target_properties(nncaseruntime PROPERTIES
+  IMPORTED_LOCATION_RELEASE "${_IMPORT_PREFIX}/lib/libNncase.Runtime.Native.so"
+  IMPORTED_SONAME_RELEASE "libNncase.Runtime.Native.so"
+  )
+
+list(APPEND _cmake_import_check_targets nncaseruntime )
+list(APPEND _cmake_import_check_files_for_nncaseruntime "${_IMPORT_PREFIX}/lib/libNncase.Runtime.Native.so" )
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
diff --git a/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets.cmake b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets.cmake
new file mode 100644
index 0000000..ef3b11a
--- /dev/null
+++ b/third_party/nncase/x86_64/lib/cmake/nncase/nncaseTargets.cmake
@@ -0,0 +1,116 @@
+# Generated by CMake
+
+if("${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}" LESS 2.8)
+   message(FATAL_ERROR "CMake >= 2.8.0 required")
+endif()
+if(CMAKE_VERSION VERSION_LESS "2.8.3")
+   message(FATAL_ERROR "CMake >= 2.8.3 required")
+endif()
+cmake_policy(PUSH)
+cmake_policy(VERSION 2.8.3...3.26)
+#----------------------------------------------------------------
+# Generated CMake target import file.
+#----------------------------------------------------------------
+
+# Commands may need to know the format version.
+set(CMAKE_IMPORT_FILE_VERSION 1)
+
+# Protect against multiple inclusion, which would fail when already imported targets are added once more.
+set(_cmake_targets_defined "")
+set(_cmake_targets_not_defined "")
+set(_cmake_expected_targets "")
+foreach(_cmake_expected_target IN ITEMS nncaseruntime nncasebase)
+  list(APPEND _cmake_expected_targets "${_cmake_expected_target}")
+  if(TARGET "${_cmake_expected_target}")
+    list(APPEND _cmake_targets_defined "${_cmake_expected_target}")
+  else()
+    list(APPEND _cmake_targets_not_defined "${_cmake_expected_target}")
+  endif()
+endforeach()
+unset(_cmake_expected_target)
+if(_cmake_targets_defined STREQUAL _cmake_expected_targets)
+  unset(_cmake_targets_defined)
+  unset(_cmake_targets_not_defined)
+  unset(_cmake_expected_targets)
+  unset(CMAKE_IMPORT_FILE_VERSION)
+  cmake_policy(POP)
+  return()
+endif()
+if(NOT _cmake_targets_defined STREQUAL "")
+  string(REPLACE ";" ", " _cmake_targets_defined_text "${_cmake_targets_defined}")
+  string(REPLACE ";" ", " _cmake_targets_not_defined_text "${_cmake_targets_not_defined}")
+  message(FATAL_ERROR "Some (but not all) targets in this export set were already defined.\nTargets Defined: ${_cmake_targets_defined_text}\nTargets not yet defined: ${_cmake_targets_not_defined_text}\n")
+endif()
+unset(_cmake_targets_defined)
+unset(_cmake_targets_not_defined)
+unset(_cmake_expected_targets)
+
+
+# Compute the installation prefix relative to this file.
+get_filename_component(_IMPORT_PREFIX "${CMAKE_CURRENT_LIST_FILE}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+get_filename_component(_IMPORT_PREFIX "${_IMPORT_PREFIX}" PATH)
+if(_IMPORT_PREFIX STREQUAL "/")
+  set(_IMPORT_PREFIX "")
+endif()
+
+# Create imported target nncaseruntime
+add_library(nncaseruntime SHARED IMPORTED)
+
+set_target_properties(nncaseruntime PROPERTIES
+  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
+  INTERFACE_LINK_LIBRARIES "gsl::gsl-lite"
+)
+
+# Create imported target nncasebase
+add_library(nncasebase INTERFACE IMPORTED)
+
+set_target_properties(nncasebase PROPERTIES
+  INTERFACE_COMPILE_DEFINITIONS "NNCASE_DLL;NNCASE_SIMULATOR"
+  INTERFACE_INCLUDE_DIRECTORIES "${_IMPORT_PREFIX}/include"
+  INTERFACE_LINK_LIBRARIES "gsl::gsl-lite"
+)
+
+if(CMAKE_VERSION VERSION_LESS 3.0.0)
+  message(FATAL_ERROR "This file relies on consumers using CMake 3.0.0 or greater.")
+endif()
+
+# Load information for each installed configuration.
+file(GLOB _cmake_config_files "${CMAKE_CURRENT_LIST_DIR}/nncaseTargets-*.cmake")
+foreach(_cmake_config_file IN LISTS _cmake_config_files)
+  include("${_cmake_config_file}")
+endforeach()
+unset(_cmake_config_file)
+unset(_cmake_config_files)
+
+# Cleanup temporary variables.
+set(_IMPORT_PREFIX)
+
+# Loop over all imported files and verify that they actually exist
+foreach(_cmake_target IN LISTS _cmake_import_check_targets)
+  foreach(_cmake_file IN LISTS "_cmake_import_check_files_for_${_cmake_target}")
+    if(NOT EXISTS "${_cmake_file}")
+      message(FATAL_ERROR "The imported target \"${_cmake_target}\" references the file
+   \"${_cmake_file}\"
+but this file does not exist.  Possible reasons include:
+* The file was deleted, renamed, or moved to another location.
+* An install or uninstall procedure did not complete successfully.
+* The installation package was faulty and contained
+   \"${CMAKE_CURRENT_LIST_FILE}\"
+but not all the files it references.
+")
+    endif()
+  endforeach()
+  unset(_cmake_file)
+  unset("_cmake_import_check_files_for_${_cmake_target}")
+endforeach()
+unset(_cmake_target)
+unset(_cmake_import_check_targets)
+
+# This file does not depend on other imported targets which have
+# been exported from the same project but in a separate export set.
+
+# Commands beyond this point should not need to know the version.
+set(CMAKE_IMPORT_FILE_VERSION)
+cmake_policy(POP)
diff --git a/third_party/nncase/x86_64/lib/libNncase.Runtime.Native.so b/third_party/nncase/x86_64/lib/libNncase.Runtime.Native.so
new file mode 100644
index 0000000..21e274e
Binary files /dev/null and b/third_party/nncase/x86_64/lib/libNncase.Runtime.Native.so differ
diff --git a/third_party/nncase/x86_64/lib/libnncase.simulator.k230.so b/third_party/nncase/x86_64/lib/libnncase.simulator.k230.so
new file mode 100644
index 0000000..3c38463
Binary files /dev/null and b/third_party/nncase/x86_64/lib/libnncase.simulator.k230.so differ
diff --git a/third_party/nncase/x86_64/lib/libnncase.simulator.xpu.so b/third_party/nncase/x86_64/lib/libnncase.simulator.xpu.so
new file mode 100644
index 0000000..ea6340b
Binary files /dev/null and b/third_party/nncase/x86_64/lib/libnncase.simulator.xpu.so differ
diff --git a/third_party/nncase/x86_64/python/nncase/__init__.py b/third_party/nncase/x86_64/python/nncase/__init__.py
new file mode 100644
index 0000000..cef1b15
--- /dev/null
+++ b/third_party/nncase/x86_64/python/nncase/__init__.py
@@ -0,0 +1,416 @@
+# Copyright 2019-2021 Canaan Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+"""nncase."""
+
+from __future__ import annotations
+
+import io
+import itertools
+import re
+import subprocess
+import shutil
+import os
+import sys
+import string
+import numpy as np
+from pathlib import Path
+from shutil import which
+from typing import List
+import platform
+
+os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
+import _nncase
+from _nncase import RuntimeTensor, TensorDesc, Simulator
+
+
+def _initialize():
+    compiler_path = os.getenv("NNCASE_COMPILER")
+    if not compiler_path:
+        compiler_path = os.path.join(os.path.dirname(_nncase.__file__),
+                                     "nncase", "Nncase.Compiler.dll")
+    _nncase.initialize(compiler_path)
+
+
+_initialize()
+# _nncase.launch_debugger()
+
+
+class ImportOptions:
+    def __init__(self) -> None:
+        pass
+
+
+class PTQTensorOptions:
+    use_mix_quant: bool
+    use_mse_quant_w: bool
+    export_quant_scheme: bool
+    export_weight_range_by_channel: bool
+    dump_quant_error: bool
+    dump_quant_error_symmetric_for_signed: bool
+    quant_type: str
+    w_quant_type: str
+    calibrate_method: str
+    finetune_weights_method: str
+    input_mean: float
+    input_std: float
+    quant_scheme: str
+    quant_scheme_strict_mode: bool
+    samples_count: int
+    cali_data: List[RuntimeTensor]
+
+    def __init__(self) -> None:
+        self.use_mix_quant: bool = False
+        self.use_mse_quant_w = False
+        self.export_quant_scheme: bool = False
+        self.export_weight_range_by_channel: bool = False
+        self.dump_quant_error: bool = False
+        self.dump_quant_error_symmetric_for_signed: bool = True
+        self.quant_type: str = "uint8"
+        self.w_quant_type: str = "uint8"
+        self.calibrate_method: str = "Kld"
+        self.finetune_weights_method: str = "NoFineTuneWeights"
+        self.input_mean: float = 0.5
+        self.input_std: float = 0.5
+        self.quant_scheme: str = ""
+        self.quant_scheme_strict_mode: bool = False
+        self.samples_count: int = 5
+        self.cali_data: List[RuntimeTensor] = []
+
+    def set_tensor_data(self, data: List[List[np.ndarray]]) -> None:
+        reshape_data = list(map(list, zip(*data)))
+        self.cali_data = [RuntimeTensor.from_numpy(
+            d) for d in itertools.chain.from_iterable(reshape_data)]
+
+
+class GraphEvaluator:
+    _inputs: List[RuntimeTensor]
+    _func: _nncase.Function
+    _params: _nncase.Var
+    _outputs: List[RuntimeTensor]
+
+    def __init__(self, func: _nncase.Function) -> None:
+        self._func = func
+        self._params = func.parameters
+        self._inputs = list([None] * len(self._params))
+        self._outputs = None
+
+    def get_input_tensor(self, index: int):
+        assert index < len(self._inputs)
+        tensor = self._inputs[index]
+        return tensor.to_runtime_tensor() if tensor else None
+
+    def set_input_tensor(self, index: int, value: RuntimeTensor):
+        assert index < len(self._inputs)
+        self._inputs[index] = _nncase.RTValue.from_runtime_tensor(value)
+
+    def get_output_tensor(self, index: int):
+        return self._outputs[index]
+
+    def run(self):
+        self._outputs = self._func.body.evaluate(self._params, self._inputs).to_runtime_tensors()
+
+    @ property
+    def outputs_size(self) -> int:
+        return len(self._outputs)
+
+
+class IRModule():
+    _module: _nncase.IRModule = None
+
+    def __init__(self, module: _nncase.IRModule):
+        assert module.entry != None
+        self._module = module
+
+    @ property
+    def entry(self) -> _nncase.IR.Function:
+        return self._module.entry
+
+
+class Compiler:
+    _target: _nncase.Target
+    _session: _nncase.CompileSession
+    _compiler: _nncase.Compiler
+    _compile_options: _nncase.CompileOptions
+    _quantize_options: _nncase.QuantizeOptions
+    _shape_bucket_options: _nncase.ShapeBucketOptions
+    _module: IRModule
+
+    def __init__(self, compile_options: CompileOptions) -> None:
+        self._compile_options = _nncase.CompileOptions()
+        self.__process_compile_options(compile_options)
+        self._session = _nncase.CompileSession(self._target, self._compile_options)
+        self._compiler = self._session.compiler
+        self._quantize_options = None
+        self._shape_bucket_options = _nncase.ShapeBucketOptions()
+        self.init_shape_bucket_options(compile_options)
+
+    def init_shape_bucket_options(self, compile_options: CompileOptions) -> None:
+        self._shape_bucket_options = _nncase.ShapeBucketOptions()
+        self._shape_bucket_options.segments_count = compile_options.shape_bucket_segments_count
+        self._shape_bucket_options.enable = compile_options.shape_bucket_enable
+        self._shape_bucket_options.range_info = compile_options.shape_bucket_range_info
+        self._shape_bucket_options.segments_count = compile_options.shape_bucket_segments_count
+        self._shape_bucket_options.fix_var_map = compile_options.shape_bucket_fix_var_map
+        self._compile_options.shape_bucket_options = self._shape_bucket_options
+
+    def compile(self) -> None:
+        self._compiler.compile()
+
+    @ property
+    def module(self) -> IRModule:
+        return self._module
+
+    def create_evaluator(self, stage: int) -> GraphEvaluator:
+        return GraphEvaluator(self._module.entry)
+
+    def gencode(self, stream: io.RawIOBase) -> None:
+        self._compiler.gencode(stream)
+
+    def gencode_tobytes(self) -> bytes:
+        code = io.BytesIO()
+        self.gencode(code)
+        return code.getvalue()
+
+    def import_caffe(self, model: bytes, prototxt: bytes) -> None:
+        raise NotImplementedError("import_caffe")
+
+    def import_onnx(self, model_content: bytes, options: ImportOptions) -> None:
+        self._compile_options.input_format = "onnx"
+        self._import_onnx_module(model_content)
+
+    def import_tflite(self, model_content: bytes, options: ImportOptions) -> None:
+        self._compile_options.input_format = "tflite"
+        self._import_tflite_module(model_content)
+
+    def import_ncnn(self, model_param: bytes, model_bin: bytes, options: ImportOptions) -> None:
+        self._compile_options.input_format = "ncnn"
+        self._import_ncnn_module(model_param, model_bin)
+
+    def use_ptq(self, ptq_dataset_options: PTQTensorOptions) -> None:
+        dataset = [_nncase.RTValue.from_runtime_tensor(
+            data) for data in ptq_dataset_options.cali_data]
+        provider = _nncase.CalibrationDatasetProvider(
+            dataset, ptq_dataset_options.samples_count, self._module.entry.parameters) if len(dataset) != 0 else []
+        if not self._quantize_options:
+            self._quantize_options = _nncase.QuantizeOptions()
+            self._compile_options.quantize_options = self._quantize_options
+        if len(dataset) != 0:
+            self._quantize_options.calibration_dataset = provider
+        self._quantize_options.model_quant_mode = _nncase.ModelQuantMode.UsePTQ
+
+        if (ptq_dataset_options.calibrate_method == "NoClip"):
+            self._quantize_options.calibrate_method = _nncase.CalibMethod.NoClip
+        elif (ptq_dataset_options.calibrate_method == "Kld"):
+            self._quantize_options.calibrate_method = _nncase.CalibMethod.Kld
+        else:
+            raise Exception("Unsupported Calibrate Method")
+
+        if (ptq_dataset_options.finetune_weights_method == "NoFineTuneWeights"):
+            self._quantize_options.finetune_weights_method = _nncase.FineTuneWeightsMethod.NoFineTuneWeights
+        elif (ptq_dataset_options.finetune_weights_method == "UseSquant"):
+            self._quantize_options.finetune_weights_method = _nncase.FineTuneWeightsMethod.UseSquant
+        elif (ptq_dataset_options.finetune_weights_method == "UseAdaRound"):
+            self._quantize_options.finetune_weights_method = _nncase.FineTuneWeightsMethod.UseAdaRound
+        else:
+            raise Exception("Unsupported Finetune Weights Method")
+
+        if (ptq_dataset_options.quant_type == "uint8"):
+            self._quantize_options.quant_type = _nncase.QuantType.Uint8
+        elif (ptq_dataset_options.quant_type == "int8"):
+            self._quantize_options.quant_type = _nncase.QuantType.Int8
+        elif (ptq_dataset_options.quant_type == "int16"):
+            self._quantize_options.quant_type = _nncase.QuantType.Int16
+        else:
+            raise Exception("Unsupported Quant Type")
+
+        if (ptq_dataset_options.w_quant_type == "uint8"):
+            self._quantize_options.w_quant_type = _nncase.QuantType.Uint8
+        elif (ptq_dataset_options.w_quant_type == "int8"):
+            self._quantize_options.w_quant_type = _nncase.QuantType.Int8
+        elif (ptq_dataset_options.w_quant_type == "int16"):
+            self._quantize_options.w_quant_type = _nncase.QuantType.Int16
+        else:
+            raise Exception("Unsupported Weights Quant Type")
+
+        self._quantize_options.use_mix_quant = ptq_dataset_options.use_mix_quant
+        self._quantize_options.quant_scheme = ptq_dataset_options.quant_scheme
+        self._quantize_options.quant_scheme_strict_mode = ptq_dataset_options.quant_scheme_strict_mode
+        self._quantize_options.export_quant_scheme = ptq_dataset_options.export_quant_scheme
+        self._quantize_options.export_weight_range_by_channel = ptq_dataset_options.export_weight_range_by_channel
+        self._quantize_options.dump_quant_error = ptq_dataset_options.dump_quant_error
+        self._quantize_options.dump_quant_error_symmetric_for_signed = ptq_dataset_options.dump_quant_error_symmetric_for_signed
+
+    def dump_range_options(self) -> DumpRangeTensorOptions:
+        raise NotImplementedError("dump_range_options")
+
+    def __process_compile_options(self, compile_options: CompileOptions) -> ClCompileOptions:
+        self._target = _nncase.Target(compile_options.target)
+        if compile_options.preprocess:
+            self._compile_options.preprocess = compile_options.preprocess
+            self._compile_options.swapRB = compile_options.swapRB
+            if compile_options.input_type == "uint8":
+                self._compile_options.input_type = _nncase.InputType.Uint8
+            elif compile_options.input_type == "int8":
+                self._compile_options.input_type = _nncase.InputType.Int8
+            if compile_options.input_type == "float32":
+                self._compile_options.input_type = _nncase.InputType.Float32
+            self._compile_options.input_shape = str(compile_options.input_shape)[1:-1]
+            self._compile_options.input_range = str(compile_options.input_range)[1:-1]
+            self._compile_options.mean = str(compile_options.mean)[1:-1]
+            self._compile_options.std = str(compile_options.std)[1:-1]
+            self._compile_options.input_layout = compile_options.input_layout
+            self._compile_options.output_layout = compile_options.output_layout
+            self._compile_options.letterbox_value = compile_options.letterbox_value
+
+        self._compile_options.input_file = compile_options.input_file
+        dump_flags = _nncase.DumpFlags.Nothing if not compile_options.dump_ir else _nncase.DumpFlags(
+            _nncase.DumpFlags.PassIR)
+        if (compile_options.dump_asm):
+            dump_flags = _nncase.DumpFlags(dump_flags | _nncase.DumpFlags.CodeGen)
+        self._compile_options.dump_flags = dump_flags
+        self._compile_options.dump_dir = compile_options.dump_dir
+
+    def _import_onnx_module(self, model_content: bytes | io.RawIOBase) -> None:
+        stream = io.BytesIO(model_content) if isinstance(model_content, bytes) else model_content
+        self._module = IRModule(self._compiler.import_onnx_module(stream))
+
+    def _import_tflite_module(self, model_content: bytes | io.RawIOBase) -> None:
+        stream = io.BytesIO(model_content) if isinstance(model_content, bytes) else model_content
+        self._module = IRModule(self._compiler.import_tflite_module(stream))
+
+    def _import_ncnn_module(self, model_param: bytes | io.RawIOBase, model_bin: bytes | io.RawIOBase) -> None:
+        param_stream = io.BytesIO(model_param) if isinstance(model_param, bytes) else model_param
+        bin_stream = io.BytesIO(model_bin) if isinstance(model_bin, bytes) else model_bin
+        self._module = IRModule(self._compiler.import_ncnn_module(param_stream, bin_stream))
+
+
+def check_target(target: str):
+    def test_target(target: str):
+        return target in ["cpu", "k510", "k230", "xpu"]
+
+    def target_exists(target: str):
+        return _nncase.Target.exists(target)
+
+    return test_target(target) and target_exists(target)
+
+
+class DumpRangeTensorOptions:
+    calibrate_method: str
+    samples_count: int
+
+    def set_tensor_data(self, data: bytes):
+        pass
+
+
+class CalibMethod:
+    NoClip: int = 0
+    Kld: int = 1
+    Random: int = 2
+
+
+class ModelQuantMode:
+    NoQuant: int = 0
+    UsePTQ: int = 1
+    UseQAT: int = 2
+
+
+class ClQuantizeOptions():
+    CalibrationDataset: object
+    CalibrationMethod: CalibMethod
+    BindQuantMethod: bool
+    UseSquant: bool
+    UseAdaRound: bool
+
+
+class ClCompileOptions():
+    InputFile: str
+    InputFormat: str
+    Target: str
+    DumpLevel: int
+    DumpDir: str
+    QuantType: int
+    WQuantType: int
+    OutputFile: str
+    ModelQuantMode: int
+    QuantizeOptions: ClQuantizeOptions
+    SwapRB: bool
+    InputRange: List[float]
+    InputShape: List[int]
+    InputType: str
+    Mean: List[float]
+    Std: List[float]
+    PreProcess: bool
+    InputLayout: str
+    OutputLayout: str
+    LetterBoxValue: float
+
+
+class CompileOptions:
+    target: str
+    preprocess: bool
+    swapRB: bool
+    input_type: str
+    input_shape: List[int]
+    input_range: List[float]
+    input_file: str
+    mean: List[float]
+    std: List[float]
+    input_layout: str
+    output_layout: str
+    letterbox_value: float
+    dump_asm: bool
+    dump_ir: bool
+    dump_dir: str
+    shape_bucket_enable: bool
+    shape_bucket_range_info: dict
+    shape_bucket_segments_count: int
+    shape_bucket_fix_var_map: dict
+
+    def __init__(self) -> None:
+
+        self.target = "cpu"
+        self.preprocess = False
+        self.swapRB = False
+        self.input_type = "float32"
+        self.input_shape = []
+        self.input_range = []
+        self.input_file = ""
+        self.mean = [0, 0, 0]
+        self.std = [1, 1, 1]
+        self.input_layout = ""
+        self.output_layout = ""
+        self.letterbox_value = 0
+        self.dump_asm = True
+        self.dump_ir = False
+        self.dump_dir = "tmp"
+        self.shape_bucket_enable = False
+        self.shape_bucket_range_info = {}
+        self.shape_bucket_segments_count = 2
+        self.shape_bucket_fix_var_map = {}
+
+
+class ShapeBucketOptions:
+    enable: bool
+    var_map: dict
+    range_info: dict
+    segments_count: int
+    fix_var_map: dict
+
+    def __init__(self) -> None:
+        self.enable = False
+        self.var_map = {}
+        self.range_info = {}
+        self.segments_count = 2
+        self.fix_var_map = {}
